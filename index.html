<!doctype html>



  


<html class="theme-next muse use-motion" lang="zh-Hans">
<head>
  <!-- hexo-inject:begin --><!-- hexo-inject:end --><meta charset="UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=edge" />
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"/>



<meta http-equiv="Cache-Control" content="no-transform" />
<meta http-equiv="Cache-Control" content="no-siteapp" />















  
  
  <link href="/lib/fancybox/source/jquery.fancybox.css?v=2.1.5" rel="stylesheet" type="text/css" />




  
  
  
  

  
    
    
  

  
    
      
    

    
  

  

  
    
      
    

    
  

  
    
      
    

    
  

  
    
    
    <link href="//fonts.googleapis.com/css?family=Lato:300,300italic,400,400italic,700,700italic|Roboto Slab:300,300italic,400,400italic,700,700italic|Lobster Two:300,300italic,400,400italic,700,700italic|PT Mono:300,300italic,400,400italic,700,700italic&subset=latin,latin-ext" rel="stylesheet" type="text/css">
  






<link href="/lib/font-awesome/css/font-awesome.min.css?v=4.6.2" rel="stylesheet" type="text/css" />

<link href="/css/main.css?v=5.1.0" rel="stylesheet" type="text/css" />


  <meta name="keywords" content="Hexo, NexT" />








  <link rel="shortcut icon" type="image/x-icon" href="/favicon.ico?v=5.1.0" />






<meta name="description" content="Record and Think!">
<meta property="og:type" content="website">
<meta property="og:title" content="Schwimmer&#39;s Blog">
<meta property="og:url" content="http://Schwimmer.github.io/index.html">
<meta property="og:site_name" content="Schwimmer&#39;s Blog">
<meta property="og:description" content="Record and Think!">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Schwimmer&#39;s Blog">
<meta name="twitter:description" content="Record and Think!">



<script type="text/javascript" id="hexo.configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '/',
    scheme: 'Muse',
    sidebar: {"position":"left","display":"post","offset":12,"offset_float":0,"b2t":false,"scrollpercent":false},
    fancybox: true,
    motion: true,
    duoshuo: {
      userId: '0',
      author: '博主'
    },
    algolia: {
      applicationID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    }
  };
</script>



  <link rel="canonical" href="http://Schwimmer.github.io/"/>





  <title> Schwimmer's Blog </title><!-- hexo-inject:begin --><!-- hexo-inject:end -->
</head>

<body itemscope itemtype="http://schema.org/WebPage" lang="zh-Hans">

  














  
  
    
  

  <!-- hexo-inject:begin --><!-- hexo-inject:end --><div class="container sidebar-position-left 
   page-home 
 ">
    <div class="headband"></div>

    <header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-wrapper">
  <div class="site-meta ">
    

    <div class="custom-logo-site-title">
      <a href="/"  class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">Schwimmer's Blog</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
      
        <p class="site-subtitle"></p>
      
  </div>

  <div class="site-nav-toggle">
    <button>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
    </button>
  </div>
</div>

<nav class="site-nav">
  

  
    <ul id="menu" class="menu">
      
        
        <li class="menu-item menu-item-home">
          <a href="/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-home"></i> <br />
            
            首页
          </a>
        </li>
      
        
        <li class="menu-item menu-item-archives">
          <a href="/archives" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-archive"></i> <br />
            
            归档
          </a>
        </li>
      
        
        <li class="menu-item menu-item-tags">
          <a href="/tags" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-tags"></i> <br />
            
            标签
          </a>
        </li>
      

      
    </ul>
  

  
</nav>



 </div>
    </header>

    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          <div id="content" class="content">
            
  <section id="posts" class="posts-expand">
    
      

  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">
    <link itemprop="mainEntityOfPage" href="http://Schwimmer.github.io/2018/01/25/pandas/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Schwimmer">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Schwimmer's Blog">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
            
            
              
                
                <a class="post-title-link" href="/2018/01/25/pandas/" itemprop="url">
                  未命名
                </a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2018-01-25T17:02:30+08:00">
                2018-01-25
              </time>
            

            

            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    


    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1 id="pandas"><a href="#pandas" class="headerlink" title="pandas"></a>pandas</h1><h1 id="1、DataFrame"><a href="#1、DataFrame" class="headerlink" title="1、DataFrame"></a>1、DataFrame</h1><h2 id="1-1-创建随机"><a href="#1-1-创建随机" class="headerlink" title="1.1 创建随机"></a>1.1 创建随机</h2><p>引入pandas包</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line">In [1]: import pandas as pd</div><div class="line"></div><div class="line">In [2]: import numpy as np</div><div class="line"></div><div class="line">In [3]: import matplotlib.pyplot as plt</div></pre></td></tr></table></figure>
<p>创建一个Series，pandas可以生成一个默认的索引</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">s = pd.Series([1,3,5,np.nan,6,8])</div></pre></td></tr></table></figure>
<p>通过numpy创建DataFrame，包含一个日期索引，以及标记的列</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div></pre></td><td class="code"><pre><div class="line">dates = pd.date_range(&apos;20170101&apos;, periods=6)</div><div class="line">df = pd.DataFrame(np.random.randn(6,4), index=dates, columns=list(&apos;ABCD&apos;))</div><div class="line"></div><div class="line">df</div><div class="line">Out[4]: </div><div class="line">                   A         B         C         D</div><div class="line">2016-10-10  0.630275  1.081899 -1.594402 -2.571683</div><div class="line">2016-10-11 -0.211379 -0.166089 -0.480015 -0.346706</div><div class="line">2016-10-12 -0.416171 -0.640860  0.944614 -0.756651</div><div class="line">2016-10-13  0.652248  0.186364  0.943509  0.053282</div><div class="line">2016-10-14 -0.430867 -0.494919 -0.280717 -1.327491</div><div class="line">2016-10-15  0.306519 -2.103769 -0.019832  0.035211</div></pre></td></tr></table></figure>
<p>其中，<code>np.random.randn</code>可以返回一个随机数组</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">np.random.randn(1,2)</div><div class="line"></div><div class="line">Out[11]: array([[-2.67809797,  1.49728361]])</div></pre></td></tr></table></figure>
<ul>
<li>np.random.rand  随机样本位于[0,1)中</li>
<li>np.random.randn 从标准正态分布$N=(\mu , \sigma ^2)$中返回样本，默认的范围是$N(0,1)$，等价于np.random.standard_normal</li>
</ul>
<blockquote>
<p>如果要返回2*4的$N(3,6.25)$的随机分布，可知均值是3，标准差是2.5，则</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">&gt; 3+2.5*np.random.randn(2,4)</div><div class="line">&gt;</div></pre></td></tr></table></figure>
</blockquote>
<p>如果在matlib模块中使用，则返回的是matrix而不是array</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">import</span> numpy.matlib</div><div class="line">np.matlib.randn(<span class="number">1</span>,<span class="number">2</span>)</div><div class="line"></div><div class="line">Out[<span class="number">13</span>]: matrix([[ <span class="number">0.13107513</span>, <span class="number">-0.87977247</span>]])</div></pre></td></tr></table></figure>
<h2 id="1-2-通过dict创建"><a href="#1-2-通过dict创建" class="headerlink" title="1.2 通过dict创建"></a>1.2 通过dict创建</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div></pre></td><td class="code"><pre><div class="line">df2 = pd.DataFrame(&#123; &apos;A&apos; : 1.,</div><div class="line">                     &apos;B&apos; : pd.Timestamp(&apos;20130102&apos;),</div><div class="line">                     &apos;C&apos; : pd.Series(1,index=list(range(4)),dtype=&apos;float32&apos;),</div><div class="line">                     &apos;D&apos; : np.array([3] * 4,dtype=&apos;int32&apos;),</div><div class="line">                     &apos;E&apos; : pd.Categorical([&quot;test&quot;,&quot;train&quot;,&quot;test&quot;,&quot;train&quot;]),</div><div class="line">                     &apos;F&apos; : &apos;foo&apos; &#125;)</div><div class="line">                     </div><div class="line">Out[20]: </div><div class="line">     A          B    C  D      E    F</div><div class="line">0  1.0 2013-01-02  1.0  3   test  foo</div><div class="line">1  1.0 2013-01-02  1.0  3  train  foo</div><div class="line">2  1.0 2013-01-02  1.0  3   test  foo</div><div class="line">3  1.0 2013-01-02  1.0  3  train  foo</div></pre></td></tr></table></figure>
<p>有几个方法可以构造一个Timestamp对象</p>
<ul>
<li>pd.Timestamp</li>
</ul>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div></pre></td><td class="code"><pre><div class="line">import pandas as pd</div><div class="line">from datetime import datetime as dt</div><div class="line">p1=pd.Timestamp(2017,6,19)</div><div class="line">p2=pd.Timestamp(dt(2017,6,19,hour=9,minute=13,second=45))</div><div class="line">p3=pd.Timestamp(&quot;2017-6-19 9:13:45&quot;)</div><div class="line"></div><div class="line">print(&quot;type of p1:&quot;,type(p1))</div><div class="line">print(p1)</div><div class="line">print(&quot;type of p2:&quot;,type(p2))</div><div class="line">print(p2)</div><div class="line">print(&quot;type of p3:&quot;,type(p3))</div><div class="line">print(p3)</div><div class="line"></div><div class="line"></div><div class="line">(&apos;type of p1:&apos;, &lt;class &apos;pandas.tslib.Timestamp&apos;&gt;)</div><div class="line">2017-06-19 00:00:00</div><div class="line">(&apos;type of p2:&apos;, &lt;class &apos;pandas.tslib.Timestamp&apos;&gt;)</div><div class="line">2017-06-19 09:13:45</div><div class="line">(&apos;type of p3:&apos;, &lt;class &apos;pandas.tslib.Timestamp&apos;&gt;)</div><div class="line">2017-06-19 09:13:45</div></pre></td></tr></table></figure>
<ul>
<li>to_datetime()</li>
</ul>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div></pre></td><td class="code"><pre><div class="line">import pandas as pd</div><div class="line">from datetime import datetime as dt</div><div class="line"></div><div class="line">p4=pd.to_datetime(&quot;2017-6-19 9:13:45&quot;)</div><div class="line">p5=pd.to_datetime(dt(2017,6,19,hour=9,minute=13,second=45))</div><div class="line"></div><div class="line">print(&quot;type of p4:&quot;,type(p4))</div><div class="line">print(p4)</div><div class="line">print(&quot;type of p5:&quot;,type(p5))</div><div class="line">print(p5)</div><div class="line"></div><div class="line">(&apos;type of p4:&apos;, &lt;class &apos;pandas.tslib.Timestamp&apos;&gt;)</div><div class="line">2017-06-19 09:13:45</div><div class="line">(&apos;type of p5:&apos;, &lt;class &apos;pandas.tslib.Timestamp&apos;&gt;)</div><div class="line">2017-06-19 09:13:45</div></pre></td></tr></table></figure>
<p>在df2对象中，每一列都有对应的dtypes</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div></pre></td><td class="code"><pre><div class="line">df2.dtypes</div><div class="line"></div><div class="line">Out[30]: </div><div class="line">A           float64</div><div class="line">B    datetime64[ns]</div><div class="line">C           float32</div><div class="line">D             int32</div><div class="line">E          category</div><div class="line">F            object</div><div class="line">dtype: object</div></pre></td></tr></table></figure>
<h2 id="1-3-查看数据"><a href="#1-3-查看数据" class="headerlink" title="1.3 查看数据"></a>1.3 查看数据</h2><p>参考<a href="http://pandas.pydata.org/pandas-docs/stable/basics.html#basics" target="_blank" rel="external">Basics section</a></p>
<p>查看head和tail</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">df.head(1)</div><div class="line">df.tail(3)</div></pre></td></tr></table></figure>
<p>查看index、column和数据</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">df.index</div><div class="line">df.columns</div><div class="line">df.values</div></pre></td></tr></table></figure>
<p>显示数据的快速统计</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div></pre></td><td class="code"><pre><div class="line">df.describe()</div><div class="line">Out[19]: </div><div class="line">              A         B         C         D</div><div class="line">count  6.000000  6.000000  6.000000  6.000000</div><div class="line">mean   0.073711 -0.431125 -0.687758 -0.233103</div><div class="line">std    0.843157  0.922818  0.779887  0.973118</div><div class="line">min   -0.861849 -2.104569 -1.509059 -1.135632</div><div class="line">25%   -0.611510 -0.600794 -1.368714 -1.076610</div><div class="line">50%    0.022070 -0.228039 -0.767252 -0.386188</div><div class="line">75%    0.658444  0.041933 -0.034326  0.461706</div><div class="line">max    1.212112  0.567020  0.276232  1.071804</div></pre></td></tr></table></figure>
<p>转置</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">df.T</div></pre></td></tr></table></figure>
<p>通过列名来排序</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">#对于矩阵，axis=0表示行，1表示列</div><div class="line">df.sort_index(axis=1, ascending=False)</div></pre></td></tr></table></figure>
<p>通过某一列的数值排序</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">df.sort_values(by=&apos;B&apos;)</div></pre></td></tr></table></figure>
<h2 id="1-4-选择"><a href="#1-4-选择" class="headerlink" title="1.4 选择"></a>1.4 选择</h2><p>选择某一列</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">df[&apos;A&apos;]</div></pre></td></tr></table></figure>
<p>选择某几行</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">df[0:3]</div><div class="line">#也可以通过行的索引来选择，但是不能单独写某一行</div><div class="line">df[&apos;20130102&apos;:&apos;20130104&apos;]</div></pre></td></tr></table></figure>
<h1 id="2、Series"><a href="#2、Series" class="headerlink" title="2、Series"></a>2、Series</h1><h1 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h1><p><a href="http://pandas.pydata.org/pandas-docs/stable/10min.html#minutes-to-pandas" target="_blank" rel="external">10 Minutes to pandas</a></p>
<p><a href="http://blog.csdn.net/csdn15698845876/article/details/73456967" target="_blank" rel="external">pandas中Timestamp类用法讲解</a></p>

          
        
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">
    <link itemprop="mainEntityOfPage" href="http://Schwimmer.github.io/2018/01/25/Gensim-LDA/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Schwimmer">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Schwimmer's Blog">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
            
            
              
                
                <a class="post-title-link" href="/2018/01/25/Gensim-LDA/" itemprop="url">
                  未命名
                </a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2018-01-25T17:02:30+08:00">
                2018-01-25
              </time>
            

            

            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    


    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1 id="Gensim-LDA"><a href="#Gensim-LDA" class="headerlink" title="Gensim-LDA"></a>Gensim-LDA</h1><p><a href="http://blog.csdn.net/whzhcahzxh/article/details/17528261" target="_blank" rel="external">http://blog.csdn.net/whzhcahzxh/article/details/17528261</a></p>
<p>首先，引用gensim包，gensim包中引用corpora,models, similarities，分别做语料库建立，模型库和相似度比较库，后面可以看到例子</p>
<p>from gensim import corpora, models, similarities</p>
<p>我调用了结巴分词做中文处理，所以同样</p>
<p>import jieba</p>
<p>手工写个文本列表</p>
<p>sentences = [“我喜欢吃土豆”,”土豆是个百搭的东西”,”我不喜欢今天雾霾的北京”]</p>
<p>用结巴分词后待用，因为gensim包做主题模型，在意的是语料库，所以，中文英文，one-term，two-term都是无所谓的，如果有已经生成好的语料库，那么可以考虑直接跳到建模环节</p>
<p>官方提供的语料库范例是这样的：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div></pre></td><td class="code"><pre><div class="line">corpus = [[(0, 1.0), (1, 1.0), (2, 1.0)],</div><div class="line">&gt;&gt;&gt;           [(2, 1.0), (3, 1.0), (4, 1.0), (5, 1.0), (6, 1.0), (8, 1.0)],</div><div class="line">&gt;&gt;&gt;           [(1, 1.0), (3, 1.0), (4, 1.0), (7, 1.0)],</div><div class="line">&gt;&gt;&gt;           [(0, 1.0), (4, 2.0), (7, 1.0)],</div><div class="line">&gt;&gt;&gt;           [(3, 1.0), (5, 1.0), (6, 1.0)],</div><div class="line">&gt;&gt;&gt;           [(9, 1.0)],</div><div class="line">&gt;&gt;&gt;           [(9, 1.0), (10, 1.0)],</div><div class="line">&gt;&gt;&gt;           [(9, 1.0), (10, 1.0), (11, 1.0)],</div><div class="line">&gt;&gt;&gt;           [(8, 1.0), (10, 1.0), (11, 1.0)]]</div></pre></td></tr></table></figure>
<p>每个中括号代表一句话，用逗号隔开，（0，1.0）代表词典中编号为0的词出现了一次，以此类推，很好理解</p>
<p>回到过程中来，将范例的语句分词</p>
<p>words=[]<br>for doc in sentences:<br>​    words.append(list(jieba.cut(doc)))<br>print words</p>
<p>输出：</p>
<p>[[u’\u6211’, u’\u559c\u6b22’, u’\u5403’, u’\u571f\u8c46’], [u’\u571f\u8c46’, u’\u662f’, u’\u4e2a’, u’\u767e’, u’\u642d’, u’\u7684’, u’\u4e1c\u897f’], [u’\u6211’, u’\u4e0d’, u’\u559c\u6b22’, u’\u4eca\u5929’, u’\u96fe’, u’\u973e’, u’\u7684’, u’\u5317\u4eac’]]</p>
<p>此时输出的格式为unicode，不影响后期运算，因此我保留不变，如果想看分词结果可以用循环输出jieba分词结果</p>
<p>得到的分词结果构造词典</p>
<p>dic = corpora.Dictionary(words)<br>print dic<br>print dic.token2id</p>
<p>输出：</p>
<p>Dictionary(15 unique tokens)<br>{‘\xe5\x8c\x97\xe4\xba\xac’: 12, ‘\xe6\x90\xad’: 6, ‘\xe7\x9a\x84’: 9, ‘\xe5\x96\x9c\xe6\xac\xa2’: 1, ‘\xe4\xb8\x8d’: 10, ‘\xe4\xb8\x9c\xe8\xa5\xbf’: 4, ‘\xe5\x9c\x9f\xe8\xb1\x86’: 2, ‘\xe9\x9c\xbe’: 14, ‘\xe6\x98\xaf’: 7, ‘\xe4\xb8\xaa’: 5, ‘\xe9\x9b\xbe’: 13, ‘\xe7\x99\xbe’: 8, ‘\xe4\xbb\x8a\xe5\xa4\xa9’: 11, ‘\xe6\x88\x91’: 3, ‘\xe5\x90\x83’: 0}<br>可以看到各个词或词组在字典中的编号</p>
<p>为了方便看，我给了个循环输出：</p>
<p>for word,index in dic.token2id.iteritems():<br>​    print word +” 编号为:”+ str(index)</p>
<p>输出：</p>
<p>北京 编号为:12<br>搭 编号为:6<br>的 编号为:9<br>喜欢 编号为:1<br>不 编号为:10<br>东西 编号为:4<br>土豆 编号为:2<br>霾 编号为:14<br>是 编号为:7<br>个 编号为:5<br>雾 编号为:13<br>百 编号为:8<br>今天 编号为:11<br>我 编号为:3<br>吃 编号为:0</p>
<p>为什么是乱序，我也不知道</p>
<p>词典生成好之后，就开始生成语料库了</p>
<p>corpus = [dic.doc2bow(text) for text in words]<br>print corpus</p>
<p>输出：</p>
<p>[[(0, 1), (1, 1), (2, 1), (3, 1)], [(2, 1), (4, 1), (5, 1), (6, 1), (7, 1), (8, 1), (9, 1)], [(1, 1), (3, 1), (9, 1), (10, 1), (11, 1), (12, 1), (13, 1), (14, 1)]]</p>
<p>语料库的官方描述写的是向量空间模型格式的语料库，<em>Corpus</em> is simply an object which, when iterated over, returns its documents represented as sparse vectors.</p>
<p>官方说明给了一个tips：</p>
<p>In this example, the whole corpus is stored in memory, as a Python list. However,the corpus interface only dictates that a corpus must support iteration over its constituent documents. For very large corpora, it is advantageous to keep the corpus on disk, and access its documents sequentially, one at a time. All the operations and transformations are implemented in such a way that makes them independent of the size of the corpus, memory-wise.</p>
<p>大概意思就是说范例中的语料库是存在内存中的一个列表格式，但是接口对语料库的要求只是，支持在构建文本文件中可循环即可，因此对于很大的语料库，最好还是存在硬盘上，然后依次访问文件。这样可以不用考虑语料库的size，也避免了内存占用太多</p>
<p>此时，得到了语料库，接下来做一个TF-IDF变换</p>
<p>可以理解成 将用词频向量表示一句话 变换成为用 词的重要性向量表示一句话</p>
<p>（TF-IDF变换：评估一字词对于一个文件集或一个语料库中的其中一份文件的重要程度。字词的重要性随着它在文件中出现的次数成正比增加，但同时会随着它在<a href="http://baike.baidu.com/view/686705.htm" target="_blank" rel="external">语料库</a>中出现的频率成反比下降。）</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div></pre></td><td class="code"><pre><div class="line"><span class="comment">#通过语料库得到tfidf模型</span></div><div class="line">tfidf = models.TfidfModel(corpus)</div><div class="line">vec = [(<span class="number">0</span>, <span class="number">1</span>), (<span class="number">4</span>, <span class="number">1</span>)]</div><div class="line"><span class="keyword">print</span> tfidf[vec]</div><div class="line"><span class="comment">#对corpus的每个文档中的每个词计算tfidf，得到的结果是，每个文档的每个词都是一个元组，包括id和tfidf值</span></div><div class="line">corpus_tfidf = tfidf[corpus]</div><div class="line"><span class="keyword">for</span> doc <span class="keyword">in</span> corpus_tfidf:</div><div class="line">    <span class="keyword">print</span> doc</div></pre></td></tr></table></figure>
<p>输出：</p>
<p>[(0, 0.7071067811865475), (4, 0.7071067811865475)]<br>[(0, 0.8425587958192721), (1, 0.3109633824035548), (2, 0.3109633824035548), (3, 0.3109633824035548)]<br>[(2, 0.16073253746956623), (4, 0.4355066251613605), (5, 0.4355066251613605), (6, 0.4355066251613605), (7, 0.4355066251613605), (8, 0.4355066251613605), (9, 0.16073253746956623)]<br>[(1, 0.1586956620869655), (3, 0.1586956620869655), (9, 0.1586956620869655), (10, 0.42998768831312806), (11, 0.42998768831312806), (12, 0.42998768831312806), (13, 0.42998768831312806), (14, 0.42998768831312806)]</p>
<p>vec是查询文本向量，比较vec和训练中的三句话相似度</p>
<p>index = similarities.SparseMatrixSimilarity(tfidf[corpus], num_features=14)<br>sims = index[tfidf[vec]]<br>print list(enumerate(sims))</p>
<p>输出：</p>
<p>[(0, 0.59577906), (1, 0.30794966), (2, 0.0)]</p>
<p>表示和第1句话相似度为59.578%，和第二句话的相似度位30.79%，第三句没有相似度，</p>
<p>我们看看vec这句话是什么：0为吃，4为东西，所以vec这句话可以是[“吃东西”]或者[“东西吃”]</p>
<p>而第一句话”我喜欢吃土豆”,”土豆是个百搭的东西”明显有相似度，而第三句话”我不喜欢今天雾霾的北京”，相似度几乎为0，至于为什么第一句比第二句更相似，就需要考虑TfIdf document representation和cosine similarity measure了</p>
<p>回到tfidf转换，接着训练LSI模型，假定三句话属于2个主题，</p>
<p>lsi = models.LsiModel(corpus_tfidf, id2word=dic, num_topics=2)<br>lsiout=lsi.print_topics(2)<br>print lsiout[0]<br>print lsiout[1]</p>
<p>输出：</p>
<p>0.532<em>“吃” + 0.290</em>“喜欢” + 0.290<em>“我” + 0.258</em>“土豆” + 0.253<em>“霾” + 0.253</em>“雾” + 0.253<em>“北京” + 0.253</em>“今天” + 0.253<em>“不” + 0.166</em>“东西”<br>0.393<em>“百” + 0.393</em>“搭” + 0.393<em>“东西” + 0.393</em>“是” + 0.393<em>“个” + -0.184</em>“霾” + -0.184<em>“雾” + -0.184</em>“北京” + -0.184<em>“今天” + -0.184</em>“不”</p>
<p>这就是基于SVD建立的两个主题模型内容</p>
<p>将文章投影到主题空间中</p>
<p>corpus_lsi = lsi[corpus_tfidf]<br>for doc in corpus_lsi:<br>​    print doc</p>
<p>输出：</p>
<p>[(0, -0.70861576320682107), (1, 0.1431958007198823)]<br>[(0, -0.42764142348481798), (1, -0.88527674470703799)]<br>[(0, -0.66124862582594512), (1, 0.4190711252114323)]</p>
<p>因此第一三两句和主题一相似，第二句和主题二相似</p>
<p>同理做个LDA</p>
<p>lda = models.LdaModel(corpus_tfidf, id2word=dic, num_topics=2)<br>ldaOut=lda.print_topics(2)<br>print ldaOut[0]<br>print ldaOut[1]<br>corpus_lda = lda[corpus_tfidf]<br>for doc in corpus_lda:<br>​    print doc</p>
<p>得到的结果每次都变，给一次的输出：</p>
<p>0.077<em>吃 + 0.075</em>北京 + 0.075<em>雾 + 0.074</em>今天 + 0.073<em>不 + 0.072</em>霾 + 0.070<em>喜欢 + 0.068</em>我 + 0.062<em>的 + 0.061</em>土豆<br>0.091<em>吃 + 0.073</em>搭 + 0.073<em>土豆 + 0.073</em>个 + 0.073<em>是 + 0.072</em>百 + 0.071<em>东西 + 0.066</em>我 + 0.065<em>喜欢 + 0.059</em>霾<br>[(0, 0.31271095988105352), (1, 0.68728904011894654)]<br>[(0, 0.19957991735916861), (1, 0.80042008264083142)]<br>[(0, 0.80940337254233863), (1, 0.19059662745766134)]</p>
<p>第一二句和主题二相似，第三句和主题一相似</p>
<p>结论和LSI不一样，我估计这和样本数目太少，区别度不高有关，毕竟让我来区分把第一句和哪一句分在一个主题，我也不确定</p>
<p>输入一句话，查询属于LSI得到的哪个主题类型，先建立索引：</p>
<p>index = similarities.MatrixSimilarity(lsi[corpus])<br>query = “雾霾”<br>query_bow = dic.doc2bow(list(jieba.cut(query)))<br>print query_bow<br>query_lsi = lsi[query_bow]<br>print query_lsi</p>
<p>输出:</p>
<p>[(13, 1), (14, 1)]<br>[(0, 0.50670602027401368), (1, -0.3678056037187441)]</p>
<p>与第一个主题相似</p>
<p>比较和第几句话相似，用LSI得到的索引接着做，并排序输出</p>
<p>sims = index[query_lsi]<br>print list(enumerate(sims))<br>sort_sims = sorted(enumerate(sims), key=lambda item: -item[1])<br>print sort_sims</p>
<p>输出：</p>
<p>[(0, 0.90161765), (1, -0.10271341), (2, 0.99058259)]<br>[(2, 0.99058259), (0, 0.90161765), (1, -0.10271341)]</p>
<p>可见和第二句话相似度很高，因为只有第二句话出现了雾霾两个词，可是惊讶的是和第一句话的相似度也很高，这得益于LSI模型的算法：<strong>在A和C共现，B和C共现的同时，可以找到A和B的相似度</strong></p>
<h1 id="Gensim-Tutorials"><a href="#Gensim-Tutorials" class="headerlink" title="Gensim-Tutorials"></a>Gensim-Tutorials</h1><p><a href="http://radimrehurek.com/gensim/tutorial.html" target="_blank" rel="external">http://radimrehurek.com/gensim/tutorial.html</a></p>
<p>Gensim 使用Python标准logging模块来记录log，使用方法是</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">import logging</div><div class="line">logging.basicConfig(format=&apos;%(asctime)s : %(levelname)s : %(message)s&apos;, level=logging.INFO)</div></pre></td></tr></table></figure>
<h1 id="快速示例"><a href="#快速示例" class="headerlink" title="快速示例"></a>快速示例</h1>
          
        
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">
    <link itemprop="mainEntityOfPage" href="http://Schwimmer.github.io/2018/01/25/网页中可以提取什么/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Schwimmer">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Schwimmer's Blog">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
            
            
              
                
                <a class="post-title-link" href="/2018/01/25/网页中可以提取什么/" itemprop="url">
                  未命名
                </a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2018-01-25T17:02:30+08:00">
                2018-01-25
              </time>
            

            

            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    


    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <hr>
<h2 id="网页中可以提取什么"><a href="#网页中可以提取什么" class="headerlink" title="网页中可以提取什么"></a>网页中可以提取什么</h2>
          
        
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">
    <link itemprop="mainEntityOfPage" href="http://Schwimmer.github.io/2018/01/25/OpenRTB笔记/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Schwimmer">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Schwimmer's Blog">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
            
            
              
                
                <a class="post-title-link" href="/2018/01/25/OpenRTB笔记/" itemprop="url">
                  未命名
                </a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2018-01-25T17:02:30+08:00">
                2018-01-25
              </time>
            

            

            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    


    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <hr>
<h2 id="OpenRTB笔记"><a href="#OpenRTB笔记" class="headerlink" title="OpenRTB笔记"></a>OpenRTB笔记</h2><p><a href="https://github.com/leeowenowen/OpenRTB" target="_blank" rel="external">文档的中文翻译</a></p>
<p>1 术语</p>
<table>
<thead>
<tr>
<th>名称</th>
<th>解释</th>
</tr>
</thead>
<tbody>
<tr>
<td>Seat</td>
<td>期望获取展示并使用竞拍者代表他们进行竞拍的实体</td>
</tr>
<tr>
<td>Publisher</td>
<td>操作一个或者多个网站的实体</td>
</tr>
<tr>
<td>Site</td>
<td>如果没有特殊说明，指的是一个支持广告内容的网页或者应用</td>
</tr>
<tr>
<td>Deal ID</td>
<td>标识在特定场景下Publisher与Seat之间预先安排用于购买展示的协议</td>
</tr>
</tbody>
</table>
<p>2、对象模型</p>
<p>2.1 BidRequest</p>
<p>在它的直属子对象中，只有<code>Imp</code>是技术上必须的，因为它是描述一次展示的基础信息，必须使用<code>Banner</code>, <code>Video</code>以及<code>Native</code>中的至少一个来定义展示的类型（例如， 无论一个或者多个展示者想要接收；尽管一次竞价是这些指明类型中的明确的一种）。一个展示对象可能包含一组私有市场。</p>
<p><img src="https://raw.githubusercontent.com/leeowenowen/OpenRTB_API_Specification-/master/res/bid_request_object_model.png" alt=""></p>
<h1 id="iAB标签体系"><a href="#iAB标签体系" class="headerlink" title="iAB标签体系"></a>iAB标签体系</h1>
          
        
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">
    <link itemprop="mainEntityOfPage" href="http://Schwimmer.github.io/2018/01/25/gensim处理中文word2vec/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Schwimmer">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Schwimmer's Blog">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
            
            
              
                
                <a class="post-title-link" href="/2018/01/25/gensim处理中文word2vec/" itemprop="url">
                  未命名
                </a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2018-01-25T17:02:30+08:00">
                2018-01-25
              </time>
            

            

            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    


    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1 id="gensim处理中文word2vec"><a href="#gensim处理中文word2vec" class="headerlink" title="gensim处理中文word2vec"></a>gensim处理中文word2vec</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">from</span> gensim.models <span class="keyword">import</span> KeyedVectors  </div><div class="line"></div><div class="line">model = KeyedVectors.load_word2vec_format(<span class="string">'/home/david/00projects/00user-gene/model_20150427'</span>, binary=<span class="keyword">True</span>)  </div><div class="line">a = model.similarity(<span class="string">'refreshed'</span>, <span class="string">'Refreshed'</span>)</div></pre></td></tr></table></figure>
<p>这是用中文训练出来的模型，会报错</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">UnicodeDecodeError: &apos;utf8&apos; codec can&apos;t decode byte 0x9b in position 2: invalid start byte</div></pre></td></tr></table></figure>
<p>官网的FAQ是这样的</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div></pre></td><td class="code"><pre><div class="line">Q10: Loading a word2vec model fails with UnicodeDecodeError: &apos;utf-8&apos; codec can&apos;t decode bytes in position ...</div><div class="line"></div><div class="line">A: The strings (words) stored in your model are not valid utf8. By default, gensim decodes the words using the strict encoding settings, which results in the above exception whenever an invalid utf8 sequence is encountered.</div><div class="line"></div><div class="line">The fix is on your side and it is to either:</div><div class="line"></div><div class="line">a) Store your model using a program that understands unicode and utf8 (such as gensim). Some C and Java word2vec tools are known to truncate the strings at byte boundaries, which can result in cutting a multi-byte utf8 character in half, making it non-valid utf8, leading to this error.</div><div class="line"></div><div class="line">b) Set the unicode_errors flag when running load_word2vec_model, e.g. load_word2vec_model(..., unicode_errors=&apos;ignore&apos;). Note that this silences the error, but the utf8 problem is still there -- invalid utf8 characters will just be ignored in this case.</div></pre></td></tr></table></figure>
<p>然并卵。</p>

          
        
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">
    <link itemprop="mainEntityOfPage" href="http://Schwimmer.github.io/2018/01/25/中文文本聚类/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Schwimmer">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Schwimmer's Blog">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
            
            
              
                
                <a class="post-title-link" href="/2018/01/25/中文文本聚类/" itemprop="url">
                  未命名
                </a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2018-01-25T17:02:30+08:00">
                2018-01-25
              </time>
            

            

            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    


    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <hr>
<hr>
<h1 id="中文文本聚类"><a href="#中文文本聚类" class="headerlink" title="中文文本聚类"></a>中文文本聚类</h1><p>1、处理掉英文、数字、字符等，只保留中文</p>

          
        
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">
    <link itemprop="mainEntityOfPage" href="http://Schwimmer.github.io/2018/01/25/机器学习笔记-最大熵/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Schwimmer">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Schwimmer's Blog">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
            
            
              
                
                <a class="post-title-link" href="/2018/01/25/机器学习笔记-最大熵/" itemprop="url">
                  未命名
                </a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2018-01-25T17:02:30+08:00">
                2018-01-25
              </time>
            

            

            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    


    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1 id="机器学习笔记-最大熵"><a href="#机器学习笔记-最大熵" class="headerlink" title="机器学习笔记-最大熵"></a>机器学习笔记-最大熵</h1><h1 id="1、最大熵原理"><a href="#1、最大熵原理" class="headerlink" title="1、最大熵原理"></a>1、最大熵原理</h1><p>日常生活中，很多事情的发生表现出一定的随机性，试验的结果往往是不确定的，也不知道这个随机现象所服从的概率分布。<strong>最大熵的实质</strong>就是，在已知部分知识的前提下，关于未知分布最合理的推断就是符合已知知识最不确定或者最随机的推断。任何其他的选择都意味着我们增加了其他的约束和假设。</p>
<p>将最大熵应用到分类，就是最大熵模型。给定一个训练集：<br>$$<br>T = \{  (x_1,y_1),  (x_2,y_2),…, (x_N,y_N)\}<br>$$<br>其中$x_i \in X$是输入，$y_i \in Y$是输出，X和Y表示输入和输出空间。N为样本数。<strong>目标是</strong>，利用最大熵原理选出一个最好的分类模型，即对于任意给定的输入$x \in X$，可以以概率$p(y|x)$输出$y \in Y$ 。</p>
<p>按照最大熵原理，应该<strong>优先保证模型满足已知的所有约束</strong>。思路是，从训练数据T中抽取若干有用的特征，要求这些特征在T上关于经验分布$\tilde{p}(x,y)$的数学期望与它们在模型中关于$p(x,y)$的数学期望相等。这样，一个特征就是一个约束了。</p>
<p>这里就涉及到，<strong>特征如何刻画？经验分布如何表示？</strong></p>
<h1 id="2、特征函数"><a href="#2、特征函数" class="headerlink" title="2、特征函数"></a>2、特征函数</h1><p>假设通过特征选择，抽取若干特征。特征通常由特征函数来表示。例如<br>$$<br>f(x,y) =\left\{\begin{matrix}<br>\begin{aligned}<br>&amp; 1，若x,y满足某个事实 \ <br>&amp; 0，否则<br>\end{aligned}<br>\end{matrix}\right.<br>$$<br>这里的特征不是指输入的某个特征，而是指输入和输出共同的特征。</p>
<blockquote>
<p>例如，假设我们需要判断“打”是动词还是量词，已知的训练数据有</p>
<p>(x1,y1)=(一打火柴，量词);</p>
<p>(x2,y2)=(三打啤酒，量词);</p>
<p>(x3,y3)=(打电话，动词);</p>
<p>(x4,y4)=(打篮球，动词);</p>
<p>通过观察，发现“打”前面是数字时，是量词，“打”后面是名词时，是动词。这就是从训练数据中提取的两个特征，可分别用特征函数表示为</p>
</blockquote>
<h1 id="3、经验分布"><a href="#3、经验分布" class="headerlink" title="3、经验分布"></a>3、经验分布</h1><p>经验（概率）分布就是通过对训练集T进行统计得到的分布，用$\tilde p$表示。这里列举两个经验分布<br>$$<br>\tilde p(x,y) = \frac {count(x,y)} {N} , \tilde p(x)=\frac {count(x)} {N}<br>$$<br>其中，count表示出现的次数。</p>
<h1 id="4、约束条件"><a href="#4、约束条件" class="headerlink" title="4、约束条件"></a>4、约束条件</h1><p>对于任意一个特征函数f，$E_{\tilde p}f$ 表示f在训练数据T上关于$\tilde p(x,y)$的数学期望， $E_{p}f$ 表示f在训练数据T上关于$p(x,y)$的数学期望。按照期望的定义，我们有<br>$$<br>E_{\tilde p}f=\sum_{x,y}\tilde p(x,y)f(x,y)<br>$$</p>
<p>$$<br>E_{ p}f=\sum_{x,y} p(x,y)f(x,y)<br>$$</p>
<p>其中，p(x,y)是未知的，而建模的目标是生成$p(y|x)$，因此，根据Bayes定理，$p(x,y)=p(x)p(y|x)$。在样本数量足够的条件下，$p(x)$可以用$\tilde p(x)$近似表示。这样<br>$$<br>E_{ p}f=\sum_{x,y} \tilde p(x)p(y|x)f(x,y)<br>$$<br>对于概率分布$p(y|x)$，我们希望特征f的期望值应该和从训练集中得到的特征期望值是一致的，因此，<strong>增加约束</strong><br>$$<br>E_{ p}f=E_{\tilde p}f<br>$$<br>假设我们从训练集中抽取了n个特征，相应的，便有n个特征函数$f_i(i=1,2,…,n)$以及n个约束条件<br>$$<br>C_i:E_{ p}(f_i)=E_{\tilde p}(f_i) \tag {3-1}<br>$$</p>
<blockquote>
<p>关于约束条件的几何解释</p>
<p><img src="/2018/01/25/机器学习笔记-最大熵/home/david/00projects/00markdown/public_for_git/Algorithm/机器学习笔记-最大熵/最大熵1.png" alt="最大熵1"></p>
<p>（a）：P是所有可能的概率空间，此时没有约束条件，所有的概率模型$p(y|x)$都是允许的；</p>
<p>（b）：增加了一个线性约束条件$C_1$，此时，目标分布$p(y|x)$只能落在由$C_1$定义的线段上；</p>
<p>（c）：在（b）的基础上增加了另一个约束条件$C_2$ ，且$C_1 \cap C_2  \neq \varnothing$。此时，目标分布只能落在交点上，即被唯一确定；</p>
<p>（d）：在（b）基础上增加了另一个约束$C_3$，且$C_1 \cap C_2  = \varnothing$，此时不存在能够同时满足$C_1$和$C_3$的$p(y|x)$。</p>
</blockquote>
<p>利用（3-1）定义的约束条件，我们定义P的一个子空间<br>$$<br>C=\{p \in P | E_p(f_i)={\tau}_i, i=1,2,…,n\}<br>$$</p>
<h1 id="5、最大熵模型"><a href="#5、最大熵模型" class="headerlink" title="5、最大熵模型"></a>5、最大熵模型</h1><p>由于我们的目标是获得一个条件分布，因此这里也采用相应的条件熵<br>$$<br>H(p(y|x))=-\sum_{x,y} \tilde p(x)p(y|x)\log p(y|x)<br>$$<br>可以看出这里也是用$\tilde p(x)$来近似$p(x)$。以下将$H(p(y|x))$简记为$H(p)$。至此，可以给出最大熵模型的完整描述。</p>
<p>对于给定的训练集T，特征函数$f_i(x,y), i=1,2,…n$，最大熵模型就是求解<br>$$<br>\underset {p \in C} {max}    H(p) = \begin{pmatrix}<br>-\sum_{x,y} \tilde p(x)p(y|x)\log p(y|x)<br>\end{pmatrix}, \\<br>s.t. \sum_y p(y|x)=1 \tag {5-1} \\<br>s.t.  C=\{p \in P | E_p(f_i)={\tau}_i, i=1,2,…,n\}<br>$$<br>其中的s.t.是为了保证$p(y|x)$是一个（合法的）条件概率分布。</p>
<p>等价于一个求极小值问题<br>$$<br>\underset {p \in C} {min}    -H(p) = \begin{pmatrix}<br>\sum_{x,y} \tilde p(x)p(y|x)\log p(y|x)<br>\end{pmatrix}, \\<br>s.t. \sum_y p(y|x)=1 \tag {5-2} \\<br>s.t.  C=\{p \in P | E_p(f_i)={\tau}_i, i=1,2,…,n\}<br>$$</p>
<h1 id="6、模型求解"><a href="#6、模型求解" class="headerlink" title="6、模型求解"></a>6、模型求解</h1><p>对于5-1的求解，主要思路和步骤如下：</p>
<ol>
<li>利用Lagrange乘子将最大熵模型由一个带约束的最优化问题转为无约束的最优化问题，这是一个<strong>极小极大问题（min max）</strong>。</li>
<li>利用对偶问题等价性，转化为求解上一步得到的极大/极小问题的对偶问题，也是一个极大极小问题。</li>
</ol>
<h2 id="6-1-原始问题和对偶问题"><a href="#6-1-原始问题和对偶问题" class="headerlink" title="6.1 原始问题和对偶问题"></a>6.1 原始问题和对偶问题</h2><p>根据（5-2），引入拉格朗日乘子$\lambda=(\lambda_0,\lambda_1,…,\lambda_n)^T$，定义拉格朗日函数<br>$$<br>L(p,\lambda) = -H(p) + \lambda_0(1-\sum_y p(y|x))+\sum_{i=1}^n\lambda_i(\tau_i-E_p(f_i))  \tag{6-1}<br>$$<br>利用对偶性，求解（6-1）的<strong>原始问题</strong>表示为：<br>$$<br>\underset {p \in C} {min}  \underset {\lambda} {max} L(p,\lambda) \tag{6-2}<br>$$<br><strong>对偶问题</strong>为：<br>$$<br>\underset {\lambda} {max} \underset {p \in C} {min}  L(p,\lambda) \tag{6-3}<br>$$<br>由于$H(p)$是关于p的凸函数，因此要求解最大熵模型，只需求解对偶问题（6-3）即可。</p>
<h3 id="6-1-1-指数形式的解"><a href="#6-1-1-指数形式的解" class="headerlink" title="6.1.1 指数形式的解"></a>6.1.1 指数形式的解</h3><p>首先求解内部的极小问题。由于$\underset {p \in C} {min}  L(p,\lambda)$是关于$\lambda$的函数，将其记做：<br>$$<br>\Psi (\lambda) =\underset {p \in C} {min}  L(p,\lambda) = L(p_{\lambda}, \lambda) \tag {6-4}<br>$$<br>其中<br>$$<br>p_{\lambda}=\underset {p \in C} {argmin} L(p,\lambda)=p_{\lambda}(y|x) \tag {6-5}<br>$$<br>根据拉格朗日乘子法，求$L(p,\lambda)$对$p(y|x)$的偏导，得（求解过程略）：<br>$$<br>p_{\lambda}=\frac {1} {Z_{\lambda}(x)}  \exp(\sum_{i=1}^n \lambda_i f_i(x,y)) \tag{6-6}<br>$$<br>其中，<br>$$<br>Z_{\lambda}(x)=\sum_y \exp(\sum_{i=1}^n \lambda_i f_i(x,y)) \tag{6-7}<br>$$<br>称为<strong>规范化因子</strong>（normalizing factor）。注意，此时已经没有$\lambda_0$了。</p>
<p>由（6-6）定义的$p_{\lambda}$就是最大熵模型的解，它具有<strong>指数形式</strong>。其中，$\lambda_i$就是特征$f_i$的权重，越大表示特征越重要。</p>
<h3 id="6-1-2-最大似然估计"><a href="#6-1-2-最大似然估计" class="headerlink" title="6.1.2 最大似然估计"></a>6.1.2 最大似然估计</h3><p>得到对偶问题的内层极小值问题的解之后，接着求解外层的极大值问题$\underset {\lambda} {max}  \Psi(\lambda)$。</p>
<p>设其解为<br>$$<br>\lambda^<em> = \underset {\lambda} {argmax}  \Psi(\lambda) \tag{6-8}<br>$$<br>则最大熵模型的解为<br>$$<br>p^</em>=p_{\lambda^*} \tag{6-9}<br>$$</p>
<p>根据推导，最大化$\Psi(\lambda)$与最大似然估计是等价的！</p>
<h1 id="7、最优化方法"><a href="#7、最优化方法" class="headerlink" title="7、最优化方法"></a>7、最优化方法</h1><p>通用的方法有梯度下降，拟牛顿法等，最大熵模型有两个量身定做的方法：通用迭代尺度法（Generalized Iterative Scaling，GIS）和改进的迭代尺度法（Impoved Iterative Scaling，IIS）。</p>
<h2 id="7-1-GIS算法"><a href="#7-1-GIS算法" class="headerlink" title="7.1 GIS算法"></a>7.1 GIS算法</h2><blockquote>
<p>算法1：</p>
<p>S1：初始化参数，令$\lambda=0$</p>
<p>S2：计算$E_{\tilde p}(f_i), i=1,2,…,n$</p>
<p>S3：执行一次迭代，对参数做一次刷新。</p>
<p>​    计算$E_{p_{\lambda}}(f_i)$</p>
<p>​    FOR i=1,2,…,n DO {</p>
<p>​        $\lambda_i  +=  \eta \log\frac {E_{\tilde p}(f_i)} {E_{p_{\lambda}}(f_i)}$</p>
<p>​    }</p>
<p>S4：检查是否收敛，若未收敛则继续S3</p>
</blockquote>
<p>其中，$\eta$是学习率，在实际中取$\frac {1} {C}$，$$，表示训练数据中包含特征最多的那个样本所包含的特征个数。<br>$$<br>\Delta\lambda_i=\eta \log\frac {E_{\tilde p}(f_i)} {E_{p_{\lambda}}(f_i)}<br>$$<br>是校正量。</p>
<p>每次迭代，先用当前的权重估算每个特征$f_i$在训练数据中的概率分布的期望，然后逐个与相应的经验分布的期望比较，其偏差程度通过$\log\frac {E_{\tilde p}(f_i)} {E_{p_{\lambda}}(f_i)}$来进行刻画。</p>
<p>收敛条件就是当两次迭代的$\lambda$在一个较小的范围。</p>
<p>GIS每次迭代时间很长，不太稳定，容易溢出，一般不会使用。</p>
<h2 id="7-2-IIS算法"><a href="#7-2-IIS算法" class="headerlink" title="7.2 IIS算法"></a>7.2 IIS算法</h2><p>与GIS的不同主要在$\Delta\lambda_i$的计算上。IIS通过求解方程<br>$$<br>\sum_{x,y} \tilde p(x)p(y|x)f_i(x,y)\exp(\Delta\lambda_i\sum_{i=1}^nf_i(x,y))=\tilde p(f_i)<br>$$<br>1）若$\sum_{i=1}^nf_i(x,y)$为常数，即对任意样本(x,y)，都有$\sum_{i=1}^nf_i(x,y)=C$，则<br>$$<br>\Delta\lambda_i=\frac {1} {C} \log\frac {E_{\tilde p}(f_i)} {E_{p_{\lambda}}(f_i)}<br>$$<br>此时，IIS可以看做是GIS的一种推广。</p>
<p>2）若$\sum_{i=1}^nf_i(x,y)$不是常数，则需要通过数值方式来求解$\Delta\lambda_i$，如牛顿法。</p>
<h1 id="8、优缺点"><a href="#8、优缺点" class="headerlink" title="8、优缺点"></a>8、优缺点</h1><p>优点是：在建模时，只需要集中精力选取特征，不需要花费精力考虑如何使用这些特征，可以灵活使用不同类型的特征。</p>
<p>缺点是计算量大。</p>
<p>参考</p>
<p>【1】 <a href="http://blog.csdn.net/itplus/article/details/26550273" target="_blank" rel="external">最大熵学习笔记</a></p>
<p>【2】统计学习方法</p>

          
        
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">
    <link itemprop="mainEntityOfPage" href="http://Schwimmer.github.io/2017/11/09/Python编码问题/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Schwimmer">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Schwimmer's Blog">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
            
            
              
                
                <a class="post-title-link" href="/2017/11/09/Python编码问题/" itemprop="url">
                  Python编码问题
                </a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2017-11-09T15:51:07+08:00">
                2017-11-09
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/python/" itemprop="url" rel="index">
                    <span itemprop="name">python</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    


    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1 id="Python编码问题"><a href="#Python编码问题" class="headerlink" title="Python编码问题"></a>Python编码问题</h1><p>困扰了很长时间的问题，找到一篇解释不错的文章，转载并整理之。</p>
<p><a href="http://www.jianshu.com/p/5017d8342dd2" target="_blank" rel="external">‘ascii’ codec can’t decode byte 0xe4 in position 0: ordinal not in range(128)</a></p>
<p><strong>python的编码是<code>unicode -&gt; str</code>，解码是<code>str -&gt; unicode</code></strong></p>
<p>关于文件开头的”编码指示”，也就是<code>-*- coding: -*-</code>这个语句。Python 默认脚本文件都是 UTF-8 编码的，当文件中有非 UTF-8 编码范围内的字符的时候就要使用”编码指示”来修正. 关于 sys.defaultencoding，这个在解码没有明确指明解码方式的时候使用。比如我有如下代码：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line">#! /usr/bin/env python   </div><div class="line"># -*- coding: utf-8 -*-   </div><div class="line">s = &apos;中文&apos;  # 注意这里的 str 是 str 类型的，而不是 unicode   </div><div class="line">s.encode(&apos;gb18030&apos;)</div></pre></td></tr></table></figure>
<p>这句代码将 s 重新编码为<code>gb18030</code>的格式，即进行<code>unicode -&gt; str</code>的转换。因为 s 本身就是 str类型的，因此 Python 会自动的先将 s 解码为<code>unicode</code>，然后再编码成 <code>gb18030</code>。因为解码是python自动进行的，我们没有指明解码方式，python 就会使用<code>sys.defaultencoding</code>指明的方式来解码。很多情况下 <code>sys.defaultencoding</code> 是<code>ANSCII</code>，如果 s 不是这个类型就会出错。</p>
<p>拿上面的情况来说，我的 <code>sys.defaultencoding</code>是<code>anscii</code>，而 s 的编码方式和文件的编码方式一致，是 utf8 的，所以出错了:<code>UnicodeDecodeError: &#39;ascii&#39; codec can&#39;t decode byte 0xe4 in position 0: ordinal not in range(128)</code> </p>
<h2 id="Unicode和UTF8的区别"><a href="#Unicode和UTF8的区别" class="headerlink" title="Unicode和UTF8的区别"></a>Unicode和UTF8的区别</h2><ol>
<li><p><code>unicode</code>指的是万国码，是一种“字码表”。而utf-8是这种字码表储存的编码方法。unicode不一定要由utf-8这种方式编成<code>bytecode</code>储存，也可以使用utf-16,utf-7等其他方式。目前大多都以utf-8的方式来变成<code>bytecode</code>。</p>
</li>
<li><p><code>python</code>中字符串类型分为<code>byte string</code> 和<code>unicode string</code>两种。</p>
</li>
<li><p>如果在python文件中指定编码方式为<code>utf-8(#coding=utf-8)</code>，那么所有带中文的字符串都会被认为是utf-8编码的byte string（例如：mystr=”你好”），但是在函数中所产生的字符串则被认为是unicode string<br>问题就出在这边，unicode string 和byte string是不可以混合使用的，一旦混合使用了，就会产生这样的错误。例如：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">self.response.out.write(&quot;你好&quot;+self.request.get(&quot;argu&quot;))</div></pre></td></tr></table></figure>
<p>​</p>
</li>
</ol>
<p><strong>以下有两个解决方法：</strong>      </p>
<ul>
<li><p>第一种,是明确的指示出 s 的编码方式 </p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line">#! /usr/bin/env python </div><div class="line"># -*- coding: utf-8 -*- </div><div class="line">s = &apos;中文&apos; </div><div class="line">s.decode(&apos;utf-8&apos;).encode(&apos;gb18030&apos;)</div></pre></td></tr></table></figure>
</li>
<li><p>第二种,更改<code>sys.defaultencoding</code>为文件的编码方式 </p>
</li>
</ul>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line">#! /usr/bin/env python </div><div class="line"># -*- coding: utf-8 -*- </div><div class="line">import sys #要重新载入sys。因为 Python 初始化后会删除 sys.setdefaultencoding 这个方 法</div><div class="line">reload(sys) </div><div class="line">sys.setdefaultencoding(&apos;utf-8&apos;)</div></pre></td></tr></table></figure>

          
        
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">
    <link itemprop="mainEntityOfPage" href="http://Schwimmer.github.io/2017/07/12/人群地理信息分析/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Schwimmer">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Schwimmer's Blog">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
            
            
              
                
                <a class="post-title-link" href="/2017/07/12/人群地理信息分析/" itemprop="url">
                  人群地理信息分析
                </a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2017-07-12T11:49:53+08:00">
                2017-07-12
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/算法/" itemprop="url" rel="index">
                    <span itemprop="name">算法</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    


    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>数据源</p>
<p>移动端的request中</p>

          
        
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">
    <link itemprop="mainEntityOfPage" href="http://Schwimmer.github.io/2017/07/12/浅谈在线最优化求解算法-以CTR预测模型为例/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Schwimmer">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Schwimmer's Blog">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
            
            
              
                
                <a class="post-title-link" href="/2017/07/12/浅谈在线最优化求解算法-以CTR预测模型为例/" itemprop="url">
                  浅谈在线最优化求解算法-以CTR预测模型为例
                </a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2017-07-12T11:49:53+08:00">
                2017-07-12
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/机器学习算法推导/" itemprop="url" rel="index">
                    <span itemprop="name">机器学习算法推导</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    


    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>[TOC]</p>
<h1 id="1、最优化求解问题"><a href="#1、最优化求解问题" class="headerlink" title="1、最优化求解问题"></a>1、最优化求解问题</h1><p>通常，我们需要求解的最优化问题有如下三类：</p>
<p><strong>（1）无约束优化问题</strong>：<br>$$<br>X=\arg \underset{X}{min}f(X)<br>$$<br>含义是求解X，令目标函数$f(X)$最小。</p>
<p>对于这类问题，在$f(X)$ 是凸函数的前提下，通常做法就是对$f(X)$ 求导，并令$\frac {\partial} {\partial X} f(X) =0$ ，求解可以得到最优值。</p>
<blockquote>
<p> <strong>凸函数</strong></p>
<p> 如果$f(x)$是定义在N维向量空间上的实变量函数，对于在$f(x)$的定义域C上的任意两个点$x_1$和$x_2$，以及任意[0,1]之间的值t都有：<br> $$<br> f(tX_1 + (1-t)X_2) \leq tf(X_1)+(1-t)f(X_2)\\<br> \forall X_1,X_2 \in C,  0 \leq t \leq 1<br> $$<br> 则称$f(x)$是凸函数。一个函数是凸函数是其存在最优解的充要条件。</p>
<p> 此外，如果$f(x)$满足<br> $$<br> f(tX_1 + (1-t)X_2)&lt; tf(X_1)+(1-t)f(X_2)\\<br> \forall X_1,X_2 \in C,  0 \leq t \leq 1<br> $$<br> 则$f(x)$为严格凸函数。如下图所示，左边是严格凸函数，右边是凸函数</p>
<p> <img src="/2017/07/12/浅谈在线最优化求解算法-以CTR预测模型为例/凸函数.png" alt="凸函数"></p>
</blockquote>
<p><strong>（2）有等式约束的最优化问题</strong>：<br>$$<br>X=\arg \underset{X}{min}f(X)\\<br>s.t. h_k(X)=0;k=1,2,…,n<br>$$<br>含义是在n个等式约束$h_k(X)$ 的条件下求解X，另目标函数$f(X)$最小。</p>
<p>针对有等式的最优化问题，采用<strong>拉格朗日乘数法</strong>进行求解，通过拉格朗日系数$A=[a_1,a_2,…,a_n]^T$ 把等式约束和目标函数组合成一个式子<br>$$<br>X=\arg \underset{X}{min}[f(X)+ A^TH(X)]<br>$$<br>相当于转化成无约束最优化求解问题，解决方法是分别对X，A求偏导并令其等于0。</p>
<p><strong>（3）不等式约束的优化问题求解</strong> ：<br>$$<br>X=\arg \underset{X}{min}f(X)\\<br>s.t. h_k(X)=0;k=1,2,…,n\\<br>g_l(X)\leq 0;l=1,2,…,m<br>$$</p>
<p>对于不等式约束，通过KKT条件求解。将所有的约束和目标函数写为一个式子<br>$$<br>L(X,A,B)=f(X)+A^TH(X)+B^TG(X)<br>$$<br>KKT条件是说最优值必须满足以下条件：<br>$$<br>\frac \partial {\partial X} L(X,A,B)=0\\<br>H(X)=0\\<br>B^TG(X)=0<br>$$<br>KKT条件是求解最优值的必要条件，要使其成为充要条件，还需要f(x)为凸函数。</p>
<h1 id="2、批量最优化求解算法"><a href="#2、批量最优化求解算法" class="headerlink" title="2、批量最优化求解算法"></a>2、批量最优化求解算法</h1><p>一些定义：</p>
<p>$i=1,2,…,N$表示向量维度</p>
<p>$j=1,2,…,M$表示样本个数</p>
<p>$t=1,2,…$表示迭代次数</p>
<h2 id="2-1-批量和随机求解"><a href="#2-1-批量和随机求解" class="headerlink" title="2.1 批量和随机求解"></a>2.1 批量和随机求解</h2><p>我们面对的最优化问题都是无约束的最优化问题（有约束的也可以转成无约束的），因此通常可以将其描述为<br>$$<br>W=\arg \underset{W}{min}   l(W,Z)\\<br>Z=\{ (X_j,y_j) | j=1,2,…,M  \}\\<br>y_j=h(W,X_j)<br>\tag {2-1-1}<br>$$<br>就是<strong>在已知训练集的情况下，求使得目标函数最小的权重矩阵</strong>。其中，$Z$是训练集，$\mathbf{X}$是特征向量，$X_j$是其中一个样本，$Y$是预测值，$y_j$是其中一个样本对应的预测值。一共有M个样本。$h(W,X_j)$ 是特征向量到预测值的<strong>映射函数</strong>，$ l(W,Z)$ 最优化求解的目标函数，也称为<strong>损失函数</strong>，$W$ 为特征权重，也就是在损失函数中需要求解的参数。</p>
<blockquote>
<p> 损失函数一般包括损失项和正则项</p>
</blockquote>
<p>常用的损失函数有：</p>
<p>（1）<strong>平方损失函数</strong>（线性回归）</p>
<p>最小二乘法（Ordinary Least Squares）是常用的一种平方损失函数，最小二乘的基本原理是：最优拟合直线应该是使各点到回归直线的距离和最小的直线，即平方和最小。</p>
<p>线性回归的映射函数为：<br>$$<br>h(W,X_j)=W^TX_j<br>$$<br>损失函数可以表示为<br>$$<br>l(W,Z)=\sum_{j=1}^M (y_j-W^TX_j)^2<br>$$<br>（2）<strong>Logistics损失函数</strong>（逻辑回归）</p>
<p>逻辑回归的映射函数为：<br>$$<br>h(W,X_j)=\frac 1 {1+e^{-W^TX_j}}<br>$$</p>
<blockquote>
<p>logistic函数的优点是：</p>
<p>1、他的输入范围是$-\infty \rightarrow  + \infty $ ，<strong>输出范围是(0,1)，正好满足概率分布为（0，1）的要求</strong>。我们用概率去描述分类器，自然比单纯的某个阈值要方便很多； </p>
<p>2、是一个单调上升的函数，具有良好的连续性，<strong>不存在不连续点</strong>。</p>
</blockquote>
<p>由于该函数服从伯努利分布（0-1分布），通过最大似然估计，对于每一维的权重W，损失函数可以表示为<br>$$<br>l(W,Z)=(Y-h_W(\mathbf X))X<br>$$</p>
<blockquote>
<p><strong>推导过程</strong></p>
<p>令<br>$$<br>h_W(X) = \frac 1 {1+e^{-W^T\mathbf X}}<br>$$<br>该函数服从伯努利分布（一次点击要么成功，要么失败，通过训练集可以知道不同特征组合下成功和失败的概率）<br>$$<br>P(Y=1 | \mathbf X;W) = h_W(\mathbf X)\\<br>P(Y=0 | \mathbf X;W) = 1-h_W(\mathbf X)<br>$$<br>则概率分布函数为<br>$$<br>P(Y|\mathbf X;W) = (h_W(\mathbf X))^Y<em>(1-h_W(\mathbf X))^{1-Y}<br>$$<br>（<em>*也就是说，我们有样本，通过样本能知道概率分布，那么我们需要知道得到这个概率分布的最有可能的参数W。即我们通过样本知道一些特征组合下的点击率，现在需要求概率函数中的系数。</em></em>）</p>
<p>我们假设样本数据相互独立，所以它们的联合分布可以表示为各边际分布的乘积，用似然函数表示为：<br>$$<br>\begin{aligned}<br>L(W)=P(Y|\mathbf X;W) &amp;= (h_W(\mathbf X))^Y(1-h_W(\mathbf X))^{1-Y}\\<br>&amp;=\prod_{j=1}^M(h_W(X_j))^{y_j}(1-h_W(X_j))^{1-y_j}<br>\end{aligned}<br>\tag {2-1-2}<br>$$<br>从而，损失函数的求解，可以转化为求最有可能导致这样概率分布的W，也就是求L(W)的最大值。最简单的方法就是对W求偏导，并令导数为零。</p>
<p>在多数情况下，直接对变量进行求导反而会使得计算式子更加的复杂，此时可以借用对数函数。由于对数函数是单调增函数，因此与（2-1-2）具有相同的最大值，上式变为<br>$$<br>\begin{aligned}<br>l(W) &amp;= Log L(W)\\<br>&amp;=\sum_{j=1}^M(y_jln h(X_j)+(1-y_j)ln (1-h(X_j)))<br>\end{aligned}<br>$$<br>对其求关于W的偏导</p>
<p>首先求logistic函数的导数，得（最后一个X是对$W^TX$的求导）<br>$$<br>h_W^{‘}(\mathbf X) = h_W(\mathbf X)(1-h_W(\mathbf X))X<br>$$</p>
<blockquote>
<p><strong>推导过程如下</strong></p>
<p><img src="/2017/07/12/浅谈在线最优化求解算法-以CTR预测模型为例/求导的推导.jpg" alt="求导的推导"></p>
</blockquote>
<p>为了求解方便，将l(W)转为（其实1/M没用，完全可以去掉，不懂为何要加上）<br>$$<br>J(W) = -\frac {1}{M} l(W)<br>$$<br>则就变成求J(W)的最小值。求偏导的过程如下：</p>
<p><img src="/2017/07/12/浅谈在线最优化求解算法-以CTR预测模型为例/最大似然估计求偏导.png" alt="最大似然估计求偏导"></p>
<p>最后得到目标函数（损失函数）为：<br>$$<br>\frac {\partial }{\partial W}J(W) =-\frac{1}{M} (Y-h_W(\mathbf X))X<br>$$</p>
</blockquote>
<p>对于损失函数的求解，一个典型的方法就是梯度下降法，由于损失函数是凸函数，因此沿着梯度下降的方向找到最小点。</p>
<p>假设样本总数为n，<strong>批量梯度下降</strong>是：<br>$$<br>Repeat until convergence \{ \\<br>W^{(t+1)} := W^t - \eta^t\triangledown  _{W}l(W^{t},Z) \\<br>\}\\<br> \tag{1-2}<br>$$<br>而<strong>随机梯度下降（SGD）</strong>是：<br>$$<br>Repeat until convergence \{ \\<br>      for j=1 to M, \{ \\<br>          W^{(t+1)} := W^t - \eta^t\triangledown  _{W}l(W^{t},Z_j) \\<br>\}<br>$$<br>两者的区别是：</p>
<p>前者每次更新$W$都需要遍历一次整个样本集合；而后者在遍历样本集合的时候，每个样本都能改变$W$ ，有更快的收敛速度 。由于SGD针对观测到的随机一条数据进行权重的更新，很适合进行增量计算，实现梯度下降的online模式。</p>
<h2 id="2-2-正则化"><a href="#2-2-正则化" class="headerlink" title="2.2 正则化"></a>2.2 正则化</h2><p>正则化的主要目的是防止过拟合。对于损失函数构成的模型，可能会出现有些权重很大，有些权重很小的情况，导致过拟合，使得模型的复杂度提高，泛化能力较差（对未知数据的预测能力）。</p>
<p> <img src="/2017/07/12/浅谈在线最优化求解算法-以CTR预测模型为例/过拟合1.png" alt="过拟合1"></p>
<p>而正则化就是对损失函数中权重的限制，限制其模不要太大：<br>$$<br>W=\arg \underset{W}{min}   l(W,Z)\\<br>s.t. \Psi(W)&lt;\delta<br>$$</p>
<p>其中，$\Psi(W)$称为正则化因子，是一个关于W求模的函数，常用的正则化因子有L1和L2正则化。<br>$$<br>L1 Regularization         \Psi(W)=||W||_1=\sum_{i=1}^N|w_i|\\<br>L2  Regularization       \Psi(W)=||W||_2^2=\sum_{i=1}^N(w_i)^2=W^TW<br>$$<br>L1和L2的主要区别有两个：</p>
<p>（1）L1在0处不可导，而L2可导。</p>
<p>（2）L1通常能产生更稀疏的模型，也就是W的更多维度是0。这些为0的权重就代表了不是很重要的维度，所以能起到特征选择的目的。</p>
<p>（3）L2能限制特征权重各个维度的模不要太大，解决过拟合。</p>
<blockquote>
<p><img src="/2017/07/12/浅谈在线最优化求解算法-以CTR预测模型为例/正则化解空间.png" alt="正则化解空间"><br> 其中，左图的圆形区域是L2正则化的单位圆，右图的方形区域是L1正则化的单位圆。<br><strong>单位圆</strong></p>
<p>使$||X||_p=1$的图形，当p=1和2时，单位圆分别为$|x|+|y|=1$和$x^2+y^2=1$。</p>
</blockquote>
<p>但是在SGD中，由于每次W的更新并不是沿着全局梯度进行下降，而是沿着某个样本产生的梯度方向进行下降，这样即使采用L1的方式也很难产生稀疏解。因此在接下来的在线最优化求解算法中，稀疏性是一个主要的追求目标。</p>
<p>参考：</p>
<p><a href="http://www.mamicode.com/info-detail-517504.html【正则化方法：L1和L2" target="_blank" rel="external">http://www.mamicode.com/info-detail-517504.html【正则化方法：L1和L2</a> regularization、数据集扩增、dropout】</p>
<p><a href="http://blog.csdn.net/zouxy09/article/details/24971995/【机器学习中的范数规则化之（一）L0、L1与L2范数】" target="_blank" rel="external">http://blog.csdn.net/zouxy09/article/details/24971995/【机器学习中的范数规则化之（一）L0、L1与L2范数】</a></p>
<h1 id="3、在线最优化求解算法"><a href="#3、在线最优化求解算法" class="headerlink" title="3、在线最优化求解算法"></a>3、在线最优化求解算法</h1><h2 id="3-1-截断梯度法TG"><a href="#3-1-截断梯度法TG" class="headerlink" title="3.1 截断梯度法TG"></a>3.1 截断梯度法TG</h2><p>为了使特征权重W有更多的0，最简单的方法就是设一个阈值，当W的某个维度值小于这个阈值的时候置为0，这个称为<strong>简单截断法</strong>。但实际中W的某个系数比较小可能是由于该维度训练不足引起，所以这么做会导致这部分特征的丢失。于是又改进为<strong>截断梯度法Truncated Gradient</strong>。</p>
<h3 id="3-1-1-简单截断法"><a href="#3-1-1-简单截断法" class="headerlink" title="3.1.1 简单截断法"></a>3.1.1 简单截断法</h3><p>以$k$为窗口，当$t/k$不为整数时，采用标准的SGD；否则，采用如下的权重更新方式：<br>$$<br>W^{t+1}=T_0(W^t - \eta^tG^t,\theta) \\<br>T_0(v_i,\theta) = \begin{Bmatrix}<br>0 if |v_i|\leqslant \theta\ <br>v_i otherwise<br>\end{Bmatrix}<br>$$</p>
<p>其中，$G^t=\triangledown  _{W}l(W^{t},Z^{t})$ 代表第t次迭代中损失函数的梯度，$\eta^{t}$ 是学习率，通常将其设置为 $1/\sqrt{t}$ 的函数。可以看出，简单截断法的思路是，如果某个维度的权重变化小于设定的$\theta$ ，则直接置为0。</p>
<h3 id="3-1-2-截断梯度法"><a href="#3-1-2-截断梯度法" class="headerlink" title="3.1.2 截断梯度法"></a>3.1.2 截断梯度法</h3><p>在前一种方法上的改进。加入了L1正则化项$\eta^{t}\lambda sgn(W^{t})$ 。</p>
<p>$$<br>W^{t+1}=W^t-\eta ^tG^t-\eta^t\lambda sgn(W^t)<br>$$<br>其中$sgn(v)$是符号函数。由于每次仅根据一个样本进行更新，因此也不再使用区分样本的下表$j$。</p>
<p>采用类似的方式表示为：<br>$$<br>W^{t+1}=T_1(W^t - \eta^tG^t,\eta^t\lambda^t,\theta) \\<br>T_1(v_i,\alpha,\theta) = \begin{Bmatrix}<br>\begin{aligned}<br>&amp; max(0,v_i-\alpha) if v_i\in [0,\theta]\ <br>&amp; min(0,v_i+\alpha) if v_i\in [-\theta,0]\\<br>&amp; v_i otherwise<br>\end{aligned}<br>\end{Bmatrix}<br>$$<br>其中，$\lambda^{t} \in \mathbb{R}$且$\lambda^{t}\geqslant0 $ 。同样以k为窗口，每k步进行一次截断。当t/k不为整数时，$\lambda^{t}=0$， 否则，$\lambda^{t}=k\lambda$。可以看出，$\lambda$和$\theta$决定了权重的稀疏程度，这两个值越大越稀疏。</p>
<h2 id="3-2-前向后向切分FOBOS"><a href="#3-2-前向后向切分FOBOS" class="headerlink" title="3.2 前向后向切分FOBOS"></a>3.2 前向后向切分FOBOS</h2><h3 id="3-2-1-FOBOS算法原理"><a href="#3-2-1-FOBOS算法原理" class="headerlink" title="3.2.1 FOBOS算法原理"></a>3.2.1 FOBOS算法原理</h3><p>在FOBOS（Forward-backward Splitting）中，将权重的更新分为两个步骤：<br>$$<br>W^{t+\frac{1}{2}} = W^t-\eta^tG^{t}\\<br>W^{t+1}=\arg \underset{W}{min} \{\frac {1} {2} ||W- W^{t+\frac{1}{2}}||_2^2+\eta^{t+\frac {1}{2}}\Psi (W)\}<br>\tag {3-2-1}<br>$$<br>前一个步骤还是标准的梯度下降，后一个步骤可以理解为对梯度下降的结果进行微调，其中第一项是L2正则化，表示不能离损失迭代结果太远，第二项$\Psi (W)$是正则化项。</p>
<p>将上面两个式子合并，有<br>$$<br>W^{t+1}=\arg \underset{W}{min} \{\frac {1} {2} ||W- W^{t}-\eta^{t}G^{t}||_2^2+\eta^{t+\frac {1}{2}}\Psi (W)\}<br>$$<br>令<br>$$<br>F(W)=\frac {1} {2} ||W- W^{t}-\eta^{t}G^{t}||_2^2+\eta^{t+\frac {1}{2}}\Psi (W)<br>$$<br>如果$W^{t+1}$存在一个最优解，<strong><em>那么可以推断0向量一定属于$F(W)$的一维次梯度集合</em>。</strong><br>$$<br>0 \in \partial F(W)=W-W^{t}+\eta^{t}G^{t}+\eta^{t+\frac 1 2}\partial \Psi(W)<br>$$</p>
<blockquote>
<p><strong>次导数和次梯度</strong></p>
<p>参考SubGradient.pdf</p>
<p>次导数是一个区间，一维次梯度就是次导数</p>
</blockquote>
<p>由于$W^{t+1}=\arg \underset{x}{min} F(W)$，则有：<br>$$<br>0=\left \{ W-W^{t} - \eta^{t}G^{t}+\eta^{t+\frac {1}{2}}\partial\Psi(W) \right \}|_{W=W^{t+1}}<br>$$</p>
<p>便可以得到另一种更新权重的方式<br>$$<br>W^{t+1}=W^{t}+ \eta^{t}G^{t}-\eta^{t+\frac {1}{2}}\partial\Psi(W^{t+1})<br>$$<br>从上式可以看到权重的更新不仅与迭代前的状态有关，也与迭代后的$W^{t+1}$有关。</p>
<h3 id="3-2-2-L1-FOBOS"><a href="#3-2-2-L1-FOBOS" class="headerlink" title="3.2.2 L1-FOBOS"></a>3.2.2 L1-FOBOS</h3><p>在L1正则化下，有$\Psi (W)=\lambda||w||_1$ 。对于（2-3-1），<br>$$<br>W^{t+1}=\arg \underset{W}{min} \{\frac {1} {2} ||W- W^{t+\frac{1}{2}}||_2^2+\eta^{t+\frac {1}{2}}\Psi (W)\}<br>$$<br>用向量V来表示$W^{t+\frac 1 2}$ ，用标量$\tilde{\lambda} \in \mathbb{R}$来表示$\eta^{t+\frac 1 2}\lambda$ ，将公式展开，并改写为<br>$$<br>W^{t+1}=\arg \underset{W}{min}\sum_{i=1}^N (\frac {1} {2}(w_i-v_i)^2+ \tilde{\lambda}|w_i|)<br>\tag {3-2-2}<br>$$<br>可以看到，在求和公式中的每一项都是大于0的，所以公式（3-2-2）可以拆解成对特征权重W的每一维度单独求解<br>$$<br>w_i^{t+1}=\arg \underset{w_i}{min}(\frac {1} {2}(w_i-v_i)^2+ \tilde{\lambda}|w_i|)<br>\tag {3-2-3}<br>$$<br>假设$w_i^<em>$是一个维度上的最优解，通过反证法证明$w_i^</em>v_i\geq0$（证明略）。再分$v_i\geq0$和$v_i&lt;0$来讨论。</p>
<p><strong>（1）当$v_i\geq0$时</strong>，</p>
<p>由于$w_i^<em>v_i\geq0$，所以$w_i^</em> \geq0$ 。相当于给（2-3-3）增加了一个不等式约束条件：<br>$$<br>w_i^{t+1}=\arg \underset{w_i}{min}(\frac {1} {2}(w_i-v_i)^2+ \tilde{\lambda}|w_i|)\\<br>s.t. -w_i\leq 0<br>$$<br>通过拉格朗日乘子求解这个含不等式的约束问题。</p>
<p>引入拉格朗日系数$\beta \geq 0$ ，由KKT条件，有<br>$$<br>\frac \partial {\partial w_i}\left ( \frac {1} {2}(w_i-v_i)^2+ \tilde{\lambda}|w_i|-\beta w_i \right )|_{w_i=w_i^<em>}=0 \\<br>\beta w_i^</em>=0<br>$$<br>根据上面的求导可得<br>$$<br>w_i^*=v_i-\tilde{\lambda}+\beta<br>$$<br>再分为两种情况</p>
<p>① 当$w_i^<em> &gt; 0$ 时，由于$\beta w_i^</em>=0$ 所以$\beta=0$，此时有$w_i^*=v_i-\tilde{\lambda}$ ，从而$v_i-\tilde{\lambda} &gt; 0$ 。</p>
<p>② 当$w_i^* = 0$ 时，有$v_i-\tilde{\lambda}+\beta=0$ 。由于$\beta \geq 0$ ，所以$v_i-\tilde{\lambda} \leq 0$  。</p>
<p>可以得出，当$v_i\geq0$ 时，<br>$$<br>w_i^<em> = max(0, v_i-\tilde{\lambda})<br>$$<br><em>*（2）当$v_i&lt;0$时</em></em>，</p>
<p>采用同样的分析方法，得到<br>$$<br>w_i^* =- max(0, -v_i-\tilde{\lambda})<br>$$<br>综上，可得FOBOS在L1正则化条件下，特征权重各个维度的更新方式为：<br>$$<br>\begin{aligned}<br>w_i^{t+1} &amp;= sgn(v_i)max(0,|v_i|-\tilde{\lambda})\\<br>&amp; = sgn(w_i^{t}-\eta^{t}g_i^{t})max \left \{ 0, |w_i^{t}-\eta^{t}g_i^{t}|-\eta^{t+ \frac {1} {2}} \lambda \right \}<br> \end{aligned}<br> \tag{3-2-4}<br>$$<br>其中，$g_i^{t}$就是梯度在维度i上的取值。</p>
<p><strong>从公式（3-2-4）可以看出，L1-FOBOS每次更新W的时候，对W的每个维度都会进行判定，当$|w_i^{t}-\eta^{t}g_i^{t}|-\eta^{t+ \frac {1} {2}} \lambda&lt;0$的时候对齐进行截断，即权重置为0。</strong></p>
<p>换一种写法，<br>$$<br>|w_i^{t}-\eta^{t}g_i^{t}|&lt;\eta^{t+ \frac {1} {2}} \lambda<br>\tag {3-2-5}<br>$$<br>可以看出截断的意义是，<strong>当一条样本产生的梯度不足以令对应维度上的权重值发生足够大的变大（$\eta^{t+ \frac {1} {2}} \lambda$ ），则认为在本次更新过程中该维度不重要，令其权重为0</strong>。</p>
<p>若对L1-FOBOS进行适当的变换，可以发现，L1-FOBOS就是TG在特定条件下的特殊形式。</p>
<h2 id="3-3-RDA"><a href="#3-3-RDA" class="headerlink" title="3.3 RDA"></a>3.3 RDA</h2><h3 id="3-3-1-RDA算法原理"><a href="#3-3-1-RDA算法原理" class="headerlink" title="3.3.1 RDA算法原理"></a>3.3.1 RDA算法原理</h3><p>TG和FOBOS都是建立在SGD的基础之上，属于梯度下降类型的方法，这类型方法的优点就是精度比较高，并且 TG、 FOBOS 也都能在稀疏性上得到提升。 但是有些其它类型的算法，例如 RDA，是从另一个方面来求解 Online Optimization 并且更有效地提升了特征权重的稀疏性。 </p>
<p>正则对偶平均（ RDA, Regularized Dual Averaging） 是微软十年的研究成果， RDA 是 Simple Dual Averaging Scheme 的一个扩展， 由 Lin Xiao 发表于 2010 年 。</p>
<p>在 RDA 中， 特征权重的更新策略为：<br>$$<br>W^{t+1} = \arg \underset{W}{min} \left \{ \frac 1 t \sum_{r=1}^t \left \langle G^r,W \right \rangle  +\Psi(W)+\frac {\beta^{t}}{t}h(W) \right \}<br>\tag {3-3-1}<br>$$<br>本质上，公式（3-3-1）包括了3个部分：</p>
<p>（1）线性函数$\frac 1 t \sum_{r=1}^t \left \langle G^r,W \right \rangle$ 包含了之前所有梯度（或次梯度）的平均值（dual average），$G^r$ 是梯度；</p>
<p>（2）$\Psi(W)$ 为正则项；</p>
<p>（3）额外正则项$\frac {\beta^{t}}{t}h(W)$。其中$h(W)$是一个辅助的严格凸函数。$\{\beta^{t}|t\geq 1\}$ 是一个非负且非自减序列。</p>
<h3 id="3-3-2-L1-RDA"><a href="#3-3-2-L1-RDA" class="headerlink" title="3.3.2 L1-RDA"></a>3.3.2 L1-RDA</h3><p>在L1正则化下，有$\Psi (W)=\lambda||w||_1$，并且由于$h(W)$是一个关于W的严格凸函数，就令$h(W)=\frac {1} {2} ||W||_2^2 $ 。此外，将$\{\beta^{t}|t\geq 1\}$定义为$\beta^{t}=\gamma \sqrt t $ 。再代入（2-4-1），有<br>$$<br>W^{t+1} = \arg \underset{W}{min} \left \{ \frac 1 t \sum_{r=1}^t \left \langle G^r,W \right \rangle  +\lambda||w||_1+\frac {\gamma} {2\sqrt t}||W||_2^2 \right \}<br>\tag {3-3-2}<br>$$<br>分解到每一个权重的维度上<br>$$<br>w_i^{t+1} = \arg \underset{w_i}{min} \left \{ \bar{g_i}^{t}w_i +\lambda|w_i|+\frac {\gamma} {2\sqrt t}w_i^2 \right \}<br>\tag {3-3-3}<br>$$<br>这里$\lambda &gt;0, \frac {\gamma} {\sqrt t}&gt;0,  \bar{g_i}^{t} = \frac 1 t \sum_{r=1}^t g_i^{(r)}$ 。公式（2-4-3）就是一个无约束的非平滑最优化问题（因为第二项$\lambda|w_i|$ 在0处不可导）。所以用次导数求解。</p>
<p>假设$w_i^<em>$ 是其最优解，并且定义$\xi \in \partial  |w_i|$为$|w_i|$ 在$w_i^</em>$ 的次导数，则有<br>$$<br>\partial |w_i^<em>| =  \left\{\begin{matrix}<br>-1&lt;\xi&lt;1  &amp; if w_i^</em>=0\ <br>1 &amp; if w_i^<em>&gt;0\ <br>-1 &amp; if w_i^</em><0 \end{matrix}\right.="" $$="" 对公式（3-3-3）求次导数，并令其为0，则有="" \bar{g_i}^{t}="" +="" \lambda\xi="" \frac="" {\gamma}="" {\sqrt="" t}="" w_i="0" 由于$\lambda="">0$，再分情况讨论（略），可以得到L1-RDA特征权重的各个维度更新的方式为：<br>$$<br>w_i^{t+1}=\begin{Bmatrix}<br>0 &amp; if |\bar{g_i}^{t}|&lt;\lambda\ <br>-\frac {\sqrt t}{\gamma}\left (\bar{g_i}^{t}-\lambda sgn(\bar{g_i}^{t})  \right ) &amp; otherwise<br>\end{Bmatrix}<br>\tag {3-3-4}<br>$$<br><strong>这里可以看出，当某个维度上累积梯度平均值的绝对值小于阈值$\lambda$ 时，产生截断</strong>。</0></p>
<h3 id="3-3-3-L1-RDA和L1-FOBOS的比较"><a href="#3-3-3-L1-RDA和L1-FOBOS的比较" class="headerlink" title="3.3.3 L1-RDA和L1-FOBOS的比较"></a>3.3.3 L1-RDA和L1-FOBOS的比较</h3><p>在L1-FOBOS中，进行截断的条件是<br>$$<br>|w_i^{t}-\eta^{t}g_i^{t}|&lt;\eta^{t+ \frac {1} {2}} \lambda<br>$$<br>通常会定义$\eta$为与$\frac 1 {\sqrt t}$ 正相关的函数$\eta=\Theta \left ( \frac {1} {\sqrt t} \right )$ 。因此L1-FOBOS的<strong>截断阈值为$\Theta \left ( \frac {1} {\sqrt t} \right )\lambda$  ，</strong>随着**t的增加，这个阈值会逐渐降低。</p>
<p>相比较而言，L1-RDA的<strong>截断阈值是$\lambda$ </strong>。是一个常数，并不随着t变化，因此相对于L1-FOBOS更简单粗暴。这种性质使得L1-RDA更容易产生稀疏性。此外， RDA 中判定截断的对象是梯度的累加平均值$\bar{g_i}^{t} $ ， 不同于 TG或L1-FOBOS 中针对单次梯度计算的结果进行判定，避免了由于某些维度由于训练不足导致截断的问题。 并且通过调节一个参数$\lambda$，很容易在精度和稀疏性上进行权衡 。</p>
<h2 id="3-4-FTRL"><a href="#3-4-FTRL" class="headerlink" title="3.4 FTRL"></a>3.4 FTRL</h2><p>有实验证明， <strong>L1-FOBOS 这一类基于梯度下降的方法有比较高的精度，但是 L1-RDA 却能在损失一定精度的情况下产生更好的稀疏性。 FTRL则是结合了两者的优点</strong>。</p>
<h3 id="3-4-1-L1-FOBOS和L1-RDA在形式上的统一"><a href="#3-4-1-L1-FOBOS和L1-RDA在形式上的统一" class="headerlink" title="3.4.1 L1-FOBOS和L1-RDA在形式上的统一"></a>3.4.1 L1-FOBOS和L1-RDA在形式上的统一</h3><p>之前提到，L1-FOBOS可以表示为（这里令$\eta^{t+\frac 1 2}=\eta^t=\Theta(\frac 1 {\sqrt t})$  是一个随t变化的非增正序列）<br>$$<br>W^{t+1}=\arg \underset{W}{min} \{\frac {1} {2} ||W- W^t-\eta^tG^t||^2+\eta^{t}\lambda||w||_1\}<br>$$<br>将其按W的维度分解为N个独立的最优化步骤<br>$$<br>\underset{w_i}{minimize} \left \{  \frac 1 2 (w_i-w_i^t+\eta^tg_i^t)^2+\eta^t\lambda|w_i| \right \}\\<br>=\underset{w_i}{minimize}\left \{  \frac 1 2 (w_i-w_i^t)^2 + \frac 1 2(\eta^tg_i^t)^2+w_i\eta^tg_i^t- w_i^t\eta^tg_i^t+    \eta^t\lambda|w_i| \right \}\\<br>$$<br>同时除以$\eta^t$ ，得到<br>$$<br>\underset{w_i}{minimize}\left \{ w_ig_i^t+\lambda|w_i|+\frac 1 {2\eta^t}(w_i-w_i^t)^2 + [\frac {\eta^t}{2}(g_i^t)2+w_i^tg_i^t] \right \}<br>$$<br>由于$\frac {\eta^t}{2}(g_i^t)2+w_i^tg_i^t$ 与变量$w_i$ 无关，因此上式可以等价于<br>$$<br>\underset{w_i}{minimize}\left \{ w_ig_i^t+\lambda|w_i|+\frac 1 {2\eta^t}(w_i-w_i^t)^2 +  \right \}<br>$$<br>再将这N个独立的合并，则L1-FOBOS可以写成<br>$$<br>W^{t+1} = \arg \underset{W}{min} \left \{ G^t\cdot W+\lambda||W||_1+\frac 1 {2\eta^t}||W-W^t||_2^2 \right \}<br>$$<br>而对于L1-RDA的公式（3-3-2）<br>$$<br>W^{t+1} = \arg \underset{W}{min} \left \{ \frac 1 t \sum_{r=1}^t \left \langle G^r,W \right \rangle  +\lambda||w||_1+\frac {\gamma} {2\sqrt t}||W||_2^2 \right \} \\<br>$$<br>同时乘以t，得到<br>$$<br>\begin{aligned}<br>W^{t+1} &amp; = \arg \underset{W}{min} \left \{ \sum_{r=1}^t  G^r \cdot W  +t\lambda||w||_1+\frac {1} {2\eta^t}||W-0||_2^2 \right \}\\<br>&amp; =\arg \underset{W}{min} \left \{  G^{1:t} \cdot W  +t\lambda||w||_1+\frac {1} {2\eta^t}||W-0||_2^2 \right \}<br>\end{aligned}<br>$$<br>如果令$\sigma ^s = \frac 1 {\eta^s}-\frac 1 {\eta^{s-1}}$  ，则$\sigma^{1:t} = \frac 1 {\eta^t}$ 。L1-FOBOS和L1-RDA的公式可以写成<br>$$<br>W^{t+1} = \arg \underset{W}{min} \left \{ G^t\cdot W+\lambda||W||_1+\frac 1 2\sigma^{1:t}||W-W^t||_2^2 \right \}\\<br>W^{t+1} =\arg \underset{W}{min} \left \{  G^{1:t} \cdot W  +t\lambda||W||_1+\frac 1 2\sigma^{1:t}||W-0||_2^2 \right \}<br>\tag {3-4-1}<br>$$<br>比较这两个公式，可以看出L1-FOBOS和L1-RDA的区别在于：</p>
<p>（1）前者对梯度只考虑当前的状态，而后者的梯度是累加的形式；</p>
<p>（2）前者的第三项限制了W的变化不能离已经迭代过的解太远，后者限制W不能离0太远。</p>
<h3 id="3-4-2-FTRL算法原理"><a href="#3-4-2-FTRL算法原理" class="headerlink" title="3.4.2 FTRL算法原理"></a>3.4.2 FTRL算法原理</h3><p>FTRL综合考虑了L1-FOBOS和L1-RDA中对正则项和W限制的区别，其特征权重的更新公式为<br>$$<br>W^{t+1} =\arg \underset{W}{min} \left \{  G^{1:t} \cdot W  +\lambda_1||W||_1+\lambda_2||W||_2^2+\frac 1 2\sum_{s=1}^t \sigma^s ||W-W^s||_2^2 \right \}<br>\tag {3-4-2}<br>$$<br>其中L2的正则项在论文中并没有出现，但是2013年的FTRL工程化实现的论文却使用。事实上该项的引入并不影响FRTL<br>的稀疏性， 后面的推导过程会显示这一点。 L2正则项的引入仅仅相当于对最优化过程多了一个约束，使得结果求解结果更加“平滑”。 </p>
<p>对（3-4-2）进行变换，将其的最后一项展开<br>$$<br>W^{t+1} =\arg \underset{W}{min} \left \{  (G^{1:t}-\sum_{s=1}^t\sigma^sW^s) \cdot W  +\lambda_1||W||_1+\frac 1 2 (\lambda_2+\sum_{s=1}^t\sigma^s)||W||_2^2+\frac 1 2\sum_{s=1}^t \sigma^s ||W^s||_2^2 \right \}<br>$$<br>其中，由于$\frac 1 2\sum_{s=1}^t \sigma^s ||W^s||_2^2$ 相对于W是常数项，再令<br>$$<br>Z^{t} =G^{1:t}-\sum_{s=1}^t\sigma^sW^s<br>\tag {3-4-3}<br>$$<br>上式等价于<br>$$<br>W^{t+1} =\arg \underset{W}{min} \left \{  Z^t \cdot W  +\lambda_1||W||_1+\frac 1 2 (\lambda_2+\sum_{s=1}^t\sigma^s)||W||_2^2 \right \}<br>$$<br>再针对每个维度将其拆解成N个独立的标量最小化问题<br>$$<br> \underset{w_i}{minimize} \left \{  z_i^tw_i  +\lambda_1|w_i|+\frac 1 2 (\lambda_2+\sum_{s=1}^t\sigma^s)w_i^2 \right \}<br>$$<br>到这里，遇到了与L1-RDA的（3-3-3）类似的优化问题，用相同的分析方法可以得到<br>$$<br>w_i^{t+1}=\left\{\begin{matrix}<br>0 &amp; if |z_i^t|&lt;\lambda_1\ <br>-\left ( \lambda_2+\sum_{s=1}^t\sigma^s \right )^{-1} \left ( z_i^t-\lambda_1 sgn(z_i^t) \right ) &amp; otherwise<br>\end{matrix} \right.<br>\tag {3-4-4}<br>$$<br>可以看出，引入L2并没有对FTRL结果的稀疏性产生影响。</p>
<h3 id="3-4-3-学习率"><a href="#3-4-3-学习率" class="headerlink" title="3.4.3 学习率"></a>3.4.3 学习率</h3><p>前面的推导中，学习率的选择和计算没有被提及。事实上在FTRL中，每个维度的学习率都是单独考虑的。</p>
<p>考虑特征维度的变化率：如果特征 1 比特征 2 的变化更快，那么在维度 1 上的学习率应该下降得更快。我们很容易就可以想到可以用某个维度上梯度分量来反映这种变化率。在FTRL 中，维度 i上的学习率是这样计算的<strong>（原作者没有推导过程）</strong>：<br>$$<br>\eta_i^t=\frac {\alpha}{\beta + \sqrt {\sum_{s=1}^t (g_i^s)^2}}<br>$$<br>由于$\sum_{s=1}^t\sigma^s=\frac 1 {\eta^t}$ ，因此（3-4-4）就变成<br>$$<br>w_i^{t+1}=\left\{\begin{matrix}<br>0 &amp; if |z_i^t|&lt;\lambda_1\ <br>-\left ( \lambda_2 + \frac {\beta + \sqrt {\sum_{s=1}^t (g_i^s)^2}}{\alpha}  \right )^{-1} \left ( z_i^t-\lambda_1 sgn(z_i^t) \right ) &amp; otherwise<br>\end{matrix} \right.<br>\tag {3-4-5}<br>$$<br>这里的$\alpha, \beta$ 都是要输入的参数。</p>
<h3 id="2-5-4-伪代码解读"><a href="#2-5-4-伪代码解读" class="headerlink" title="2.5.4 伪代码解读"></a>2.5.4 伪代码解读</h3><p> <img src="/2017/07/12/浅谈在线最优化求解算法-以CTR预测模型为例/FTRL伪代码.png" alt="FTRL伪代码"></p>
<p>首先设置各个参数的初始值，包括</p>
<ul>
<li>更新学习率的$\alpha,\beta$。</li>
<li>L1和L2正则化的参数$\lambda_1, \lambda_2$ </li>
<li>更新权重时用到的$z_i$ 一维数组（数组的长度是特征项个数），初始值是0</li>
<li>存放梯度累加的$n_i$ 一维数组（数组的长度是特征项个数），初始值是0</li>
</ul>
<p>算法步骤中：</p>
<p>（1）第一阶段，计算第t次迭代的预测值</p>
<p><strong>S1</strong>：用给定的初始值计算权重$w_{t,i}$，并计算出预测值$p_t$ 。见①</p>
<p>（2）第二阶段，更新第t+1次的权重，对当前样本不为0的每个特征项都要进行一次更新。在第i个特征项中，</p>
<p><strong>S1</strong>：采用logloss计算损失函数的梯度$g_{t+1}$，见②</p>
<p><strong>S2</strong>：可以看出①里面还需要计算$n_i$  和$z_i$ 在第t+1次的值。</p>
<p>对于$z_i$，根据公式（2-5-3）<br>$$<br>Z^{t} =G^{1:t}-\sum_{s=1}^t\sigma^sW^s<br>$$<br>可以看出z的更新可以通过下式计算<br>$$<br>\begin {aligned}<br>Z^{t+1}&amp; =G^{1:t+1}-\sum_{s=1}^{t+1}\sigma^sW^s\\<br>&amp;=G^{1:t}-\sum_{s=1}^t\sigma^sW^s + G^{t+1} - \sigma^{t+1}W^{t+1}\\<br>&amp;=Z^t + G^{t+1} - \sigma^{t+1}W^{t+1}<br> \end{aligned}<br> \tag {3-4-6}<br>$$<br>则需要计算$\sigma^{t+1}$ 的值。而根据上文的推导<br>$$<br>\sigma ^s = \frac 1 {\eta^s}-\frac 1 {\eta^{s-1}}<br>$$<br>又<br>$$<br>\eta_i^t=\frac {\alpha}{\beta + \sqrt {\sum_{s=1}^t (g_i^s)^2}}<br>$$<br>则<br>$$<br>\begin {aligned}<br>\sigma ^{t+1}&amp; = \frac 1 {\eta^{t+1}}-\frac 1 {\eta^t}\\<br>&amp;=\frac {\beta + \sqrt {\sum_{s=1}^{t+1} (g_i^s)^2}}{\alpha}-\frac {\beta + \sqrt {\sum_{s=1}^t (g_i^s)^2}}{\alpha}\\<br>&amp;=\frac 1 \alpha \left ( \sqrt {\sum_{s=1}^{t+1} (g_i^s)^2}- \sqrt {\sum_{s=1}^t (g_i^s)^2}\right )<br> \end{aligned}<br>$$<br>由于用$n_i$ 记录$g_i$ 的累加和，上式可以变成<br>$$<br>\sigma ^{t+1} = \sqrt {n^t+(g^{t+1})^2}-\sqrt {n^t}<br>\tag {3-4-7}<br>$$<br>见③。再根据公式（3-4-6），计算$z_i$ 的值，见④。</p>
<p><strong>S3</strong>：对于$n_i$ ，根据公式（3-4-7），<br>$$<br>n^{t+1} = n^t +(g^{t+1})^2<br>$$<br>见⑤。</p>
<h3 id="2-5-5-实现代码"><a href="#2-5-5-实现代码" class="headerlink" title="2.5.5 实现代码"></a>2.5.5 实现代码</h3><figure class="highlight scala"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div></pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">predict</span></span>(x: <span class="type">Array</span>[<span class="type">Int</span>]): <span class="type">Double</span> = &#123;</div><div class="line">  <span class="keyword">var</span> wTx = <span class="number">0.0</span></div><div class="line"></div><div class="line">  x foreach &#123; x =&gt;</div><div class="line">    <span class="keyword">val</span> sign = <span class="keyword">if</span> (z(x) &lt; <span class="number">0</span>) <span class="number">-1.0</span> <span class="keyword">else</span> <span class="number">1.0</span></div><div class="line"></div><div class="line">    <span class="keyword">if</span> (sign * z(x) &lt;= <span class="type">L1</span>)</div><div class="line">      w(x) = <span class="number">0.0</span></div><div class="line">    <span class="keyword">else</span></div><div class="line">      w(x) = (sign * <span class="type">L1</span> - z(x)) / ((beta + math.sqrt(n(x))) / alpha + <span class="type">L2</span>)</div><div class="line"></div><div class="line">    wTx = wTx + w(x)</div><div class="line">  &#125;</div><div class="line">  <span class="keyword">return</span> <span class="number">1.0</span> / (<span class="number">1.0</span> + math.exp(-math.max(math.min(wTx, <span class="number">35.0</span>), <span class="number">-35.0</span>)))</div><div class="line">&#125;</div><div class="line"></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">update</span></span>(x: <span class="type">Array</span>[<span class="type">Int</span>], p: <span class="type">Double</span>, y: <span class="type">Int</span>): <span class="type">Unit</span> = &#123;</div><div class="line">  <span class="keyword">val</span> g = p - y</div><div class="line"></div><div class="line">  x foreach &#123; x =&gt;</div><div class="line">    <span class="keyword">val</span> sigma = (math.sqrt(n(x) + g * g) - math.sqrt(n(x))) / alpha</div><div class="line">    z(x) = z(x) + g - sigma * w(x)</div><div class="line">    n(x) = n(x) + g * g</div><div class="line">  &#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<p>从代码可以看出，在更新权重时，SGD和FTRL的区别在于：</p>
<p><del>SGD在遍历每个样本的时候，都会更新所有维度的权重，而FTRL在遍历每个样本的时候只会更新样本对应维度的权重。从而可以节省训练的时间</del></p>
<p>并不是节省时间。SGD也可以用于在线学习，过拟合的限制上没有FTRL好。参数太多，会导致模型复杂度上升，容易过拟合。</p>
<h3 id="3-4-6-实验及结论"><a href="#3-4-6-实验及结论" class="headerlink" title="3.4.6 实验及结论"></a>3.4.6 实验及结论</h3><p>1、</p>
<p>训练：16-10-22的前7天数据</p>
<p>预测：16-10-22当天数据</p>
<p>维度：1048576</p>
<p>参数：默认</p>
<p> <img src="/2017/07/12/浅谈在线最优化求解算法-以CTR预测模型为例/roc3.png" alt="roc3"></p>
<p>logloss：</p>
<p>线上方法：0.274321867859</p>
<p>FRTL：0.0326626593411</p>
<p>2、</p>
<p>训练：16-10-22的前7天数据</p>
<p>预测：16-10-22当天数据，其中每9条用于在线学习，预测第10条</p>
<p>维度：1048576</p>
<p>参数：默认</p>
<p>训练时间：11:54-12:18</p>
<p> <img src="/2017/07/12/浅谈在线最优化求解算法-以CTR预测模型为例/roc1.png" alt="roc1"></p>
<p>logloss：</p>
<p>线上方法：0.275704770725</p>
<p>FRTL：0.032281346379</p>
<p>3、</p>
<p>训练集：16-10-18的前10天数据</p>
<p>预测：16-10-18当天数据，其中每9条用于在线学习，预测第10条</p>
<p>维度：4194304</p>
<p>参数：默认</p>
<p>训练时间：13:50-14:19</p>
<p> <img src="/2017/07/12/浅谈在线最优化求解算法-以CTR预测模型为例/roc2.png" alt="roc2"></p>
<p>logloss</p>
<p>线上方法：0.073087783303</p>
<p>FTRL：0.022967801811</p>
<p>4、</p>
<p>训练集：16-10-18的前10天数据</p>
<p>预测：16-10-18当天数据，其中每9条用于在线学习，预测第10条</p>
<p>维度：4194304</p>
<p>参数：训练的特征项改为1-10</p>
<p>训练时间：17:07-17:45</p>
<p> <img src="/2017/07/12/浅谈在线最优化求解算法-以CTR预测模型为例/roc4.png" alt="roc4"></p>
<p>logloss</p>
<p>线上方法：0.073087783303</p>
<p>FTRL：0.0221369813697</p>
<p>特征权重不为0的维度有11301个</p>
<h2 id="观点"><a href="#观点" class="headerlink" title="观点"></a>观点</h2><p>FTRL在线训练时间长了效果往往会下降，因为学习率会逐渐降低，必须要offline结合online。</p>
<h1 id="主要参考资料"><a href="#主要参考资料" class="headerlink" title="主要参考资料"></a>主要参考资料</h1><p>【在线最优化求解(Online Optimization)-冯扬】</p>
<p>【逻辑回归从入门到精通-腾讯柳超】</p>
<p>【FTRL的理论论文】Factorization machines with follow-the-regularized-leader for CTR prediction in display advertising  <a href="http://www0.cs.ucl.ac.uk/staff/w.zhang/rtb-papers/fm-ftrl.pdf" target="_blank" rel="external">http://www0.cs.ucl.ac.uk/staff/w.zhang/rtb-papers/fm-ftrl.pdf</a></p>
<p>【FTRL的工程实现论文】<a href="https://www.eecs.tufts.edu/~dsculley/papers/ad-click-prediction.pdf" target="_blank" rel="external">https://www.eecs.tufts.edu/~dsculley/papers/ad-click-prediction.pdf</a> </p>

          
        
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
  </section>

  
  <nav class="pagination">
    <span class="page-number current">1</span><a class="page-number" href="/page/2/">2</a><a class="extend next" rel="next" href="/page/2/"><i class="fa fa-angle-right"></i></a>
  </nav>



          </div>
          


          

        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    <div class="sidebar-inner">

      

      

      <section class="site-overview sidebar-panel sidebar-panel-active">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
          <img class="site-author-image" itemprop="image"
               src="/images/avatar.gif"
               alt="Schwimmer" />
          <p class="site-author-name" itemprop="name">Schwimmer</p>
           
              <p class="site-description motion-element" itemprop="description">Record and Think!</p>
          
        </div>
        <nav class="site-state motion-element">

          
            <div class="site-state-item site-state-posts">
              <a href="/archives">
                <span class="site-state-item-count">20</span>
                <span class="site-state-item-name">日志</span>
              </a>
            </div>
          

          
            
            
            <div class="site-state-item site-state-categories">
              
                <span class="site-state-item-count">10</span>
                <span class="site-state-item-name">分类</span>
              
            </div>
          

          
            
            
            <div class="site-state-item site-state-tags">
              
                <span class="site-state-item-count">12</span>
                <span class="site-state-item-name">标签</span>
              
            </div>
          

        </nav>

        

        <div class="links-of-author motion-element">
          
        </div>

        
        

        
        

        


      </section>

      

      

    </div>
  </aside>


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <div class="copyright" >
  
  &copy; 
  <span itemprop="copyrightYear">2018</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">Schwimmer</span>
</div>


<div class="powered-by">
  由 <a class="theme-link" href="https://hexo.io">Hexo</a> 强力驱动
</div>

<div class="theme-info">
  主题 -
  <a class="theme-link" href="https://github.com/iissnan/hexo-theme-next">
    NexT.Muse
  </a>
</div>

<div>
<script async src="https://dn-lbstatics.qbox.me/busuanzi/2.3/busuanzi.pure.mini.js"></script>

本站总访问量 <span id="busuanzi_value_site_pv"></span> 次&nbsp&nbsp&nbsp
本站访客数<span id="busuanzi_value_site_uv"></span>人次
</div>




        

        
      </div>
    </footer>

    
      <div class="back-to-top">
        <i class="fa fa-arrow-up"></i>
        
      </div>
    

  </div>

  

<script type="text/javascript">
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>









  






  
  <script type="text/javascript" src="/lib/jquery/index.js?v=2.1.3"></script>

  
  <script type="text/javascript" src="/lib/fastclick/lib/fastclick.min.js?v=1.0.6"></script>

  
  <script type="text/javascript" src="/lib/jquery_lazyload/jquery.lazyload.js?v=1.9.7"></script>

  
  <script type="text/javascript" src="/lib/velocity/velocity.min.js?v=1.2.1"></script>

  
  <script type="text/javascript" src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>

  
  <script type="text/javascript" src="/lib/fancybox/source/jquery.fancybox.pack.js?v=2.1.5"></script>


  


  <script type="text/javascript" src="/js/src/utils.js?v=5.1.0"></script>

  <script type="text/javascript" src="/js/src/motion.js?v=5.1.0"></script>



  
  

  

  


  <script type="text/javascript" src="/js/src/bootstrap.js?v=5.1.0"></script><!-- hexo-inject:begin --><!-- Begin: Injected MathJax -->
<script type="text/x-mathjax-config">
  MathJax.Hub.Config({"tex2jax":{"inlineMath":[["$","$"],["\\(","\\)"]],"skipTags":["script","noscript","style","textarea","pre","code"],"processEscapes":true},"TeX":{"equationNumbers":{"autoNumber":"AMS"}}});
</script>

<script type="text/x-mathjax-config">
  MathJax.Hub.Queue(function() {
    var all = MathJax.Hub.getAllJax(), i;
    for(i=0; i < all.length; i += 1) {
      all[i].SourceElement().parentNode.className += ' has-jax';
    }
  });
</script>

<script type="text/javascript" src="//cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
</script>
<!-- End: Injected MathJax -->
<!-- hexo-inject:end -->



  


  




	





  





  





  






  





  

  

  

  

</body>
</html>
