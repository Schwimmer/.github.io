<!DOCTYPE html>












  


<html class="theme-next mist use-motion" lang="zh-Hans">
<head>
  <!-- hexo-inject:begin --><!-- hexo-inject:end --><meta charset="UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=edge"/>
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2"/>
<meta name="theme-color" content="#222"/>






















<link rel="stylesheet" href="/lib/font-awesome/css/font-awesome.min.css?v=4.7.0"/>

<link rel="stylesheet" href="/css/main.css?v=7.2.0"/>


  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png?v=7.2.0">


  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png?v=7.2.0">


  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png?v=7.2.0">


  <link rel="mask-icon" href="/images/logo.svg?v=7.2.0" color="#222">







<script id="hexo.configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '/',
    scheme: 'Mist',
    version: '7.2.0',
    sidebar: {"position":"left","display":"post","offset":12,"onmobile":false,"dimmer":false},
    back2top: true,
    back2top_sidebar: false,
    fancybox: false,
    fastclick: false,
    lazyload: false,
    tabs: true,
    motion: {"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},
    algolia: {
      applicationID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    }
  };
</script>


  




  <meta name="description" content="词向量　　自然语言理解的问题要转化为机器学习的问题，第一步肯定是要找一种方法把这些符号数学化。 NLP 中最直观的词表示方法是 One-hot Representation，这种方法把每个词表示为一个很长的向量。这个向量的维度是词表大小，其中绝大多数元素为 0，只有一个维度的值为 1，这个维度就代表了当前的词。 这么简洁的表示方法配合上最大熵、SVM、CRF 等等算法已经很好地完成了 NLP 领域">
<meta property="og:type" content="article">
<meta property="og:title" content="Schwimmer&#39;s Blog">
<meta property="og:url" content="https://schwimmer.github.io/2018/09/16/机器学习/NLP/语言模型/index.html">
<meta property="og:site_name" content="Schwimmer&#39;s Blog">
<meta property="og:description" content="词向量　　自然语言理解的问题要转化为机器学习的问题，第一步肯定是要找一种方法把这些符号数学化。 NLP 中最直观的词表示方法是 One-hot Representation，这种方法把每个词表示为一个很长的向量。这个向量的维度是词表大小，其中绝大多数元素为 0，只有一个维度的值为 1，这个维度就代表了当前的词。 这么简洁的表示方法配合上最大熵、SVM、CRF 等等算法已经很好地完成了 NLP 领域">
<meta property="og:locale" content="zh-Hans">
<meta property="og:image" content="http://licstar.net/wp-content/uploads/2013/07/1.png">
<meta property="og:image" content="http://licstar.net/wp-content/uploads/2013/07/2-300x256.png">
<meta property="og:updated_time" content="2018-09-16T07:41:05.233Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Schwimmer&#39;s Blog">
<meta name="twitter:description" content="词向量　　自然语言理解的问题要转化为机器学习的问题，第一步肯定是要找一种方法把这些符号数学化。 NLP 中最直观的词表示方法是 One-hot Representation，这种方法把每个词表示为一个很长的向量。这个向量的维度是词表大小，其中绝大多数元素为 0，只有一个维度的值为 1，这个维度就代表了当前的词。 这么简洁的表示方法配合上最大熵、SVM、CRF 等等算法已经很好地完成了 NLP 领域">
<meta name="twitter:image" content="http://licstar.net/wp-content/uploads/2013/07/1.png">





  
  
  <link rel="canonical" href="https://schwimmer.github.io/2018/09/16/机器学习/NLP/语言模型/"/>



<script id="page.configurations">
  CONFIG.page = {
    sidebar: "",
  };
</script>

  <title> | Schwimmer's Blog</title>
  












  <noscript>
  <style>
  .use-motion .motion-element,
  .use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-title { opacity: initial; }

  .use-motion .logo,
  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript><!-- hexo-inject:begin --><!-- hexo-inject:end -->

</head>

<body itemscope itemtype="http://schema.org/WebPage" lang="zh-Hans">

  
  
    
  

  <!-- hexo-inject:begin --><!-- hexo-inject:end --><div class="container sidebar-position-left page-post-detail">
    <div class="headband"></div>

    <header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-wrapper">
  <div class="site-meta">
    

    <div class="custom-logo-site-title">
      <a href="/" class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">Schwimmer's Blog</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
    
    
  </div>

  <div class="site-nav-toggle">
    <button aria-label="Navigationsleiste an/ausschalten">
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
    </button>
  </div>
</div>



<nav class="site-nav">
  
    <ul id="menu" class="menu">
      
        
        
        
          
          <li class="menu-item menu-item-home">

    
    
      
    

    

    <a href="/" rel="section"><i class="menu-item-icon fa fa-fw fa-home"></i> <br/>Startseite</a>

  </li>
        
        
        
          
          <li class="menu-item menu-item-tags">

    
    
      
    

    

    <a href="/tags/" rel="section"><i class="menu-item-icon fa fa-fw fa-tags"></i> <br/>Schlagwörter</a>

  </li>
        
        
        
          
          <li class="menu-item menu-item-categories">

    
    
      
    

    

    <a href="/categories/" rel="section"><i class="menu-item-icon fa fa-fw fa-th"></i> <br/>Kategorien</a>

  </li>
        
        
        
          
          <li class="menu-item menu-item-archives">

    
    
      
    

    

    <a href="/archives/" rel="section"><i class="menu-item-icon fa fa-fw fa-archive"></i> <br/>Archiv</a>

  </li>

      
      
    </ul>
  

  
    

  

  
</nav>



  



</div>
    </header>

    


    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          
          <div id="content" class="content">
            

  <div id="posts" class="posts-expand">
    

  

  
  
  

  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="https://schwimmer.github.io/2018/09/16/机器学习/NLP/语言模型/"/>

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Schwimmer"/>
      <meta itemprop="description" content="Record and Think!"/>
      <meta itemprop="image" content="/images/avatar.gif"/>
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Schwimmer's Blog"/>
    </span>

    
      <header class="post-header">

        
        
          <h2 class="post-title" itemprop="name headline">

              
            
          </h2>
        

        <div class="post-meta">

          
          
          

          
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Veröffentlicht am</span>
              

              
                
              

              <time title="Erstellt: 2018-09-16 13:26:51 / Geändert am: 15:41:05" itemprop="dateCreated datePublished" datetime="2018-09-16T13:26:51+08:00">2018-09-16</time>
            </span>
          

          
            

            
          

          

          
            
            
          

          
          

          

          <br/>
          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        <h1 id="词向量"><a href="#词向量" class="headerlink" title="词向量"></a>词向量</h1><p>　　自然语言理解的问题要转化为机器学习的问题，第一步肯定是要找一种方法把这些符号数学化。</p>
<p>NLP 中最直观的词表示方法是 One-hot Representation，这种方法把每个词表示为一个很长的向量。这个向量的维度是词表大小，其中绝大多数元素为 0，只有一个维度的值为 1，这个维度就代表了当前的词。</p>
<p>这么简洁的表示方法配合上最大熵、SVM、CRF 等等算法已经很好地完成了 NLP 领域的各种主流任务。</p>
<p><strong>one-hot的缺点是：“词汇鸿沟”现象：任意两个词之间都是孤立的</strong>。光从这两个向量中看不出两个词是否有关系。</p>
<p>Deep Learning的词向量不是用one-hot，而是<strong>Distributed Representation</strong>。这个就是<strong>词向量</strong></p>
<p>可以认为，该模型最大的贡献就是解决了词汇鸿沟现象，可以让相关的词在向量空间上更接近。</p>
<blockquote>
<p>Distributed representation 最早是 Hinton 在 1986 年的论文《Learning distributed representations of concepts》中提出的。</p>
<p>Distributed representation 用来表示词，通常被称为“Word Representation”或“Word Embedding”，中文俗称“词向量”。周志华叫他词嵌入</p>
</blockquote>
<h1 id="词向量的训练获得"><a href="#词向量的训练获得" class="headerlink" title="词向量的训练获得"></a>词向量的训练获得</h1><p>要介绍词向量是怎么训练得到的，就不得不提到语言模型。到目前为止我了解到的所有训练方法<strong>都是在训练语言模型的同时，顺便得到词向量的</strong>。</p>
<p>词向量的训练最经典的有 3 个工作，<strong>C&amp;W 2008、M&amp;H 2008、Mikolov 2010</strong>。</p>
<h2 id="Bengio-的经典之作"><a href="#Bengio-的经典之作" class="headerlink" title="Bengio 的经典之作"></a>Bengio 的经典之作</h2><p>用神经网络训练语言模型的思想最早由百度 IDL 的徐伟于 2000 提出。其论文《Can Artificial Neural Networks Learn Language Models?》提出一种用神经网络构建二元语言模型（即 $P(w<em>t|w</em>{t-1})$ ）的方法。文中的基本思路与后续的语言模型的差别已经不大了。</p>
<p>训练语言模型的最经典之作，要数 Bengio 等人在 2001 年发表在 NIPS 上的文章《A Neural Probabilistic Language Model》。当然现在看的话，肯定是要看他在 2003 年投到 JMLR 上的同名论文了。</p>
<p>Bengio 用了一个三层的神经网络来构建语言模型，同样也是 n-gram 模型。</p>
<p><img src="http://licstar.net/wp-content/uploads/2013/07/1.png" alt=""></p>
<p>图中最下方的 wt−n+1,…,wt−2,wt−1wt−n+1,…,wt−2,wt−1 就是前 n−1n−1 个词。现在需要根据这已知的 n−1n−1 个词预测下一个词 wtwt。C(w)C(w) 表示词 ww 所对应的词向量，整个模型中使用的是一套唯一的词向量，存在矩阵 CC（一个 |V|×m|V|×m 的矩阵）中。其中 |V||V| 表示词表的大小（语料中的总词数），mm 表示词向量的维度。ww 到 C(w)C(w) 的转化就是从矩阵中取出一行。<br>　　网络的第一层（输入层）是将 C(wt−n+1),…,C(wt−2),C(wt−1)C(wt−n+1),…,C(wt−2),C(wt−1) 这 n−1n−1 个向量首尾相接拼起来，形成一个 (n−1)m(n−1)m 维的向量，下面记为 xx。<br>　　网络的第二层（隐藏层）就如同普通的神经网络，直接使用 d+Hxd+Hx 计算得到。dd 是一个偏置项。在此之后，使用 tanhtanh 作为激活函数。<br>　　网络的第三层（输出层）一共有 |V||V| 个节点，每个节点 yiyi 表示 下一个词为 ii 的未归一化 log 概率。最后使用 softmax 激活函数将输出值 yy 归一化成概率。</p>
<h2 id="C-amp-W-的-SENNA"><a href="#C-amp-W-的-SENNA" class="headerlink" title="C&amp;W 的 SENNA"></a>C&amp;W 的 SENNA</h2><p>Ronan Collobert 和 Jason Weston 在 2008 年的 ICML 上发表的《A Unified Architecture for Natural Language Processing: Deep Neural Networks with Multitask Learning》里面首次介绍了他们提出的词向量的计算方法。</p>
<p>如果现在要看的话，应该去看他们在 2011 年投到 JMLR 上的论文《Natural Language Processing (Almost) from Scratch》。</p>
<p>实际上 C&amp;W 这篇论文主要目的并不是在于生成一份好的词向量，甚至不想训练语言模型，而是要用这份词向量去完成 NLP 里面的各种任务，比如词性标注、命名实体识别、短语识别、语义角色标注等等。<br>　　由于目的的不同，C&amp;W 的词向量训练方法在我看来也是最特别的。他们没有去近似地求 P(wt|w1,w2,…,wt−1)P(wt|w1,w2,…,wt−1)，而是直接去尝试近似 P(w1,w2,…,wt)P(w1,w2,…,wt)。在实际操作中，他们并没有去求一个字符串的<strong>概率</strong>，而是<strong>求窗口连续 n 个词的打分</strong> f(wt−n+1,…,wt−1,wt)f(wt−n+1,…,wt−1,wt)。打分 ff 越高的说明这句话越是正常的话；打分低的说明这句话不是太合理；如果是随机把几个词堆积在一起，那肯定是负分（差评）。打分只有相对高低之分，并没有概率的特性。<br>　　有了这个对 ff的假设，C&amp;W 就直接使用 <strong>pair-wise</strong> 的方法训练词向量。具体的来说，就是最小化下面的目标函数。</p>
<script type="math/tex; mode=display">
\sum\limits_{x\in \mathfrak{X}} { \sum\limits_{w\in \mathfrak{D}} {\max \{0 , 1-f(x)+f(x^{(w)})\} } }</script><p>x(w)x(w) 是将短语 xx 的最中间的那个词，替换成 ww。在大多数情况下，在一个正常短语的基础上随便找个词替换掉中间的词，最后得到的短语肯定不是正确的短语，所以这样构造的负样本是非常可用的（多数情况下确实是负样本，极少数情况下把正常短语当作负样本也不影响大局）。同时，由于负样本仅仅是修改了正样本中的一个词，也不会让分类面距离负样本太远而影响分类效果。再回顾这个式子，xx 是正样本，x(w)x(w) 是负样本，f(x)f(x) 是对正样本的打分，f(x(w))是对负样本的打分。最后希望正样本的打分要比负样本的打分至少高 1 分。</p>
<p>f函数的结构与Bengio的网络结构基本一致，同样是把n个词对应的词向量串成一个长向量，同样是经过一层网络（乘一个矩阵）得到隐藏层。不同在于C&amp;W的输出层只有一个节点，表示得分。当然有这种简化还是因为 C&amp;W 并不想做一个真正的语言模型，只是借用语言模型的思想辅助他完成 NLP 的其它任务。</p>
<p>因为动机不同，他公布的词向量与其他相比的主要区别是：</p>
<p>1、只有小写单词。也就是说他把大写开头的单词和小写单词当作同一个词处理。其它的词向量都是把他们当作不同的词处理的。</p>
<p>2.他公布的词向量并不直接是上述公式的优化结果，而是在此基础上进一步跑了词性标注、命名实体识别等等一系列任务的 Multi-Task Learning 之后，二次优化得到的。也可以理解为是半监督学习得到的，而非其他方法中纯无监督学习得到的。</p>
<p>不过好在 Turian 在 2010 年对 C&amp;W 和 M&amp;H 向量做对比时，重新训练了一份词向量放到了网上，那份就没上面的两个“问题”（确切的说应该是差别），也可以用的更放心。</p>
<h2 id="M-amp-H-的-HLBL"><a href="#M-amp-H-的-HLBL" class="headerlink" title="M&amp;H 的 HLBL"></a>M&amp;H 的 HLBL</h2><p>Andriy Mnih 和 Geoffrey Hinton 在 2007 年和 2008 年各发表了一篇关于训练语言模型和词向量的文章。2007 年发表在 ICML 上的《Three new graphical models for statistical language modelling》表明了 Hinton 将 Deep Learning 战场扩展到 NLP 领域的决心。2008 年发表在 NIPS 上的《A scalable hierarchical distributed language model》则提出了一种层级的思想替换了 Bengio 2003 方法中最后隐藏层到输出层最花时间的矩阵乘法，在保证效果的基础上，同时也提升了速度。</p>
<h2 id="Mikolov-的-RNNLM"><a href="#Mikolov-的-RNNLM" class="headerlink" title="Mikolov 的 RNNLM"></a>Mikolov 的 RNNLM</h2><p>mikolov就是word2vec的发明人。前文说到，Bengio 2003 论文里提了一句，可以使用一些方法降低参数个数，比如用循环神经网络。Mikolov 就抓住了这个坑，从此与循环神经网络结下了不解之缘。</p>
<p>他最早用循环神经网络做语言模型是在 INTERSPEECH 2010 上发表的《Recurrent neural network based language model》里。</p>
<p><img src="http://licstar.net/wp-content/uploads/2013/07/2-300x256.png" alt=""></p>
<p>三篇关于word2vec的论文</p>
<p><strong>1、Efficient Estimation of Word Representation in Vector Space, 2013</strong></p>
<p>传统的NNLM模型包含四层，即输入层、映射层、隐含层和输出层，计算复杂度很大程度上依赖于映射层到隐含层之间的计算，而且需要指定上下文的长度。RNNLM模型被提出用来改进NNLM模型，去掉了映射层，只有输入层、隐含层和输出层，计算复杂度来源于上一层的隐含层到下一层隐含层之间的计算。</p>
<p>传统的NNLM模型包含四层，即输入层、映射层、隐含层和输出层，计算复杂度很大程度上依赖于映射层到隐含层之间的计算，而且需要指定上下文的长度。RNNLM模型被提出用来改进NNLM模型，去掉了映射层，只有输入层、隐含层和输出层，计算复杂度来源于上一层的隐含层到下一层隐含层之间的计算。</p>
<p><strong>2、Distributed Representations of Sentences and Documents, 2014</strong></p>
<p>句向量以及段落向量如何表示：</p>
<p>句向量：利用one-hot的表示方法作为网络的输入，乘以词矩阵W，然后将得到的每个向量通过平均或者拼接的方法得到整个句子的表示，最后根据任务要求做一分类，而这过程中得到的W就是词向量矩阵，基本上还是word2vec的思路。</p>
<p>段落向量：依旧是相同的方法，只是在这里加上了一个段落矩阵，用以表示每个段落，当这些词输入第i个段落时，通过段落id就可以从这个矩阵中得到相对应的段落表示方法。需要说明的是，在相同的段落中，段落的表示是相同的。文中这样表示的动机就是段落矩阵D可以作为一个memory记住在词的context中遗失的东西，相当于增加了一个额外的信息。这样经过训练之后，我们的就得到了段落表示D，当然这个段落就可以是一段或者一篇文章。</p>
<p><strong>3、Enriching Word Vectors with Subword Information, 2016</strong></p>
<p><strong>问题：如何解决word2vec方法中罕见词效果不佳的问题，以及如何提升词形态丰富语言的性能？</strong></p>
<p>如果一个word出现次数较少那么学到的vector质量也不理想。针对这一问题作者提出使用subword信息来弥补这一问题，简单来说就是通过词缀的vector来表示词。比如unofficial是个低频词，其数据量不足以训练出高质量的vector，但是可以通过un+official这两个高频的词缀学习到不错的vector。</p>
<p>参考</p>
<p><a href="https://blog.csdn.net/sinat_26917383/article/details/52577551" target="_blank" rel="noopener">https://blog.csdn.net/sinat_26917383/article/details/52577551</a></p>
<p><a href="https://licstar.net/archives/328" target="_blank" rel="noopener">https://licstar.net/archives/328</a></p>

      
    </div>

    

    
    
    

    

    
      
    
    

    

    <footer class="post-footer">
      

      
      
      

      
        <div class="post-nav">
          <div class="post-nav-next post-nav-item">
            
              <a href="/2018/09/16/机器学习/NLP/牛津大学xDeepMind 自然语言处理/第一课/" rel="next" title="">
                <i class="fa fa-chevron-left"></i> 
              </a>
            
          </div>

          <span class="post-nav-divider"></span>

          <div class="post-nav-prev post-nav-item">
            
              <a href="/2018/09/24/总结与思考/如何落地需求/" rel="prev" title="">
                 <i class="fa fa-chevron-right"></i>
              </a>
            
          </div>
        </div>
      

      
      
    </footer>
  </div>
  
  
  
  </article>


  </div>


          </div>
          

  



        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    <div class="sidebar-inner">

      

      
        <ul class="sidebar-nav motion-element">
          <li class="sidebar-nav-toc sidebar-nav-active" data-target="post-toc-wrap">
            Inhaltsverzeichnis
          </li>
          <li class="sidebar-nav-overview" data-target="site-overview-wrap">
            Übersicht
          </li>
        </ul>
      

      <div class="site-overview-wrap sidebar-panel">
        <div class="site-overview">
          <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
            
              <p class="site-author-name" itemprop="name">Schwimmer</p>
              <div class="site-description motion-element" itemprop="description">Record and Think!</div>
          </div>

          
            <nav class="site-state motion-element">
              
                <div class="site-state-item site-state-posts">
                
                  <a href="/archives/">
                
                    <span class="site-state-item-count">315</span>
                    <span class="site-state-item-name">Artikel</span>
                  </a>
                </div>
              

              
                
                
                <div class="site-state-item site-state-categories">
                  
                    
                      <a href="/categories/">
                    
                  
                    
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                    <span class="site-state-item-count">17</span>
                    <span class="site-state-item-name">Kategorien</span>
                  </a>
                </div>
              

              
                
                
                <div class="site-state-item site-state-tags">
                  
                    
                      <a href="/tags/">
                    
                  
                    
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                    <span class="site-state-item-count">55</span>
                    <span class="site-state-item-name">schlagwörter</span>
                  </a>
                </div>
              
            </nav>
          

          

          

          

          

          
          

          
            
          
          

        </div>
      </div>

      
      <!--noindex-->
        <div class="post-toc-wrap motion-element sidebar-panel sidebar-panel-active">
          <div class="post-toc">

            
            
            
            

            
              <div class="post-toc-content"><ol class="nav"><li class="nav-item nav-level-1"><a class="nav-link" href="#词向量"><span class="nav-number">1.</span> <span class="nav-text">词向量</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#词向量的训练获得"><span class="nav-number">2.</span> <span class="nav-text">词向量的训练获得</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#Bengio-的经典之作"><span class="nav-number">2.1.</span> <span class="nav-text">Bengio 的经典之作</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#C-amp-W-的-SENNA"><span class="nav-number">2.2.</span> <span class="nav-text">C&amp;W 的 SENNA</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#M-amp-H-的-HLBL"><span class="nav-number">2.3.</span> <span class="nav-text">M&amp;H 的 HLBL</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Mikolov-的-RNNLM"><span class="nav-number">2.4.</span> <span class="nav-text">Mikolov 的 RNNLM</span></a></li></ol></li></ol></div>
            

          </div>
        </div>
      <!--/noindex-->
      

      

    </div>
  </aside>
  


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <div class="copyright">&copy; <span itemprop="copyrightYear">2019</span>
  <span class="with-love" id="animate">
    <i class="fa fa-user"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">Schwimmer</span>

  

  
</div>


  <div class="powered-by">Erstellt mit  <a href="https://hexo.io" class="theme-link" rel="noopener" target="_blank">Hexo</a> v3.5.0</div>



  <span class="post-meta-divider">|</span>



  <div class="theme-info">Design – <a href="https://theme-next.org" class="theme-link" rel="noopener" target="_blank">NexT.Mist</a> v7.2.0</div>




        








        
      </div>
    </footer>

    
      <div class="back-to-top">
        <i class="fa fa-arrow-up"></i>
        
      </div>
    

    

    

    
  </div>

  

<script>
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>


























  
  <script src="/lib/jquery/index.js?v=3.4.1"></script>

  
  <script src="/lib/velocity/velocity.min.js?v=1.2.1"></script>

  
  <script src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>


  


  <script src="/js/utils.js?v=7.2.0"></script>

  <script src="/js/motion.js?v=7.2.0"></script>



  
  


  <script src="/js/schemes/muse.js?v=7.2.0"></script>




  
  <script src="/js/scrollspy.js?v=7.2.0"></script>
<script src="/js/post-details.js?v=7.2.0"></script>



  


  <script src="/js/next-boot.js?v=7.2.0"></script><!-- hexo-inject:begin --><!-- hexo-inject:end -->


  

  

  

  


  


  




  

  

  

  

  

  

  

  

  

  

  

  

  

  

</body>
</html>
