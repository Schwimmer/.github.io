<!DOCTYPE html>












  


<html class="theme-next mist use-motion" lang="zh-CN">
<head><meta name="generator" content="Hexo 3.9.0">
  <!-- hexo-inject:begin --><!-- hexo-inject:end --><meta charset="UTF-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">






















<link rel="stylesheet" href="/lib/font-awesome/css/font-awesome.min.css?v=4.7.0">

<link rel="stylesheet" href="/css/main.css?v=7.2.0">


  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png?v=7.2.0">


  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png?v=7.2.0">


  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png?v=7.2.0">


  <link rel="mask-icon" href="/images/logo.svg?v=7.2.0" color="#222">







<script id="hexo.configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '/',
    scheme: 'Mist',
    version: '7.2.0',
    sidebar: {"position":"left","display":"post","offset":12,"onmobile":false,"dimmer":false},
    back2top: true,
    back2top_sidebar: false,
    fancybox: false,
    fastclick: false,
    lazyload: false,
    tabs: true,
    motion: {"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},
    algolia: {
      applicationID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    }
  };
</script>


  




  <meta name="description" content="插入hive表控制part文件数量http://blog.sina.com.cn/s/blog_604c7cdd0102wbsw.html 12345-- 每个文件上限500Mset hive.exec.reducers.bytes.per.reducer=512000000;insert overwrite table carthage.gps_address_info_weekly_bak P">
<meta name="keywords" content="hive">
<meta property="og:type" content="article">
<meta property="og:title" content="hive技巧总结">
<meta property="og:url" content="https://schwimmer.github.io/2018/03/31/hadoop-spark/hive笔记/index.html">
<meta property="og:site_name" content="Schwimmer&#39;s Blog">
<meta property="og:description" content="插入hive表控制part文件数量http://blog.sina.com.cn/s/blog_604c7cdd0102wbsw.html 12345-- 每个文件上限500Mset hive.exec.reducers.bytes.per.reducer=512000000;insert overwrite table carthage.gps_address_info_weekly_bak P">
<meta property="og:locale" content="zh-CN">
<meta property="og:image" content="https://schwimmer.github.io/.io//pic/image-20190704165407658.png">
<meta property="og:image" content="https://schwimmer.github.io/.io//pic/70.png">
<meta property="og:updated_time" content="2019-07-04T08:55:19.782Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="hive技巧总结">
<meta name="twitter:description" content="插入hive表控制part文件数量http://blog.sina.com.cn/s/blog_604c7cdd0102wbsw.html 12345-- 每个文件上限500Mset hive.exec.reducers.bytes.per.reducer=512000000;insert overwrite table carthage.gps_address_info_weekly_bak P">
<meta name="twitter:image" content="https://schwimmer.github.io/.io//pic/image-20190704165407658.png">





  
  
  <link rel="canonical" href="https://schwimmer.github.io/2018/03/31/hadoop-spark/hive笔记/">



<script id="page.configurations">
  CONFIG.page = {
    sidebar: "",
  };
</script>

  <title>hive技巧总结 | Schwimmer's Blog</title>
  




  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-143240576-1"></script>
  <script>
    var host = window.location.hostname;
    if (host !== "localhost" || !true) {
      window.dataLayer = window.dataLayer || [];
      function gtag(){dataLayer.push(arguments);}
      gtag('js', new Date());
      gtag('config', 'UA-143240576-1');
    }
  </script>









  <noscript>
  <style>
  .use-motion .motion-element,
  .use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-title { opacity: initial; }

  .use-motion .logo,
  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript><!-- hexo-inject:begin --><!-- hexo-inject:end -->

</head>

<body itemscope="" itemtype="http://schema.org/WebPage" lang="zh-CN">

  
  
    
  

  <!-- hexo-inject:begin --><!-- hexo-inject:end --><div class="container sidebar-position-left page-post-detail">
    <div class="headband"></div>

    <header id="header" class="header" itemscope="" itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-wrapper">
  <div class="site-meta">
    

    <div class="custom-logo-site-title">
      <a href="/" class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">Schwimmer's Blog</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
    
    
  </div>

  <div class="site-nav-toggle">
    <button aria-label="切换导航栏">
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
    </button>
  </div>
</div>



<nav class="site-nav">
  
    <ul id="menu" class="menu">
      
        
        
        
          
          <li class="menu-item menu-item-home">

    
    
      
    

    

    <a href="/" rel="section"><i class="menu-item-icon fa fa-fw fa-home"></i> <br>首页</a>

  </li>
        
        
        
          
          <li class="menu-item menu-item-tags">

    
    
      
    

    

    <a href="/tags/" rel="section"><i class="menu-item-icon fa fa-fw fa-tags"></i> <br>标签</a>

  </li>
        
        
        
          
          <li class="menu-item menu-item-categories">

    
    
      
    

    

    <a href="/categories/" rel="section"><i class="menu-item-icon fa fa-fw fa-th"></i> <br>分类</a>

  </li>
        
        
        
          
          <li class="menu-item menu-item-archives">

    
    
      
    

    

    <a href="/archives/" rel="section"><i class="menu-item-icon fa fa-fw fa-archive"></i> <br>归档</a>

  </li>

      
      
        <li class="menu-item menu-item-search">
          
            <a href="javascript:;" class="popup-trigger">
          
            
              <i class="menu-item-icon fa fa-search fa-fw"></i> <br>搜索</a>
        </li>
      
    </ul>
  

  
    

  

  
    <div class="site-search">
      
  <div class="popup search-popup local-search-popup">
  <div class="local-search-header clearfix">
    <span class="search-icon">
      <i class="fa fa-search"></i>
    </span>
    <span class="popup-btn-close">
      <i class="fa fa-times-circle"></i>
    </span>
    <div class="local-search-input-wrapper">
      <input autocomplete="off" placeholder="搜索..." spellcheck="false" type="text" id="local-search-input">
    </div>
  </div>
  <div id="local-search-result"></div>
</div>



    </div>
  
</nav>



  



</div>
    </header>

    


    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          
          <div id="content" class="content">
            

  <div id="posts" class="posts-expand">
    

  

  
  
  

  

  <article class="post post-type-normal" itemscope="" itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="https://schwimmer.github.io/2018/03/31/hadoop-spark/hive笔记/">

    <span hidden itemprop="author" itemscope="" itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Schwimmer">
      <meta itemprop="description" content="Record and Think!">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope="" itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Schwimmer's Blog">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">hive技巧总结

              
            
          </h1>
        

        <div class="post-meta">

          
          
          

          
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              

              
                
              

              <time title="创建时间：2018-03-31 10:28:31" itemprop="dateCreated datePublished" datetime="2018-03-31T10:28:31+08:00">2018-03-31</time>
            </span>
          

          
            

            
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="fa fa-calendar-check-o"></i>
                </span>
                
                  <span class="post-meta-item-text">更新于</span>
                
                <time title="修改时间：2019-07-04 16:55:19" itemprop="dateModified" datetime="2019-07-04T16:55:19+08:00">2019-07-04</time>
              </span>
            
          

          
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope="" itemtype="http://schema.org/Thing"><a href="/categories/大数据平台工具/" itemprop="url" rel="index"><span itemprop="name">大数据平台工具</span></a></span>

                
                
              
            </span>
          

          
            
            
              
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="fa fa-comment-o"></i>
                </span>
            
                <span class="post-meta-item-text">评论数：</span>
                <a href="/2018/03/31/hadoop-spark/hive笔记/#comments" itemprop="discussionUrl">
                  <span class="post-comments-count disqus-comment-count" data-disqus-identifier="2018/03/31/hadoop-spark/hive笔记/" itemprop="commentCount"></span>
                </a>
              </span>
            
          

          
          

          
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-eye"></i>
                 阅读次数： 
                <span class="busuanzi-value" id="busuanzi_value_page_pv"></span>
              </span>
            </span>
          

          <br>
          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        <h1 id="插入hive表控制part文件数量"><a href="#插入hive表控制part文件数量" class="headerlink" title="插入hive表控制part文件数量"></a>插入hive表控制part文件数量</h1><p><a href="http://blog.sina.com.cn/s/blog_604c7cdd0102wbsw.html" target="_blank" rel="noopener">http://blog.sina.com.cn/s/blog_604c7cdd0102wbsw.html</a></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">-- 每个文件上限500M</span><br><span class="line">set hive.exec.reducers.bytes.per.reducer=512000000;</span><br><span class="line">insert overwrite table carthage.gps_address_info_weekly_bak PARTITION(DATA_DATE=&apos;2019-01-15&apos;)</span><br><span class="line">select * from carthage.gps_address_info DISTRIBUTE by RAND();</span><br><span class="line">-- DISTRIBUTE by RAND()主要靠这个控制reduce的文件数</span><br></pre></td></tr></table></figure>
<h1 id="strict模式"><a href="#strict模式" class="headerlink" title="strict模式"></a>strict模式</h1><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">set hive.mapred.mode=strict</span><br></pre></td></tr></table></figure>
<p>有助于前置解决一些语法和可能的逻辑错误。</p>
<h1 id="限制小文件数量"><a href="#限制小文件数量" class="headerlink" title="限制小文件数量"></a>限制小文件数量</h1><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">set mapred.max.split.size=256000000;        -- 决定每个map处理的最大的文件大小，单位为B</span><br><span class="line">set mapred.min.split.size.per.node=10000000;         -- 节点中可以处理的最小的文件大小</span><br><span class="line">set mapred.min.split.size.per.rack=10000000;          -- 机架中可以处理的最小的文件大小</span><br></pre></td></tr></table></figure>
<h1 id="查询时如何去掉重复数据"><a href="#查询时如何去掉重复数据" class="headerlink" title="查询时如何去掉重复数据"></a>查询时如何去掉重复数据</h1><p>假设数据为</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">name  adx        tran_id                  cost        ts</span><br><span class="line">ck        5         125.168.10.0           33.00   1407234660</span><br><span class="line">ck        5         187.18.99.00           33.32   1407234661</span><br><span class="line">ck        5         125.168.10.0           33.24   1407234661</span><br></pre></td></tr></table></figure>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">select * from (select *,row_number() over (partition by tran_id order by timestamp asc) num from table) t where t.num=1;</span><br></pre></td></tr></table></figure>
<blockquote>
<p>附上：<br><strong>ROW_NUMBER() OVER函数的基本用法 </strong></p>
<p>语法：ROW_NUMBER() OVER(PARTITION BY COLUMN ORDER BY COLUMN) </p>
<p>简单的说row_number()从1开始，为每一条分组记录返回一个数字，这里的ROW_NUMBER() OVER (ORDER BY xlh DESC) 是先把xlh列降序，再为降序以后的没条xlh记录返回一个序号。<br>示例： </p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">&gt; xlh           row_num </span><br><span class="line">&gt; 1700              1 </span><br><span class="line">&gt; 1500              2 </span><br><span class="line">&gt; 1085              3 </span><br><span class="line">&gt; 710                4 </span><br><span class="line">&gt;</span><br></pre></td></tr></table></figure>
</blockquote>
<p>&gt;</p>
<blockquote>
<p>row_number() OVER (PARTITION BY COL1 ORDER BY COL2) 表示根据COL1分组，在分组内部根据 COL2排序，而此函数计算的值就表示每组内部排序后的顺序编号（组内连续的唯一的) </p>
</blockquote>
<h1 id="split后的数组长度"><a href="#split后的数组长度" class="headerlink" title="split后的数组长度"></a>split后的数组长度</h1><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">size(split(driving_districts,&apos;;&apos;))</span><br></pre></td></tr></table></figure>
<h1 id="切换队列"><a href="#切换队列" class="headerlink" title="切换队列"></a>切换队列</h1><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">set mapred.job.queue.name=data;</span><br></pre></td></tr></table></figure>
<p>sqoop切换队列是</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">-D mapred.job.queue.name=data</span><br></pre></td></tr></table></figure>
<h1 id="加载hdfs的udf"><a href="#加载hdfs的udf" class="headerlink" title="加载hdfs的udf"></a>加载hdfs的udf</h1><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">ADD JAR hdfs://iclick/zyz/udf/zyz_udf2.jar;</span><br><span class="line">CREATE TEMPORARY FUNCTION get_region as &apos;org.apache.hadoop.hive.ql.udf.Ip2GeoCodeUDF&apos;;</span><br></pre></td></tr></table></figure>
<h1 id="Hive-Trash"><a href="#Hive-Trash" class="headerlink" title="Hive Trash"></a>Hive Trash</h1><p>hive删除表时，会移除表的元数据和数据，而HDFS上的数据，如果配置了Trash，会移到.Trash/Current目录下。删除外部表时，表中的数据不会被删除。</p>
<h1 id="性能"><a href="#性能" class="headerlink" title="性能"></a>性能</h1><p>用groupby代替distinct，少用orderby</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line">同事写了个hive的sql语句，执行效率特别慢，跑了一个多小时程序只是map完了，reduce进行到20%。</span><br><span class="line">该Hive语句如下：</span><br><span class="line">select count(distinct ip) </span><br><span class="line">from (select ip as ip from comprehensive.f_client_boot_daily where year=&quot;2013&quot; and month=&quot;10&quot;  </span><br><span class="line">union all </span><br><span class="line">select pub_ip as ip from f_app_boot_daily where year=&quot;2013&quot; and month=&quot;10&quot; </span><br><span class="line">union all select ip as ip from format_log.format_pv1 where year=&quot;2013&quot; and month=&quot;10&quot; and url_first_id=1 </span><br><span class="line">) d </span><br><span class="line"></span><br><span class="line">       分析：select ip as ip from comprehensive.f_client_boot_daily where year=&quot;2013&quot; and month=&quot;10&quot;这个语句筛选出来的数据约有10亿条，select pub_ip as ip from f_app_boot_daily where year=&quot;2013&quot; and month=&quot;10&quot;约有10亿条条，select ip as ip from format_log.format_pv1 where year=&quot;2013&quot; and month=&quot;10&quot; and url_first_id=1 筛选出来的数据约有10亿条，总的数据量大约30亿条。这么大的数据量，使用disticnt函数，所有的数据只会shuffle到一个reducer上，导致reducer数据倾斜严重。</span><br><span class="line">       解决办法：</span><br><span class="line">       首先，通过使用groupby，按照ip进行分组。改写后的sql语句如下：</span><br><span class="line">select count(*) </span><br><span class="line">from </span><br><span class="line">(select ip </span><br><span class="line">from</span><br><span class="line">(select ip as ip from comprehensive.f_client_boot_daily where year=&quot;2013&quot; and month=&quot;10&quot; </span><br><span class="line">union all </span><br><span class="line">select pub_ip as ip from f_app_boot_daily where year=&quot;2013&quot; and month=&quot;10&quot; </span><br><span class="line">union all select ip as ip from format_log.format_pv1 where year=&quot;2013&quot; and month=&quot;10&quot; and url_first_id=1</span><br><span class="line">) d </span><br><span class="line">group by ip ) b </span><br><span class="line">       然后，合理的设置reducer数量，将数据分散到多台机器上。set mapred.reduce.tasks=50; </span><br><span class="line">       经过优化后，速度提高非常明显。整个作业跑完大约只需要20多分钟的时间。</span><br></pre></td></tr></table></figure>
<p>提高order by的性能<a href="https://blog.csdn.net/djd1234567/article/details/51917603" target="_blank" rel="noopener">https://blog.csdn.net/djd1234567/article/details/51917603</a></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br></pre></td><td class="code"><pre><span class="line">Hive中的order by跟传统的sql语言中的order by作用是一样的，会对查询的结果做一次全局排序，所以说，只有hive的sql中制定了order by所有的数据都会到同一个reducer进行处理（不管有多少map，也不管文件有多少的block只会启动一个reducer）。但是对于大量数据这 将会消耗很长的时间去执行。</span><br><span class="line"></span><br><span class="line">    这里跟传统的sql还有一点区别：如果指定了hive.mapred.mode=strict（默认值是nonstrict）,这时就必须指定limit 来限制输出条数，原因是：所有的数据都会在同一个reducer端进行，数据量大的情况下可能不能出结果，那么在这样的严格模式下，必须指定输出的条数。</span><br><span class="line"></span><br><span class="line">    所以数据量大的时候能不用order by就不用，可以使用sort by结合distribute by来进行实现。sort by是局部排序，而distribute by是控制map怎么划分reducer。</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    Hive中指定了sort by，那么在每个reducer端都会做排序，也就是说保证了局部有序（每个reducer出来的数据是有序的，但是不能保证所有的数据是有序的，除非只有一个reducer），好处是：执行了局部排序之后可以为接下去的全局排序提高不少的效率（其实就是做一次归并排序就可以做到全局排序了）</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    ditribute by是控制map的输出在reducer是如何划分的，举个例子，我们有一张表，mid是指这个store所属的商户，money是这个商户的盈利，name是这个store的名字</span><br><span class="line"></span><br><span class="line">store:</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">mid	money	name</span><br><span class="line">AA	15.0	商店1</span><br><span class="line">AA	20.0	商店2</span><br><span class="line">BB	22.0	商店3</span><br><span class="line">CC	44.0	商店4</span><br><span class="line">    执行hive语句：</span><br><span class="line"></span><br><span class="line">[sql] view plain copy</span><br><span class="line">select mid, money, name from store distribute by mid sort by mid asc, money asc  </span><br><span class="line">我 们所有的mid相同的数据会被送到同一个reducer去处理，这就是因为指定了distribute by mid，这样的话就可以统计出每个商户中各个商店盈利的排序了（这个肯定是全局有序的，因为相同的商户会放到同一个reducer去处理）。这里需要注意 的是distribute by必须要写在sort by之前。</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">cluster by</span><br><span class="line">    cluster by的功能就是distribute by和sort by相结合，如下2个语句是等价的：</span><br><span class="line"></span><br><span class="line">[sql] view plain copy</span><br><span class="line">select mid, money, name from store cluster by mid  </span><br><span class="line">select mid, money, name from store distribute by mid sort by mid  </span><br><span class="line">    如果需要获得与上面的中语句一样的效果：</span><br><span class="line"></span><br><span class="line">[sql] view plain copy</span><br><span class="line">select mid, money, name from store cluster by mid sort by money  </span><br><span class="line">    注意被cluster by指定的列只能是降序，不能指定asc和desc。</span><br></pre></td></tr></table></figure>
<h1 id="问题集"><a href="#问题集" class="headerlink" title="问题集"></a>问题集</h1><h2 id="查询ES表报错"><a href="#查询ES表报错" class="headerlink" title="查询ES表报错"></a>查询ES表报错</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Failed with exception java.io.IOException:org.elasticsearch.hadoop.rest.EsHadoopInvalidRequest: The number of slices [1126] is too large. It must be less than [1024]. This limit can be set by changing the [index.max_slices_per_scroll] index level settin</span><br></pre></td></tr></table></figure>
<p>修改es的设置</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">PUT /megacorp/_settings</span><br><span class="line"></span><br><span class="line">&#123;</span><br><span class="line"></span><br><span class="line">  &quot;index&quot;: &#123;</span><br><span class="line"></span><br><span class="line">    &quot;max_slices_per_scroll&quot; : 1126</span><br><span class="line"></span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h2 id="上传hive-UDF包后重启hive-server报错"><a href="#上传hive-UDF包后重启hive-server报错" class="headerlink" title="上传hive UDF包后重启hive server报错"></a>上传hive UDF包后重启hive server报错</h2><h2 id="hive-udf没有权限执行"><a href="#hive-udf没有权限执行" class="headerlink" title="hive udf没有权限执行"></a>hive udf没有权限执行</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Error while compiling statement: FAILED: SemanticException No valid privileges User dmp does not have privileges for CREATEFUNCTION The required privileges: Server=server1-&gt;URI=file:///home/hive/aux_libs/carthage-common-udf-hive-test.jar-&gt;action=*;</span><br></pre></td></tr></table></figure>
<h2 id="没有找到jar包的报错"><a href="#没有找到jar包的报错" class="headerlink" title="没有找到jar包的报错"></a>没有找到jar包的报错</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Error while compiling statement: FAILED: SemanticException [Error 10014]: Line 1:7 Wrong arguments &apos;70.0&apos;: org.apache.hadoop.hive.ql.metadata.HiveException: Unable to execute method public java.lang.String com.mljr.carthage.common.geo.udf.hive.UDFGeoLocation.evaluate(java.lang.Double,java.lang.Double) on object com.mljr.carthage.common.geo.udf.hive.UDFGeoLocation@54ee9573 of class com.mljr.carthage.common.geo.udf.hive.UDFGeoLocation with arguments &#123;50.0:java.lang.Double, 70.0:java.lang.Double&#125; of size 2</span><br></pre></td></tr></table></figure>
<p>其他都是可以的，就这个udf的第二个参数一直报错。经测试，还是UDF本身的问题，跟参数的设置没有关系。</p>
<p>最后发现问题是udf的jar包上传后，关联的一些jar包没有打进去，手动加上</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line">&lt;plugin&gt;</span><br><span class="line">				&lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt;</span><br><span class="line">				&lt;artifactId&gt;maven-shade-plugin&lt;/artifactId&gt;</span><br><span class="line">				&lt;version&gt;1.6&lt;/version&gt;</span><br><span class="line">				&lt;executions&gt;</span><br><span class="line">					&lt;execution&gt;</span><br><span class="line">						&lt;phase&gt;package&lt;/phase&gt;</span><br><span class="line">						&lt;goals&gt;</span><br><span class="line">							&lt;goal&gt;shade&lt;/goal&gt;</span><br><span class="line">						&lt;/goals&gt;</span><br><span class="line">						&lt;configuration&gt;</span><br><span class="line">							&lt;artifactSet&gt;</span><br><span class="line">								&lt;includes&gt;</span><br><span class="line">									&lt;include&gt;com.mljr.carthage:carthage-common-geo&lt;/include&gt;</span><br><span class="line">									&lt;include&gt;com.alibaba:fastjson&lt;/include&gt;</span><br><span class="line">									&lt;include&gt;com.github.davidmoten:geo&lt;/include&gt;</span><br><span class="line">									&lt;include&gt;com.github.davidmoten:grumpy-core&lt;/include&gt;</span><br><span class="line">								&lt;/includes&gt;</span><br><span class="line">							&lt;/artifactSet&gt;</span><br><span class="line">						&lt;/configuration&gt;</span><br><span class="line">					&lt;/execution&gt;</span><br><span class="line">				&lt;/executions&gt;</span><br><span class="line">			&lt;/plugin&gt;</span><br></pre></td></tr></table></figure>
<h1 id="hive用高版本的UDF"><a href="#hive用高版本的UDF" class="headerlink" title="hive用高版本的UDF"></a>hive用高版本的UDF</h1><p>在hive2.0中有类似于months_between的函数，可以实现2个时间之间的月份差。但是低版本没有这个函数</p>
<p>解决：</p>
<p>下载hive-2.1源码包</p>
<p><a href="http://mirrors.hust.edu.cn/apache/hive/hive-2.2.0/" target="_blank" rel="noopener">http://mirrors.hust.edu.cn/apache/hive/hive-2.2.0/</a></p>
<p>导入eclipse，查找months_between</p>
<p>在org.apache.hadoop.hive.ql.udf.generic包下找到GenericUDFMonthsBetween类，移植即可</p>
<p>/ql/src/java/org/apache/hadoop/hive/ql/udf/generic/GenericUDFMonthsBetween.java</p>
<h1 id="String转date"><a href="#String转date" class="headerlink" title="String转date"></a>String转date</h1><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">select cast(to_date(from_unixtime(unix_timestamp(&apos;12-05-2010&apos;, &apos;dd-MM-yyyy&apos;))) as date)</span><br></pre></td></tr></table></figure>
<h1 id="MapJoin异常问题处理总结"><a href="#MapJoin异常问题处理总结" class="headerlink" title="MapJoin异常问题处理总结"></a>MapJoin异常问题处理总结</h1><p><a href="https://yq.aliyun.com/articles/64306" target="_blank" rel="noopener">https://yq.aliyun.com/articles/64306</a></p>
<h1 id="替换hive分隔符"><a href="#替换hive分隔符" class="headerlink" title="替换hive分隔符"></a>替换hive分隔符</h1><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sed -i &apos;.bak&apos; &apos;s/^A/,/g&apos; baseinfo05.csv</span><br></pre></td></tr></table></figure>
<p><code>^A</code>要用ctrl+V+A打出来</p>
<h1 id="Beeline导出csv后特殊符号"><a href="#Beeline导出csv后特殊符号" class="headerlink" title="Beeline导出csv后特殊符号"></a>Beeline导出csv后特殊符号</h1><p>导出csv后，由于某个字段（比如经纬度），本身就包括逗号，于是在导出时加上了特殊字符。</p>
<p>sublime打开是</p>
<p><img src="/.io//pic/image-20190704165407658.png" alt="image-20190704165407658"></p>
<p>于是搜索替换的方法，用vim打开后，</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">:%s/\%x00/&quot;/g</span><br></pre></td></tr></table></figure>
<p>就替换为了双引号，这样在读取csv的时候会将双引号自动转义</p>
<h1 id="LOAD-DATA"><a href="#LOAD-DATA" class="headerlink" title="LOAD DATA"></a>LOAD DATA</h1><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">LOAD DATA [LOCAL] INPATH &apos;filepath&apos; [OVERWRITE] INTO TABLE tablename[PARTITION (partcol1=val1,partcol2=val2,…)]</span><br></pre></td></tr></table></figure>
<p>最好不要用LOCAL，要从hadoop加载数据。local读的是hive服务器的本地路径。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"># coding:utf-8</span><br><span class="line">from pyhive import hive</span><br><span class="line">from TCLIService.ttypes import TOperationState</span><br><span class="line"></span><br><span class="line"># 打开hive连接</span><br><span class="line">hiveConn = hive.connect(host=&apos;192.168.83.135&apos;,port=11111,username=&apos;hadoop&apos;)</span><br><span class="line">cursor = hiveConn.cursor()</span><br><span class="line"></span><br><span class="line"># 执行sql语句</span><br><span class="line">sql = &apos;&apos;&apos; LOAD DATA LOCAL INPATH &apos;/home/hadoop/HivePy/employee.txt&apos; OVERWRITE INTO TABLE userdbbypy.employee &apos;&apos;&apos;</span><br><span class="line">cursor.execute(sql, async=True)</span><br><span class="line"></span><br><span class="line"># 得到执行语句的状态</span><br><span class="line">status = cursor.poll().operationState</span><br><span class="line">print &quot;status:&quot;,status</span><br><span class="line"></span><br><span class="line"># 关闭hive连接</span><br><span class="line">cursor.close()</span><br><span class="line">hiveConn.close()</span><br></pre></td></tr></table></figure>
<h1 id="return-code-3"><a href="#return-code-3" class="headerlink" title="return code 3"></a>return code 3</h1><p>试试</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">set hive.vectorized.execution.enabled=false;</span><br></pre></td></tr></table></figure>
<h1 id="hive锁表"><a href="#hive锁表" class="headerlink" title="hive锁表"></a>hive锁表</h1><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Completed compiling command</span><br></pre></td></tr></table></figure>
<p>若卡在上面的语句，说明锁表</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">show locks carthage_dev.baseinfo_personal_info;</span><br><span class="line">-- 如果是</span><br><span class="line"></span><br><span class="line">unlock table dwh_dml_risk_dev.rec_car_operation;</span><br><span class="line">show locks carthage_dev.baseinfo_personal_info partition(data_date=&apos;20180517&apos;);</span><br><span class="line">unlock table dwh_dml_risk_dev.rec_car_operation partition(data_date=&apos;2018-09-30&apos;);</span><br></pre></td></tr></table></figure>
<p>hive解锁的脚本是<code>all_hive_unlock.sh</code></p>
<h1 id="hive新增列报错"><a href="#hive新增列报错" class="headerlink" title="hive新增列报错"></a>hive新增列报错</h1><p>在添加字段是可以通过CASCADE关键字来，避免出现这种问题。如alter table table_name add columns(age int) CASCADE</p>
<p><a href="https://qubole.zendesk.com/hc/en-us/articles/115002396646-Hive-Null-Pointer-Exception-in-select-query-after-modifying-table-definition" target="_blank" rel="noopener">https://qubole.zendesk.com/hc/en-us/articles/115002396646-Hive-Null-Pointer-Exception-in-select-query-after-modifying-table-definition</a></p>
<blockquote>
<p>This can happen in the scenario where table definition and specific partition definition is different, and the underlying data matches table definition but not partition definition.</p>
<p>When a table with partitions is altered to add a column using statement:</p>
<p><em>ALTER TABLE <tablename> ADD COLUMNS (c1 int);</tablename></em></p>
<p>The table definition for existing partitions don’t get modified as per the above statement. As a result of this there is a mismatch between partition and table definition. </p>
<p>This is ok if the partition data matches the definition of partition, but if the data matches definition of table itself, NPE is thrown as there is a mismatch in data vs definition.</p>
<p>To avoid this issue, this statement should be used in hadoop2</p>
<p><em>ALTER TABLE <tablename> ADD COLUMNS (c1 int) CASCADE;</tablename></em> </p>
<p>In case of hadoop1, CASCADE option is not available. Hence, as long as the table is external table, following can be done:</p>
<ol>
<li>Drop and recreate partitions for this table</li>
<li>Alter partition definition for specific partition having issues</li>
</ol>
</blockquote>
<p>用了cascade 无效。</p>
<p>找到原因：</p>
<p>hive表是ORC格式的，因此cascade无效，若改成text格式则成功。</p>
<p>解决方案：</p>
<p>若必须是ORC格式，建表是先预留若干字段，后期改名字</p>
<h1 id="hive分区解锁"><a href="#hive分区解锁" class="headerlink" title="hive分区解锁"></a>hive分区解锁</h1><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">show locks carthage_dev.baseinfo_personal_info;</span><br><span class="line">unlock table carthage_dev.baseinfo_personal_info;</span><br><span class="line">show locks carthage_dev.baseinfo_personal_info partition(data_date=&apos;20180517&apos;);</span><br><span class="line">unlock table carthage_dev.baseinfo_personal_info partition(data_date=&apos;20180517&apos;);</span><br></pre></td></tr></table></figure>
<p>解锁的技巧：</p>
<p>1、定位哪张表锁住，可以分批执行sql，定位关键表</p>
<p>2、show locks并下载，观察锁表的状态，通过</p>
<p><code>show locks table extends</code>可以看依赖的表</p>
<p>3、用脚本all_hive_unlock.sh解锁</p>
<h2 id="hive-column-rename"><a href="#hive-column-rename" class="headerlink" title="hive column rename"></a>hive column rename</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">alter table carthage_dev.gps_wx_stop_status CHANGE stop_region_center_lon stop_status_center_lon string</span><br></pre></td></tr></table></figure>
<h1 id="hive配置"><a href="#hive配置" class="headerlink" title="hive配置"></a>hive配置</h1><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">-- 输出为gzip</span><br><span class="line">set hive.exec.compress.output=true;    </span><br><span class="line">set mapred.output.compression.codec=org.apache.hadoop.io.compress.GzipCodec;</span><br><span class="line">-- 输出为一个文件</span><br><span class="line">set mapred.reduce.tasks=1;</span><br></pre></td></tr></table></figure>
<h1 id="hive-timestamp转时间"><a href="#hive-timestamp转时间" class="headerlink" title="hive timestamp转时间"></a>hive timestamp转时间</h1><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">from_unixtime(unix_timestamp(),‘yyyy/MM/dd HH:mm:ss’);</span><br><span class="line"></span><br><span class="line">from_unixtime(cast(cast(time as bigint)/1000 as bigint),&apos;yyyy/MM/dd HH:mm:ss&apos;)</span><br></pre></td></tr></table></figure>
<h1 id="常用日期函数"><a href="#常用日期函数" class="headerlink" title="常用日期函数"></a>常用日期函数</h1><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">to_date：日期时间转日期函数    </span><br><span class="line">	select to_date(&apos;2018-04-02 13:34:12&apos;);   输出：2018-04-02   </span><br><span class="line">from_unixtime：转化unix时间戳到当前时区的时间格式    </span><br><span class="line">	select from_unixtime(1524573762,&apos;yyyy-MM-dd HH:mm:ss&apos;);    输出：2018-04-24 20:42:42</span><br><span class="line">unix_timestamp：获取当前unix时间戳    </span><br><span class="line">	select unix_timestamp();    输出：1524573762  </span><br><span class="line">	select unix_timestamp(&apos;2018-04-01 13:01:20&apos;);  输出：1522558880</span><br><span class="line">datediff：返回开始日期减去结束日期的天数    </span><br><span class="line">	select datediff(&apos;2018-04-09&apos;,&apos;2018-04-01&apos;);    输出：8    </span><br><span class="line">date_sub：返回日期前n天的日期    </span><br><span class="line">	select date_sub(&apos;2018-04-09&apos;,4);    输出：2018-04-05    </span><br><span class="line">date_add：返回日期后n天的日期    </span><br><span class="line">	select date_add(&apos;2018-04-09&apos;,4);    输出：2018-04-13  </span><br><span class="line">add_months：月份增加函数</span><br><span class="line">	select add_months(&apos;2018-02-10&apos;, 2 );    输出：2018-04-10 </span><br><span class="line">last_day：返回当月底日期</span><br><span class="line">	select last_day(&apos;2018-02-21&apos;);    输出：2018-02-28</span><br></pre></td></tr></table></figure>
<h1 id="hive-字符串函数"><a href="#hive-字符串函数" class="headerlink" title="hive 字符串函数"></a>hive 字符串函数</h1><p><strong>1. 字符串长度函数：length</strong></p>
<p>语法: length(string A)</p>
<p>返回值: int</p>
<p>说明：返回字符串A的长度</p>
<p>举例：</p>
<p>hive&gt; select length(‘abcedfg’) from lxw_dual;</p>
<p>7</p>
<p><strong>2. 字符串反转函数：reverse</strong></p>
<p>语法: reverse(string A)</p>
<p>返回值: string</p>
<p>说明：返回字符串A的反转结果</p>
<p>举例：</p>
<p>hive&gt; select reverse(abcedfg’) from lxw_dual;</p>
<p>gfdecba</p>
<p><strong>3. 字符串连接函数：concat</strong></p>
<p>语法: concat(string A, string B…)</p>
<p>返回值: string</p>
<p>说明：返回输入字符串连接后的结果，支持任意个输入字符串</p>
<p>举例：</p>
<p>hive&gt; select concat(‘abc’,’def’,’gh’) from lxw_dual;</p>
<p>abcdefgh</p>
<p><strong>4. 带分隔符字符串连接函数：concat_ws</strong></p>
<p>语法: concat_ws(string SEP, string A, string B…)</p>
<p>返回值: string</p>
<p>说明：返回输入字符串连接后的结果，SEP表示各个字符串间的分隔符</p>
<p>举例：</p>
<p>hive&gt; select concat_ws(‘,’,’abc’,’def’,’gh’) from lxw_dual;</p>
<p>abc,def,gh</p>
<p><strong>5. 字符串截取函数：substr,substring</strong></p>
<p>语法: substr(string A, int start),substring(string A, int start)</p>
<p>返回值: string</p>
<p>说明：返回字符串A从start位置到结尾的字符串</p>
<p>举例：</p>
<p>hive&gt; select substr(‘abcde’,3) from lxw_dual;</p>
<p>cde</p>
<p>hive&gt; select substring(‘abcde’,3) from lxw_dual;</p>
<p>cde</p>
<p>hive&gt;  selectsubstr(‘abcde’,-1) from lxw_dual;  （和ORACLE相同）</p>
<p>e</p>
<p><strong>6. 字符串截取函数：substr,substring</strong></p>
<p>语法: substr(string A, int start, int len),substring(string A, intstart, int len)</p>
<p>返回值: string</p>
<p>说明：返回字符串A从start位置开始，长度为len的字符串</p>
<p>举例：</p>
<p>hive&gt; select substr(‘abcde’,3,2) from lxw_dual;</p>
<p>cd</p>
<p>hive&gt; select substring(‘abcde’,3,2) from lxw_dual;</p>
<p>cd</p>
<p>hive&gt;select substring(‘abcde’,-2,2) from lxw_dual;</p>
<p>de</p>
<p><strong>7. 字符串转大写函数：upper,ucase</strong></p>
<p>语法: upper(string A) ucase(string A)</p>
<p>返回值: string</p>
<p>说明：返回字符串A的大写格式</p>
<p>举例：</p>
<p>hive&gt; select upper(‘abSEd’) from lxw_dual;</p>
<p>ABSED</p>
<p>hive&gt; select ucase(‘abSEd’) from lxw_dual;</p>
<p>ABSED</p>
<p><strong>8. 字符串转小写函数：lower,lcase</strong></p>
<p>语法: lower(string A) lcase(string A)</p>
<p>返回值: string</p>
<p>说明：返回字符串A的小写格式</p>
<p>举例：</p>
<p>hive&gt; select lower(‘abSEd’) from lxw_dual;</p>
<p>absed</p>
<p>hive&gt; select lcase(‘abSEd’) from lxw_dual;</p>
<p>absed</p>
<p><strong>9. 去空格函数：trim</strong></p>
<p>语法: trim(string A)</p>
<p>返回值: string</p>
<p>说明：去除字符串两边的空格</p>
<p>举例：</p>
<p>hive&gt; select trim(‘ abc ‘) from lxw_dual;</p>
<p>abc</p>
<p><strong>10. 左边去空格函数：ltrim</strong></p>
<p>语法: ltrim(string A)</p>
<p>返回值: string</p>
<p>说明：去除字符串左边的空格</p>
<p>举例：</p>
<p>hive&gt; select ltrim(‘ abc ‘) from lxw_dual;</p>
<p>abc</p>
<p><strong>11. 右边去空格函数：rtrim</strong></p>
<p>语法: rtrim(string A)</p>
<p>返回值: string</p>
<p>说明：去除字符串右边的空格</p>
<p>举例：</p>
<p>hive&gt; select rtrim(‘ abc ‘) from lxw_dual;</p>
<p>abc</p>
<p><strong>12. 正则表达式替换函数：regexp_replace</strong></p>
<p>语法: regexp_replace(string A, string B, string C)</p>
<p>返回值: string</p>
<p>说明：将字符串A中的符合java正则表达式B的部分替换为C。注意，在有些情况下要使用转义字符,类似oracle中的regexp_replace函数。</p>
<p>举例：</p>
<p>hive&gt; select regexp_replace(‘foobar’, ‘oo|ar’, ‘’) from lxw_dual;</p>
<p>fb</p>
<p><strong>13. 正则表达式解析函数：regexp_extract</strong></p>
<p>语法: regexp_extract(string subject, string pattern, int index)</p>
<p>返回值: string</p>
<p>说明：将字符串subject按照pattern正则表达式的规则拆分，返回index指定的字符。</p>
<p>举例：</p>
<p>hive&gt; select regexp_extract(‘foothebar’, ‘foo(.*?)(bar)’, 1) fromlxw_dual;</p>
<p>the</p>
<p>hive&gt; select regexp_extract(‘foothebar’, ‘foo(.*?)(bar)’, 2) fromlxw_dual;</p>
<p>bar</p>
<p>hive&gt; select regexp_extract(‘foothebar’, ‘foo(.*?)(bar)’, 0) fromlxw_dual;</p>
<p>foothebar</p>
<p><strong>注意，在有些情况下要使用转义字符，下面的等号要用双竖线转义，这是java**</strong>正则表达式的规则。**</p>
<p>select data_field,</p>
<p>​     regexp_extract(data_field,’.*?bgStart\=(<sup><a href="#fn_&" id="reffn_&">&</a></sup>+)’,1) as aaa,</p>
<p>​     regexp_extract(data_field,’.*?contentLoaded_headStart\=(<sup><a href="#fn_&" id="reffn_&">&</a></sup>+)’,1) as bbb,</p>
<p>​     regexp_extract(data_field,’.*?AppLoad2Req\=(<sup><a href="#fn_&" id="reffn_&">&</a></sup>+)’,1) as ccc</p>
<p>​     from pt_nginx_loginlog_st</p>
<p>​     where pt = ‘2012-03-26’limit 2;</p>
<p><strong>14. URL解析函数：parse_url</strong></p>
<p>语法: parse_url(string urlString, string partToExtract [, stringkeyToExtract])</p>
<p>返回值: string</p>
<p>说明：返回URL中指定的部分。partToExtract的有效值为：HOST, PATH, QUERY, REF, PROTOCOL, AUTHORITY, FILE, and USERINFO.</p>
<p>举例：</p>
<p>hive&gt; selectparse_url(‘<a href="http://facebook.com/path1/p.php?k1=v1&amp;k2=v2#Ref1" target="_blank" rel="noopener">http://facebook.com/path1/p.php?k1=v1&amp;k2=v2#Ref1</a>‘, ‘HOST’) fromlxw_dual;</p>
<p>facebook.com</p>
<p>hive&gt; selectparse_url(‘<a href="http://facebook.com/path1/p.php?k1=v1&amp;k2=v2#Ref1" target="_blank" rel="noopener">http://facebook.com/path1/p.php?k1=v1&amp;k2=v2#Ref1</a>‘, ‘QUERY’,’k1’) from lxw_dual;</p>
<p>v1</p>
<p><strong>15. json解析函数：get_json_object</strong></p>
<p>语法: get_json_object(string json_string, string path)</p>
<p>返回值: string</p>
<p>说明：解析json的字符串json_string,返回path指定的内容。如果输入的json字符串无效，那么返回NULL。</p>
<p>举例：</p>
<p>hive&gt; select get_json_object(‘{“store”:</p>
<p>>  {“fruit”:[{“weight”:8,”type”:”apple”},{“weight”:9,”type”:”pear”}],</p>
<p>>   “bicycle”:{“price”:19.95,”color”:”red”}</p>
<p>>   },</p>
<p>> “email”:”amy@only_for_json_udf_test.net”,</p>
<p>>  “owner”:”amy”</p>
<p>> }</p>
<p>> ‘,’$.owner’) from lxw_dual;</p>
<p>amy</p>
<p><strong>16. 空格字符串函数：space</strong></p>
<p>语法: space(int n)</p>
<p>返回值: string</p>
<p>说明：返回长度为n的字符串</p>
<p>举例：</p>
<p>hive&gt; select space(10) from lxw_dual;</p>
<p>hive&gt; select length(space(10)) from lxw_dual;</p>
<p>10</p>
<p><strong>17. 重复字符串函数：repeat</strong></p>
<p>语法: repeat(string str, int n)</p>
<p>返回值: string</p>
<p>说明：返回重复n次后的str字符串</p>
<p>举例：</p>
<p>hive&gt; select repeat(‘abc’,5) from lxw_dual;</p>
<p>abcabcabcabcabc</p>
<p><strong>18. 首字符ascii函数：ascii</strong></p>
<p>语法: ascii(string str)</p>
<p>返回值: int</p>
<p>说明：返回字符串str第一个字符的ascii码</p>
<p>举例：</p>
<p>hive&gt; select ascii(‘abcde’) from lxw_dual;</p>
<p>97</p>
<p><strong>19. 左补足函数：lpad</strong></p>
<p>语法: lpad(string str, int len, string pad)</p>
<p>返回值: string</p>
<p>说明：将str进行用pad进行左补足到len位</p>
<p>举例：</p>
<p>hive&gt; select lpad(‘abc’,10,’td’) from lxw_dual;</p>
<p>tdtdtdtabc</p>
<p><strong>注意：与GP**</strong>，ORACLE<strong>**不同，pad</strong> <strong>不能默认</strong></p>
<p><strong>20. 右补足函数：rpad</strong></p>
<p>语法: rpad(string str, int len, string pad)</p>
<p>返回值: string</p>
<p>说明：将str进行用pad进行右补足到len位</p>
<p>举例：</p>
<p>hive&gt; select rpad(‘abc’,10,’td’) from lxw_dual;</p>
<p>abctdtdtdt</p>
<p><strong>21. 分割字符串函数: split</strong></p>
<p>语法:  split(string str, stringpat)</p>
<p>返回值:  array</p>
<p>说明: 按照pat字符串分割str，会返回分割后的字符串数组</p>
<p>举例：</p>
<p>hive&gt; select split(‘abtcdtef’,’t’) from lxw_dual;</p>
<p>[“ab”,”cd”,”ef”]</p>
<p><strong>22. 集合查找函数:find_in_set</strong></p>
<p>语法: find_in_set(string str, string strList)</p>
<p>返回值: int</p>
<p>说明: 返回str在strlist第一次出现的位置，strlist是用逗号分割的字符串。如果没有找该str字符，则返回0</p>
<p>举例：</p>
<p>hive&gt; select find_in_set(‘ab’,’ef,ab,de’) from lxw_dual;</p>
<p>2</p>
<p>hive&gt; select find_in_set(‘at’,’ef,ab,de’) from lxw_dual;</p>
<p>0</p>
<p>instr</p>
<h1 id="group后拼接"><a href="#group后拼接" class="headerlink" title="group后拼接"></a>group后拼接</h1><p>group_concat( [distinct] 要连接的字段 [order by 排序字段 asc/desc ] [separator ‘分隔符’] )</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">select userid,bankid,group_concat(cast(creditlimit as string))</span><br><span class="line">from vdm_fin.cc_user_bill_0724</span><br><span class="line">group by userid,bankid</span><br></pre></td></tr></table></figure>
<p><img src="/.io//pic/70.png" alt="è¿éåå¾çæè¿°"></p>
<p><strong>hive实现相同的功能：</strong></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">SELECT id,</span><br><span class="line">concat_ws(&apos;|&apos;, collect_set(str)) </span><br><span class="line">FROM t  </span><br><span class="line">GROUP BY id;1234</span><br></pre></td></tr></table></figure>
<p>主意:collect_set 只能返回不重复的集合<br>若要返回带重复的要用collect_list</p>
<p>2、collect_list 展示子表排序后结果，collect_set 不受子表排序影响<br>select phone,collect_list(user_id) ,collect_set(user_id) from<br>(select * from a order by order_time asc)b<br>group by phone<br>结果：123456789    [1,1,3,2,2]    [1,3,2]</p>
<p>a表数据如下<br>phone    user_id order_time<br>123456789    1    2018/8/23<br>123456789    3    2018/8/24<br>123456789    2    2018/8/25<br>123456789    1    2018/8/22<br>123456789    2    2018/8/26</p>

      
    </div>

    

    
    
    

    

    
      
    
    

    

    <footer class="post-footer">
      
        
          
        
        <div class="post-tags">
          
            <a href="/tags/hive/" rel="tag"># hive</a>
          
        </div>
      

      
      
      

      
        <div class="post-nav">
          <div class="post-nav-next post-nav-item">
            
              <a href="/2018/03/31/地理信息挖掘/GeoHash/" rel="next" title="GeoHash">
                <i class="fa fa-chevron-left"></i> GeoHash
              </a>
            
          </div>

          <span class="post-nav-divider"></span>

          <div class="post-nav-prev post-nav-item">
            
              <a href="/2018/03/31/地理信息挖掘/经纬度找POI/" rel="prev" title="经纬度找POI">
                经纬度找POI <i class="fa fa-chevron-right"></i>
              </a>
            
          </div>
        </div>
      

      
      
    </footer>
  </div>
  
  
  
  </article>


  </div>


          </div>
          

  
    <div class="comments" id="comments">
      <div id="disqus_thread">
        <noscript>Please enable JavaScript to view the comments powered by Disqus.</noscript>
      </div>
    </div>

  



        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    <div class="sidebar-inner">

      

      
        <ul class="sidebar-nav motion-element">
          <li class="sidebar-nav-toc sidebar-nav-active" data-target="post-toc-wrap">
            文章目录
          </li>
          <li class="sidebar-nav-overview" data-target="site-overview-wrap">
            站点概览
          </li>
        </ul>
      

      <div class="site-overview-wrap sidebar-panel">
        <div class="site-overview">
          <div class="site-author motion-element" itemprop="author" itemscope="" itemtype="http://schema.org/Person">
            
              <p class="site-author-name" itemprop="name">Schwimmer</p>
              <div class="site-description motion-element" itemprop="description">Record and Think!</div>
          </div>

          
            <nav class="site-state motion-element">
              
                <div class="site-state-item site-state-posts">
                
                  <a href="/archives/">
                
                    <span class="site-state-item-count">300</span>
                    <span class="site-state-item-name">日志</span>
                  </a>
                </div>
              

              
                
                
                <div class="site-state-item site-state-categories">
                  
                    
                      <a href="/categories/">
                    
                  
                    
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                    <span class="site-state-item-count">23</span>
                    <span class="site-state-item-name">分类</span>
                  </a>
                </div>
              

              
                
                
                <div class="site-state-item site-state-tags">
                  
                    
                      <a href="/tags/">
                    
                  
                    
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                    <span class="site-state-item-count">60</span>
                    <span class="site-state-item-name">标签</span>
                  </a>
                </div>
              
            </nav>
          

          

          

          

          

          
          

          
            
          
          

        </div>
      </div>

      
      <!--noindex-->
        <div class="post-toc-wrap motion-element sidebar-panel sidebar-panel-active">
          <div class="post-toc">

            
            
            
            

            
              <div class="post-toc-content"><ol class="nav"><li class="nav-item nav-level-1"><a class="nav-link" href="#插入hive表控制part文件数量"><span class="nav-number">1.</span> <span class="nav-text">插入hive表控制part文件数量</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#strict模式"><span class="nav-number">2.</span> <span class="nav-text">strict模式</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#限制小文件数量"><span class="nav-number">3.</span> <span class="nav-text">限制小文件数量</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#查询时如何去掉重复数据"><span class="nav-number">4.</span> <span class="nav-text">查询时如何去掉重复数据</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#split后的数组长度"><span class="nav-number">5.</span> <span class="nav-text">split后的数组长度</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#切换队列"><span class="nav-number">6.</span> <span class="nav-text">切换队列</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#加载hdfs的udf"><span class="nav-number">7.</span> <span class="nav-text">加载hdfs的udf</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#Hive-Trash"><span class="nav-number">8.</span> <span class="nav-text">Hive Trash</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#性能"><span class="nav-number">9.</span> <span class="nav-text">性能</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#问题集"><span class="nav-number">10.</span> <span class="nav-text">问题集</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#查询ES表报错"><span class="nav-number">10.1.</span> <span class="nav-text">查询ES表报错</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#上传hive-UDF包后重启hive-server报错"><span class="nav-number">10.2.</span> <span class="nav-text">上传hive UDF包后重启hive server报错</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#hive-udf没有权限执行"><span class="nav-number">10.3.</span> <span class="nav-text">hive udf没有权限执行</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#没有找到jar包的报错"><span class="nav-number">10.4.</span> <span class="nav-text">没有找到jar包的报错</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#hive用高版本的UDF"><span class="nav-number">11.</span> <span class="nav-text">hive用高版本的UDF</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#String转date"><span class="nav-number">12.</span> <span class="nav-text">String转date</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#MapJoin异常问题处理总结"><span class="nav-number">13.</span> <span class="nav-text">MapJoin异常问题处理总结</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#替换hive分隔符"><span class="nav-number">14.</span> <span class="nav-text">替换hive分隔符</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#Beeline导出csv后特殊符号"><span class="nav-number">15.</span> <span class="nav-text">Beeline导出csv后特殊符号</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#LOAD-DATA"><span class="nav-number">16.</span> <span class="nav-text">LOAD DATA</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#return-code-3"><span class="nav-number">17.</span> <span class="nav-text">return code 3</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#hive锁表"><span class="nav-number">18.</span> <span class="nav-text">hive锁表</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#hive新增列报错"><span class="nav-number">19.</span> <span class="nav-text">hive新增列报错</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#hive分区解锁"><span class="nav-number">20.</span> <span class="nav-text">hive分区解锁</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#hive-column-rename"><span class="nav-number">20.1.</span> <span class="nav-text">hive column rename</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#hive配置"><span class="nav-number">21.</span> <span class="nav-text">hive配置</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#hive-timestamp转时间"><span class="nav-number">22.</span> <span class="nav-text">hive timestamp转时间</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#常用日期函数"><span class="nav-number">23.</span> <span class="nav-text">常用日期函数</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#hive-字符串函数"><span class="nav-number">24.</span> <span class="nav-text">hive 字符串函数</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#group后拼接"><span class="nav-number">25.</span> <span class="nav-text">group后拼接</span></a></li></ol></div>
            

          </div>
        </div>
      <!--/noindex-->
      

      

    </div>
  </aside>
  


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <div class="copyright">&copy; <span itemprop="copyrightYear">2019</span>
  <span class="with-love" id="animate">
    <i class="fa fa-user"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">Schwimmer</span>

  

  
</div>


  <div class="powered-by">由 <a href="https://hexo.io" class="theme-link" rel="noopener" target="_blank">Hexo</a> 强力驱动 v3.9.0</div>



  <span class="post-meta-divider">|</span>



  <div class="theme-info">主题 – <a href="https://theme-next.org" class="theme-link" rel="noopener" target="_blank">NexT.Mist</a> v7.2.0</div>




        
<div class="busuanzi-count">
  <script async src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>

  
    <span class="post-meta-item-icon">
      <i class="fa fa-user"></i>
    </span>
    <span class="site-uv" title="总访客量">
      <span class="busuanzi-value" id="busuanzi_value_site_uv"></span>
    </span>
  

  
    <span class="post-meta-divider">|</span>
  

  
    <span class="post-meta-item-icon">
      <i class="fa fa-eye"></i>
    </span>
    <span class="site-pv" title="总访问量">
      <span class="busuanzi-value" id="busuanzi_value_site_pv"></span>
    </span>
  
</div>









        
      </div>
    </footer>

    
      <div class="back-to-top">
        <i class="fa fa-arrow-up"></i>
        
      </div>
    

    

    
      <div>
        
  <script>
    window._bd_share_config = {
      "common": {
        "bdText": "",
        "bdMini": "1",
        "bdMiniList": false,
        "bdPic": ""
      },
      "image": {
        "viewList": ["tsina", "douban", "sqq", "qzone", "weixin", "twi", "fbook"],
        "viewText": "分享到：",
        "viewSize": "16"
      },
      "slide": {
        "bdImg": "5",
        "bdPos": "left",
        "bdTop": "100"
      }
    }
  </script>

<script>
  with(document)0[(getElementsByTagName('head')[0]||body).appendChild(createElement('script')).src='//bdimg.share.baidu.com/static/api/js/share.js?cdnversion='+~(-new Date()/36e5)];
</script>

      </div>
    

    
  </div>

  

<script>
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>


























  
  <script src="/lib/jquery/index.js?v=3.4.1"></script>

  
  <script src="/lib/velocity/velocity.min.js?v=1.2.1"></script>

  
  <script src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>


  


  <script src="/js/utils.js?v=7.2.0"></script>

  <script src="/js/motion.js?v=7.2.0"></script>



  
  


  <script src="/js/schemes/muse.js?v=7.2.0"></script>




  
  <script src="/js/scrollspy.js?v=7.2.0"></script>
<script src="/js/post-details.js?v=7.2.0"></script>



  


  <script src="/js/next-boot.js?v=7.2.0"></script>


  

  

  

  
  
<script>
  function loadCount() {
    var d = document, s = d.createElement('script');
    s.src = 'https://https-schwimmer-github-io.disqus.com/count.js';
    s.id = 'dsq-count-scr';
    (d.head || d.body).appendChild(s);
  }
  // defer loading until the whole page loading is completed
  window.addEventListener('load', loadCount, false);
</script>


<script>
  var disqus_config = function() {
    this.page.url = "https://schwimmer.github.io/2018/03/31/hadoop-spark/hive笔记/";
    this.page.identifier = "2018/03/31/hadoop-spark/hive笔记/";
    this.page.title = 'hive技巧总结';
    };
  function loadComments() {
    var d = document, s = d.createElement('script');
    s.src = 'https://https-schwimmer-github-io.disqus.com/embed.js';
    s.setAttribute('data-timestamp', '' + +new Date());
    (d.head || d.body).appendChild(s);
  }
  
    window.addEventListener('load', loadComments, false);
  
</script>





  


  
  <script>
    // Popup Window;
    var isfetched = false;
    var isXml = true;
    // Search DB path;
    var search_path = "search.xml";
    if (search_path.length === 0) {
      search_path = "search.xml";
    } else if (/json$/i.test(search_path)) {
      isXml = false;
    }
    var path = "/" + search_path;
    // monitor main search box;

    var onPopupClose = function (e) {
      $('.popup').hide();
      $('#local-search-input').val('');
      $('.search-result-list').remove();
      $('#no-result').remove();
      $(".local-search-pop-overlay").remove();
      $('body').css('overflow', '');
    }

    function proceedsearch() {
      $("body")
        .append('<div class="search-popup-overlay local-search-pop-overlay"></div>')
        .css('overflow', 'hidden');
      $('.search-popup-overlay').click(onPopupClose);
      $('.popup').toggle();
      var $localSearchInput = $('#local-search-input');
      $localSearchInput.attr("autocapitalize", "none");
      $localSearchInput.attr("autocorrect", "off");
      $localSearchInput.focus();
    }

    // search function;
    var searchFunc = function(path, search_id, content_id) {
      'use strict';

      // start loading animation
      $("body")
        .append('<div class="search-popup-overlay local-search-pop-overlay">' +
          '<div id="search-loading-icon">' +
          '<i class="fa fa-spinner fa-pulse fa-5x fa-fw"></i>' +
          '</div>' +
          '</div>')
        .css('overflow', 'hidden');
      $("#search-loading-icon").css('margin', '20% auto 0 auto').css('text-align', 'center');

      

      $.ajax({
        url: path,
        dataType: isXml ? "xml" : "json",
        async: true,
        success: function(res) {
          // get the contents from search data
          isfetched = true;
          $('.popup').detach().appendTo('.header-inner');
          var datas = isXml ? $("entry", res).map(function() {
            return {
              title: $("title", this).text(),
              content: $("content",this).text(),
              url: $("url" , this).text()
            };
          }).get() : res;
          var input = document.getElementById(search_id);
          var resultContent = document.getElementById(content_id);
          var inputEventFunction = function() {
            var searchText = input.value.trim().toLowerCase();
            var keywords = searchText.split(/[\s\-]+/);
            if (keywords.length > 1) {
              keywords.push(searchText);
            }
            var resultItems = [];
            if (searchText.length > 0) {
              // perform local searching
              datas.forEach(function(data) {
                var isMatch = false;
                var hitCount = 0;
                var searchTextCount = 0;
                var title = data.title.trim();
                var titleInLowerCase = title.toLowerCase();
                var content = data.content.trim().replace(/<[^>]+>/g,"");
                
                var contentInLowerCase = content.toLowerCase();
                var articleUrl = decodeURIComponent(data.url).replace(/\/{2,}/g, '/');
                var indexOfTitle = [];
                var indexOfContent = [];
                // only match articles with not empty titles
                if(title != '') {
                  keywords.forEach(function(keyword) {
                    function getIndexByWord(word, text, caseSensitive) {
                      var wordLen = word.length;
                      if (wordLen === 0) {
                        return [];
                      }
                      var startPosition = 0, position = [], index = [];
                      if (!caseSensitive) {
                        text = text.toLowerCase();
                        word = word.toLowerCase();
                      }
                      while ((position = text.indexOf(word, startPosition)) > -1) {
                        index.push({position: position, word: word});
                        startPosition = position + wordLen;
                      }
                      return index;
                    }

                    indexOfTitle = indexOfTitle.concat(getIndexByWord(keyword, titleInLowerCase, false));
                    indexOfContent = indexOfContent.concat(getIndexByWord(keyword, contentInLowerCase, false));
                  });
                  if (indexOfTitle.length > 0 || indexOfContent.length > 0) {
                    isMatch = true;
                    hitCount = indexOfTitle.length + indexOfContent.length;
                  }
                }

                // show search results

                if (isMatch) {
                  // sort index by position of keyword

                  [indexOfTitle, indexOfContent].forEach(function (index) {
                    index.sort(function (itemLeft, itemRight) {
                      if (itemRight.position !== itemLeft.position) {
                        return itemRight.position - itemLeft.position;
                      } else {
                        return itemLeft.word.length - itemRight.word.length;
                      }
                    });
                  });

                  // merge hits into slices

                  function mergeIntoSlice(text, start, end, index) {
                    var item = index[index.length - 1];
                    var position = item.position;
                    var word = item.word;
                    var hits = [];
                    var searchTextCountInSlice = 0;
                    while (position + word.length <= end && index.length != 0) {
                      if (word === searchText) {
                        searchTextCountInSlice++;
                      }
                      hits.push({position: position, length: word.length});
                      var wordEnd = position + word.length;

                      // move to next position of hit

                      index.pop();
                      while (index.length != 0) {
                        item = index[index.length - 1];
                        position = item.position;
                        word = item.word;
                        if (wordEnd > position) {
                          index.pop();
                        } else {
                          break;
                        }
                      }
                    }
                    searchTextCount += searchTextCountInSlice;
                    return {
                      hits: hits,
                      start: start,
                      end: end,
                      searchTextCount: searchTextCountInSlice
                    };
                  }

                  var slicesOfTitle = [];
                  if (indexOfTitle.length != 0) {
                    slicesOfTitle.push(mergeIntoSlice(title, 0, title.length, indexOfTitle));
                  }

                  var slicesOfContent = [];
                  while (indexOfContent.length != 0) {
                    var item = indexOfContent[indexOfContent.length - 1];
                    var position = item.position;
                    var word = item.word;
                    // cut out 100 characters
                    var start = position - 20;
                    var end = position + 80;
                    if(start < 0){
                      start = 0;
                    }
                    if (end < position + word.length) {
                      end = position + word.length;
                    }
                    if(end > content.length){
                      end = content.length;
                    }
                    slicesOfContent.push(mergeIntoSlice(content, start, end, indexOfContent));
                  }

                  // sort slices in content by search text's count and hits' count

                  slicesOfContent.sort(function (sliceLeft, sliceRight) {
                    if (sliceLeft.searchTextCount !== sliceRight.searchTextCount) {
                      return sliceRight.searchTextCount - sliceLeft.searchTextCount;
                    } else if (sliceLeft.hits.length !== sliceRight.hits.length) {
                      return sliceRight.hits.length - sliceLeft.hits.length;
                    } else {
                      return sliceLeft.start - sliceRight.start;
                    }
                  });

                  // select top N slices in content

                  var upperBound = parseInt('1');
                  if (upperBound >= 0) {
                    slicesOfContent = slicesOfContent.slice(0, upperBound);
                  }

                  // highlight title and content

                  function highlightKeyword(text, slice) {
                    var result = '';
                    var prevEnd = slice.start;
                    slice.hits.forEach(function (hit) {
                      result += text.substring(prevEnd, hit.position);
                      var end = hit.position + hit.length;
                      result += '<b class="search-keyword">' + text.substring(hit.position, end) + '</b>';
                      prevEnd = end;
                    });
                    result += text.substring(prevEnd, slice.end);
                    return result;
                  }

                  var resultItem = '';

                  if (slicesOfTitle.length != 0) {
                    resultItem += "<li><a href='" + articleUrl + "' class='search-result-title'>" + highlightKeyword(title, slicesOfTitle[0]) + "</a>";
                  } else {
                    resultItem += "<li><a href='" + articleUrl + "' class='search-result-title'>" + title + "</a>";
                  }

                  slicesOfContent.forEach(function (slice) {
                    resultItem += "<a href='" + articleUrl + "'>" +
                      "<p class=\"search-result\">" + highlightKeyword(content, slice) +
                      "...</p>" + "</a>";
                  });

                  resultItem += "</li>";
                  resultItems.push({
                    item: resultItem,
                    searchTextCount: searchTextCount,
                    hitCount: hitCount,
                    id: resultItems.length
                  });
                }
              })
            };
            if (keywords.length === 1 && keywords[0] === "") {
              resultContent.innerHTML = '<div id="no-result"><i class="fa fa-search fa-5x"></i></div>'
            } else if (resultItems.length === 0) {
              resultContent.innerHTML = '<div id="no-result"><i class="fa fa-frown-o fa-5x"></i></div>'
            } else {
              resultItems.sort(function (resultLeft, resultRight) {
                if (resultLeft.searchTextCount !== resultRight.searchTextCount) {
                  return resultRight.searchTextCount - resultLeft.searchTextCount;
                } else if (resultLeft.hitCount !== resultRight.hitCount) {
                  return resultRight.hitCount - resultLeft.hitCount;
                } else {
                  return resultRight.id - resultLeft.id;
                }
              });
              var searchResultList = '<ul class=\"search-result-list\">';
              resultItems.forEach(function (result) {
                searchResultList += result.item;
              })
              searchResultList += "</ul>";
              resultContent.innerHTML = searchResultList;
            }
          }

          if ('auto' === 'auto') {
            input.addEventListener('input', inputEventFunction);
          } else {
            $('.search-icon').click(inputEventFunction);
            input.addEventListener('keypress', function (event) {
              if (event.keyCode === 13) {
                inputEventFunction();
              }
            });
          }

          // remove loading animation
          $(".local-search-pop-overlay").remove();
          $('body').css('overflow', '');

          proceedsearch();
        }
      });
    }

    // handle and trigger popup window;
    $('.popup-trigger').click(function(e) {
      e.stopPropagation();
      if (isfetched === false) {
        searchFunc(path, 'local-search-input', 'local-search-result');
      } else {
        proceedsearch();
      };
    });

    $('.popup-btn-close').click(onPopupClose);
    $('.popup').click(function(e){
      e.stopPropagation();
    });
    $(document).on('keyup', function (event) {
      var shouldDismissSearchPopup = event.which === 27 &&
        $('.search-popup').is(':visible');
      if (shouldDismissSearchPopup) {
        onPopupClose();
      }
    });
  </script>





  

  

  
  

  
  

  
    
      <script type="text/x-mathjax-config">
  

  MathJax.Hub.Config({
    tex2jax: {
      inlineMath: [ ['$', '$'], ['\\(', '\\)'] ],
      processEscapes: true,
      skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
    },
    TeX: {
      
      equationNumbers: {
        autoNumber: 'AMS'
      }
    }
  });
  MathJax.Hub.Register.StartupHook('TeX Jax Ready', function() {
    MathJax.InputJax.TeX.prefilterHooks.Add(function(data) {
      if (data.display) {
        var next = data.script.nextSibling;
        while (next && next.nodeName.toLowerCase() === '#text') { next = next.nextSibling }
        if (next && next.nodeName.toLowerCase() === 'br') { next.parentNode.removeChild(next) }
      }
    });
  });
</script>

<script type="text/x-mathjax-config">
  MathJax.Hub.Queue(function() {
    var all = MathJax.Hub.getAllJax(), i;
    for (i = 0; i < all.length; i += 1) {
      document.getElementById(all[i].inputID + '-Frame').parentNode.className += ' has-jax';
    }
  });
</script>
<script src="//cdn.jsdelivr.net/npm/mathjax@2/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script><!-- hexo-inject:begin --><!-- Begin: Injected MathJax -->
<script type="text/x-mathjax-config">
  MathJax.Hub.Config({"tex2jax":{"inlineMath":[["$","$"],["\\(","\\)"]],"skipTags":["script","noscript","style","textarea","pre","code"],"processEscapes":true},"TeX":{"equationNumbers":{"autoNumber":"AMS"}}});
</script>

<script type="text/x-mathjax-config">
  MathJax.Hub.Queue(function() {
    var all = MathJax.Hub.getAllJax(), i;
    for(i=0; i < all.length; i += 1) {
      all[i].SourceElement().parentNode.className += ' has-jax';
    }
  });
</script>

<script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js">
</script>
<!-- End: Injected MathJax -->
<!-- hexo-inject:end -->

    
  


  

  

  

  

  

  

  

  

  

  

  

</body>
</html>
