<!doctype html>



  


<html class="theme-next pisces use-motion" lang="zh-Hans">
<head>
  <!-- hexo-inject:begin --><!-- hexo-inject:end --><meta charset="UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=edge" />
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"/>



<meta http-equiv="Cache-Control" content="no-transform" />
<meta http-equiv="Cache-Control" content="no-siteapp" />



  <meta name="google-site-verification" content="Mx7Ikp0IpBtTbSpHDTBV0_CMJA-E8CLn8NRIrwyq5m4" />






<meta name="baidu-site-verification" content="ZBTsWx4NdC" />






  
  
  <link href="/lib/fancybox/source/jquery.fancybox.css?v=2.1.5" rel="stylesheet" type="text/css" />




  
  
  
  

  
    
    
  

  
    
      
    

    
  

  

  
    
      
    

    
  

  
    
      
    

    
  

  
    
    
    <link href="//fonts.googleapis.com/css?family=Lato:300,300italic,400,400italic,700,700italic|Roboto Slab:300,300italic,400,400italic,700,700italic|Lobster Two:300,300italic,400,400italic,700,700italic|PT Mono:300,300italic,400,400italic,700,700italic&subset=latin,latin-ext" rel="stylesheet" type="text/css">
  






<link href="/lib/font-awesome/css/font-awesome.min.css?v=4.6.2" rel="stylesheet" type="text/css" />

<link href="/css/main.css?v=5.1.0" rel="stylesheet" type="text/css" />


  <meta name="keywords" content="记录笔记的地方" />








  <link rel="shortcut icon" type="image/x-icon" href="/favicon.ico?v=5.1.0" />






<meta name="description" content="大致分为3类： 1、Value数据类型的Transformation算子。不触发提交作业，针对处理的数据项是Value型的数据。 2、Key-Value型的Transformation算子。针对Key-Value数据对。 3、Action算子。触发SparkContext提交Job。 Value型Transformation算子可以根据RDD变换算子的输入分区与输出分区关系分为以下几个类型：  输">
<meta property="og:type" content="article">
<meta property="og:title" content="spark算子分类及功能">
<meta property="og:url" content="https://schwimmer.github.io/2018/04/03/hadoop-spark/spark/spark算子分类及功能/index.html">
<meta property="og:site_name" content="Schwimmer&#39;s Blog">
<meta property="og:description" content="大致分为3类： 1、Value数据类型的Transformation算子。不触发提交作业，针对处理的数据项是Value型的数据。 2、Key-Value型的Transformation算子。针对Key-Value数据对。 3、Action算子。触发SparkContext提交Job。 Value型Transformation算子可以根据RDD变换算子的输入分区与输出分区关系分为以下几个类型：  输">
<meta property="og:locale" content="zh-Hans">
<meta property="og:image" content="https://schwimmer.github.io/2018/04/03/hadoop-spark/spark/spark算子分类及功能/glom.png">
<meta property="og:image" content="https://schwimmer.github.io/2018/04/03/hadoop-spark/spark/spark算子分类及功能/cartesian.png">
<meta property="og:image" content="https://schwimmer.github.io/2018/04/03/hadoop-spark/spark/spark算子分类及功能/takeSample.png">
<meta property="og:image" content="https://schwimmer.github.io/2018/04/03/hadoop-spark/spark/spark算子分类及功能/cache.png">
<meta property="og:image" content="https://schwimmer.github.io/2018/04/03/hadoop-spark/spark/spark算子分类及功能/persist缓存模式.png">
<meta property="og:image" content="https://schwimmer.github.io/2018/04/03/hadoop-spark/spark/spark算子分类及功能/combineByKey.png">
<meta property="og:image" content="https://schwimmer.github.io/2018/04/03/hadoop-spark/spark/spark算子分类及功能/reduceByKey.png">
<meta property="og:image" content="https://schwimmer.github.io/2018/04/03/hadoop-spark/spark/spark算子分类及功能/reduce.png">
<meta property="og:updated_time" content="2018-04-07T14:14:09.023Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="spark算子分类及功能">
<meta name="twitter:description" content="大致分为3类： 1、Value数据类型的Transformation算子。不触发提交作业，针对处理的数据项是Value型的数据。 2、Key-Value型的Transformation算子。针对Key-Value数据对。 3、Action算子。触发SparkContext提交Job。 Value型Transformation算子可以根据RDD变换算子的输入分区与输出分区关系分为以下几个类型：  输">
<meta name="twitter:image" content="https://schwimmer.github.io/2018/04/03/hadoop-spark/spark/spark算子分类及功能/glom.png">



<script type="text/javascript" id="hexo.configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '/',
    scheme: 'Pisces',
    sidebar: {"position":"left","display":"always","offset":12,"offset_float":0,"b2t":false,"scrollpercent":false},
    fancybox: true,
    motion: true,
    duoshuo: {
      userId: '0',
      author: '博主'
    },
    algolia: {
      applicationID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    }
  };
</script>



  <link rel="canonical" href="https://schwimmer.github.io/2018/04/03/hadoop-spark/spark/spark算子分类及功能/"/>





  <title> spark算子分类及功能 | Schwimmer's Blog </title><!-- hexo-inject:begin --><!-- hexo-inject:end -->
</head>

<body itemscope itemtype="http://schema.org/WebPage" lang="zh-Hans">

  














  
  
    
  

  <!-- hexo-inject:begin --><!-- hexo-inject:end --><div class="container sidebar-position-left page-post-detail ">
    <div class="headband"></div>

    <header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-wrapper">
  <div class="site-meta ">
    

    <div class="custom-logo-site-title">
      <a href="/"  class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">Schwimmer's Blog</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
      
        <h1 class="site-subtitle" itemprop="description"></h1>
      
  </div>

  <div class="site-nav-toggle">
    <button>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
    </button>
  </div>
</div>

<nav class="site-nav">
  

  
    <ul id="menu" class="menu">
      
        
        <li class="menu-item menu-item-home">
          <a href="/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-home"></i> <br />
            
            首页
          </a>
        </li>
      
        
        <li class="menu-item menu-item-categories">
          <a href="/categories" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-th"></i> <br />
            
            分类
          </a>
        </li>
      
        
        <li class="menu-item menu-item-archives">
          <a href="/archives" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-archive"></i> <br />
            
            归档
          </a>
        </li>
      
        
        <li class="menu-item menu-item-tags">
          <a href="/tags" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-tags"></i> <br />
            
            标签
          </a>
        </li>
      

      
        <li class="menu-item menu-item-search">
          
            <a href="javascript:;" class="popup-trigger">
          
            
              <i class="menu-item-icon fa fa-search fa-fw"></i> <br />
            
            搜索
          </a>
        </li>
      
    </ul>
  

  
    <div class="site-search">
      
  <div class="popup search-popup local-search-popup">
  <div class="local-search-header clearfix">
    <span class="search-icon">
      <i class="fa fa-search"></i>
    </span>
    <span class="popup-btn-close">
      <i class="fa fa-times-circle"></i>
    </span>
    <div class="local-search-input-wrapper">
      <input autocapitalize="off" autocomplete="off" autocorrect="off"
             placeholder="搜索..." spellcheck="false"
             type="text" id="local-search-input">
    </div>
  </div>
  <div id="local-search-result"></div>
</div>



    </div>
  
</nav>



 </div>
    </header>

    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          <div id="content" class="content">
            

  <div id="posts" class="posts-expand">
    

  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">
    <link itemprop="mainEntityOfPage" href="https://schwimmer.github.io/2018/04/03/hadoop-spark/spark/spark算子分类及功能/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Schwimmer">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Schwimmer's Blog">
    </span>

    
      <header class="post-header">

        
        
          <h2 class="post-title" itemprop="name headline">
            
            
              
                spark算子分类及功能
              
            
          </h2>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2018-04-03T21:55:41+08:00">
                2018-04-03
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/spark/" itemprop="url" rel="index">
                    <span itemprop="name">spark</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
            <!--noindex-->
              <span class="post-comments-count">
                <span class="post-meta-divider">|</span>
                <span class="post-meta-item-icon">
                  <i class="fa fa-comment-o"></i>
                </span>
                <a href="/2018/04/03/hadoop-spark/spark/spark算子分类及功能/#comments" itemprop="discussionUrl">
                  <span class="post-comments-count hc-comment-count" data-xid="2018/04/03/hadoop-spark/spark/spark算子分类及功能/" itemprop="commentsCount"></span>
                </a>
              </span>
              <!--/noindex-->
            
          

          
          

          

          

          

        </div>
      </header>
    


    <div class="post-body" itemprop="articleBody">

      
      

      
        <p>大致分为3类：</p>
<p>1、Value数据类型的Transformation算子。不触发提交作业，针对处理的数据项是Value型的数据。</p>
<p>2、Key-Value型的Transformation算子。针对Key-Value数据对。</p>
<p>3、Action算子。触发SparkContext提交Job。</p>
<h1 id="Value型Transformation算子"><a href="#Value型Transformation算子" class="headerlink" title="Value型Transformation算子"></a>Value型Transformation算子</h1><p>可以根据RDD变换算子的输入分区与输出分区关系分为以下几个类型：</p>
<ul>
<li>输入分区和输出分区一对一型；</li>
<li>多对一型；</li>
<li>多对多型；</li>
<li>输出为输入子集型。</li>
</ul>
<h2 id="一对一型"><a href="#一对一型" class="headerlink" title="一对一型"></a>一对一型</h2><h3 id="map"><a href="#map" class="headerlink" title="map"></a>map</h3><p>等action触发提交后，在同一个stage中运算。</p>
<h3 id="flatMap"><a href="#flatMap" class="headerlink" title="flatMap"></a>flatMap</h3><h3 id="mapPartitions"><a href="#mapPartitions" class="headerlink" title="mapPartitions"></a>mapPartitions</h3><p>map是对rdd中的每一个元素进行操作，而mapPartitions(foreachPartition)则是对rdd中的<strong>每个分区的迭代器</strong>进行操作。</p>
<p>如果在map过程中需要频繁创建额外的对象(例如将rdd中的数据通过jdbc写入<a href="http://lib.csdn.net/base/mysql" target="_blank" rel="noopener">数据库</a>,map需要为每个元素创建一个链接而mapPartition为每个partition创建一个链接),则mapPartitions效率比map高的多。</p>
<p>SparkSql或DataFrame默认会对程序进行mapPartition的优化。</p>
<h3 id="glom"><a href="#glom" class="headerlink" title="glom"></a>glom</h3><p>将每个RDD分区形成一个数组。</p>
<p><img src="/2018/04/03/hadoop-spark/spark/spark算子分类及功能/glom.png" alt=""></p>
<h2 id="多对一型"><a href="#多对一型" class="headerlink" title="多对一型"></a>多对一型</h2><h3 id="union"><a href="#union" class="headerlink" title="union"></a>union</h3><p>++符号相当于union</p>
<h2 id="cartesian"><a href="#cartesian" class="headerlink" title="cartesian"></a>cartesian</h2><p>对两个RDD中所有元素进行笛卡尔积操作。</p>
<p><img src="/2018/04/03/hadoop-spark/spark/spark算子分类及功能/cartesian.png" alt=""></p>
<h2 id="多对多型"><a href="#多对多型" class="headerlink" title="多对多型"></a>多对多型</h2><h3 id="groupBy"><a href="#groupBy" class="headerlink" title="groupBy"></a>groupBy</h3><p>例如</p>
<p>1）将用户数据预处理</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">val cleanF = sc.clean(f)</div></pre></td></tr></table></figure>
<p>2）对数据map进行函数操作，最后再对groupByKey进行分组操作</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">this.map(t =&gt; (cleanF(t), t)).groupByKey(p)</div></pre></td></tr></table></figure>
<p>其中，p确定了分区个数和分区函数，也就决定了并行化的程度。</p>
<h2 id="子集型"><a href="#子集型" class="headerlink" title="子集型"></a>子集型</h2><h3 id="filter"><a href="#filter" class="headerlink" title="filter"></a>filter</h3><h3 id="distinct"><a href="#distinct" class="headerlink" title="distinct"></a>distinct</h3><h3 id="substract"><a href="#substract" class="headerlink" title="substract"></a>substract</h3><p>集合的差操作。RDD1去除RDD2交集中的所有元素。</p>
<h3 id="sample"><a href="#sample" class="headerlink" title="sample"></a>sample</h3><p>采样。可以设定有放回的采样、百分比、随机种子。</p>
<h3 id="takeSample"><a href="#takeSample" class="headerlink" title="takeSample"></a>takeSample</h3><p>不使用相对比例采样，而是按设定的采样个数进行采样。同时返回结果也不是RDD，而是相当于对采样后的数据进行Collect()，返回单机的数组。</p>
<p><img src="/2018/04/03/hadoop-spark/spark/spark算子分类及功能/takeSample.png" alt=""></p>
<h2 id="Cache型"><a href="#Cache型" class="headerlink" title="Cache型"></a>Cache型</h2><h3 id="cache"><a href="#cache" class="headerlink" title="cache"></a>cache</h3><p>将RDD从磁盘缓存到内存，相当于<code>persist(MEMORY_ONLY)</code> 的功能。</p>
<p><img src="/2018/04/03/hadoop-spark/spark/spark算子分类及功能/cache.png" alt=""></p>
<h2 id="persist"><a href="#persist" class="headerlink" title="persist"></a>persist</h2><p>缓存到哪里，由StorageLevel枚举类型决定。有以下几种类型的组合：DISK磁盘，MEMORY内存，SER数据是否序列化存储。可以缓存的模式有</p>
<p><img src="/2018/04/03/hadoop-spark/spark/spark算子分类及功能/persist缓存模式.png" alt=""></p>
<h1 id="Key-Value型Transformation算子"><a href="#Key-Value型Transformation算子" class="headerlink" title="Key-Value型Transformation算子"></a>Key-Value型Transformation算子</h1><h2 id="输入和输出分区一对一"><a href="#输入和输出分区一对一" class="headerlink" title="输入和输出分区一对一"></a>输入和输出分区一对一</h2><h3 id="mapValues"><a href="#mapValues" class="headerlink" title="mapValues"></a>mapValues</h3><p>针对(Key, Value)型数据中的Value进行Map操作，而不对key进行处理。</p>
<p>比如<code>a=&gt;a+2</code>只对value进行+2操作</p>
<h2 id="对单个或两个RDD聚集"><a href="#对单个或两个RDD聚集" class="headerlink" title="对单个或两个RDD聚集"></a>对单个或两个RDD聚集</h2><p>单个RDD聚集</p>
<h3 id="combineByKey"><a href="#combineByKey" class="headerlink" title="combineByKey"></a>combineByKey</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line">combineByKey[C](createCombiner:(V)=&gt; C,</div><div class="line">mergeValue:(C, V)=&gt; C,</div><div class="line">mergeCombiners:(C, C)=&gt; C,</div><div class="line">partitioner: Partitioner</div><div class="line">mapSideCombine: Boolean = true,</div><div class="line">serializer: Serializer =null): RDD[(K, C)]</div></pre></td></tr></table></figure>
<p>其中，</p>
<p><code>createCombiner:(V)=&gt;C</code> 会遍历分区中的所有元素，因此每个元素的键要么还没有遇到过，要么就<br>和之前的某个元素的键相同。如果这是一个新的元素， combineByKey() 会使用一个叫作 createCombiner() 的函数来创建 。</p>
<p><code>mergeValue</code> 当C已经存在的情况下,需要merge,如把item V加到seq C中,或者叠加。</p>
<p><code>mergeCombiners</code> 合并两个C</p>
<p><code>partitioner</code> 分区器，Shuffle时需要通过Partitioner的分区策略进行分区。</p>
<p><code>mapSideCombine</code> 为了减小传输量,很多combine可以在map端先做。例如,叠加可以先在一个partition中把所有相同的Key的Value叠加，再shuffle。</p>
<p><code>serializer</code> 传输序列化</p>
<p>整个过程相当于将元素为<code>(int,int)</code>的转变为了<code>(int, Seq[Int])</code>的RDD。</p>
<p><img src="/2018/04/03/hadoop-spark/spark/spark算子分类及功能/combineByKey.png" alt=""></p>
<h3 id="reduceByKey"><a href="#reduceByKey" class="headerlink" title="reduceByKey"></a>reduceByKey</h3><p>是combineByKey的一种简单情况。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">def reduceByKey(partitioner: Partitioner, func: (V, V) =&gt; V): RDD[(K, V)] = &#123;</div><div class="line">	combineByKey[V]((v: V) =&gt; v, func, func, partitioner)</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<p><img src="/2018/04/03/hadoop-spark/spark/spark算子分类及功能/reduceByKey.png" alt=""></p>
<h3 id="combineByKey和reduceByKey区别"><a href="#combineByKey和reduceByKey区别" class="headerlink" title="combineByKey和reduceByKey区别"></a>combineByKey和reduceByKey区别</h3><p>转自<a href="https://www.zhihu.com/question/45420080/answer/99044117" target="_blank" rel="noopener">请教Spark 中 combinebyKey 和 reduceByKey的传入函数参数的区别？</a>例如：</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">val</span> testData = sc.parallelize(<span class="type">Seq</span>((<span class="string">"t1"</span>, <span class="number">1</span>), (<span class="string">"t1"</span>, <span class="number">2</span>), (<span class="string">"t1"</span>, <span class="number">3</span>), (<span class="string">"t2"</span>, <span class="number">2</span>), (<span class="string">"t2"</span>, <span class="number">5</span>)))</div><div class="line"><span class="keyword">val</span> testDataCombine = testData.combineByKey(x=&gt;x,(x:<span class="type">Int</span>,y:<span class="type">Int</span>)=&gt;x+y,(x:<span class="type">Int</span>,y:<span class="type">Int</span>)=&gt;x+y)</div><div class="line"><span class="keyword">val</span> testDataReduce = testData.reduceByKey((x,y)=&gt;x+y)</div></pre></td></tr></table></figure>
<p>combineByKey要指定x和y的Int类型，不然会报错无法识别”+”这个方法符，而reduceByKey不用指派类型。</p>
<p>从两者的方法签名</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div></pre></td><td class="code"><pre><div class="line"><span class="class"><span class="keyword">class</span> <span class="title">PairRDDFunctions</span>[<span class="type">K</span>, <span class="type">V</span>](<span class="params">...</span>) </span>&#123;</div><div class="line">  <span class="function"><span class="keyword">def</span> <span class="title">reduceByKey</span></span>(func: (<span class="type">V</span>, <span class="type">V</span>) =&gt; <span class="type">V</span>): <span class="type">RDD</span>[(<span class="type">K</span>, <span class="type">V</span>)]</div><div class="line"></div><div class="line">  <span class="function"><span class="keyword">def</span> <span class="title">combineByKey</span></span>[<span class="type">C</span>](</div><div class="line">      createCombiner: <span class="type">V</span> =&gt; <span class="type">C</span>,</div><div class="line">      mergeValue: (<span class="type">C</span>, <span class="type">V</span>) =&gt; <span class="type">C</span>,</div><div class="line">      mergeCombiners: (<span class="type">C</span>, <span class="type">C</span>) =&gt; <span class="type">C</span>): <span class="type">RDD</span>[(<span class="type">K</span>, <span class="type">C</span>)]</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<p>可以看到 reduceByKey 的 func 参数的类型只依赖于 PairRDDFunction 的类型参数 V，在这个例子里也就是 Int。于是 func 的类型已经确定为 (Int, Int) =&gt; Int，所以就不需要额外标识类型了。</p>
<p>而 combineByKey 比 reduceByKey 更加通用，它允许各个 partition 在 shuffle 前先做 local reduce 得到一个类型为 C 的中间值，待 shuffle 后再做合并得到各个 key 对应的 C。也就是说<strong>C可以是任意定义的数据类型</strong>，所以必须要指定数据类型，在上面的例子中比较简单，看不出来。</p>
<p>以求均值为例，我们可以让每个 partiton 先求出单个 partition 内各个 key 对应的所有整数的和 sum 以及个数 count，然后返回一个 pair (sum, count)。在 shuffle 后累加各个 key 对应的所有 sum 和 count，再相除得到均值：</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">val</span> sumCountPairs: <span class="type">RDD</span>[(<span class="type">String</span>, (<span class="type">Int</span>, <span class="type">Long</span>))] = testData.combineByKey(</div><div class="line">  (_: <span class="type">Int</span>) =&gt; (<span class="number">0</span>, <span class="number">0</span>L),</div><div class="line"></div><div class="line">  (pair: (<span class="type">Int</span>, <span class="type">Long</span>), value: <span class="type">Int</span>) =&gt;</div><div class="line">    (pair._1 + value, pair._2 + <span class="number">1</span>L),</div><div class="line"></div><div class="line">  (pair1: (<span class="type">Int</span>, <span class="type">Long</span>), pair2: (<span class="type">Int</span>, <span class="type">Long</span>)) =&gt;</div><div class="line">    (pair1._1 + part2._1, pair2._2 + pair2._2)</div><div class="line">)</div><div class="line"></div><div class="line"><span class="keyword">val</span> averages: <span class="type">RDD</span>[<span class="type">String</span>, <span class="type">Double</span>] = sumCountPairs.mapValues &#123;</div><div class="line">  <span class="keyword">case</span> (sum, <span class="number">0</span>L) =&gt; <span class="number">0</span>D</div><div class="line">  <span class="keyword">case</span> (sum, count) =&gt; sum.toDouble / count</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<p>这里的C就通过V定义成了<code>(Int, Long)</code></p>
<p>另一个，学生平均成绩的例子</p>
<p><a href="https://blog.csdn.net/t1dmzks/article/details/70249743" target="_blank" rel="noopener">https://blog.csdn.net/t1dmzks/article/details/70249743</a></p>
<p><a href="https://www.edureka.co/blog/apache-spark-combinebykey-explained" target="_blank" rel="noopener">https://www.edureka.co/blog/apache-spark-combinebykey-explained</a></p>
<h3 id="partitionBy"><a href="#partitionBy" class="headerlink" title="partitionBy"></a>partitionBy</h3><p>对RDD进行分区操作。如果原有RDD的partitioner与现有的一致，则不变；否则相当于根据partitioner生成一个新的ShuffledRDD。</p>
<p>对两个RDD进行聚集</p>
<h3 id="？cogroup"><a href="#？cogroup" class="headerlink" title="？cogroup"></a>？cogroup</h3><p>将连个RDD协同划分。每个RDD中相同Key的元素分别聚合为一个集合，并返回两个RDD中对应Key的元素集合的迭代器。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">(K, (Iterable[V], Iterable[W]))</div></pre></td></tr></table></figure>
<h2 id="连接"><a href="#连接" class="headerlink" title="连接"></a>连接</h2><h3 id="join"><a href="#join" class="headerlink" title="join"></a>join</h3><p>对两个需要连接的RDD进行cogroup操作。之后形成新的RDD，对每个key下的元素进行笛卡尔积操作，返回的结果再flat。函数实现为</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">this.cogroup(other, partitioner).flatMapValues &#123; case (vs, ws) =&gt;</div><div class="line">for (v &lt;- vs; w &lt;- ws) yield (v, w) &#125;</div></pre></td></tr></table></figure>
<p>本质就是通过cogroup先进行协同划分，再通过flatMapValues将合并的数据打散。</p>
<p>例如</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div><div class="line">54</div><div class="line">55</div><div class="line">56</div><div class="line">57</div><div class="line">58</div><div class="line">59</div><div class="line">60</div><div class="line">61</div><div class="line">62</div><div class="line">63</div><div class="line">64</div><div class="line">65</div><div class="line">66</div><div class="line">67</div><div class="line">68</div><div class="line">69</div><div class="line">70</div><div class="line">71</div><div class="line">72</div><div class="line">73</div><div class="line">74</div><div class="line">75</div><div class="line">76</div><div class="line">77</div><div class="line">78</div><div class="line">79</div><div class="line">80</div><div class="line">81</div><div class="line">82</div><div class="line">83</div><div class="line">84</div><div class="line">85</div><div class="line">86</div><div class="line">87</div><div class="line">88</div><div class="line">89</div><div class="line">90</div><div class="line">91</div><div class="line">92</div><div class="line">93</div><div class="line">94</div><div class="line">95</div><div class="line">96</div><div class="line">97</div><div class="line">98</div><div class="line">99</div><div class="line">100</div><div class="line">101</div><div class="line">102</div><div class="line">103</div><div class="line">104</div><div class="line">105</div><div class="line">106</div><div class="line">107</div><div class="line">108</div><div class="line">109</div><div class="line">110</div><div class="line">111</div><div class="line">112</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">import</span> org.apache.spark.sql.types.&#123;<span class="type">DataTypes</span>, <span class="type">StructField</span>, <span class="type">StructType</span>&#125;</div><div class="line"><span class="keyword">import</span> org.apache.spark.sql.&#123;<span class="type">Row</span>, <span class="type">SQLContext</span>&#125;</div><div class="line"><span class="keyword">import</span> org.apache.spark.&#123;<span class="type">SparkConf</span>, <span class="type">SparkContext</span>&#125;</div><div class="line"></div><div class="line"><span class="class"><span class="keyword">object</span> <span class="title">Run</span> </span>&#123;</div><div class="line">  <span class="function"><span class="keyword">def</span> <span class="title">main</span></span>(args: <span class="type">Array</span>[<span class="type">String</span>]) &#123;</div><div class="line">    <span class="keyword">val</span> conf = <span class="keyword">new</span> <span class="type">SparkConf</span>().setAppName(<span class="string">"test"</span>).setMaster(<span class="string">"local"</span>)</div><div class="line">    <span class="keyword">val</span> sc = <span class="keyword">new</span> <span class="type">SparkContext</span>(conf)</div><div class="line">    sc.setLogLevel(<span class="string">"ERROR"</span>)</div><div class="line">    <span class="keyword">val</span> sqlContext = <span class="keyword">new</span> <span class="type">SQLContext</span>(sc)</div><div class="line"></div><div class="line">    <span class="comment">/**</span></div><div class="line">      * id      name</div><div class="line">      * 1       zhangsan</div><div class="line">      * 2       lisi</div><div class="line">      * 3       wangwu</div><div class="line">      */</div><div class="line">    <span class="keyword">val</span> idName = sc.parallelize(<span class="type">Array</span>((<span class="number">1</span>, <span class="string">"zhangsan"</span>), (<span class="number">2</span>, <span class="string">"lisi"</span>), (<span class="number">3</span>, <span class="string">"wangwu"</span>)))</div><div class="line"></div><div class="line">    <span class="comment">/**</span></div><div class="line">      * id      age</div><div class="line">      * 1       30</div><div class="line">      * 2       29</div><div class="line">      * 4       21</div><div class="line">      */</div><div class="line">    <span class="keyword">val</span> idAge = sc.parallelize(<span class="type">Array</span>((<span class="number">1</span>, <span class="number">30</span>), (<span class="number">2</span>, <span class="number">29</span>), (<span class="number">4</span>, <span class="number">21</span>)))</div><div class="line"></div><div class="line">    <span class="comment">/** *******************************RDD **********************************/</span></div><div class="line"></div><div class="line">    println(<span class="string">"*********************************RDD**********************************"</span>)</div><div class="line"></div><div class="line">    println(<span class="string">"\n内关联（inner join）\n"</span>)</div><div class="line">    <span class="comment">// 内关联（inner join）</span></div><div class="line">    <span class="comment">//  只保留两边id相等的部分</span></div><div class="line">    <span class="comment">/**</span></div><div class="line">      * (1,(zhangsan,30))</div><div class="line">      * (2,(lisi,29))</div><div class="line">      */</div><div class="line">    idName.join(idAge).collect().foreach(println)</div><div class="line"></div><div class="line">    println(<span class="string">"\n左外关联（left out join）\n"</span>)</div><div class="line">    <span class="comment">// 左外关联（left out join）</span></div><div class="line">    <span class="comment">// 以左边的数据为标准, 左边的数据一律保留</span></div><div class="line">    <span class="comment">// 右边分三情况:</span></div><div class="line">    <span class="comment">//      一: 左边的id, 右边有, 则合并数据; (1,(zhangsan,Some(30)))</span></div><div class="line">    <span class="comment">//      二: 左边的id, 右边没有, 则右边为空; (3,(wangwu,None))</span></div><div class="line">    <span class="comment">//      三: 右边的id, 左边没有, 则不保留; 右边有id为4的行, 但结果中并未保留</span></div><div class="line">    <span class="comment">/**</span></div><div class="line">      * (1,(zhangsan,Some(30)))</div><div class="line">      * (2,(lisi,Some(29)))</div><div class="line">      * (3,(wangwu,None))</div><div class="line">      */</div><div class="line">    idName.leftOuterJoin(idAge).collect().foreach(println)</div><div class="line"></div><div class="line">    println(<span class="string">"\n右外关联（right outer join）\n"</span>)</div><div class="line">    <span class="comment">// 右外关联（right outer join）</span></div><div class="line">    <span class="comment">// 以右边的数据为标准, 右边的数据一律保留</span></div><div class="line">    <span class="comment">// 左边分三种情况:</span></div><div class="line">    <span class="comment">//      一: 右边的id, 左边有, 则合并数据; (1,(Some(zhangsan),30))</span></div><div class="line">    <span class="comment">//      二: 右边的id, 左边没有, 则左边为空; (4,(None,21))</span></div><div class="line">    <span class="comment">//      三: 左边的id, 右边没有, 则不保留; 左边有id为3的行, 但结果中并为保留</span></div><div class="line">    <span class="comment">/**</span></div><div class="line">      * (1,(Some(zhangsan),30))</div><div class="line">      * (2,(Some(lisi),29))</div><div class="line">      * (4,(None,21))</div><div class="line">      */</div><div class="line">    idName.rightOuterJoin(idAge).collect().foreach(println)</div><div class="line"></div><div class="line">    println(<span class="string">"\n全外关联（full outer join）\n"</span>)</div><div class="line">    <span class="comment">// 全外关联（full outer join）</span></div><div class="line">    <span class="comment">/**</span></div><div class="line">      *</div><div class="line">      * (1,(Some(zhangsan),Some(30)))</div><div class="line">      * (2,(Some(lisi),Some(29)))</div><div class="line">      * (3,(Some(wangwu),None))</div><div class="line">      * (4,(None,Some(21)))</div><div class="line">      */</div><div class="line">    idName.fullOuterJoin(idAge).collect().foreach(println)</div><div class="line"></div><div class="line">    <span class="comment">/** *******************************DataFrame **********************************/</span></div><div class="line">    <span class="keyword">val</span> schema1 = <span class="type">StructType</span>(<span class="type">Array</span>(<span class="type">StructField</span>(<span class="string">"id"</span>, <span class="type">DataTypes</span>.<span class="type">IntegerType</span>, nullable = <span class="literal">true</span>), <span class="type">StructField</span>(<span class="string">"name"</span>, <span class="type">DataTypes</span>.<span class="type">StringType</span>, nullable = <span class="literal">true</span>)))</div><div class="line">    <span class="keyword">val</span> idNameDF = sqlContext.createDataFrame(idName.map(t =&gt; <span class="type">Row</span>(t._1, t._2)), schema1)</div><div class="line"></div><div class="line">    <span class="keyword">val</span> schema2 = <span class="type">StructType</span>(<span class="type">Array</span>(<span class="type">StructField</span>(<span class="string">"id"</span>, <span class="type">DataTypes</span>.<span class="type">IntegerType</span>, nullable = <span class="literal">true</span>), <span class="type">StructField</span>(<span class="string">"age"</span>, <span class="type">DataTypes</span>.<span class="type">IntegerType</span>, nullable = <span class="literal">true</span>)))</div><div class="line">    <span class="keyword">val</span> idAgeDF = sqlContext.createDataFrame(idAge.map(t =&gt; <span class="type">Row</span>(t._1, t._2)), schema2)</div><div class="line">    println(<span class="string">"*********************************DataFrame**********************************"</span>)</div><div class="line"></div><div class="line">    println(<span class="string">"\n内关联（inner join）\n"</span>)</div><div class="line">    <span class="comment">// 相当于调用, idNameDF.join(idAgeDF, Seq("id"), "inner").collect().foreach(println)</span></div><div class="line">    <span class="comment">// 这里只是调用了封装的API</span></div><div class="line">    idNameDF.join(idAgeDF, <span class="string">"id"</span>).collect().foreach(println)</div><div class="line"></div><div class="line">    println(<span class="string">"\n左外关联（left out join）\n"</span>)</div><div class="line">    idNameDF.join(idAgeDF, <span class="type">Seq</span>(<span class="string">"id"</span>), <span class="string">"left_outer"</span>).collect().foreach(println)</div><div class="line"></div><div class="line">    println(<span class="string">"\n右外关联（right outer join）\n"</span>)</div><div class="line">    idNameDF.join(idAgeDF, <span class="type">Seq</span>(<span class="string">"id"</span>), <span class="string">"right_outer"</span>).collect().foreach(println)</div><div class="line"></div><div class="line">    println(<span class="string">"\n全外关联（full outer join）\n"</span>)</div><div class="line">    idNameDF.join(idAgeDF, <span class="type">Seq</span>(<span class="string">"id"</span>), <span class="string">"outer"</span>).collect().foreach(println)</div><div class="line"></div><div class="line">    println(<span class="string">"\nleft semi join\n"</span>)</div><div class="line">    <span class="comment">// left semi join</span></div><div class="line">    <span class="comment">// 左边的id, 在右边有, 就保留左边的数据; 右边的数据不保留, 只有id的有意义的</span></div><div class="line">    <span class="comment">/**</span></div><div class="line">      * [1,zhangsan]</div><div class="line">      * [2,lisi]</div><div class="line">      */</div><div class="line">    idNameDF.join(idAgeDF, <span class="type">Seq</span>(<span class="string">"id"</span>), <span class="string">"leftsemi"</span>).collect().foreach(println)</div><div class="line">  &#125;</div><div class="line"></div><div class="line">&#125;</div></pre></td></tr></table></figure>
<p>当出现相同Key时, join会出现笛卡尔积, 而cogroup的处理方式不同</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div><div class="line">54</div><div class="line">55</div><div class="line">56</div><div class="line">57</div><div class="line">58</div><div class="line">59</div><div class="line">60</div><div class="line">61</div><div class="line">62</div><div class="line">63</div><div class="line">64</div><div class="line">65</div><div class="line">66</div><div class="line">67</div><div class="line">68</div><div class="line">69</div><div class="line">70</div><div class="line">71</div><div class="line">72</div><div class="line">73</div><div class="line">74</div><div class="line">75</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">import</span> org.apache.spark.sql.<span class="type">SQLContext</span></div><div class="line"><span class="keyword">import</span> org.apache.spark.&#123;<span class="type">SparkConf</span>, <span class="type">SparkContext</span>&#125;</div><div class="line"></div><div class="line"><span class="class"><span class="keyword">object</span> <span class="title">Run</span> </span>&#123;</div><div class="line">  <span class="function"><span class="keyword">def</span> <span class="title">main</span></span>(args: <span class="type">Array</span>[<span class="type">String</span>]) &#123;</div><div class="line">    <span class="keyword">val</span> conf = <span class="keyword">new</span> <span class="type">SparkConf</span>().setAppName(<span class="string">"test"</span>).setMaster(<span class="string">"local"</span>)</div><div class="line">    <span class="keyword">val</span> sc = <span class="keyword">new</span> <span class="type">SparkContext</span>(conf)</div><div class="line">    sc.setLogLevel(<span class="string">"ERROR"</span>)</div><div class="line">    <span class="keyword">val</span> sqlContext = <span class="keyword">new</span> <span class="type">SQLContext</span>(sc)</div><div class="line"></div><div class="line">    <span class="comment">/**</span></div><div class="line">      * id      name</div><div class="line">      * 1       zhangsan</div><div class="line">      * 2       lisi</div><div class="line">      * 3       wangwu</div><div class="line">      */</div><div class="line">    <span class="keyword">val</span> idName = sc.parallelize(<span class="type">Array</span>((<span class="number">1</span>, <span class="string">"zhangsan"</span>), (<span class="number">2</span>, <span class="string">"lisi"</span>), (<span class="number">3</span>, <span class="string">"wangwu"</span>)))</div><div class="line"></div><div class="line">    <span class="comment">/**</span></div><div class="line">      * id      age</div><div class="line">      * 1       30</div><div class="line">      * 2       29</div><div class="line">      * 4       21</div><div class="line">      */</div><div class="line">    <span class="keyword">val</span> idAge = sc.parallelize(<span class="type">Array</span>((<span class="number">1</span>, <span class="number">30</span>), (<span class="number">2</span>, <span class="number">29</span>), (<span class="number">4</span>, <span class="number">21</span>)))</div><div class="line"></div><div class="line">    println(<span class="string">"\ncogroup\n"</span>)</div><div class="line"></div><div class="line">    <span class="comment">/**</span></div><div class="line">      * (1,(CompactBuffer(zhangsan),CompactBuffer(30)))</div><div class="line">      * (2,(CompactBuffer(lisi),CompactBuffer(29)))</div><div class="line">      * (3,(CompactBuffer(wangwu),CompactBuffer()))</div><div class="line">      * (4,(CompactBuffer(),CompactBuffer(21)))</div><div class="line">      */</div><div class="line">    idName.cogroup(idAge).collect().foreach(println)</div><div class="line"></div><div class="line">    println(<span class="string">"\njoin\n"</span>)</div><div class="line">    <span class="comment">// fullOuterJoin于cogroup的结果类似, 只是数据结构不一样</span></div><div class="line">    <span class="comment">/**</span></div><div class="line">      * (1,(Some(zhangsan),Some(30)))</div><div class="line">      * (2,(Some(lisi),Some(29)))</div><div class="line">      * (3,(Some(wangwu),None))</div><div class="line">      * (4,(None,Some(21)))</div><div class="line">      */</div><div class="line">    idName.fullOuterJoin(idAge).collect().foreach(println)</div><div class="line"></div><div class="line">    <span class="comment">/**</span></div><div class="line">      * id      score</div><div class="line">      * 1       100</div><div class="line">      * 2       90</div><div class="line">      * 2       95</div><div class="line">      */</div><div class="line">    <span class="keyword">val</span> idScore = sc.parallelize(<span class="type">Array</span>((<span class="number">1</span>, <span class="number">100</span>), (<span class="number">2</span>, <span class="number">90</span>), (<span class="number">2</span>, <span class="number">95</span>)))</div><div class="line"></div><div class="line">    println(<span class="string">"\ncogroup, 出现相同id时\n"</span>)</div><div class="line"></div><div class="line">    <span class="comment">/**</span></div><div class="line">      * (1,(CompactBuffer(zhangsan),CompactBuffer(100)))</div><div class="line">      * (2,(CompactBuffer(lisi),CompactBuffer(90, 95)))</div><div class="line">      * (3,(CompactBuffer(wangwu),CompactBuffer()))</div><div class="line">      */</div><div class="line">    idName.cogroup(idScore).collect().foreach(println)</div><div class="line"></div><div class="line">    println(<span class="string">"\njoin, 出现相同id时\n"</span>)</div><div class="line"></div><div class="line">    <span class="comment">/**</span></div><div class="line">      * (1,(Some(zhangsan),Some(100)))</div><div class="line">      * (2,(Some(lisi),Some(90)))</div><div class="line">      * (2,(Some(lisi),Some(95)))</div><div class="line">      * (3,(Some(wangwu),None))</div><div class="line">      */</div><div class="line">    idName.fullOuterJoin(idScore).collect().foreach(println)</div><div class="line">  &#125;</div><div class="line"></div><div class="line">&#125;</div></pre></td></tr></table></figure>
<h1 id="Actions算子"><a href="#Actions算子" class="headerlink" title="Actions算子"></a>Actions算子</h1><h2 id="无输出"><a href="#无输出" class="headerlink" title="无输出"></a>无输出</h2><h3 id="foreach"><a href="#foreach" class="headerlink" title="foreach"></a>foreach</h3><h2 id="HDFS"><a href="#HDFS" class="headerlink" title="HDFS"></a>HDFS</h2><h3 id="saveAsTextFile"><a href="#saveAsTextFile" class="headerlink" title="saveAsTextFile"></a>saveAsTextFile</h3><p>将数据输出，存储到HDFS的指定目录。</p>
<h3 id="saveAsObjectFile"><a href="#saveAsObjectFile" class="headerlink" title="saveAsObjectFile"></a>saveAsObjectFile</h3><p>将分区中每10个元素组成一个Array，然后将这个Array序列化，映射为<code>(Null, BytesWritable(Y))</code>的元素，写入HDFS为SequenceFile的格式。</p>
<h2 id="Scala集合和数据类型"><a href="#Scala集合和数据类型" class="headerlink" title="Scala集合和数据类型"></a>Scala集合和数据类型</h2><h3 id="collect"><a href="#collect" class="headerlink" title="collect"></a>collect</h3><p>相当于toArray，但toArray已经过时不推荐使用。collect将RDD返回为一个单机的scala Array数组。</p>
<h3 id="collectAsMap"><a href="#collectAsMap" class="headerlink" title="collectAsMap"></a>collectAsMap</h3><p>返回一个单机的HashMap。对于重复Key的RDD，后面覆盖前面的。</p>
<h3 id="reduceByKeyLocally"><a href="#reduceByKeyLocally" class="headerlink" title="reduceByKeyLocally"></a>reduceByKeyLocally</h3><p>先对RDD整体进行reduce再collectAsMap。</p>
<h3 id="lookup"><a href="#lookup" class="headerlink" title="lookup"></a>lookup</h3><p>Lookup函数对(Key,Value)型的RDD操作，返回指定Key对应的元素形成的Seq。这</p>
<p>个函数处理优化的部分在于，如果这个RDD包含分区器，则只会对应处理K所在的分区，然</p>
<p>后返回由(K,V)形成的Seq。如果RDD不包含分区器，则需要对全RDD元素进行暴力扫描</p>
<p>处理，搜索指定K对应的元素。</p>
<h3 id="count"><a href="#count" class="headerlink" title="count"></a>count</h3><h3 id="top"><a href="#top" class="headerlink" title="top"></a>top</h3><p>返回最大的k个元素</p>
<h3 id="take"><a href="#take" class="headerlink" title="take"></a>take</h3><p>返回最小的k个</p>
<h3 id="takeOrdered"><a href="#takeOrdered" class="headerlink" title="takeOrdered"></a>takeOrdered</h3><p>返回最小的k个元素，并且在返回的数组中保持元素的顺序。</p>
<h3 id="first"><a href="#first" class="headerlink" title="first"></a>first</h3><p>相当于top(1)，可以定义排序的方式Ordering[T]</p>
<h3 id="reduce"><a href="#reduce" class="headerlink" title="reduce"></a>reduce</h3><p>相当于对RDD中的元素进行reduceLeft函数的操作。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">Some(iter.reduceLeft(cleanF))</div></pre></td></tr></table></figure>
<p>先对每个分区的集合进行reduceLeft，结果形成一个元素，再对这个结果做reduceLeft。</p>
<p>例如，用户自定义函数为</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">f:(A,B)=&gt;(A._1+&quot;@&quot;+B._1,A._2+B._2)</div></pre></td></tr></table></figure>
<p><img src="/2018/04/03/hadoop-spark/spark/spark算子分类及功能/reduce.png" alt=""></p>
<h3 id="fold"><a href="#fold" class="headerlink" title="fold"></a>fold</h3><p>和reduce原理相同，接收与reduce接收的函数签名相同的函数，不同点是，另外再加上一个初始值作为第一次调用的结果。</p>
<h3 id="aggregate"><a href="#aggregate" class="headerlink" title="aggregate"></a>aggregate</h3><p>可以对两个不同类型的元素进行聚合，即支持异构。它先聚合每一个分区里的元素，然后将所有结果返回回来，再用一个给定的conbine方法以及给定的初始值zero value进行聚合。</p>
<blockquote>
<p>没懂</p>
<p>aggreagate与fold和reduce的不同之处在于,aggregate相当于采用归并的方式进行数<br>据聚集,这种聚集是并行化的。而在fold和reduce函数的运算过程中,每个分区中需要进行<br>串行处理,每个分区串行计算完结果,结果再按之前的方式进行聚集,并返回最终聚集结<br>果。</p>
</blockquote>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">def aggregate [U: ClassTag] (zeroValue: U) (seqOp: (U,T)=&gt;U，combOp: (U,U)=&gt;U):U</div></pre></td></tr></table></figure>
<p>由以上可以看到，(zeroValue: U)是给定一个初值，后半部分有两个函数，seqOp与combOp。<br>seqOp相当于是在各个分区里进行的聚合操作，它支持(U,T)=&gt;U，也就是支持不同类型的聚合。<br>combOp是将seqOp后的结果再进行聚合，此时的结果全部是U类，只能进行同构聚合。</p>
<h1 id="两个特殊变量"><a href="#两个特殊变量" class="headerlink" title="两个特殊变量"></a>两个特殊变量</h1><h2 id="broadcast"><a href="#broadcast" class="headerlink" title="broadcast"></a>broadcast</h2><p>用于广播Map Side Join中的小表，以及广播大变量等场景。这些数据集合在单节点内存能够容纳,不需要像RDD那样在节点之间打散存储。Spark运行时把广播变量数据发到各个节点,并保存下来,后续计算可以复用。</p>
<p>相比Hadoop的distributed cache，广播的内容可以跨作业共享。</p>
<h2 id="accumulator"><a href="#accumulator" class="headerlink" title="accumulator"></a>accumulator</h2><p>允许做全局累加操作，如accumulator变量广泛使用在应用中记录当前的运行指标的情景。</p>

      
    </div>

    <div>
      
        

      
    </div>

    <div>
      
        

      
    </div>

    <div>
      
        

      
    </div>

    <footer class="post-footer">
      

      
        
      

      
        <div class="post-nav">
          <div class="post-nav-next post-nav-item">
            
              <a href="/2018/04/03/hadoop-spark/spark/spark工作机制/" rel="next" title="spark工作机制">
                <i class="fa fa-chevron-left"></i> spark工作机制
              </a>
            
          </div>

          <span class="post-nav-divider"></span>

          <div class="post-nav-prev post-nav-item">
            
              <a href="/2018/04/03/地理信息挖掘/轨迹挖掘/" rel="prev" title="轨迹挖掘">
                轨迹挖掘 <i class="fa fa-chevron-right"></i>
              </a>
            
          </div>
        </div>
      

      
      
    </footer>
  </article>



    <div class="post-spread">
      
    </div>
  </div>


          </div>
          


          
  <div class="comments" id="comments">
    
      <div id="hypercomments_widget"></div>
    
  </div>


        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    <div class="sidebar-inner">

      

      
        <ul class="sidebar-nav motion-element">
          <li class="sidebar-nav-toc sidebar-nav-active" data-target="post-toc-wrap" >
            文章目录
          </li>
          <li class="sidebar-nav-overview" data-target="site-overview">
            站点概览
          </li>
        </ul>
      

      <section class="site-overview sidebar-panel">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
          <img class="site-author-image" itemprop="image"
               src="/images/avatar.gif"
               alt="Schwimmer" />
          <p class="site-author-name" itemprop="name">Schwimmer</p>
           
              <p class="site-description motion-element" itemprop="description"></p>
           
        </div>
        <nav class="site-state motion-element">

          
            <div class="site-state-item site-state-posts">
              <a href="/archives">
                <span class="site-state-item-count">127</span>
                <span class="site-state-item-name">日志</span>
              </a>
            </div>
          

          
            
            
            <div class="site-state-item site-state-categories">
              <a href="/categories/index.html">
                <span class="site-state-item-count">16</span>
                <span class="site-state-item-name">分类</span>
              </a>
            </div>
          

          
            
            
            <div class="site-state-item site-state-tags">
              <a href="/tags/index.html">
                <span class="site-state-item-count">55</span>
                <span class="site-state-item-name">标签</span>
              </a>
            </div>
          

        </nav>

        

        <div class="links-of-author motion-element">
          
        </div>

        
        

        
        

        


      </section>

      
      <!--noindex-->
        <section class="post-toc-wrap motion-element sidebar-panel sidebar-panel-active">
          <div class="post-toc">

            
              
            

            
              <div class="post-toc-content"><ol class="nav"><li class="nav-item nav-level-1"><a class="nav-link" href="#Value型Transformation算子"><span class="nav-number">1.</span> <span class="nav-text">Value型Transformation算子</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#一对一型"><span class="nav-number">1.1.</span> <span class="nav-text">一对一型</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#map"><span class="nav-number">1.1.1.</span> <span class="nav-text">map</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#flatMap"><span class="nav-number">1.1.2.</span> <span class="nav-text">flatMap</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#mapPartitions"><span class="nav-number">1.1.3.</span> <span class="nav-text">mapPartitions</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#glom"><span class="nav-number">1.1.4.</span> <span class="nav-text">glom</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#多对一型"><span class="nav-number">1.2.</span> <span class="nav-text">多对一型</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#union"><span class="nav-number">1.2.1.</span> <span class="nav-text">union</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#cartesian"><span class="nav-number">1.3.</span> <span class="nav-text">cartesian</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#多对多型"><span class="nav-number">1.4.</span> <span class="nav-text">多对多型</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#groupBy"><span class="nav-number">1.4.1.</span> <span class="nav-text">groupBy</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#子集型"><span class="nav-number">1.5.</span> <span class="nav-text">子集型</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#filter"><span class="nav-number">1.5.1.</span> <span class="nav-text">filter</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#distinct"><span class="nav-number">1.5.2.</span> <span class="nav-text">distinct</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#substract"><span class="nav-number">1.5.3.</span> <span class="nav-text">substract</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#sample"><span class="nav-number">1.5.4.</span> <span class="nav-text">sample</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#takeSample"><span class="nav-number">1.5.5.</span> <span class="nav-text">takeSample</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Cache型"><span class="nav-number">1.6.</span> <span class="nav-text">Cache型</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#cache"><span class="nav-number">1.6.1.</span> <span class="nav-text">cache</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#persist"><span class="nav-number">1.7.</span> <span class="nav-text">persist</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#Key-Value型Transformation算子"><span class="nav-number">2.</span> <span class="nav-text">Key-Value型Transformation算子</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#输入和输出分区一对一"><span class="nav-number">2.1.</span> <span class="nav-text">输入和输出分区一对一</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#mapValues"><span class="nav-number">2.1.1.</span> <span class="nav-text">mapValues</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#对单个或两个RDD聚集"><span class="nav-number">2.2.</span> <span class="nav-text">对单个或两个RDD聚集</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#combineByKey"><span class="nav-number">2.2.1.</span> <span class="nav-text">combineByKey</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#reduceByKey"><span class="nav-number">2.2.2.</span> <span class="nav-text">reduceByKey</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#combineByKey和reduceByKey区别"><span class="nav-number">2.2.3.</span> <span class="nav-text">combineByKey和reduceByKey区别</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#partitionBy"><span class="nav-number">2.2.4.</span> <span class="nav-text">partitionBy</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#？cogroup"><span class="nav-number">2.2.5.</span> <span class="nav-text">？cogroup</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#连接"><span class="nav-number">2.3.</span> <span class="nav-text">连接</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#join"><span class="nav-number">2.3.1.</span> <span class="nav-text">join</span></a></li></ol></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#Actions算子"><span class="nav-number">3.</span> <span class="nav-text">Actions算子</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#无输出"><span class="nav-number">3.1.</span> <span class="nav-text">无输出</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#foreach"><span class="nav-number">3.1.1.</span> <span class="nav-text">foreach</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#HDFS"><span class="nav-number">3.2.</span> <span class="nav-text">HDFS</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#saveAsTextFile"><span class="nav-number">3.2.1.</span> <span class="nav-text">saveAsTextFile</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#saveAsObjectFile"><span class="nav-number">3.2.2.</span> <span class="nav-text">saveAsObjectFile</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Scala集合和数据类型"><span class="nav-number">3.3.</span> <span class="nav-text">Scala集合和数据类型</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#collect"><span class="nav-number">3.3.1.</span> <span class="nav-text">collect</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#collectAsMap"><span class="nav-number">3.3.2.</span> <span class="nav-text">collectAsMap</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#reduceByKeyLocally"><span class="nav-number">3.3.3.</span> <span class="nav-text">reduceByKeyLocally</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#lookup"><span class="nav-number">3.3.4.</span> <span class="nav-text">lookup</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#count"><span class="nav-number">3.3.5.</span> <span class="nav-text">count</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#top"><span class="nav-number">3.3.6.</span> <span class="nav-text">top</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#take"><span class="nav-number">3.3.7.</span> <span class="nav-text">take</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#takeOrdered"><span class="nav-number">3.3.8.</span> <span class="nav-text">takeOrdered</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#first"><span class="nav-number">3.3.9.</span> <span class="nav-text">first</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#reduce"><span class="nav-number">3.3.10.</span> <span class="nav-text">reduce</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#fold"><span class="nav-number">3.3.11.</span> <span class="nav-text">fold</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#aggregate"><span class="nav-number">3.3.12.</span> <span class="nav-text">aggregate</span></a></li></ol></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#两个特殊变量"><span class="nav-number">4.</span> <span class="nav-text">两个特殊变量</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#broadcast"><span class="nav-number">4.1.</span> <span class="nav-text">broadcast</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#accumulator"><span class="nav-number">4.2.</span> <span class="nav-text">accumulator</span></a></li></ol></li></ol></div>
            

          </div>
        </section>
      <!--/noindex-->
      

      

    </div>
  </aside>


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <div class="copyright" >
  
  &copy; 
  <span itemprop="copyrightYear">2018</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">Schwimmer</span>
</div>


<div class="powered-by">
  由 <a class="theme-link" href="https://hexo.io">Hexo</a> 强力驱动
</div>

<div class="theme-info">
  主题 -
  <a class="theme-link" href="https://github.com/iissnan/hexo-theme-next">
    NexT.Pisces
  </a>
</div>

<div>
<script async src="https://dn-lbstatics.qbox.me/busuanzi/2.3/busuanzi.pure.mini.js"></script>

本站总访问量 <span id="busuanzi_value_site_pv"></span> 次&nbsp&nbsp&nbsp
本站访客数<span id="busuanzi_value_site_uv"></span>人次
</div>




        

        
      </div>
    </footer>

    
      <div class="back-to-top">
        <i class="fa fa-arrow-up"></i>
        
      </div>
    

  </div>

  

<script type="text/javascript">
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>









  






  
  <script type="text/javascript" src="/lib/jquery/index.js?v=2.1.3"></script>

  
  <script type="text/javascript" src="/lib/fastclick/lib/fastclick.min.js?v=1.0.6"></script>

  
  <script type="text/javascript" src="/lib/jquery_lazyload/jquery.lazyload.js?v=1.9.7"></script>

  
  <script type="text/javascript" src="/lib/velocity/velocity.min.js?v=1.2.1"></script>

  
  <script type="text/javascript" src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>

  
  <script type="text/javascript" src="/lib/fancybox/source/jquery.fancybox.pack.js?v=2.1.5"></script>


  


  <script type="text/javascript" src="/js/src/utils.js?v=5.1.0"></script>

  <script type="text/javascript" src="/js/src/motion.js?v=5.1.0"></script>



  
  


  <script type="text/javascript" src="/js/src/affix.js?v=5.1.0"></script>

  <script type="text/javascript" src="/js/src/schemes/pisces.js?v=5.1.0"></script>



  
  <script type="text/javascript" src="/js/src/scrollspy.js?v=5.1.0"></script>
<script type="text/javascript" src="/js/src/post-details.js?v=5.1.0"></script>



  


  <script type="text/javascript" src="/js/src/bootstrap.js?v=5.1.0"></script>



  


  




	

		<script type="text/javascript">
		_hcwp = window._hcwp || [];

		_hcwp.push({widget:"Bloggerstream", widget_id: 100710, selector:".hc-comment-count", label: "{\%COUNT%\}" });

		
		_hcwp.push({widget:"Stream", widget_id: 100710, xid: "2018/04/03/hadoop-spark/spark/spark算子分类及功能/"});
		

		(function() {
		if("HC_LOAD_INIT" in window)return;
		HC_LOAD_INIT = true;
		var lang = (navigator.language || navigator.systemLanguage || navigator.userLanguage || "en").substr(0, 2).toLowerCase();
		var hcc = document.createElement("script"); hcc.type = "text/javascript"; hcc.async = true;
		hcc.src = ("https:" == document.location.protocol ? "https" : "http")+"://w.hypercomments.com/widget/hc/100710/"+lang+"/widget.js";
		var s = document.getElementsByTagName("script")[0];
		s.parentNode.insertBefore(hcc, s.nextSibling);
		})();
		</script>

	












  

  <script type="text/javascript">
    // Popup Window;
    var isfetched = false;
    // Search DB path;
    var search_path = "search.xml";
    if (search_path.length == 0) {
      search_path = "search.xml";
    }
    var path = "/" + search_path;
    // monitor main search box;

    function proceedsearch() {
      $("body")
        .append('<div class="search-popup-overlay local-search-pop-overlay"></div>')
        .css('overflow', 'hidden');
      $('.popup').toggle();
    }
    // search function;
    var searchFunc = function(path, search_id, content_id) {
      'use strict';
      $.ajax({
        url: path,
        dataType: "xml",
        async: true,
        success: function( xmlResponse ) {
          // get the contents from search data
          isfetched = true;
          $('.popup').detach().appendTo('.header-inner');
          var datas = $( "entry", xmlResponse ).map(function() {
            return {
              title: $( "title", this ).text(),
              content: $("content",this).text(),
              url: $( "url" , this).text()
            };
          }).get();
          var $input = document.getElementById(search_id);
          var $resultContent = document.getElementById(content_id);
          $input.addEventListener('input', function(){
            var matchcounts = 0;
            var str='<ul class=\"search-result-list\">';
            var keywords = this.value.trim().toLowerCase().split(/[\s\-]+/);
            $resultContent.innerHTML = "";
            if (this.value.trim().length > 1) {
              // perform local searching
              datas.forEach(function(data) {
                var isMatch = false;
                var content_index = [];
                var data_title = data.title.trim().toLowerCase();
                var data_content = data.content.trim().replace(/<[^>]+>/g,"").toLowerCase();
                var data_url = decodeURIComponent(data.url);
                var index_title = -1;
                var index_content = -1;
                var first_occur = -1;
                // only match artiles with not empty titles and contents
                if(data_title != '') {
                  keywords.forEach(function(keyword, i) {
                    index_title = data_title.indexOf(keyword);
                    index_content = data_content.indexOf(keyword);
                    if( index_title >= 0 || index_content >= 0 ){
                      isMatch = true;
                      if (i == 0) {
                        first_occur = index_content;
                      }
                    }

                  });
                }
                // show search results
                if (isMatch) {
                  matchcounts += 1;
                  str += "<li><a href='"+ data_url +"' class='search-result-title'>"+ data_title +"</a>";
                  var content = data.content.trim().replace(/<[^>]+>/g,"");
                  if (first_occur >= 0) {
                    // cut out 100 characters
                    var start = first_occur - 20;
                    var end = first_occur + 80;
                    if(start < 0){
                      start = 0;
                    }
                    if(start == 0){
                      end = 50;
                    }
                    if(end > content.length){
                      end = content.length;
                    }
                    var match_content = content.substring(start, end);
                    // highlight all keywords
                    keywords.forEach(function(keyword){
                      var regS = new RegExp(keyword, "gi");
                      match_content = match_content.replace(regS, "<b class=\"search-keyword\">"+keyword+"</b>");
                    });

                    str += "<p class=\"search-result\">" + match_content +"...</p>"
                  }
                  str += "</li>";
                }
              })};
            str += "</ul>";
            if (matchcounts == 0) { str = '<div id="no-result"><i class="fa fa-frown-o fa-5x" /></div>' }
            if (keywords == "") { str = '<div id="no-result"><i class="fa fa-search fa-5x" /></div>' }
            $resultContent.innerHTML = str;
          });
          proceedsearch();
        }
      });}

    // handle and trigger popup window;
    $('.popup-trigger').click(function(e) {
      e.stopPropagation();
      if (isfetched == false) {
        searchFunc(path, 'local-search-input', 'local-search-result');
      } else {
        proceedsearch();
      };
    });

    $('.popup-btn-close').click(function(e){
      $('.popup').hide();
      $(".local-search-pop-overlay").remove();
      $('body').css('overflow', '');
    });
    $('.popup').click(function(e){
      e.stopPropagation();
    });
  </script>





  

  
<script>
(function(){
    var bp = document.createElement('script');
    var curProtocol = window.location.protocol.split(':')[0];
    if (curProtocol === 'https') {
        bp.src = 'https://zz.bdstatic.com/linksubmit/push.js';        
    }
    else {
        bp.src = 'http://push.zhanzhang.baidu.com/push.js';
    }
    var s = document.getElementsByTagName("script")[0];
    s.parentNode.insertBefore(bp, s);
})();
</script>


  
  
    <script type="text/x-mathjax-config">
      MathJax.Hub.Config({
        tex2jax: {
          inlineMath: [ ['$','$'], ["\\(","\\)"]  ],
          processEscapes: true,
          skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
        }
      });
    </script>

    <script type="text/x-mathjax-config">
      MathJax.Hub.Queue(function() {
        var all = MathJax.Hub.getAllJax(), i;
        for (i=0; i < all.length; i += 1) {
          all[i].SourceElement().parentNode.className += ' has-jax';
        }
      });
    </script>
    <script type="text/javascript" src="//cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script><!-- hexo-inject:begin --><!-- hexo-inject:end -->
  


  

</body>
</html>
