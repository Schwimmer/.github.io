<!DOCTYPE html>












  


<html class="theme-next mist use-motion" lang="zh-CN">
<head><meta name="generator" content="Hexo 3.9.0">
  <!-- hexo-inject:begin --><!-- hexo-inject:end --><meta charset="UTF-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">






















<link rel="stylesheet" href="/lib/font-awesome/css/font-awesome.min.css?v=4.7.0">

<link rel="stylesheet" href="/css/main.css?v=7.2.0">


  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png?v=7.2.0">


  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png?v=7.2.0">


  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png?v=7.2.0">


  <link rel="mask-icon" href="/images/logo.svg?v=7.2.0" color="#222">







<script id="hexo.configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '/',
    scheme: 'Mist',
    version: '7.2.0',
    sidebar: {"position":"left","display":"post","offset":12,"onmobile":false,"dimmer":false},
    back2top: true,
    back2top_sidebar: false,
    fancybox: false,
    fastclick: false,
    lazyload: false,
    tabs: true,
    motion: {"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},
    algolia: {
      applicationID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    }
  };
</script>


  




  <meta name="description" content="Record and Think!">
<meta property="og:type" content="website">
<meta property="og:title" content="Schwimmer&#39;s Blog">
<meta property="og:url" content="https://schwimmer.github.io/page/28/index.html">
<meta property="og:site_name" content="Schwimmer&#39;s Blog">
<meta property="og:description" content="Record and Think!">
<meta property="og:locale" content="zh-CN">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Schwimmer&#39;s Blog">
<meta name="twitter:description" content="Record and Think!">





  
  
  <link rel="canonical" href="https://schwimmer.github.io/page/28/">



<script id="page.configurations">
  CONFIG.page = {
    sidebar: "",
  };
</script>

  <title>Schwimmer's Blog</title>
  




  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-143240576-1"></script>
  <script>
    var host = window.location.hostname;
    if (host !== "localhost" || !true) {
      window.dataLayer = window.dataLayer || [];
      function gtag(){dataLayer.push(arguments);}
      gtag('js', new Date());
      gtag('config', 'UA-143240576-1');
    }
  </script>









  <noscript>
  <style>
  .use-motion .motion-element,
  .use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-title { opacity: initial; }

  .use-motion .logo,
  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript><!-- hexo-inject:begin --><!-- hexo-inject:end -->

</head>

<body itemscope="" itemtype="http://schema.org/WebPage" lang="zh-CN">

  
  
    
  

  <!-- hexo-inject:begin --><!-- hexo-inject:end --><div class="container sidebar-position-left 
  page-home">
    <div class="headband"></div>

    <header id="header" class="header" itemscope="" itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-wrapper">
  <div class="site-meta">
    

    <div class="custom-logo-site-title">
      <a href="/" class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">Schwimmer's Blog</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
    
    
  </div>

  <div class="site-nav-toggle">
    <button aria-label="切换导航栏">
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
    </button>
  </div>
</div>



<nav class="site-nav">
  
    <ul id="menu" class="menu">
      
        
        
        
          
          <li class="menu-item menu-item-home">

    
    
      
    

    

    <a href="/" rel="section"><i class="menu-item-icon fa fa-fw fa-home"></i> <br>首页</a>

  </li>
        
        
        
          
          <li class="menu-item menu-item-tags">

    
    
      
    

    

    <a href="/tags/" rel="section"><i class="menu-item-icon fa fa-fw fa-tags"></i> <br>标签</a>

  </li>
        
        
        
          
          <li class="menu-item menu-item-categories">

    
    
      
    

    

    <a href="/categories/" rel="section"><i class="menu-item-icon fa fa-fw fa-th"></i> <br>分类</a>

  </li>
        
        
        
          
          <li class="menu-item menu-item-archives">

    
    
      
    

    

    <a href="/archives/" rel="section"><i class="menu-item-icon fa fa-fw fa-archive"></i> <br>归档</a>

  </li>

      
      
        <li class="menu-item menu-item-search">
          
            <a href="javascript:;" class="popup-trigger">
          
            
              <i class="menu-item-icon fa fa-search fa-fw"></i> <br>搜索</a>
        </li>
      
    </ul>
  

  
    

  

  
    <div class="site-search">
      
  <div class="popup search-popup local-search-popup">
  <div class="local-search-header clearfix">
    <span class="search-icon">
      <i class="fa fa-search"></i>
    </span>
    <span class="popup-btn-close">
      <i class="fa fa-times-circle"></i>
    </span>
    <div class="local-search-input-wrapper">
      <input autocomplete="off" placeholder="搜索..." spellcheck="false" type="text" id="local-search-input">
    </div>
  </div>
  <div id="local-search-result"></div>
</div>



    </div>
  
</nav>



  



</div>
    </header>

    


    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          
          <div id="content" class="content">
            
  <section id="posts" class="posts-expand">
    
      

  

  
  
  

  

  <article class="post post-type-normal" itemscope="" itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="https://schwimmer.github.io/2017/09/11/机器学习/决策树/">

    <span hidden itemprop="author" itemscope="" itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Schwimmer">
      <meta itemprop="description" content="Record and Think!">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope="" itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Schwimmer's Blog">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                
                <a href="/2017/09/11/机器学习/决策树/" class="post-title-link" itemprop="url">决策树</a>
              
            
          </h1>
        

        <div class="post-meta">

          
          
          

          
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              

              
                
              

              <time title="创建时间：2017-09-11 11:49:53" itemprop="dateCreated datePublished" datetime="2017-09-11T11:49:53+08:00">2017-09-11</time>
            </span>
          

          
            

            
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="fa fa-calendar-check-o"></i>
                </span>
                
                  <span class="post-meta-item-text">更新于</span>
                
                <time title="修改时间：2018-03-17 20:50:31" itemprop="dateModified" datetime="2018-03-17T20:50:31+08:00">2018-03-17</time>
              </span>
            
          

          
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope="" itemtype="http://schema.org/Thing"><a href="/categories/机器学习/" itemprop="url" rel="index"><span itemprop="name">机器学习</span></a></span>

                
                
              
            </span>
          

          
            
            
              
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="fa fa-comment-o"></i>
                </span>
            
                <span class="post-meta-item-text">评论数：</span>
                <a href="/2017/09/11/机器学习/决策树/#comments" itemprop="discussionUrl">
                  <span class="post-comments-count disqus-comment-count" data-disqus-identifier="2017/09/11/机器学习/决策树/" itemprop="commentCount"></span>
                </a>
              </span>
            
          

          
          

          

          <br>
          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1 id="1-决策树"><a href="#1-决策树" class="headerlink" title="1 决策树"></a>1 决策树</h1><p>公式符号</p>
<script type="math/tex; mode=display">
\begin{align}
&Ent(X)\ \ \ 熵 \\
&Gain(X)\ \ \ 信息增益\\
&Gini(X)\ \ \ 基尼指数\\
&D\ \ \ 训练集\\
&A\ \ \ 训练集的某个特征\\
&N\ \ \ 特征A的类别总数\\
&K\ \ \ 标签分类的数量\\
\end{align}</script><h2 id="1-1-关键步骤-python实现"><a href="#1-1-关键步骤-python实现" class="headerlink" title="1.1 关键步骤-python实现"></a>1.1 关键步骤-python实现</h2><p>创建决策树分支的createBranch()伪代码函数</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">检查数据集中每个子项是否属于同一个分类：</span><br><span class="line">	IF YES return 类标签；</span><br><span class="line">	ELSE </span><br><span class="line">		寻找划分数据集的最好特征；</span><br><span class="line">		划分数据集；</span><br><span class="line">		创建分支节点；</span><br><span class="line">			for 每个划分的子集</span><br><span class="line">				递归调用createBranch()并增加返回结果到分支节点中</span><br><span class="line">        return 分支节点</span><br></pre></td></tr></table></figure>
<p>对label的分类计算熵</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">calcEnt</span><span class="params">(dataSet)</span>:</span></span><br><span class="line">	labelNum = len(dataSet)</span><br><span class="line">    ent = <span class="number">0.0</span></span><br><span class="line">	<span class="comment">#定义字典存放每个类别的count统计</span></span><br><span class="line">	labelCounts = &#123;&#125;</span><br><span class="line">    <span class="comment">#统计每个label的个数</span></span><br><span class="line">	<span class="keyword">for</span> featureVec <span class="keyword">in</span> dataSet:</span><br><span class="line">        <span class="comment">#最后一列是label</span></span><br><span class="line">		label = featureVec[<span class="number">-1</span>]</span><br><span class="line">        <span class="keyword">if</span> label <span class="keyword">not</span> <span class="keyword">in</span> labelCounts.keys(): labelCounts[label] = <span class="number">0</span></span><br><span class="line">        labelCounts[label] += <span class="number">1</span></span><br><span class="line">    <span class="comment">#计算概率以及熵</span></span><br><span class="line">    <span class="keyword">for</span> key <span class="keyword">in</span> labelCounts:</span><br><span class="line">        prob = float(labelCounts[key]) / labelNum</span><br><span class="line">        ent -= prob * log(<span class="number">2</span>, prob)</span><br><span class="line">    <span class="keyword">return</span> ent</span><br></pre></td></tr></table></figure>
<p>对数据集进行划分</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">splitDataSet</span><span class="params">(dataSet, axis, value)</span>:</span></span><br><span class="line">    subDataSet = []</span><br><span class="line">    <span class="keyword">for</span> featureVec <span class="keyword">in</span> dataSet:</span><br><span class="line">        <span class="keyword">if</span> featureVec[axis] == value:</span><br><span class="line">            reducedFeatVec = featureVec[:axis]</span><br><span class="line">            reducedFeatVec.extend(featureVec[axis+<span class="number">1</span>:])</span><br><span class="line">    		resDataSet.append(reducedFeatVec)</span><br><span class="line">    <span class="keyword">return</span> subDataSet</span><br></pre></td></tr></table></figure>
<p>选出最好的数据集划分方式</p>
<p><strong>信息增益</strong></p>
<p><strong>熵</strong>的定义是</p>
<script type="math/tex; mode=display">
Ent(X) = -\sum_{i=1}^{n}p(x_i)log_2p(x_i)</script><p>n是类别总数。</p>
<p><strong>条件熵</strong>$Ent(Y|X)$表示在已知X的条件下Y的不确定性，定义为给定X时Y的条件概率分布的熵对X的期望</p>
<script type="math/tex; mode=display">
Ent(Y|X)=\sum_{i=1}^np_iEnt(Y|X=x_i)</script><p>对于训练集D以及其中的特征A，熵就是</p>
<script type="math/tex; mode=display">
Ent(D) = -\sum_{k=1}^K \frac {|C_k|}{|D|} log_2\frac{|C_k|}{|D|}</script><p>其中，K是标签分类的数量，$C_k$是每个分类的样本数</p>
<p>条件熵就是</p>
<script type="math/tex; mode=display">
\begin{aligned} 
Ent(D|A) &=\sum_{i=1}^N\frac{|D_i|}{|D|}Ent(D_i) \\
&=\sum_{i=1}^N\frac{|D_i|}{|D|}(-\sum_{k=1}^K \frac {|D_{ik}|}{|D_i|} log_2\frac{|D_{ik}|}{|D_i|})
\end{aligned}</script><p>其中，N是特征A的类别总数，$D_i$是特征A的每种类别的数量。</p>
<p>信息增益就是两者之差</p>
<script type="math/tex; mode=display">
Gain(D,A)=Ent(D)-Ent(D|A)</script><p>信息增益也称为<strong>互信息</strong>。</p>
<p>找出信息增益最大的来划分数据集</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">chooseBestFeature</span><span class="params">(dataSet)</span>:</span></span><br><span class="line">	<span class="comment">#feature数量，最后一列是label</span></span><br><span class="line">	numFeature = len(dataSet[<span class="number">0</span>]<span class="number">-1</span>)</span><br><span class="line">    bestInfoGain = <span class="number">0.0</span></span><br><span class="line">    bestFeature = <span class="number">-1</span></span><br><span class="line">	<span class="comment">#先计算熵</span></span><br><span class="line">	baseEntropy = calcEnt(dataSet)</span><br><span class="line">	<span class="keyword">for</span> i <span class="keyword">in</span> range(numFeature):</span><br><span class="line">		<span class="comment">#首先需要知道该特征有几个值</span></span><br><span class="line">		uniqueValue = set([sample[i] <span class="keyword">for</span> sample <span class="keyword">in</span> dataSet]) <span class="comment">#用set去重是最快方法</span></span><br><span class="line">		newEntropy = <span class="number">0.0</span></span><br><span class="line">        <span class="comment">#对于每个特征，计算条件熵</span></span><br><span class="line">        <span class="keyword">for</span> value <span class="keyword">in</span> uniqueValue:</span><br><span class="line">            <span class="comment">#用这个特征划分数据集</span></span><br><span class="line">            subDataSet = splitDataSet(dataSet, i, value)</span><br><span class="line">            newEntropy += calcEnt(subDataSet)</span><br><span class="line">        <span class="comment">#计算信息增益</span></span><br><span class="line">        infoGain = baseEntropy-newEntropy</span><br><span class="line">        <span class="keyword">if</span> infoGain &gt; bestInfoGain:</span><br><span class="line">            bestInfoGain = infoGain</span><br><span class="line">            bestFeature = i</span><br><span class="line"><span class="keyword">return</span> bestFeature</span><br></pre></td></tr></table></figure>
<p>如果所有特征都处理过了，但是类标签依然不是唯一的，用投票决定</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">majorityCnt</span><span class="params">(classList)</span>:</span></span><br><span class="line">	classCount=&#123;&#125;</span><br><span class="line">    <span class="keyword">for</span> vote <span class="keyword">in</span> classList:</span><br><span class="line">        <span class="keyword">if</span> vote <span class="keyword">not</span> <span class="keyword">in</span> classCount.keys() classCount[vote] = <span class="number">0</span></span><br><span class="line">        classCount[vote] += <span class="number">1</span></span><br><span class="line">    sortedClassCount = sorted(classCount, key = operator.itemgetter(<span class="number">1</span>), reverse = <span class="keyword">True</span>)</span><br><span class="line">    <span class="keyword">return</span> sortedClassCount[<span class="number">0</span>][<span class="number">0</span>]</span><br></pre></td></tr></table></figure>
<h2 id="1-2-ID3算法"><a href="#1-2-ID3算法" class="headerlink" title="1.2 ID3算法"></a>1.2 ID3算法</h2><p>与上面的步骤类似。但是ID3只有树的生成，容易过拟合。</p>
<h2 id="1-3-C4-5算法"><a href="#1-3-C4-5算法" class="headerlink" title="1.3 C4.5算法"></a>1.3 C4.5算法</h2><p>与ID3相比，C4.5用信息增益比来选择特征。</p>
<p><strong>信息增益比</strong></p>
<p>在面对类别比较少的离散数据时，两者差不多。但如果面对连续的数据（如体重、身高、年龄、距离等），或者每列数据没有明显的类别之分（最极端的例子的该列所有数据都独一无二）。</p>
<p>那么根据信息增益公式，$Ent(D)$不变，当数据独一无二时，</p>
<script type="math/tex; mode=display">
Ent(D|A)=\sum_{i=1}^n \frac {1}{n}Ent(D_i)</script><p>这样$Ent(D|A)$最小，程序会倾向于这种划分，导致划分效果差。</p>
<p>信息增益比的公式为</p>
<script type="math/tex; mode=display">
Gain_R(D,A)=\frac {Gain(D,A)}{Ent(D)}</script><p>可以理解成<strong>对分支数目的惩罚项</strong>。</p>
<h2 id="1-5-CART算法"><a href="#1-5-CART算法" class="headerlink" title="1.5 CART算法"></a>1.5 CART算法</h2><p>CART是分类与回归树，由特征选择、树的生成和剪枝组成。</p>
<p>CART是在给定输入变量X条件下输出随机变量Y的条件概率分布的方法。CART假设决策树是<strong>二叉树</strong>，内部结点特征的取值为是和否，约定左是右否。</p>
<p>决策树等价于递归的二分每个特征，将输入空间即特征空间划分为有限个单元，并在这些单元上确定预测的概率分布，也就是在输入给定的条件下输出的条件概率分布。</p>
<p>1.5.1 CART的生成</p>
<p>递归构建二叉树的过程。回归树用<strong>最小二乘</strong>，分类树用<strong>基尼指数</strong>。</p>
<p>1）回归树</p>
<p>2）分类树</p>
<p>假设有K个类，样本点属于第k类的概率是$p_k$，则基尼指数定义为</p>
<script type="math/tex; mode=display">
Gini(p) = \sum_{k=1}^K p_k(1-p_k) = 1-\sum_{k=1}^K p_k^2=1-\sum_{k=1}^K(\frac{|C_k|}{|D|})^2</script><p>如果是两分类问题，则概率分布的基尼指数为</p>
<script type="math/tex; mode=display">
Gini(P)=2p(1-p)</script><p>若样本集合D根据特征A是否取某一值a被划分为$D_1$和$D_2$两部分，即</p>
<script type="math/tex; mode=display">
D_1=\{(x,y)\in D | A(x)=a\}, D_2=D-D_1</script><p>则在特征A的条件下，集合D的基尼指数为</p>
<script type="math/tex; mode=display">
Gini(D,A)=\frac {|D_1|}{|D|}Gini(D_1)+\frac {|D_2|}{|D|}Gini(D_2)</script><p>Gini越大，样本集合的不确定性越大，与熵相似。</p>
<p><strong>算法过程</strong></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">输入：训练集D，停止条件</span><br><span class="line">输出：CART决策树</span><br><span class="line"></span><br><span class="line">从根结点递归对每个结点进行以下操作，构建二叉树：</span><br><span class="line">1）对每个特征和可能的取值a，根据A=a的为是或否，将D分割成D1和D2，计算基尼指数</span><br><span class="line">2）选出基尼指数最小的特征及其对应的切分点作为最优特征与最优切分点。</span><br><span class="line">3）对两个子结点递归调用#1、#2，直至满足停止条件</span><br><span class="line">4）生成CART决策树</span><br></pre></td></tr></table></figure>
<p>3）CART剪枝</p>
<h2 id="1-6-决策树的剪枝"><a href="#1-6-决策树的剪枝" class="headerlink" title="1.6 决策树的剪枝"></a>1.6 决策树的剪枝</h2><blockquote>
<p>如何判断剪枝后泛华性能提升？</p>
<p>用<strong>留出法</strong>。将一部分训练集作为验证集。</p>
</blockquote>
<p>剪枝是为了解决过拟合。通过极小化决策树整体的损失函数来实现。设树T的叶结点个数为$|T|$，t是T的叶结点，该叶结点有$N<em>t$个样本点，其中k类的样本点有$N</em>{tk}$个，则损失函数定义为</p>
<script type="math/tex; mode=display">
C_{\alpha}(T) = \sum_{t=1}^T N_tEnt_t(T) + \alpha|T|</script><p>由于</p>
<script type="math/tex; mode=display">
Ent_t(T) =  - \sum_{k=1}^K \frac {N_{tk}}{N_t} log_2\frac {N_{tk}}{N_t}</script><p>则令</p>
<script type="math/tex; mode=display">
C(T) = - \sum_{t=1}^T\sum_{k=1}^KN_{tk}log_2\frac {N_{tk}}{N_t}</script><p>于是</p>
<script type="math/tex; mode=display">
C_\alpha(T) = C(T) +\alpha|T|</script><p>这里，$C(T)$表示训练数据的预测误差，$|T|$表示模型复杂度，$\alpha$控制两者影响，较大时选择较简单的树，反之亦然，等于0时就不考虑模型复杂度。</p>
<p>两种剪枝思路</p>
<p><strong>预剪枝（Pre-Pruning）</strong></p>
<p>构造的同时剪枝。比如设一个阈值，熵减小的数量小于这个阈值，即使还可以继续降低熵，也停止继续创建分支。</p>
<blockquote>
<p>有些分支虽然当前划分时性能下降，但后续划分有可能又会提高，仅根据当前验证集来判断是否要继续划分，往往会导致欠拟合。</p>
</blockquote>
<p><strong>后剪枝（Post-Pruning）</strong></p>
<p>三种主要方法</p>
<p><strong>1）REP错误率降低剪枝</strong></p>
<p>简单粗暴，对每个非叶结点的子树，用其替换一个叶结点，类别用子树覆盖训练样本中类最多的代替。这样产生的简化树再跟原树比较在测试数据集中的效果。若错误更少就替换。算法以Bottom-up的方式遍历所有的子树，直到没有任何改进时，终止。</p>
<p><strong>2）PEP悲观剪枝</strong></p>
<h2 id="1-7-连续和缺失值处理"><a href="#1-7-连续和缺失值处理" class="headerlink" title="1.7 连续和缺失值处理"></a>1.7 连续和缺失值处理</h2><p>1）连续值离散化</p>
<p>jueceshu最简单的策略是<strong>二分法</strong>，也是C4.5采用的机制。</p>
<p>对于连续属性a，可以考察包含n-1个元素的候选划分点集合</p>
<script type="math/tex; mode=display">
T_a=\left \{  \frac {a^i+a^{i+1}} {2} | 1 \leqslant i \leqslant n-1    \right \}</script><p>即把区间的中位点作为候选划分点，然后像离散值那样考察划分点，再选出最优的划分点。</p>
<p>2）缺失值</p>
<p>考虑：①如何在属性值缺失的情况下进行划分属性选择？②给定划分属性，若样本在该属性的值缺失，如何划分？</p>
<p>靠<strong>权重</strong>。在判定划分时，权重相等，用已知的样本来划分属性。对于每个划分属性，若属性缺失，将缺失的记录根据属性的每个划分所占比例作为权重，分到属性的每个子结点中。</p>
<h2 id="1-8-多变量决策树"><a href="#1-8-多变量决策树" class="headerlink" title="1.8 多变量决策树"></a>1.8 多变量决策树</h2><p>非子结点不再针对某个属性，而是多个属性的线性组合。即，每个非子结点都是一个线性分类器。</p>
<h1 id="2、随机森林"><a href="#2、随机森林" class="headerlink" title="2、随机森林"></a>2、随机森林</h1><p>随机森林如何随机的，特征也随机，样本也随机</p>
<h1 id="3、GBDT"><a href="#3、GBDT" class="headerlink" title="3、GBDT"></a>3、GBDT</h1><p><a href="https://www.zhihu.com/question/266195966" target="_blank" rel="noopener">决策树是否应该用one-hot编码</a></p>
<p>参考</p>
<p>统计学习方法</p>
<p><a href="http://www.jianshu.com/p/794d08199e5e" target="_blank" rel="noopener">决策树的剪枝问题</a></p>

          
        
      
    </div>

    

    
    
    

    

    
      
    
    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  

  <article class="post post-type-normal" itemscope="" itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="https://schwimmer.github.io/2017/08/13/机器学习/NLP/Gensim-LDA/">

    <span hidden itemprop="author" itemscope="" itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Schwimmer">
      <meta itemprop="description" content="Record and Think!">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope="" itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Schwimmer's Blog">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                
                <a href="/2017/08/13/机器学习/NLP/Gensim-LDA/" class="post-title-link" itemprop="url">（转）LDA</a>
              
            
          </h1>
        

        <div class="post-meta">

          
          
          

          
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              

              
                
              

              <time title="创建时间：2017-08-13 11:49:53" itemprop="dateCreated datePublished" datetime="2017-08-13T11:49:53+08:00">2017-08-13</time>
            </span>
          

          
            

            
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="fa fa-calendar-check-o"></i>
                </span>
                
                  <span class="post-meta-item-text">更新于</span>
                
                <time title="修改时间：2018-02-01 23:21:31" itemprop="dateModified" datetime="2018-02-01T23:21:31+08:00">2018-02-01</time>
              </span>
            
          

          
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope="" itemtype="http://schema.org/Thing"><a href="/categories/NLP/" itemprop="url" rel="index"><span itemprop="name">NLP</span></a></span>

                
                
              
            </span>
          

          
            
            
              
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="fa fa-comment-o"></i>
                </span>
            
                <span class="post-meta-item-text">评论数：</span>
                <a href="/2017/08/13/机器学习/NLP/Gensim-LDA/#comments" itemprop="discussionUrl">
                  <span class="post-comments-count disqus-comment-count" data-disqus-identifier="2017/08/13/机器学习/NLP/Gensim-LDA/" itemprop="commentCount"></span>
                </a>
              </span>
            
          

          
          

          

          <br>
          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1 id="原理"><a href="#原理" class="headerlink" title="原理"></a>原理</h1><h1 id="gensim-LDA"><a href="#gensim-LDA" class="headerlink" title="gensim-LDA"></a>gensim-LDA</h1><p><a href="http://blog.csdn.net/whzhcahzxh/article/details/17528261" target="_blank" rel="noopener">http://blog.csdn.net/whzhcahzxh/article/details/17528261</a></p>
<p>引用gensim包，gensim包中引用corpora,models, similarities，分别做语料库建立，模型库和相似度比较库</p>
<p>from gensim import corpora, models, similarities</p>
<p>import jieba</p>
<h3 id="1、分词"><a href="#1、分词" class="headerlink" title="1、分词"></a>1、分词</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">sentences = [&quot;我喜欢吃土豆&quot;,&quot;土豆是个百搭的东西&quot;,&quot;我不喜欢今天雾霾的北京&quot;]</span><br><span class="line">words=[]</span><br><span class="line">for doc in sentences:</span><br><span class="line"># 结巴分词返回的是一个generator，要用list()转成list</span><br><span class="line">    words.append(list(jieba.cut(doc)))</span><br><span class="line">print words</span><br></pre></td></tr></table></figure>
<p>输出：</p>
<p>[[u’\u6211’, u’\u559c\u6b22’, u’\u5403’, u’\u571f\u8c46’], [u’\u571f\u8c46’, u’\u662f’, u’\u4e2a’, u’\u767e’, u’\u642d’, u’\u7684’, u’\u4e1c\u897f’], [u’\u6211’, u’\u4e0d’, u’\u559c\u6b22’, u’\u4eca\u5929’, u’\u96fe’, u’\u973e’, u’\u7684’, u’\u5317\u4eac’]]</p>
<p>此时输出的格式为unicode，不影响后期运算，因此我保留不变，如果想看分词结果可以用循环输出jieba分词结果</p>
<h3 id="2、分词结果构造词典"><a href="#2、分词结果构造词典" class="headerlink" title="2、分词结果构造词典"></a>2、分词结果构造词典</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">dic = corpora.Dictionary(words)</span><br><span class="line"># 词袋中的所有词</span><br><span class="line">print dic</span><br><span class="line"># 每个词和编号</span><br><span class="line">print dic.token2id</span><br></pre></td></tr></table></figure>
<p>输出：</p>
<p>Dictionary(15 unique tokens: [u’\u973e’, u’\u5403’, u’\u5317\u4eac’, u’\u7684’, u’\u4e1c\u897f’]…)</p>
<p>{u’\u973e’: 14, u’\u5403’: 0, u’\u5317\u4eac’: 12, u’\u7684’: 9, u’\u4e1c\u897f’: 4, u’\u4e2a’: 5, u’\u642d’: 6, u’\u662f’: 7, u’\u6211’: 3, u’\u559c\u6b22’: 1, u’\u4eca\u5929’: 11, u’\u571f\u8c46’: 2, u’\u4e0d’: 10, u’\u96fe’: 13, u’\u767e’: 8}</p>
<p>为方便看数据：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">for word,index in dic.token2id.iteritems():</span><br><span class="line">    print word +&quot; 编号为:&quot;+ str(index)</span><br></pre></td></tr></table></figure>
<p>输出：</p>
<p>北京 编号为:12<br>搭 编号为:6<br>的 编号为:9<br>喜欢 编号为:1<br>不 编号为:10<br>东西 编号为:4<br>土豆 编号为:2<br>霾 编号为:14<br>是 编号为:7<br>个 编号为:5<br>雾 编号为:13<br>百 编号为:8<br>今天 编号为:11<br>我 编号为:3<br>吃 编号为:0</p>
<h3 id="3、生成语料库"><a href="#3、生成语料库" class="headerlink" title="3、生成语料库"></a>3、生成语料库</h3><p>词袋模型</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">corpus = [dic.doc2bow(text) for text in words]</span><br><span class="line">print corpus</span><br></pre></td></tr></table></figure>
<p>输出：</p>
<p>[[(0, 1), (1, 1), (2, 1), (3, 1)], [(2, 1), (4, 1), (5, 1), (6, 1), (7, 1), (8, 1), (9, 1)], [(1, 1), (3, 1), (9, 1), (10, 1), (11, 1), (12, 1), (13, 1), (14, 1)]]</p>
<h3 id="4、TFIDF变换"><a href="#4、TFIDF变换" class="headerlink" title="4、TFIDF变换"></a>4、TFIDF变换</h3><p>通过语料库得到tfidf的值，由tfidf来描述句子</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#通过语料库得到tfidf模型</span></span><br><span class="line">tfidf = models.TfidfModel(corpus)</span><br><span class="line"></span><br><span class="line">vec = [(<span class="number">0</span>, <span class="number">1</span>), (<span class="number">4</span>, <span class="number">1</span>)]</span><br><span class="line"><span class="keyword">print</span> tfidf[vec]</span><br><span class="line"><span class="comment">#对corpus的每个文档中的每个词计算tfidf，得到的结果是，每个文档的每个词都是一个元组，包括id和tfidf值</span></span><br><span class="line">corpus_tfidf = tfidf[corpus]</span><br><span class="line"><span class="keyword">for</span> doc <span class="keyword">in</span> corpus_tfidf:</span><br><span class="line">    <span class="keyword">print</span> doc</span><br></pre></td></tr></table></figure>
<p>输出：</p>
<p>[(0, 0.7071067811865475), (4, 0.7071067811865475)]<br>[(0, 0.8425587958192721), (1, 0.3109633824035548), (2, 0.3109633824035548), (3, 0.3109633824035548)]<br>[(2, 0.16073253746956623), (4, 0.4355066251613605), (5, 0.4355066251613605), (6, 0.4355066251613605), (7, 0.4355066251613605), (8, 0.4355066251613605), (9, 0.16073253746956623)]<br>[(1, 0.1586956620869655), (3, 0.1586956620869655), (9, 0.1586956620869655), (10, 0.42998768831312806), (11, 0.42998768831312806), (12, 0.42998768831312806), (13, 0.42998768831312806), (14, 0.42998768831312806)]</p>
<p>vec是查询文本向量，比较vec和训练中的三句话相似度</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">index = similarities.SparseMatrixSimilarity(tfidf[corpus], num_features=14)</span><br><span class="line">sims = index[tfidf[vec]]</span><br><span class="line">print list(enumerate(sims))</span><br></pre></td></tr></table></figure>
<p>输出：</p>
<p>[(0, 0.59577906), (1, 0.30794966), (2, 0.0)]</p>
<p>表示和第1句话相似度为59.578%，和第二句话的相似度位30.79%，第三句没有相似度，</p>
<p>我们看看vec这句话是什么：0为吃，4为东西，所以vec这句话可以是[“吃东西”]或者[“东西吃”]</p>
<p>而第一句话”我喜欢吃土豆”,”土豆是个百搭的东西”明显有相似度，而第三句话”我不喜欢今天雾霾的北京”，相似度几乎为0，至于为什么第一句比第二句更相似，就需要考虑TfIdf document representation和cosine similarity measure了</p>
<p>回到tfidf转换，接着训练LSI模型，假定三句话属于2个主题，</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">lsi = models.LsiModel(corpus_tfidf, id2word=dic, num_topics=<span class="number">2</span>)</span><br><span class="line">lsiout=lsi.print_topics(<span class="number">2</span>)</span><br><span class="line"><span class="keyword">print</span> lsiout[<span class="number">0</span>]</span><br><span class="line"><span class="keyword">print</span> lsiout[<span class="number">1</span>]</span><br></pre></td></tr></table></figure>
<p>输出：</p>
<p>0.532<em>“吃” + 0.290</em>“喜欢” + 0.290<em>“我” + 0.258</em>“土豆” + 0.253<em>“霾” + 0.253</em>“雾” + 0.253<em>“北京” + 0.253</em>“今天” + 0.253<em>“不” + 0.166</em>“东西”<br>0.393<em>“百” + 0.393</em>“搭” + 0.393<em>“东西” + 0.393</em>“是” + 0.393<em>“个” + -0.184</em>“霾” + -0.184<em>“雾” + -0.184</em>“北京” + -0.184<em>“今天” + -0.184</em>“不”</p>
<p>这就是基于SVD建立的两个主题模型内容</p>
<p>将文章投影到主题空间中</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">corpus_lsi = lsi[corpus_tfidf]</span><br><span class="line"><span class="keyword">for</span> doc <span class="keyword">in</span> corpus_lsi:</span><br><span class="line">    <span class="keyword">print</span> doc</span><br></pre></td></tr></table></figure>
<p>输出：</p>
<p>[(0, -0.70861576320682107), (1, 0.1431958007198823)]<br>[(0, -0.42764142348481798), (1, -0.88527674470703799)]<br>[(0, -0.66124862582594512), (1, 0.4190711252114323)]</p>
<p>因此第一三两句和主题一相似，第二句和主题二相似</p>
<p>同理做个LDA</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">lda = models.LdaModel(corpus_tfidf, id2word=dic, num_topics=<span class="number">2</span>)</span><br><span class="line">ldaOut=lda.print_topics(<span class="number">2</span>)</span><br><span class="line"><span class="keyword">print</span> ldaOut[<span class="number">0</span>]</span><br><span class="line"><span class="keyword">print</span> ldaOut[<span class="number">1</span>]</span><br><span class="line">corpus_lda = lda[corpus_tfidf]</span><br><span class="line"><span class="keyword">for</span> doc <span class="keyword">in</span> corpus_lda:</span><br><span class="line">    <span class="keyword">print</span> doc</span><br></pre></td></tr></table></figure>
<p>得到的结果每次都变，给一次的输出：</p>
<p>0.077<em>吃 + 0.075</em>北京 + 0.075<em>雾 + 0.074</em>今天 + 0.073<em>不 + 0.072</em>霾 + 0.070<em>喜欢 + 0.068</em>我 + 0.062<em>的 + 0.061</em>土豆<br>0.091<em>吃 + 0.073</em>搭 + 0.073<em>土豆 + 0.073</em>个 + 0.073<em>是 + 0.072</em>百 + 0.071<em>东西 + 0.066</em>我 + 0.065<em>喜欢 + 0.059</em>霾<br>[(0, 0.31271095988105352), (1, 0.68728904011894654)]<br>[(0, 0.19957991735916861), (1, 0.80042008264083142)]<br>[(0, 0.80940337254233863), (1, 0.19059662745766134)]</p>
<p>第一二句和主题二相似，第三句和主题一相似</p>
<p>结论和LSI不一样，我估计这和样本数目太少，区别度不高有关，毕竟让我来区分把第一句和哪一句分在一个主题，我也不确定</p>
<p>输入一句话，查询属于LSI得到的哪个主题类型，先变成词袋模型，然后查询LSI：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">query = <span class="string">"雾霾"</span></span><br><span class="line">query_bow = dic.doc2bow(list(jieba.cut(query)))</span><br><span class="line"><span class="keyword">print</span> query_bow</span><br><span class="line">query_lsi = lsi[query_bow]</span><br><span class="line"><span class="keyword">print</span> query_lsi</span><br></pre></td></tr></table></figure>
<p>输出:</p>
<p>[(13, 1), (14, 1)]<br>[(0, 0.50670602027401368), (1, -0.3678056037187441)]</p>
<p>与第一个主题相似</p>
<p>比较和第几句话相似，用LSI得到的索引接着做，并排序输出</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">index = similarities.MatrixSimilarity(lsi[corpus])</span><br><span class="line">sims = index[query_lsi]</span><br><span class="line"><span class="keyword">print</span> list(enumerate(sims))</span><br><span class="line">sort_sims = sorted(enumerate(sims), key=<span class="keyword">lambda</span> item: -item[<span class="number">1</span>])</span><br><span class="line"><span class="keyword">print</span> sort_sims</span><br></pre></td></tr></table></figure>
<p>输出：</p>
<p>[(0, 0.90161765), (1, -0.10271341), (2, 0.99058259)]<br>[(2, 0.99058259), (0, 0.90161765), (1, -0.10271341)]</p>
<p>可见和第二句话相似度很高，因为只有第二句话出现了雾霾两个词，可是惊讶的是和第一句话的相似度也很高，这得益于LSI模型的算法：<strong>在A和C共现，B和C共现的同时，可以找到A和B的相似度</strong></p>
<p>代码位于<code>blogcodes/gensim_lda.py</code></p>

          
        
      
    </div>

    

    
    
    

    

    
      
    
    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  

  <article class="post post-type-normal" itemscope="" itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="https://schwimmer.github.io/2017/08/12/机器学习/NLP/NLP代码片段/">

    <span hidden itemprop="author" itemscope="" itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Schwimmer">
      <meta itemprop="description" content="Record and Think!">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope="" itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Schwimmer's Blog">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                
                <a href="/2017/08/12/机器学习/NLP/NLP代码片段/" class="post-title-link" itemprop="url">NLP代码片段</a>
              
            
          </h1>
        

        <div class="post-meta">

          
          
          

          
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              

              
                
              

              <time title="创建时间：2017-08-12 11:49:53" itemprop="dateCreated datePublished" datetime="2017-08-12T11:49:53+08:00">2017-08-12</time>
            </span>
          

          
            

            
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="fa fa-calendar-check-o"></i>
                </span>
                
                  <span class="post-meta-item-text">更新于</span>
                
                <time title="修改时间：2018-03-31 10:28:31" itemprop="dateModified" datetime="2018-03-31T10:28:31+08:00">2018-03-31</time>
              </span>
            
          

          
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope="" itemtype="http://schema.org/Thing"><a href="/categories/NLP/" itemprop="url" rel="index"><span itemprop="name">NLP</span></a></span>

                
                
              
            </span>
          

          
            
            
              
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="fa fa-comment-o"></i>
                </span>
            
                <span class="post-meta-item-text">评论数：</span>
                <a href="/2017/08/12/机器学习/NLP/NLP代码片段/#comments" itemprop="discussionUrl">
                  <span class="post-comments-count disqus-comment-count" data-disqus-identifier="2017/08/12/机器学习/NLP/NLP代码片段/" itemprop="commentCount"></span>
                </a>
              </span>
            
          

          
          

          

          <br>
          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1 id="根据标点拆分句子"><a href="#根据标点拆分句子" class="headerlink" title="根据标点拆分句子"></a>根据标点拆分句子</h1><p><code>[AtomSplit.java](../../../../gitlab/user-gene/nlp/src/main/java/com/buzzinate/nlp/segment/AtomSplit.java)</code></p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line">	<span class="function"><span class="keyword">public</span> <span class="keyword">static</span> List&lt;String&gt; <span class="title">splitSentences</span><span class="params">(String text)</span> <span class="keyword">throws</span> IOException </span>&#123;</span><br><span class="line">		List&lt;String&gt; result = <span class="keyword">new</span> ArrayList&lt;String&gt;();</span><br><span class="line">		<span class="keyword">int</span> last = <span class="number">0</span>;</span><br><span class="line">		<span class="keyword">for</span> (Term term: Segment.split(text, ToAnalysis.USE_USER_DEFINE)) &#123;</span><br><span class="line">			<span class="keyword">if</span> (sentenceNatures.contains(term.getNatrue().natureStr) &amp;&amp; !isWhiteSpace(term.getName())) &#123;</span><br><span class="line">				<span class="keyword">if</span> (term.getOffe() &gt; last) &#123;</span><br><span class="line">					String snippet = text.substring(last, term.getOffe()).trim();  </span><br><span class="line">					<span class="keyword">if</span> (snippet.length() &gt; <span class="number">0</span>) result.add(snippet);</span><br><span class="line">				&#125;</span><br><span class="line">				last = term.getOffe() + term.getName().length();</span><br><span class="line">			&#125;</span><br><span class="line">		&#125;</span><br><span class="line">		<span class="keyword">if</span> (text.length() &gt; last) &#123;</span><br><span class="line">			String snippet = text.substring(last, text.length()).trim();  </span><br><span class="line">			<span class="keyword">if</span> (snippet.length() &gt; <span class="number">0</span>) result.add(snippet);</span><br><span class="line">		&#125;</span><br><span class="line">		<span class="keyword">return</span> result;</span><br><span class="line">	&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">boolean</span> <span class="title">isWhiteSpace</span><span class="params">(String term)</span> </span>&#123;</span><br><span class="line">		<span class="keyword">return</span> term.length() == <span class="number">1</span> &amp;&amp; (Character.isWhitespace(term.charAt(<span class="number">0</span>)) || term.charAt(<span class="number">0</span>) == <span class="string">'-'</span>);</span><br><span class="line">	&#125;</span><br></pre></td></tr></table></figure>
<h1 id="给每个字符标记类型"><a href="#给每个字符标记类型" class="headerlink" title="给每个字符标记类型"></a>给每个字符标记类型</h1><p><code>[AtomSplit.java](../../../../gitlab/user-gene/nlp/src/main/java/com/buzzinate/nlp/segment/AtomSplit.java)</code></p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * 给每个字符标记类型，如</span></span><br><span class="line"><span class="comment"> * [2011(AT_NUM), -(AT_PUNC), 34(AT_NUM), -(AT_PUNC), 43(AT_NUM),  (AT_PUNC), 为(AT_CHINESE), 中(AT_CHINESE), 国(AT_CHINESE)]</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@param</span> text</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@return</span></span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">static</span> List&lt;Atom&gt; <span class="title">split</span><span class="params">(String text)</span> </span>&#123;</span><br><span class="line">	List&lt;Atom&gt; result = <span class="keyword">new</span> ArrayList&lt;Atom&gt;();</span><br><span class="line">	<span class="keyword">int</span> last = <span class="number">0</span>;</span><br><span class="line">	AtomType t = AtomType.AT_LETTER;</span><br><span class="line">	<span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; text.length(); i++) &#123;</span><br><span class="line">		<span class="keyword">char</span> ch = text.charAt(i);</span><br><span class="line">		<span class="keyword">if</span> (TextUtil.isAlphaOrDigit(ch) || ch == <span class="string">'\''</span> || ch == <span class="string">'.'</span>) &#123;</span><br><span class="line">			<span class="keyword">if</span> (i == last) &#123;</span><br><span class="line">				t = AtomType.AT_LETTER;</span><br><span class="line">				<span class="keyword">if</span> (Character.isDigit(ch)) t = AtomType.AT_NUM;</span><br><span class="line">			&#125;</span><br><span class="line">		&#125; <span class="keyword">else</span> <span class="keyword">if</span> (Character.isLetter(ch)) &#123;</span><br><span class="line">			<span class="keyword">if</span> (i &gt; last) result.add(<span class="keyword">new</span> Atom(text.substring(last, i), t));</span><br><span class="line">			result.add(<span class="keyword">new</span> Atom(text.substring(i, i+<span class="number">1</span>), AtomType.AT_CHINESE));</span><br><span class="line">			last = i + <span class="number">1</span>;</span><br><span class="line">		&#125; <span class="keyword">else</span> &#123;</span><br><span class="line">			<span class="keyword">if</span> (i &gt; last) result.add(<span class="keyword">new</span> Atom(text.substring(last, i), t));</span><br><span class="line">			<span class="keyword">if</span> (t != AtomType.AT_LETTER || !isConnectChar(ch)) result.add(<span class="keyword">new</span> Atom(text.substring(i, i+<span class="number">1</span>), AtomType.AT_PUNC));</span><br><span class="line">			last = i + <span class="number">1</span>;</span><br><span class="line">		&#125;</span><br><span class="line">	&#125;</span><br><span class="line">	<span class="keyword">if</span> (text.length() &gt; last) result.add(<span class="keyword">new</span> Atom(text.substring(last, text.length()), t));</span><br><span class="line">	<span class="keyword">return</span> result;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h1 id="判断字符串的语言"><a href="#判断字符串的语言" class="headerlink" title="判断字符串的语言"></a>判断字符串的语言</h1><p>有两个开源的项目可以使用。一个是Apache Tika，一个是language-detection。language-detection是google Code上开源的一个语言检测软件包，不折不扣的日货，但使用起来非常方便，其project链接如下：<a href="http://code.google.com/p/language-detection" target="_blank" rel="noopener">http://code.google.com/p/language-detection</a>。基本上，你只需要引用langdetect.jar和其依赖的jsonic-1.3.0.jar（也是日货）即可</p>
<p><code>/rocket-iaudience-api/src/main/java/com/iclick/rocket/iaudience/api/common/LanguageDetectUtil.java</code></p>
<h2 id="判断中文字符"><a href="#判断中文字符" class="headerlink" title="判断中文字符"></a>判断中文字符</h2><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Character.isLetter()</span><br></pre></td></tr></table></figure>
<h2 id="判断是否为英文或数字"><a href="#判断是否为英文或数字" class="headerlink" title="判断是否为英文或数字"></a>判断是否为英文或数字</h2><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">boolean</span> <span class="title">isAlphaOrDigit</span><span class="params">(<span class="keyword">char</span> ch)</span> </span>&#123;</span><br><span class="line">	<span class="keyword">if</span> (ch &gt;= <span class="string">'a'</span> &amp;&amp; ch &lt;= <span class="string">'z'</span>)</span><br><span class="line">		<span class="keyword">return</span> <span class="keyword">true</span>;</span><br><span class="line">	<span class="keyword">if</span> (ch &gt;= <span class="string">'A'</span> &amp;&amp; ch &lt;= <span class="string">'Z'</span>)</span><br><span class="line">		<span class="keyword">return</span> <span class="keyword">true</span>;</span><br><span class="line">	<span class="keyword">if</span> (ch &gt;= <span class="string">'0'</span> &amp;&amp; ch &lt;= <span class="string">'9'</span>)</span><br><span class="line">		<span class="keyword">return</span> <span class="keyword">true</span>;</span><br><span class="line">	<span class="keyword">return</span> <span class="keyword">false</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h1 id="去除停用词"><a href="#去除停用词" class="headerlink" title="去除停用词"></a>去除停用词</h1><p>java</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">ArrayList&lt;String&gt; wordSet = new ArrayList&lt;String&gt;();</span><br><span class="line">// 自动去除停用词</span><br><span class="line">		for (Term term : NotionalTokenizer.segment(simplePhrase)) &#123;</span><br><span class="line">			wordSet.add(term.word);</span><br><span class="line">		&#125;</span><br></pre></td></tr></table></figure>
<p>python参考gensim</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line">documents = [&quot;Human machine interface for lab abc computer applications&quot;,</span><br><span class="line">             &quot;A survey of user opinion of computer system response time&quot;,</span><br><span class="line">             &quot;The EPS user interface management system&quot;,</span><br><span class="line">             &quot;System and human system engineering testing of EPS&quot;,              </span><br><span class="line">             &quot;Relation of user perceived response time to error measurement&quot;,</span><br><span class="line">             &quot;The generation of random binary unordered trees&quot;,</span><br><span class="line">             &quot;The intersection graph of paths in trees&quot;,</span><br><span class="line">             &quot;Graph minors IV Widths of trees and well quasi ordering&quot;,</span><br><span class="line">             &quot;Graph minors A survey&quot;]</span><br><span class="line">#停用词</span><br><span class="line">stoplist = set(&apos;for a of the and to in&apos;.split())</span><br><span class="line">texts = [ [word for word in document.lower().split() if word not in stoplist ]</span><br><span class="line">         for document in documents ]</span><br><span class="line">         </span><br><span class="line">#删除仅出现一次的词</span><br><span class="line">from collections import defaultdict</span><br><span class="line">frequency = defaultdict(int)</span><br><span class="line">for text in texts:</span><br><span class="line">    for token in text:</span><br><span class="line">        frequency[token] += 1</span><br><span class="line">texts = [[token for token in text if frequency[token] &gt; 1 ] for text in texts]</span><br></pre></td></tr></table></figure>
<h1 id="分词"><a href="#分词" class="headerlink" title="分词"></a>分词</h1><p>python用jieba</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> jieba</span><br><span class="line">sentences = [<span class="string">"我喜欢吃土豆"</span>,<span class="string">"土豆是个百搭的东西"</span>,<span class="string">"我不喜欢今天雾霾的北京"</span>]</span><br><span class="line">words=[]</span><br><span class="line"><span class="keyword">for</span> doc <span class="keyword">in</span> sentences:</span><br><span class="line"><span class="comment"># 结巴分词返回的是一个generator，要用list()转成list</span></span><br><span class="line">    words.append(list(jieba.cut(doc)))</span><br><span class="line"><span class="keyword">print</span> words</span><br></pre></td></tr></table></figure>
<p>java用hanlp</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">ArrayList&lt;String&gt; wordSet = new ArrayList&lt;String&gt;();</span><br><span class="line">// 自动去除停用词</span><br><span class="line">		for (Term term : NotionalTokenizer.segment(simplePhrase)) &#123;</span><br><span class="line">			wordSet.add(term.word);</span><br><span class="line">		&#125;</span><br></pre></td></tr></table></figure>
<h1 id="英文词干化"><a href="#英文词干化" class="headerlink" title="英文词干化"></a>英文词干化</h1>
          
        
      
    </div>

    

    
    
    

    

    
      
    
    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  

  <article class="post post-type-normal" itemscope="" itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="https://schwimmer.github.io/2017/08/12/机器学习/NLP/Gensim-Tutorials/">

    <span hidden itemprop="author" itemscope="" itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Schwimmer">
      <meta itemprop="description" content="Record and Think!">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope="" itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Schwimmer's Blog">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                
                <a href="/2017/08/12/机器学习/NLP/Gensim-Tutorials/" class="post-title-link" itemprop="url">Gensim-Tutorials</a>
              
            
          </h1>
        

        <div class="post-meta">

          
          
          

          
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              

              
                
              

              <time title="创建时间：2017-08-12 11:49:53" itemprop="dateCreated datePublished" datetime="2017-08-12T11:49:53+08:00">2017-08-12</time>
            </span>
          

          
            

            
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="fa fa-calendar-check-o"></i>
                </span>
                
                  <span class="post-meta-item-text">更新于</span>
                
                <time title="修改时间：2018-02-01 23:21:31" itemprop="dateModified" datetime="2018-02-01T23:21:31+08:00">2018-02-01</time>
              </span>
            
          

          
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope="" itemtype="http://schema.org/Thing"><a href="/categories/NLP/" itemprop="url" rel="index"><span itemprop="name">NLP</span></a></span>

                
                
              
            </span>
          

          
            
            
              
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="fa fa-comment-o"></i>
                </span>
            
                <span class="post-meta-item-text">评论数：</span>
                <a href="/2017/08/12/机器学习/NLP/Gensim-Tutorials/#comments" itemprop="discussionUrl">
                  <span class="post-comments-count disqus-comment-count" data-disqus-identifier="2017/08/12/机器学习/NLP/Gensim-Tutorials/" itemprop="commentCount"></span>
                </a>
              </span>
            
          

          
          

          

          <br>
          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p><a href="http://radimrehurek.com/gensim/tutorial.html" target="_blank" rel="noopener">http://radimrehurek.com/gensim/tutorial.html</a></p>
<p>Gensim 使用Python标准logging模块来记录log，使用方法是</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">import logging</span><br><span class="line">logging.basicConfig(format=&apos;%(asctime)s : %(levelname)s : %(message)s&apos;, level=logging.INFO)</span><br></pre></td></tr></table></figure>

          
        
      
    </div>

    

    
    
    

    

    
      
    
    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  

  <article class="post post-type-normal" itemscope="" itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="https://schwimmer.github.io/2017/07/12/hadoop-spark/spark/spark-streaming笔记/">

    <span hidden itemprop="author" itemscope="" itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Schwimmer">
      <meta itemprop="description" content="Record and Think!">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope="" itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Schwimmer's Blog">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                
                <a href="/2017/07/12/hadoop-spark/spark/spark-streaming笔记/" class="post-title-link" itemprop="url">spark-streaming笔记</a>
              
            
          </h1>
        

        <div class="post-meta">

          
          
          

          
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              

              
                
              

              <time title="创建时间：2017-07-12 11:49:53" itemprop="dateCreated datePublished" datetime="2017-07-12T11:49:53+08:00">2017-07-12</time>
            </span>
          

          
            

            
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="fa fa-calendar-check-o"></i>
                </span>
                
                  <span class="post-meta-item-text">更新于</span>
                
                <time title="修改时间：2018-01-30 15:47:26" itemprop="dateModified" datetime="2018-01-30T15:47:26+08:00">2018-01-30</time>
              </span>
            
          

          
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope="" itemtype="http://schema.org/Thing"><a href="/categories/hadoop-spark/" itemprop="url" rel="index"><span itemprop="name">hadoop-spark</span></a></span>

                
                
              
            </span>
          

          
            
            
              
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="fa fa-comment-o"></i>
                </span>
            
                <span class="post-meta-item-text">评论数：</span>
                <a href="/2017/07/12/hadoop-spark/spark/spark-streaming笔记/#comments" itemprop="discussionUrl">
                  <span class="post-comments-count disqus-comment-count" data-disqus-identifier="2017/07/12/hadoop-spark/spark/spark-streaming笔记/" itemprop="commentCount"></span>
                </a>
              </span>
            
          

          
          

          

          <br>
          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1 id="spark-streaming的示例"><a href="#spark-streaming的示例" class="headerlink" title="spark streaming的示例"></a>spark streaming的示例</h1><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span>   <span class="title">main</span> </span>( args : <span class="type">Array</span>[ <span class="type">String</span> ]): <span class="type">Unit</span> = &#123;</span><br><span class="line">         <span class="comment">//关闭一些不必要的日志</span></span><br><span class="line">        <span class="type">Logger</span>. getLogger ( <span class="string">"org.apache.spark"</span> ). setLevel (<span class="type">Level</span>. <span class="type">WARN</span> )</span><br><span class="line">        <span class="type">Logger</span>. getLogger ( <span class="string">"org.eclipse.jetty.server"</span> ). setLevel (<span class="type">Level</span>. <span class="type">OFF</span> )</span><br><span class="line">      </span><br><span class="line">         <span class="keyword">val</span>   conf  =  <span class="keyword">new</span>  <span class="type">SparkConf</span>(). setAppName ( <span class="string">"wordStreaming"</span> ). setMaster ( <span class="string">"local[2]"</span> ).</span><br><span class="line">         set ( <span class="string">"spark.sql.shuffle.partitions"</span> , <span class="string">"10"</span> ). set ( <span class="string">"spark.network.timeout"</span> , <span class="string">"30s"</span> )</span><br><span class="line">        . set ( <span class="string">"spark.shuffle.compress"</span> , <span class="string">"true"</span> ). set ( <span class="string">"spark.shuffle.spill.compress"</span> , <span class="string">"true"</span> )</span><br><span class="line">        . set ( <span class="string">"spark.shuffle.manager"</span> , <span class="string">"sort"</span> )</span><br><span class="line">         <span class="keyword">val</span>   sc  =  <span class="keyword">new</span>  <span class="type">SparkContext</span>( conf )</span><br><span class="line">        </span><br><span class="line">         <span class="comment">// 创建 StreamingContext，1 秒一个批次。这里要用 sc ，而不是 conf ，因为 sc 已经创建了</span></span><br><span class="line">         <span class="keyword">val</span>   ssc  =  <span class="keyword">new</span>  <span class="type">StreamingContext</span>( sc ,  <span class="type">Seconds</span> ( <span class="number">1</span> ))</span><br><span class="line">         <span class="comment">// 获得一个 DStream 负责连接 监听端口:地址</span></span><br><span class="line">         <span class="keyword">val</span>   lines  =  ssc . socketTextStream ( <span class="string">"192.168.37.129"</span> ,  <span class="number">9999</span> )</span><br><span class="line">         <span class="comment">// 对每一行数据执行 Split 操作</span></span><br><span class="line">         <span class="keyword">val</span>   words  =  lines . flatMap ( _. split ( <span class="string">" "</span> ) )</span><br><span class="line">         <span class="comment">// 统计 word 的数量</span></span><br><span class="line">         <span class="keyword">val</span>   pairs  =  words . map ( word  =&gt; ( word ,  <span class="number">1</span> ))</span><br><span class="line">         <span class="keyword">val</span>   wordCounts  =  pairs . reduceByKey (_  +  _)</span><br><span class="line">         <span class="comment">// 输出结果</span></span><br><span class="line">         wordCounts . print ()</span><br><span class="line">        </span><br><span class="line">         ssc . start ()</span><br><span class="line">         ssc . awaitTermination () &#125;</span><br></pre></td></tr></table></figure>
<p>一开始会报错：<br>Exception in thread “main”  org.apache.spark.SparkException : Only one SparkContext may be running in this JVM (see SPARK-2243). To ignore this error, set spark.driver.allowMultipleContexts = true. The currently running SparkContext was created at: org.apache.spark.SparkContext.<init>( SparkContext.scala:82 )</init></p>
<p>错误是在<br>val   ssc  =  new  StreamingContext( conf ,  Seconds ( 1 ))   </p>
<p>因为之前sc已经创建了，所以这里的conf要改成sc</p>
<p>之后，在 192.168.37.129上启动netcat<br>nc -lk 9999<br>输入hello world</p>
<p>再启动spark的程序，可以看出会输出<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">Time: 1462790166000 ms</span><br><span class="line"></span><br><span class="line">(hello,1)</span><br><span class="line">(world,1)</span><br></pre></td></tr></table></figure></p>
<h1 id="streaming读取本地文件"><a href="#streaming读取本地文件" class="headerlink" title="streaming读取本地文件"></a>streaming读取本地文件</h1><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">val lines = ssc.textFileStream(&quot;E:\\spark&quot;)</span><br></pre></td></tr></table></figure>
<p>每当该文件夹内有新文件生成，就会自动读取</p>
<blockquote>
<p>Spark Streaming将会监控dataDirectory目录，并且处理目录下生成的任何文件（嵌套目录不被支持）。需要注意一下三点：<br>1 所有文件必须具有相同的数据格式<br>2 所有文件必须在<code>dataDirectory</code>目录下创建，文件是自动的移动和重命名到数据目录下<br>3 一旦移动，文件必须被修改。所以如果文件被持续的附加数据，新的数据不会被读取。<br>对于简单的文本文件，有一个更简单的方法streamingContext.textFileStream(dataDirectory)可以被调用。文件流不需要运行一个receiver，所以不需要分配核。</p>
</blockquote>
<h1 id="spark-streaming连接kafka"><a href="#spark-streaming连接kafka" class="headerlink" title="spark streaming连接kafka"></a>spark streaming连接kafka</h1><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">val topics = Set(&quot;test1&quot;)</span><br><span class="line">val kafkaParm = Map(&quot;metadata.broker.list&quot; -&gt; &quot;192.168.255.128:9092&quot;)</span><br></pre></td></tr></table></figure>

          
        
      
    </div>

    

    
    
    

    

    
      
    
    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  

  <article class="post post-type-normal" itemscope="" itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="https://schwimmer.github.io/2017/07/12/机器学习/面试刷题/">

    <span hidden itemprop="author" itemscope="" itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Schwimmer">
      <meta itemprop="description" content="Record and Think!">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope="" itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Schwimmer's Blog">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                
                <a href="/2017/07/12/机器学习/面试刷题/" class="post-title-link" itemprop="url">面试刷题</a>
              
            
          </h1>
        

        <div class="post-meta">

          
          
          

          
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              

              
                
              

              <time title="创建时间：2017-07-12 11:49:53" itemprop="dateCreated datePublished" datetime="2017-07-12T11:49:53+08:00">2017-07-12</time>
            </span>
          

          
            

            
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="fa fa-calendar-check-o"></i>
                </span>
                
                  <span class="post-meta-item-text">更新于</span>
                
                <time title="修改时间：2018-03-17 20:50:31" itemprop="dateModified" datetime="2018-03-17T20:50:31+08:00">2018-03-17</time>
              </span>
            
          

          
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope="" itemtype="http://schema.org/Thing"><a href="/categories/机器学习/" itemprop="url" rel="index"><span itemprop="name">机器学习</span></a></span>

                
                
              
            </span>
          

          
            
            
              
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="fa fa-comment-o"></i>
                </span>
            
                <span class="post-meta-item-text">评论数：</span>
                <a href="/2017/07/12/机器学习/面试刷题/#comments" itemprop="discussionUrl">
                  <span class="post-comments-count disqus-comment-count" data-disqus-identifier="2017/07/12/机器学习/面试刷题/" itemprop="commentCount"></span>
                </a>
              </span>
            
          

          
          

          

          <br>
          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <ol>
<li><a href="https://zhuanlan.zhihu.com/p/29965072" target="_blank" rel="noopener">那些深度学习《面试》你可能需要知道的</a></li>
<li><a href="https://zhuanlan.zhihu.com/p/29969587" target="_blank" rel="noopener">如何准备机器学习工程师的面试 ？</a></li>
<li><a href="https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/mp/homepage%3F__biz%3DMzI4MTQ2NjU5NA%3D%3D%26hid%3D1%26sn%3D93c4875b14fa5ad6f174829b2b8b4463%26scene%3D18%26devicetype%3DiPhone%2BOS9.3.5%26version%3D16051327%26lang%3Dzh_CN%26nettype%3D3G%2B%26ascene%3D7%26session_us%3Dgh_58f9504ddd59%26fontScale%3D100%26pass_ticket%3Dg8f%252FuIJqlsyfsGEdnZPm0SWWYRiZWOQHMp6bSSJ39kpkzb%252BgyByne%252BKNjMf%252Fo4pp%26wx_header%3D1%26scene%3D1" target="_blank" rel="noopener">七月在线实验室—-BAT机器学习面试题</a></li>
<li><a href="https://www.zhihu.com/question/23259302" target="_blank" rel="noopener">如何准备机器学习工程师的面试 ？</a></li>
<li><a href="https://zhuanlan.zhihu.com/p/27238249" target="_blank" rel="noopener">读完这21个机器学习面试问题和答案，入职率提升99%</a></li>
<li><a href="https://www.zhihu.com/question/25565713#answer-8243688" target="_blank" rel="noopener">国内互联网公司机器学习数据挖掘类的职位面试主要考察什么方面的东西？</a></li>
<li>….等等</li>
</ol>
<p>如何判断一个而链表中是否有环？<br>给定一棵二叉查找树中的两个元素，求它们的最近公共祖先。<br>给一个栈排序<br>基于比较的排序算法的时间复杂度是什么？证明？<br>如何求一个带权图中两个结点直接按的最短路径？如果有些权值是负的怎么办？<br>求一个字符串中所有的回文子串。<br>对这些问题你都要能够推导你的解法的时间和空间复杂度（大 O 表示法），并且尽量用最低的复杂度解决。<br><strong>只有通过大量的练习才能将这些不同类型的问题烂熟于胸，从而在面试中迅速地给出一个高效的解法。常用的算法面试准备平台有 InterviewBit、LeetCode、Interview Cake、Pramp、<a href="http://interviewing.io/" target="_blank" rel="noopener">http://interviewing.io</a> 等。</strong></p>
<p>概率论和统计典型问题</p>
<p>给出一个群体中男性和女性各自的平均身高，求整个群体的平均身高。<br>一次调查表明意大利三分之一的汽车都是法拉利，并且在那之中一半的车都是红色的。如果你在意大利的街头看到一辆红色的汽车驶来，请问它是法拉利的可能性有多大？<br>你试图找出在自己的网站上放置版头的最佳方案。变量包括版头的尺寸（大、中、小）以及放置的位置（顶部、中间、底部）。假定需要 95% 的置信水平，请问你至少需要多少次访问和点击来确定某个方案比其他的组合都要好？<br><strong>很多机器学习算法都以概率论和统计作为理论基础。对于这些基础知识有清晰的概念是极为重要的。当然同时你也要能够将这些抽象的概念与现实联系起来。</strong><br>数据建模和评估典型问题</p>
<p>一位农民想搞明白是什么因素影响了他的牛奶产量。他记录了每天的气温（30 - 40 度）、湿度（60 - 90%）、饲料消耗（2000 - 2500 千克）以及牛奶产量（500 - 1000 升）。<br>假设问题是要预测每天的牛奶产量，你会如何处理数据并建立模型？<br>这是一个什么类型的机器学习问题？<br>你的公司在开发一个面部表情识别系统。这个系统接受 1920 x 1080 的图片作为输入，并告诉用户图片中的人脸处于以下哪种情绪状态：平常、高兴、悲伤、愤怒和恐惧。当图片中没有人脸时系统要能够分辨这种情况。<br>这是一个什么类型的机器学习问题？<br>如果每个像素点由 3 个值来表示（RGB），那么输入数据的原始维度有多大？有办法降维吗？<br>如何对系统的输出进行编码？为什么？<br>过去几个世纪的气象数据展现出一种循环的气温模式：一会升高一会下降。对于这样的数据（一个年平均气温的序列），你会如何建模并预测未来 5 年的平均气温？<br>你在一家在线新闻网站工作，需要从各处收集文本，并将不同来源的内容聚集成一篇报道。你会如何设计这样一个系统？会用到哪些机器学习技术？<br><strong>应用机器学习算法和库</strong></p>
<p>你用一个给定的数据集训练一个单隐层的神经网络，发现网络的权值在训练中强烈地震荡（有时在负值和正值之间变化）。为了解决这个问题你需要调整哪个参数？<br>支持向量机的训练在本质上是在最优化哪个值？<br>LASSO 回归用 L1-norm 作为惩罚项，而岭回归（Ridge Regression）则使用 L2-norm 作为惩罚项。这两者哪个更有可能得到一个稀疏（某些项的系数为 0）的模型？<br>在用反向传播法训练一个 10 层的神经网络时，你发现前 3 层的权值完全没有变化，而 4 ~ 6 层的权值则变化得非常慢。这是为什么？如何解决？<br>你手上有一个关于小麦产出的数据集，包括年降雨量 R、平均海拔 A 以及小麦产量 O。你经过初步分析认为产量跟年降雨量的平方以及平均海报的对数之间存在关系，即：O = β_0 + β_1 x R^2 + β_2 x log(A)。能用线性回归求出系数 β 吗？<br>你可以通过像 Kaggle 比赛那样的数据科学和机器学习挑战来了解各种各样的问题和它们之间的细微差别。多多参加这些比赛，并尝试应用不同的机器学习模型。<br>软件工程和系统设计典型问题</p>
<p>你有一个电商网站，当用户点击一个商品打开详情页面时，你想基于商品特征和用户的购买历史为用户推荐 5 个其他的商品显示在页面的底部。你需要哪些服务和数据表来实现这个功能？请写一个查询语句或一段过程式代码来返回所要推荐的 5 个商品。<br>对于 YouTube 那样的在线视频网站，你会收集哪些数据来衡量用户的参与度和视频的人气度？<br>一个简单的垃圾邮件检测系统是这样的：它每次处理一封邮件，统计不同单词的出现频率（Term frequency），并将这些频率与之前已经被标注为垃圾 / 正常邮件的那些频率进行比较。现在需要对这系统进行拓展来处理海量的邮件流量，请设计一个 Map-Reduce 方案在一个集群上部署这个系统。<br>你要生成一个实时的热力图，来展示用户正在浏览和点击一个网页的哪些部分。在客户端和服务端分别需要哪些组件 / 服务 / API 来实现这个功能？</p>
<p><a href="http://blog.csdn.net/u010496169/article/details/73743973" target="_blank" rel="noopener">机器学习岗位面试问题汇总 之 集成学习</a></p>

          
        
      
    </div>

    

    
    
    

    

    
      
    
    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  

  <article class="post post-type-normal" itemscope="" itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="https://schwimmer.github.io/2017/07/12/hadoop-spark/presto笔记/">

    <span hidden itemprop="author" itemscope="" itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Schwimmer">
      <meta itemprop="description" content="Record and Think!">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope="" itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Schwimmer's Blog">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                
                <a href="/2017/07/12/hadoop-spark/presto笔记/" class="post-title-link" itemprop="url">presto笔记</a>
              
            
          </h1>
        

        <div class="post-meta">

          
          
          

          
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              

              
                
              

              <time title="创建时间：2017-07-12 11:49:53" itemprop="dateCreated datePublished" datetime="2017-07-12T11:49:53+08:00">2017-07-12</time>
            </span>
          

          
            

            
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="fa fa-calendar-check-o"></i>
                </span>
                
                  <span class="post-meta-item-text">更新于</span>
                
                <time title="修改时间：2019-06-13 15:36:33" itemprop="dateModified" datetime="2019-06-13T15:36:33+08:00">2019-06-13</time>
              </span>
            
          

          
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope="" itemtype="http://schema.org/Thing"><a href="/categories/hadoop-spark/" itemprop="url" rel="index"><span itemprop="name">hadoop-spark</span></a></span>

                
                
              
            </span>
          

          
            
            
              
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="fa fa-comment-o"></i>
                </span>
            
                <span class="post-meta-item-text">评论数：</span>
                <a href="/2017/07/12/hadoop-spark/presto笔记/#comments" itemprop="discussionUrl">
                  <span class="post-comments-count disqus-comment-count" data-disqus-identifier="2017/07/12/hadoop-spark/presto笔记/" itemprop="commentCount"></span>
                </a>
              </span>
            
          

          
          

          

          <br>
          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1 id="增加kafka配置"><a href="#增加kafka配置" class="headerlink" title="增加kafka配置"></a>增加kafka配置</h1><p>1、在<code>/opt/presto-server-0.152/etc/catalog/</code>增加文件<code>kafka.properties</code>，内容是</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">connector.name=kafka</span><br><span class="line">kafka.table-names=showup,click    </span><br><span class="line">kafka.nodes=10.11.10.33:9092</span><br><span class="line">#kafka.hide-internal-columns-hidden=false</span><br><span class="line">kafka.default-schema=rawdata</span><br></pre></td></tr></table></figure>
<p>其中，</p>
<blockquote>
<p>kafka.table-names 跟topic名称相同，如果topic是带前缀的，比如rawdata.showup，那么schema就是rawdata。</p>
<p>kafka.hide-internal-columns-hidden 建表后有一系列内置column，默认这些是隐藏的，设为false使其显示。</p>
<p>kafka.default-schema 如果topic没有前缀，默认的schema是default，可以用该参数修改默认schema名称。</p>
</blockquote>
<p>2、在etc的config.propreties中的datasources增加kafka</p>
<p>3、增加topic描述文件</p>
<p>放在<code>etc/kafka</code>目录中，以<code>.json</code>结尾，文件名和表名最好一致。例如：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line">&#123;</span><br><span class="line">    &quot;tableName&quot;: &quot;click_dis&quot;,</span><br><span class="line">    &quot;schemaName&quot;: &quot;rawdata&quot;,</span><br><span class="line">    &quot;topicName&quot;: &quot;click_dis&quot;,</span><br><span class="line">    &quot;key&quot;: &#123;</span><br><span class="line">        &quot;dataFormat&quot;: &quot;raw&quot;,</span><br><span class="line">        &quot;fields&quot;: [</span><br><span class="line">            &#123;</span><br><span class="line">                &quot;name&quot;: &quot;kafka_key&quot;,</span><br><span class="line">                &quot;type&quot;: &quot;VARCHAR&quot;,</span><br><span class="line">                &quot;hidden&quot;: &quot;false&quot;</span><br><span class="line">            &#125;</span><br><span class="line">        ]</span><br><span class="line">    &#125;,</span><br><span class="line">    &quot;message&quot;: &#123;</span><br><span class="line">        &quot;dataFormat&quot;: &quot;json&quot;,</span><br><span class="line">        &quot;fields&quot;: [</span><br><span class="line">            &#123;</span><br><span class="line">                &quot;name&quot;: &quot;dt_i&quot;,</span><br><span class="line">                &quot;mapping&quot;: &quot;dt_i&quot;,</span><br><span class="line">                &quot;type&quot;: &quot;BIGINT&quot;</span><br><span class="line">            &#125;</span><br><span class="line">        ]</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>4、重启presto服务器</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">/opt/presto-server-0.152/bin/launcher restart</span><br></pre></td></tr></table></figure>
<p>5、连接服务器测试</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">/opt/jdk1.8.0_102/bin/java -jar /opt/presto-server-0.152/presto-cli --server 10.11.10.33:8082 --catalog kafka --schema rawdata</span><br></pre></td></tr></table></figure>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">select * from click limit 10;</span><br></pre></td></tr></table></figure>
<p>其中内置column的意思是：</p>
<div class="table-container">
<table>
<thead>
<tr>
<th>Column name</th>
<th>Type</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td>_partition_id</td>
<td>BIGINT</td>
<td>包含这行数据的kafka partition的id</td>
</tr>
<tr>
<td>_partition_offset</td>
<td>BIGINT</td>
<td>kafka partition的offset</td>
</tr>
<tr>
<td>_segment_start</td>
<td>BIGINT</td>
<td>在该segment中的最小offset</td>
</tr>
<tr>
<td>_segment_end</td>
<td>BIGINT</td>
<td>在该segment中的最大offset</td>
</tr>
<tr>
<td>_segment_count</td>
<td>BIGINT</td>
<td>对于一个未压缩的topic，_segment_start + _segment_count is equal to _partition_offset</td>
</tr>
<tr>
<td>_message_corrupt</td>
<td>BOOLEAN</td>
<td>为TRUE就说明解码器不能解析message</td>
</tr>
<tr>
<td>_message</td>
<td>VARCHAR</td>
<td>UTF-8编码的string，只对text的topic有效</td>
</tr>
<tr>
<td>_message_length</td>
<td>BIGINT</td>
<td>message长度</td>
</tr>
<tr>
<td>_key_corrupt</td>
<td>BOOLEAN</td>
<td>为TRUE就说明解码器不能解析key</td>
</tr>
<tr>
<td>_key</td>
<td>VARCHAR</td>
<td>UTF-8编码的string</td>
</tr>
<tr>
<td>_key_length</td>
<td>BIGINT</td>
<td>key的长度</td>
</tr>
</tbody>
</table>
</div>
<p>查询key</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">select count(1) from showup_dis where kafka_key like &apos;20161009%&apos;;</span><br></pre></td></tr></table></figure>
<h1 id="语法"><a href="#语法" class="headerlink" title="语法"></a>语法</h1><h2 id="string转日期"><a href="#string转日期" class="headerlink" title="string转日期"></a>string转日期</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">date(b.data_date)</span><br></pre></td></tr></table></figure>
<h2 id="日期转string"><a href="#日期转string" class="headerlink" title="日期转string"></a>日期转string</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">cast(gpstime as varchar)</span><br></pre></td></tr></table></figure>
<h2 id="时间的string转timestamp"><a href="#时间的string转timestamp" class="headerlink" title="时间的string转timestamp"></a>时间的string转timestamp</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">cast(&apos;2019-03-01 12:00:00&apos; as timestamp)</span><br></pre></td></tr></table></figure>
<h2 id="日期加减"><a href="#日期加减" class="headerlink" title="日期加减"></a>日期加减</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">cast((date(b.data_date) - interval &apos;1&apos; day) as varchar)</span><br></pre></td></tr></table></figure>
<h2 id="日期转时间戳"><a href="#日期转时间戳" class="headerlink" title="日期转时间戳"></a>日期转时间戳</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">select to_unixtime(timestamp &apos;2018-12-27&apos;)*1000</span><br></pre></td></tr></table></figure>
<h2 id="两个日期相差的天数"><a href="#两个日期相差的天数" class="headerlink" title="两个日期相差的天数"></a>两个日期相差的天数</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">date_diff(&apos;day&apos;, date(last_date), date(&apos;2019-03-05&apos;))</span><br></pre></td></tr></table></figure>
<h1 id="presto-ui实现总数的统计"><a href="#presto-ui实现总数的统计" class="headerlink" title="presto ui实现总数的统计"></a>presto ui实现总数的统计</h1><p>/Users/david/david/git/yanagishima/src/main/java/yanagishima/service/PrestoServiceImpl.java</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">private</span> <span class="keyword">void</span> <span class="title">processData</span><span class="params">(StatementClient client, String datasource, String queryId, String query, PrestoQueryResult prestoQueryResult, List&lt;String&gt; columns, List&lt;List&lt;String&gt;&gt; rowDataList, <span class="keyword">long</span> start, <span class="keyword">int</span> limit, String userName)</span> </span>&#123;</span><br><span class="line">        Duration queryMaxRunTime = <span class="keyword">new</span> Duration(<span class="keyword">this</span>.yanagishimaConfig.getQueryMaxRunTimeSeconds(datasource), TimeUnit.SECONDS);</span><br><span class="line">        Path dst = getResultFilePath(datasource, queryId, <span class="keyword">false</span>);</span><br><span class="line">        <span class="keyword">int</span> lineNumber = <span class="number">0</span>;</span><br><span class="line">        <span class="keyword">int</span> maxResultFileByteSize = yanagishimaConfig.getMaxResultFileByteSize();</span><br><span class="line">        <span class="keyword">int</span> resultBytes = <span class="number">0</span>;</span><br><span class="line">        <span class="keyword">try</span> (BufferedWriter bw = Files.newBufferedWriter(dst, StandardCharsets.UTF_8);</span><br><span class="line">             CSVPrinter csvPrinter = <span class="keyword">new</span> CSVPrinter(bw, CSVFormat.EXCEL.withDelimiter(<span class="string">'\t'</span>).withNullString(<span class="string">"\\N"</span>).withRecordSeparator(System.getProperty(<span class="string">"line.separator"</span>)));) &#123;</span><br><span class="line">            csvPrinter.printRecord(columns);</span><br><span class="line">            lineNumber++;</span><br><span class="line">            <span class="keyword">while</span> (client.isRunning()) &#123;</span><br><span class="line">                Iterable&lt;List&lt;Object&gt;&gt; data = client.currentData().getData();</span><br><span class="line">                <span class="keyword">if</span> (data != <span class="keyword">null</span>) &#123;</span><br><span class="line">                    <span class="keyword">for</span>(List&lt;Object&gt; row : data) &#123;</span><br><span class="line">                        List&lt;String&gt; columnDataList = <span class="keyword">new</span> ArrayList&lt;&gt;();</span><br><span class="line">                        List&lt;Object&gt; tmpColumnDataList = row.stream().collect(Collectors.toList());</span><br><span class="line">                        <span class="keyword">for</span> (Object tmpColumnData : tmpColumnDataList) &#123;</span><br><span class="line">                            <span class="keyword">if</span> (tmpColumnData <span class="keyword">instanceof</span> Long) &#123;</span><br><span class="line">                                columnDataList.add(((Long) tmpColumnData).toString());</span><br><span class="line">                            &#125; <span class="keyword">else</span> <span class="keyword">if</span> (tmpColumnData <span class="keyword">instanceof</span> Double) &#123;</span><br><span class="line">                                <span class="keyword">if</span>(Double.isNaN((Double)tmpColumnData) || Double.isInfinite((Double) tmpColumnData)) &#123;</span><br><span class="line">                                    columnDataList.add(tmpColumnData.toString());</span><br><span class="line">                                &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">                                    columnDataList.add(BigDecimal.valueOf((Double) tmpColumnData).toPlainString());</span><br><span class="line">                                &#125;</span><br><span class="line">                            &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">                                <span class="keyword">if</span> (tmpColumnData == <span class="keyword">null</span>) &#123;</span><br><span class="line">                                    columnDataList.add(<span class="keyword">null</span>);</span><br><span class="line">                                &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">                                    columnDataList.add(tmpColumnData.toString());</span><br><span class="line">                                &#125;</span><br><span class="line">                            &#125;</span><br><span class="line">                        &#125;</span><br><span class="line">                        <span class="keyword">try</span> &#123;</span><br><span class="line">                            csvPrinter.printRecord(columnDataList);</span><br><span class="line">                            lineNumber++;</span><br><span class="line">                            resultBytes += columnDataList.toString().getBytes(StandardCharsets.UTF_8).length;</span><br><span class="line">                            <span class="keyword">if</span>(resultBytes &gt; maxResultFileByteSize) &#123;</span><br><span class="line">                                String message = String.format(<span class="string">"Result file size exceeded %s bytes. queryId=%s, datasource=%s"</span>, maxResultFileByteSize, queryId, datasource);</span><br><span class="line">                                storeError(db, datasource, <span class="string">"presto"</span>, client.currentStatusInfo().getId(), query, userName, message);</span><br><span class="line">                                <span class="keyword">throw</span> <span class="keyword">new</span> RuntimeException(message);</span><br><span class="line">                            &#125;</span><br><span class="line">                        &#125; <span class="keyword">catch</span> (IOException e) &#123;</span><br><span class="line">                            <span class="keyword">throw</span> <span class="keyword">new</span> RuntimeException(e);</span><br><span class="line">                        &#125;</span><br><span class="line">                        <span class="keyword">if</span> (client.getQuery().toLowerCase().startsWith(<span class="string">"show"</span>) || rowDataList.size() &lt; limit) &#123;</span><br><span class="line">                            rowDataList.add(columnDataList);</span><br><span class="line">                        &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">                            prestoQueryResult.setWarningMessage(String.format(<span class="string">"now fetch size is %d. This is more than %d. So, fetch operation stopped."</span>, rowDataList.size(), limit));</span><br><span class="line">                        &#125;</span><br><span class="line">                    &#125;</span><br><span class="line">                &#125;</span><br><span class="line">                client.advance();</span><br><span class="line">                checkTimeout(db, queryMaxRunTime, start, datasource, <span class="string">"presto"</span>, queryId, query, userName);</span><br><span class="line">            &#125;</span><br><span class="line">        &#125; <span class="keyword">catch</span> (IOException e) &#123;</span><br><span class="line">            <span class="keyword">throw</span> <span class="keyword">new</span> RuntimeException(e);</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        prestoQueryResult.setLineNumber(lineNumber);</span><br><span class="line">        <span class="keyword">try</span> &#123;</span><br><span class="line">            <span class="keyword">long</span> size = Files.size(dst);</span><br><span class="line">            DataSize rawDataSize = <span class="keyword">new</span> DataSize(size, DataSize.Unit.BYTE);</span><br><span class="line">            prestoQueryResult.setRawDataSize(rawDataSize.convertToMostSuccinctDataSize());</span><br><span class="line">        &#125; <span class="keyword">catch</span> (IOException e) &#123;</span><br><span class="line">            <span class="keyword">throw</span> <span class="keyword">new</span> RuntimeException(e);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br></pre></td></tr></table></figure>
<h1 id="空值替换"><a href="#空值替换" class="headerlink" title="空值替换"></a>空值替换</h1><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">coalesce</span><br></pre></td></tr></table></figure>

          
        
      
    </div>

    

    
    
    

    

    
      
    
    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  

  <article class="post post-type-normal" itemscope="" itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="https://schwimmer.github.io/2017/07/12/机器学习/机器学习笔记-最大熵/">

    <span hidden itemprop="author" itemscope="" itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Schwimmer">
      <meta itemprop="description" content="Record and Think!">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope="" itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Schwimmer's Blog">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                
                <a href="/2017/07/12/机器学习/机器学习笔记-最大熵/" class="post-title-link" itemprop="url">机器学习笔记-最大熵</a>
              
            
          </h1>
        

        <div class="post-meta">

          
          
          

          
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              

              
                
              

              <time title="创建时间：2017-07-12 11:49:53" itemprop="dateCreated datePublished" datetime="2017-07-12T11:49:53+08:00">2017-07-12</time>
            </span>
          

          
            

            
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="fa fa-calendar-check-o"></i>
                </span>
                
                  <span class="post-meta-item-text">更新于</span>
                
                <time title="修改时间：2018-03-17 20:50:31" itemprop="dateModified" datetime="2018-03-17T20:50:31+08:00">2018-03-17</time>
              </span>
            
          

          
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope="" itemtype="http://schema.org/Thing"><a href="/categories/机器学习/" itemprop="url" rel="index"><span itemprop="name">机器学习</span></a></span>

                
                
              
            </span>
          

          
            
            
              
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="fa fa-comment-o"></i>
                </span>
            
                <span class="post-meta-item-text">评论数：</span>
                <a href="/2017/07/12/机器学习/机器学习笔记-最大熵/#comments" itemprop="discussionUrl">
                  <span class="post-comments-count disqus-comment-count" data-disqus-identifier="2017/07/12/机器学习/机器学习笔记-最大熵/" itemprop="commentCount"></span>
                </a>
              </span>
            
          

          
          

          

          <br>
          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1 id="1、最大熵原理"><a href="#1、最大熵原理" class="headerlink" title="1、最大熵原理"></a>1、最大熵原理</h1><p>日常生活中，很多事情的发生表现出一定的随机性，试验的结果往往是不确定的，也不知道这个随机现象所服从的概率分布。<strong>最大熵的实质</strong>就是，在已知部分知识的前提下，关于未知分布最合理的推断就是符合已知知识最不确定或者最随机的推断。任何其他的选择都意味着我们增加了其他的约束和假设。</p>
<p>将最大熵应用到分类，就是最大熵模型。给定一个训练集：</p>
<script type="math/tex; mode=display">
T = \{  (x_1,y_1),  (x_2,y_2),..., (x_N,y_N)\}</script><p>其中$x_i \in X$是输入，$y_i \in Y$是输出，X和Y表示输入和输出空间。N为样本数。<strong>目标是</strong>，利用最大熵原理选出一个最好的分类模型，即对于任意给定的输入$x \in X$，可以以概率$p(y|x)$输出$y \in Y$ 。</p>
<p>按照最大熵原理，应该<strong>优先保证模型满足已知的所有约束</strong>。思路是，从训练数据T中抽取若干有用的特征，要求这些特征在T上关于经验分布$\tilde{p}(x,y)$的数学期望与它们在模型中关于$p(x,y)$的数学期望相等。这样，一个特征就是一个约束了。</p>
<p>这里就涉及到，<strong>特征如何刻画？经验分布如何表示？</strong></p>
<h1 id="2、特征函数"><a href="#2、特征函数" class="headerlink" title="2、特征函数"></a>2、特征函数</h1><p>假设通过特征选择，抽取若干特征。特征通常由特征函数来表示。例如</p>
<script type="math/tex; mode=display">
f(x,y) =\left\{\begin{matrix}
\begin{aligned}
& 1，若x,y满足某个事实 \\ 
& 0，否则
\end{aligned}
\end{matrix}\right.</script><p>这里的特征不是指输入的某个特征，而是指输入和输出共同的特征。</p>
<blockquote>
<p>例如，假设我们需要判断“打”是动词还是量词，已知的训练数据有</p>
<p>(x1,y1)=(一打火柴，量词);</p>
<p>(x2,y2)=(三打啤酒，量词);</p>
<p>(x3,y3)=(打电话，动词);</p>
<p>(x4,y4)=(打篮球，动词);</p>
<p>通过观察，发现“打”前面是数字时，是量词，“打”后面是名词时，是动词。这就是从训练数据中提取的两个特征，可分别用特征函数表示为</p>
</blockquote>
<h1 id="3、经验分布"><a href="#3、经验分布" class="headerlink" title="3、经验分布"></a>3、经验分布</h1><p>经验（概率）分布就是通过对训练集T进行统计得到的分布，用$\tilde p$表示。这里列举两个经验分布</p>
<script type="math/tex; mode=display">
\tilde p(x,y) = \frac {count(x,y)} {N} , \tilde p(x)=\frac {count(x)} {N}</script><p>其中，count表示出现的次数。</p>
<h1 id="4、约束条件"><a href="#4、约束条件" class="headerlink" title="4、约束条件"></a>4、约束条件</h1><p>对于任意一个特征函数f，$E<em>{\tilde p}f$ 表示f在训练数据T上关于$\tilde p(x,y)$的数学期望， $E</em>{p}f$ 表示f在训练数据T上关于$p(x,y)$的数学期望。按照期望的定义，我们有</p>
<script type="math/tex; mode=display">
E_{\tilde p}f=\sum_{x,y}\tilde p(x,y)f(x,y)</script><script type="math/tex; mode=display">
E_{ p}f=\sum_{x,y} p(x,y)f(x,y)</script><p>其中，p(x,y)是未知的，而建模的目标是生成$p(y|x)$，因此，根据Bayes定理，$p(x,y)=p(x)p(y|x)$。在样本数量足够的条件下，$p(x)$可以用$\tilde p(x)$近似表示。这样</p>
<script type="math/tex; mode=display">
E_{ p}f=\sum_{x,y} \tilde p(x)p(y|x)f(x,y)</script><p>对于概率分布$p(y|x)$，我们希望特征f的期望值应该和从训练集中得到的特征期望值是一致的，因此，<strong>增加约束</strong></p>
<script type="math/tex; mode=display">
E_{ p}f=E_{\tilde p}f</script><p>假设我们从训练集中抽取了n个特征，相应的，便有n个特征函数$f_i(i=1,2,…,n)$以及n个约束条件</p>
<script type="math/tex; mode=display">
C_i:E_{ p}(f_i)=E_{\tilde p}(f_i) \tag {3-1}</script><blockquote>
<p>关于约束条件的几何解释</p>
<p><img src="/.io//最大熵1.png" alt="最大熵1"></p>
<p>（a）：P是所有可能的概率空间，此时没有约束条件，所有的概率模型$p(y|x)$都是允许的；</p>
<p>（b）：增加了一个线性约束条件$C_1$，此时，目标分布$p(y|x)$只能落在由$C_1$定义的线段上；</p>
<p>（c）：在（b）的基础上增加了另一个约束条件$C_2$ ，且$C_1 \cap C_2  \neq \varnothing$。此时，目标分布只能落在交点上，即被唯一确定；</p>
<p>（d）：在（b）基础上增加了另一个约束$C_3$，且$C_1 \cap C_2  = \varnothing$，此时不存在能够同时满足$C_1$和$C_3$的$p(y|x)$。</p>
</blockquote>
<p>利用（3-1）定义的约束条件，我们定义P的一个子空间</p>
<script type="math/tex; mode=display">
C=\{p \in P | E_p(f_i)={\tau}_i, i=1,2,...,n\}</script><h1 id="5、最大熵模型"><a href="#5、最大熵模型" class="headerlink" title="5、最大熵模型"></a>5、最大熵模型</h1><p>由于我们的目标是获得一个条件分布，因此这里也采用相应的条件熵</p>
<script type="math/tex; mode=display">
H(p(y|x))=-\sum_{x,y} \tilde p(x)p(y|x)\log p(y|x)</script><p>可以看出这里也是用$\tilde p(x)$来近似$p(x)$。以下将$H(p(y|x))$简记为$H(p)$。至此，可以给出最大熵模型的完整描述。</p>
<p>对于给定的训练集T，特征函数$f_i(x,y), i=1,2,…n$，最大熵模型就是求解</p>
<script type="math/tex; mode=display">
\underset {p \in C} {max} \ \  H(p) = \begin{pmatrix}
-\sum_{x,y} \tilde p(x)p(y|x)\log p(y|x)
\end{pmatrix}, \\
s.t. \sum_y p(y|x)=1 \tag {5-1} \\
s.t. \ C=\{p \in P | E_p(f_i)={\tau}_i, i=1,2,...,n\}</script><p>其中的s.t.是为了保证$p(y|x)$是一个（合法的）条件概率分布。</p>
<p>等价于一个求极小值问题</p>
<script type="math/tex; mode=display">
\underset {p \in C} {min} \ \  -H(p) = \begin{pmatrix}
\sum_{x,y} \tilde p(x)p(y|x)\log p(y|x)
\end{pmatrix}, \\
s.t. \sum_y p(y|x)=1 \tag {5-2} \\
s.t. \ C=\{p \in P | E_p(f_i)={\tau}_i, i=1,2,...,n\}</script><h1 id="6、模型求解"><a href="#6、模型求解" class="headerlink" title="6、模型求解"></a>6、模型求解</h1><p>对于5-1的求解，主要思路和步骤如下：</p>
<ol>
<li>利用Lagrange乘子将最大熵模型由一个带约束的最优化问题转为无约束的最优化问题，这是一个<strong>极小极大问题（min max）</strong>。</li>
<li>利用对偶问题等价性，转化为求解上一步得到的极大/极小问题的对偶问题，也是一个极大极小问题。</li>
</ol>
<h2 id="6-1-原始问题和对偶问题"><a href="#6-1-原始问题和对偶问题" class="headerlink" title="6.1 原始问题和对偶问题"></a>6.1 原始问题和对偶问题</h2><p>根据（5-2），引入拉格朗日乘子$\lambda=(\lambda_0,\lambda_1,…,\lambda_n)^T$，定义拉格朗日函数</p>
<script type="math/tex; mode=display">
L(p,\lambda) = -H(p) + \lambda_0(1-\sum_y p(y|x))+\sum_{i=1}^n\lambda_i(\tau_i-E_p(f_i))  \tag{6-1}</script><p>利用对偶性，求解（6-1）的<strong>原始问题</strong>表示为：</p>
<script type="math/tex; mode=display">
\underset {p \in C} {min}\  \underset {\lambda} {max}\ L(p,\lambda) \tag{6-2}</script><p><strong>对偶问题</strong>为：</p>
<script type="math/tex; mode=display">
\underset {\lambda} {max}\ \underset {p \in C} {min}\  L(p,\lambda) \tag{6-3}</script><p>由于$H(p)$是关于p的凸函数，因此要求解最大熵模型，只需求解对偶问题（6-3）即可。</p>
<h3 id="6-1-1-指数形式的解"><a href="#6-1-1-指数形式的解" class="headerlink" title="6.1.1 指数形式的解"></a>6.1.1 指数形式的解</h3><p>首先求解内部的极小问题。由于$\underset {p \in C} {min}\  L(p,\lambda)$是关于$\lambda$的函数，将其记做：</p>
<script type="math/tex; mode=display">
\Psi (\lambda) =\underset {p \in C} {min}\  L(p,\lambda) = L(p_{\lambda}, \lambda) \tag {6-4}</script><p>其中</p>
<script type="math/tex; mode=display">
p_{\lambda}=\underset {p \in C} {argmin}\ L(p,\lambda)=p_{\lambda}(y|x) \tag {6-5}</script><p>根据拉格朗日乘子法，求$L(p,\lambda)$对$p(y|x)$的偏导，得（求解过程略）：</p>
<script type="math/tex; mode=display">
p_{\lambda}=\frac {1} {Z_{\lambda}(x)} \ \exp(\sum_{i=1}^n \lambda_i f_i(x,y)) \tag{6-6}</script><p>其中，</p>
<script type="math/tex; mode=display">
Z_{\lambda}(x)=\sum_y \exp(\sum_{i=1}^n \lambda_i f_i(x,y)) \tag{6-7}</script><p>称为<strong>规范化因子</strong>（normalizing factor）。注意，此时已经没有$\lambda_0$了。</p>
<p>由（6-6）定义的$p_{\lambda}$就是最大熵模型的解，它具有<strong>指数形式</strong>。其中，$\lambda_i$就是特征$f_i$的权重，越大表示特征越重要。</p>
<h3 id="6-1-2-最大似然估计"><a href="#6-1-2-最大似然估计" class="headerlink" title="6.1.2 最大似然估计"></a>6.1.2 最大似然估计</h3><p>得到对偶问题的内层极小值问题的解之后，接着求解外层的极大值问题$\underset {\lambda} {max} \ \Psi(\lambda)$。</p>
<p>设其解为</p>
<script type="math/tex; mode=display">
\lambda^* = \underset {\lambda} {argmax} \ \Psi(\lambda) \tag{6-8}</script><p>则最大熵模型的解为</p>
<script type="math/tex; mode=display">
p^*=p_{\lambda^*} \tag{6-9}</script><p>根据推导，最大化$\Psi(\lambda)$与最大似然估计是等价的！</p>
<h1 id="7、最优化方法"><a href="#7、最优化方法" class="headerlink" title="7、最优化方法"></a>7、最优化方法</h1><p>通用的方法有梯度下降，拟牛顿法等，最大熵模型有两个量身定做的方法：通用迭代尺度法（Generalized Iterative Scaling，GIS）和改进的迭代尺度法（Impoved Iterative Scaling，IIS）。</p>
<h2 id="7-1-GIS算法"><a href="#7-1-GIS算法" class="headerlink" title="7.1 GIS算法"></a>7.1 GIS算法</h2><blockquote>
<p>算法1：</p>
<p>S1：初始化参数，令$\lambda=0$</p>
<p>S2：计算$E_{\tilde p}(f_i),\ i=1,2,…,n$</p>
<p>S3：执行一次迭代，对参数做一次刷新。</p>
<p>​    计算$E<em>{p</em>{\lambda}}(f_i)$</p>
<p>​    FOR i=1,2,…,n DO {</p>
<p>​        $\lambda<em>i\  += \ \eta \log\frac {E</em>{\tilde p}(f<em>i)} {E</em>{p_{\lambda}}(f_i)}$</p>
<p>​    }</p>
<p>S4：检查是否收敛，若未收敛则继续S3</p>
</blockquote>
<p>其中，$\eta$是学习率，在实际中取$\frac {1} {C}$，$$，表示训练数据中包含特征最多的那个样本所包含的特征个数。</p>
<script type="math/tex; mode=display">
\Delta\lambda_i=\eta \log\frac {E_{\tilde p}(f_i)} {E_{p_{\lambda}}(f_i)}</script><p>是校正量。</p>
<p>每次迭代，先用当前的权重估算每个特征$f<em>i$在训练数据中的概率分布的期望，然后逐个与相应的经验分布的期望比较，其偏差程度通过$\log\frac {E</em>{\tilde p}(f<em>i)} {E</em>{p_{\lambda}}(f_i)}$来进行刻画。</p>
<p>收敛条件就是当两次迭代的$\lambda$在一个较小的范围。</p>
<p>GIS每次迭代时间很长，不太稳定，容易溢出，一般不会使用。</p>
<h2 id="7-2-IIS算法"><a href="#7-2-IIS算法" class="headerlink" title="7.2 IIS算法"></a>7.2 IIS算法</h2><p>与GIS的不同主要在$\Delta\lambda_i$的计算上。IIS通过求解方程</p>
<script type="math/tex; mode=display">
\sum_{x,y} \tilde p(x)p(y|x)f_i(x,y)\exp(\Delta\lambda_i\sum_{i=1}^nf_i(x,y))=\tilde p(f_i)</script><p>1）若$\sum<em>{i=1}^nf_i(x,y)$为常数，即对任意样本(x,y)，都有$\sum</em>{i=1}^nf_i(x,y)=C$，则</p>
<script type="math/tex; mode=display">
\Delta\lambda_i=\frac {1} {C} \log\frac {E_{\tilde p}(f_i)} {E_{p_{\lambda}}(f_i)}</script><p>此时，IIS可以看做是GIS的一种推广。</p>
<p>2）若$\sum_{i=1}^nf_i(x,y)$不是常数，则需要通过数值方式来求解$\Delta\lambda_i$，如牛顿法。</p>
<h1 id="8、优缺点"><a href="#8、优缺点" class="headerlink" title="8、优缺点"></a>8、优缺点</h1><p>优点是：在建模时，只需要集中精力选取特征，不需要花费精力考虑如何使用这些特征，可以灵活使用不同类型的特征。</p>
<p>缺点是计算量大。</p>
<p>参考</p>
<p>【1】 <a href="http://blog.csdn.net/itplus/article/details/26550273" target="_blank" rel="noopener">最大熵学习笔记</a></p>
<p>【2】统计学习方法</p>

          
        
      
    </div>

    

    
    
    

    

    
      
    
    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  

  <article class="post post-type-normal" itemscope="" itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="https://schwimmer.github.io/2017/07/12/Elastic Search/Elastic Search配置和使用/">

    <span hidden itemprop="author" itemscope="" itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Schwimmer">
      <meta itemprop="description" content="Record and Think!">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope="" itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Schwimmer's Blog">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                
                <a href="/2017/07/12/Elastic Search/Elastic Search配置和使用/" class="post-title-link" itemprop="url">Elastic Search 配置和使用</a>
              
            
          </h1>
        

        <div class="post-meta">

          
          
          

          
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              

              
                
              

              <time title="创建时间：2017-07-12 11:49:53" itemprop="dateCreated datePublished" datetime="2017-07-12T11:49:53+08:00">2017-07-12</time>
            </span>
          

          
            

            
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="fa fa-calendar-check-o"></i>
                </span>
                
                  <span class="post-meta-item-text">更新于</span>
                
                <time title="修改时间：2018-03-17 20:50:31" itemprop="dateModified" datetime="2018-03-17T20:50:31+08:00">2018-03-17</time>
              </span>
            
          

          
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope="" itemtype="http://schema.org/Thing"><a href="/categories/Elastic-Search/" itemprop="url" rel="index"><span itemprop="name">Elastic Search</span></a></span>

                
                
              
            </span>
          

          
            
            
              
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="fa fa-comment-o"></i>
                </span>
            
                <span class="post-meta-item-text">评论数：</span>
                <a href="/2017/07/12/Elastic Search/Elastic Search配置和使用/#comments" itemprop="discussionUrl">
                  <span class="post-comments-count disqus-comment-count" data-disqus-identifier="2017/07/12/Elastic Search/Elastic Search配置和使用/" itemprop="commentCount"></span>
                </a>
              </span>
            
          

          
          

          

          <br>
          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>官网：<a href="https://www.elastic.co/products/elasticsearch" target="_blank" rel="noopener">https://www.elastic.co/products/elasticsearch</a>    </p>
<p>最好的教程：<a href="https://es.xiaoleilu.com/" target="_blank" rel="noopener">https://es.xiaoleilu.com/</a></p>
<p>docker的ELK环境：<a href="https://hub.docker.com/r/sebp/elk/" target="_blank" rel="noopener">https://hub.docker.com/r/sebp/elk/</a></p>
<p>ES 5.4中文文档   <a href="http://cwiki.apachecn.org/pages/viewpage.action?pageId=4260364" target="_blank" rel="noopener">http://cwiki.apachecn.org/pages/viewpage.action?pageId=4260364</a></p>
<h1 id="0、基本概念"><a href="#0、基本概念" class="headerlink" title="0、基本概念"></a>0、基本概念</h1><p><strong>接近实时（NRT）</strong></p>
<pre><code>Elasticsearch是一个接近实时的搜索平台。这意味着，从索引一个文档直到这个文档能够被搜索到有一个轻微的延迟（通常是1秒）。
</code></pre><p><strong>集群（cluster）</strong><br>    一个集群就是由一个或多个节点组织在一起，它们共同持有你整个的数据，并一起提供索引和搜索功能。一个集群一个唯一的名字标识，这个名字默认就是 “elasticsearch”。这个名字是重要的，因为一个节点只能通过指定某个集群的名字，来加入这个集群。在产品环境中显式地设定这个名字是一个好 习惯，但是使用默认值来进行测试/开发也是不错的。</p>
<p><strong>节点（node）</strong><br>    一个节点是你集群中的一个服务器，作为集群的一部分，它存储你的数据，参与集群的索引和搜索功能。和集群类似，一个节点也是由一个名字来标识的，默认情况 下，这个名字是一个随机的漫威漫画角色的名字，这个名字会在启动的时候赋予节点。这个名字对于管理工作来说挺重要的，因为在这个管理过程中，你会去确定网 络中的哪些服务器对应于Elasticsearch集群中的哪些节点。</p>
<pre><code>一个节点可以通过配置集群名称的方式来加入一个指定的集群。默认情况下，每个节点都会被安排加入到一个叫做“elasticsearch”的集群中，这意 味着，如果你在你的网络中启动了若干个节点，并假定它们能够相互发现彼此，它们将会自动地形成并加入到一个叫做“elasticsearch”的集群中。

在一个集群里，只要你想，可以拥有任意多个节点。而且，如果当前你的网络中没有运行任何Elasticsearch节点，这时启动一个节点，会默认创建并加入一个叫做“elasticsearch”的集群。
</code></pre><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">Relational DB -&gt; Databases -&gt; Tables -&gt; Rows -&gt; Columns</span><br><span class="line">Elasticsearch -&gt; Indices   -&gt; Types  -&gt; Documents -&gt; Fields</span><br></pre></td></tr></table></figure>
<p><strong>索引（index）</strong></p>
<pre><code>一个索引就是一个拥有几分相似特征的文档的集合。比如说，你可以有一个客户数据的索引，另一个产品目录的索引，还有一个订单数据的索引。一个索引由一个名 字来标识（必须全部是小写字母的），并且当我们要对对应于这个索引中的文档进行索引、搜索、更新和删除的时候，都要使用到这个名字。

在一个集群中，如果你想，可以定义任意多的索引。
</code></pre><p><strong>类型（type）</strong></p>
<pre><code>在一个索引中，你可以定义一种或多种类型。一个类型是你的索引的一个逻辑上的分类/分区，其语义完全由你来定。通常，会为具有一组共同字段的文档定义一个 类型。比如说，我们假设你运营一个博客平台并且将你所有的数据存储到一个索引中。在这个索引中，你可以为用户数据定义一个类型，为博客数据定义另一个类 型，当然，也可以为评论数据定义另一个类型。
</code></pre><p><strong>文档（document）</strong></p>
<pre><code>一个文档是一个可被索引的基础信息单元。比如，你可以拥有某一个客户的文档，某一个产品的一个文档，当然，也可以拥有某个订单的一个文档。文档以 JSON（Javascript Object Notation）格式来表示，而JSON是一个到处存在的互联网数据交互格式。

在一个index/type里面，只要你想，你可以存储任意多的文档。注意，尽管一个文档，物理上存在于一个索引之中，文档必须被索引/赋予一个索引的type。
</code></pre><p><strong>分片和复制（shards &amp; replicas）</strong></p>
<pre><code>一个索引可以存储超出单个结点硬件限制的大量数据。比如，一个具有10亿文档的索引占据1TB的磁盘空间，而任一节点都没有这样大的磁盘空间；或者单个节点处理搜索请求，响应太慢。

为了解决这个问题，Elasticsearch提供了将索引划分成多份的能力，这些份就叫做分片。当你创建一个索引的时候，你可以指定你想要的分片的数量。每个分片本身也是一个功能完善并且独立的“索引”，这个“索引”可以被放置到集群中的任何节点上。

分片之所以重要，主要有两方面的原因：

    - 允许你水平分割/扩展你的内容容量
    - 允许你在分片（潜在地，位于多个节点上）之上进行分布式的、并行的操作，进而提高性能/吞吐量

至于一个分片怎样分布，它的文档怎样聚合回搜索请求，是完全由Elasticsearch管理的，对于作为用户的你来说，这些都是透明的。

在一个网络/云的环境里，失败随时都可能发生，在某个分片/节点不知怎么的就处于离线状态，或者由于任何原因消失了，这种情况下，有一个故障转移机制是非 常有用并且是强烈推荐的。为此目的，Elasticsearch允许你创建分片的一份或多份拷贝，这些拷贝叫做复制分片，或者直接叫复制。

复制之所以重要，有两个主要原因：
    - 在分片/节点失败的情况下，提供了高可用性。因为这个原因，注意到复制分片从不与原/主要（original/primary）分片置于同一节点上是非常重要的。
    - 扩展你的搜索量/吞吐量，因为搜索可以在所有的复制上并行运行

总之，每个索引可以被分成多个分片。一个索引也可以被复制0次（意思是没有复制）或多次。一旦复制了，每个索引就有了主分片（作为复制源的原来的分片）和 复制分片（主分片的拷贝）之别。分片和复制的数量可以在索引创建的时候指定。在索引创建之后，你可以在任何时候动态地改变复制的数量，但是你事后不能改变 分片的数量。

默认情况下，Elasticsearch中的每个索引被分片5个主分片和1个复制，这意味着，如果你的集群中至少有两个节点，你的索引将会有5个主分片和另外5个复制分片（1个完全拷贝），这样的话每个索引总共就有10个分片。
</code></pre><h1 id="1、安装-5-5-0"><a href="#1、安装-5-5-0" class="headerlink" title="1、安装-5.5.0"></a>1、安装-5.5.0</h1><h2 id="1-1-ElasticSearch"><a href="#1-1-ElasticSearch" class="headerlink" title="1.1 ElasticSearch"></a>1.1 ElasticSearch</h2><p>下载的</p>
<p>elasticsearch-5.5.0.tar.gz</p>
<p>kibana-5.5.0-linux-x86_64.tar.gz</p>
<p>解压到/home/david/opt，在主目录直接运行</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ bin/elasticsearch</span><br></pre></td></tr></table></figure>
<p>启动服务，启动后，访问localhost:9200，若出现</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">&#123;</span><br><span class="line">  &quot;name&quot; : &quot;Jr1It8C&quot;,</span><br><span class="line">  &quot;cluster_name&quot; : &quot;elasticsearch&quot;,</span><br><span class="line">  &quot;cluster_uuid&quot; : &quot;JMo_h3-USdegKS1yZ0WCnA&quot;,</span><br><span class="line">  &quot;version&quot; : &#123;</span><br><span class="line">    &quot;number&quot; : &quot;5.5.0&quot;,</span><br><span class="line">    &quot;build_hash&quot; : &quot;260387d&quot;,</span><br><span class="line">    &quot;build_date&quot; : &quot;2017-06-30T23:16:05.735Z&quot;,</span><br><span class="line">    &quot;build_snapshot&quot; : false,</span><br><span class="line">    &quot;lucene_version&quot; : &quot;6.6.0&quot;</span><br><span class="line">  &#125;,</span><br><span class="line">  &quot;tagline&quot; : &quot;You Know, for Search&quot;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>则说明安装成功。</p>
<h2 id="1-2-Marvel"><a href="#1-2-Marvel" class="headerlink" title="1.2 Marvel"></a>1.2 Marvel</h2><p>5.0后集成到了x-pack中</p>
<p>1）安装X-pack到elasticsearch</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ bin/elasticsearch-plugin install x-pack</span><br></pre></td></tr></table></figure>
<p>2）安装到kibana</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">bin/kibana-plugin install x-pack</span><br></pre></td></tr></table></figure>
<p>用户名elastic</p>
<p>密码changeme</p>
<h2 id="1-3-关闭服务"><a href="#1-3-关闭服务" class="headerlink" title="1.3 关闭服务"></a>1.3 关闭服务</h2><p>关闭Elastic search </p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ps -ef | grep elastic</span><br></pre></td></tr></table></figure>
<p>关闭kibana </p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">fuser -n tcp 5601</span><br></pre></td></tr></table></figure>
<h1 id="2、第一个例子"><a href="#2、第一个例子" class="headerlink" title="2、第一个例子"></a>2、第一个例子</h1><p>摘自教程</p>
<blockquote>
<p>假设我们刚好在<strong>Megacorp</strong>工作，这时人力资源部门出于某种目的需要让我们创建一个员工目录，这个目录用于促进人文关怀和用于实时协同工作，所以它有以下不同的需求：</p>
<ul>
<li>数据能够包含多个值的标签、数字和纯文本。</li>
<li>检索任何员工的所有信息。</li>
<li>支持结构化搜索，例如查找30岁以上的员工。</li>
<li>支持简单的全文搜索和更复杂的<strong>短语(phrase)</strong>搜索</li>
<li>高亮搜索结果中的关键字</li>
<li>能够利用图表管理分析这些数据</li>
</ul>
</blockquote>
<h2 id="2-1-索引员工文档"><a href="#2-1-索引员工文档" class="headerlink" title="2.1 索引员工文档"></a>2.1 索引员工文档</h2><p><strong>索引</strong>含义的区分</p>
<p>你可能已经注意到<strong>索引(index)</strong>这个词在Elasticsearch中有着不同的含义，所以有必要在此做一下区分:</p>
<ul>
<li>索引（名词） 如上文所述，一个<strong>索引(index)</strong>就像是传统关系数据库中的<strong>数据库</strong>，它是相关文档存储的地方，index的复数是<strong>indices </strong>或<strong>indexes</strong>。</li>
<li>索引（动词） <strong>「索引一个文档」</strong>表示把一个文档存储到<strong>索引（名词）</strong>里，以便它可以被检索或者查询。这很像SQL中的<code>INSERT</code>关键字，差别是，如果文档已经存在，新的文档将覆盖旧的文档。</li>
<li>倒排索引 传统数据库为特定列增加一个索引，例如B-Tree索引来加速检索。Elasticsearch和Lucene使用一种叫做<strong>倒排索引(inverted index)</strong>的数据结构来达到相同目的。</li>
</ul>
<p>创建一个员工目录</p>
<ul>
<li>每个文档的类型为<code>employee</code>。</li>
<li><code>employee</code>类型归属于索引<code>megacorp</code>。</li>
<li><code>megacorp</code>索引存储在Elasticsearch集群中。</li>
</ul>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line">PUT /megacorp/employee/1</span><br><span class="line">&#123;</span><br><span class="line">    &quot;first_name&quot; : &quot;John&quot;,</span><br><span class="line">    &quot;last_name&quot; :  &quot;Smith&quot;,</span><br><span class="line">    &quot;age&quot; :        25,</span><br><span class="line">    &quot;about&quot; :      &quot;I love to go rock climbing&quot;,</span><br><span class="line">    &quot;interests&quot;: [ &quot;sports&quot;, &quot;music&quot; ]</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">PUT /megacorp/employee/2</span><br><span class="line">&#123;</span><br><span class="line">    &quot;first_name&quot; :  &quot;Jane&quot;,</span><br><span class="line">    &quot;last_name&quot; :   &quot;Smith&quot;,</span><br><span class="line">    &quot;age&quot; :         32,</span><br><span class="line">    &quot;about&quot; :       &quot;I like to collect rock albums&quot;,</span><br><span class="line">    &quot;interests&quot;:  [ &quot;music&quot; ]</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">PUT /megacorp/employee/3</span><br><span class="line">&#123;</span><br><span class="line">    &quot;first_name&quot; :  &quot;Douglas&quot;,</span><br><span class="line">    &quot;last_name&quot; :   &quot;Fir&quot;,</span><br><span class="line">    &quot;age&quot; :         35,</span><br><span class="line">    &quot;about&quot;:        &quot;I like to build cabinets&quot;,</span><br><span class="line">    &quot;interests&quot;:  [ &quot;forestry&quot; ]</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h2 id="2-2-检索文档"><a href="#2-2-检索文档" class="headerlink" title="2.2 检索文档"></a>2.2 检索文档</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">GET /megacorp/employee/1</span><br></pre></td></tr></table></figure>
<p>响应的内容中包含一些文档的元信息，John Smith的原始JSON文档包含在<code>_source</code>字段中。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">&#123;</span><br><span class="line">   &quot;_index&quot;: &quot;megacorp&quot;,</span><br><span class="line">   &quot;_type&quot;: &quot;employee&quot;,</span><br><span class="line">   &quot;_id&quot;: &quot;1&quot;,</span><br><span class="line">   &quot;_version&quot;: 1,</span><br><span class="line">   &quot;found&quot;: true,</span><br><span class="line">   &quot;_source&quot;: &#123;</span><br><span class="line">      &quot;first_name&quot;: &quot;John&quot;,</span><br><span class="line">      &quot;last_name&quot;: &quot;Smith&quot;,</span><br><span class="line">      &quot;age&quot;: 25,</span><br><span class="line">      &quot;about&quot;: &quot;I love to go rock climbing&quot;,</span><br><span class="line">      &quot;interests&quot;: [</span><br><span class="line">         &quot;sports&quot;,</span><br><span class="line">         &quot;music&quot;</span><br><span class="line">      ]</span><br><span class="line">   &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p><strong>简单搜索</strong></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">GET /megacorp/employee/_search</span><br></pre></td></tr></table></figure>
<p>使用关键字<code>_search</code>来取代原来的文档ID。响应内容的<code>hits</code>数组中包含了我们所有的三个文档。默认情况下搜索会返回前10个结果。</p>
<figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line">&#123;</span><br><span class="line">   <span class="attr">"took"</span>: <span class="number">6</span>,</span><br><span class="line">   <span class="attr">"timed_out"</span>: <span class="literal">false</span>,</span><br><span class="line">   <span class="attr">"_shards"</span>: &#123;</span><br><span class="line">      <span class="attr">"total"</span>: <span class="number">5</span>,</span><br><span class="line">      <span class="attr">"successful"</span>: <span class="number">5</span>,</span><br><span class="line">      <span class="attr">"failed"</span>: <span class="number">0</span></span><br><span class="line">   &#125;,</span><br><span class="line">   <span class="attr">"hits"</span>: &#123;</span><br><span class="line">      <span class="attr">"total"</span>: <span class="number">3</span>,</span><br><span class="line">      <span class="attr">"max_score"</span>: <span class="number">1</span>,</span><br><span class="line">      <span class="attr">"hits"</span>: [</span><br><span class="line">         &#123;</span><br><span class="line">            <span class="attr">"_index"</span>: <span class="string">"megacorp"</span>,</span><br><span class="line">            <span class="attr">"_type"</span>: <span class="string">"employee"</span>,</span><br><span class="line">            <span class="attr">"_id"</span>: <span class="string">"2"</span>,</span><br><span class="line">            <span class="attr">"_score"</span>: <span class="number">1</span>,</span><br><span class="line">            <span class="attr">"_source"</span>: &#123;</span><br><span class="line">               <span class="attr">"first_name"</span>: <span class="string">"Jane"</span>,</span><br><span class="line">               <span class="attr">"last_name"</span>: <span class="string">"Smith"</span>,</span><br><span class="line">               <span class="attr">"age"</span>: <span class="number">32</span>,</span><br><span class="line">               <span class="attr">"about"</span>: <span class="string">"I like to collect rock albums"</span>,</span><br><span class="line">               <span class="attr">"interests"</span>: [</span><br><span class="line">                  <span class="string">"music"</span></span><br><span class="line">               ]</span><br><span class="line">            &#125;</span><br><span class="line">         &#125;,</span><br><span class="line">         ......        </span><br><span class="line">      ]</span><br><span class="line">   &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>接下来，让我们搜索姓氏中包含<strong>“Smith”</strong>的员工。要做到这一点，我们将在命令行中使用轻量级的搜索方法。这种方法常被称作<strong>查询字符串(query string)</strong>搜索，因为我们像传递URL参数一样去传递查询语句：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">GET /megacorp/employee/_search?q=last_name:Smith</span><br></pre></td></tr></table></figure>
<h2 id="2-3-使用DSL语句查询"><a href="#2-3-使用DSL语句查询" class="headerlink" title="2.3 使用DSL语句查询"></a>2.3 使用DSL语句查询</h2><p>查询字符串搜索便于通过命令行完成<strong>特定(ad hoc)</strong>的搜索，但是它也有局限性（参阅简单搜索章节）。Elasticsearch提供丰富且灵活的查询语言叫做<strong>DSL查询(Query DSL)</strong>,它允许你构建更加复杂、强大的查询。</p>
<p><strong>DSL(Domain Specific Language特定领域语言)</strong>以JSON请求体的形式出现。我们可以这样表示之前关于“Smith”的查询:</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">GET /megacorp/employee/_search</span><br><span class="line">&#123;</span><br><span class="line">    &quot;query&quot; : &#123;</span><br><span class="line">        &quot;match&quot; : &#123;</span><br><span class="line">            &quot;last_name&quot; : &quot;Smith&quot;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h2 id="2-4-更复杂的搜索"><a href="#2-4-更复杂的搜索" class="headerlink" title="2.4 更复杂的搜索"></a>2.4 更复杂的搜索</h2><p>我们让搜索稍微再变的复杂一些。我们依旧想要找到姓氏为“Smith”的员工，但是我们只想得到年龄大于30岁的员工。我们的语句将添加<strong>过滤器(filter)</strong>,它使得我们高效率的执行一个结构化搜索：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">GET /megacorp/employee/_search</span><br><span class="line">&#123;</span><br><span class="line">    &quot;query&quot; : &#123;</span><br><span class="line">        &quot;filtered&quot; : &#123;</span><br><span class="line">            &quot;filter&quot; : &#123;</span><br><span class="line">                &quot;range&quot; : &#123;</span><br><span class="line">                    &quot;age&quot; : &#123; &quot;gt&quot; : 30 &#125; &lt;1&gt;</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;,</span><br><span class="line">            &quot;query&quot; : &#123;</span><br><span class="line">                &quot;match&quot; : &#123;</span><br><span class="line">                    &quot;last_name&quot; : &quot;smith&quot; &lt;2&gt;</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>5.0以后的DSL语法变了</p>
<h1 id="3、数据"><a href="#3、数据" class="headerlink" title="3、数据"></a>3、数据</h1><h2 id="3-1-文档"><a href="#3-1-文档" class="headerlink" title="3.1 文档"></a>3.1 文档</h2><p>一个文档不只有数据。它还包含了<strong>元数据(metadata)</strong>——<strong>关于</strong>文档的信息。三个必须的元数据节点是：</p>
<div class="table-container">
<table>
<thead>
<tr>
<th>节点</th>
<th>说明</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>_index</code></td>
<td>文档存储的地方</td>
</tr>
<tr>
<td><code>_type</code></td>
<td>文档代表的对象的类</td>
</tr>
<tr>
<td><code>_id</code></td>
<td>文档的唯一标识</td>
</tr>
</tbody>
</table>
</div>
<h3 id="index"><a href="#index" class="headerlink" title="_index"></a><code>_index</code></h3><p><strong>索引(index)</strong>类似于关系型数据库里的“数据库”——它是我们存储和索引关联数据的地方。</p>
<blockquote>
<p>提示：</p>
<p>事实上，我们的数据被存储和索引在<strong>分片(shards)</strong>中，索引只是一个把一个或多个分片分组在一起的逻辑空间。然而，这只是一些内部细节——我们的程序完全不用关心分片。对于我们的程序而言，文档存储在<strong>索引(index)</strong>中。剩下的细节由Elasticsearch关心既可。</p>
</blockquote>
<p>我们将会在《索引管理》章节中探讨如何创建并管理索引，但现在，我们将让Elasticsearch为我们创建索引。我们唯一需要做的仅仅是选择一个索引名。这个名字必须是全部小写，不能以下划线开头，不能包含逗号。让我们使用<code>website</code>做为索引名。</p>
<h3 id="type"><a href="#type" class="headerlink" title="_type"></a><code>_type</code></h3><p>在应用中，我们使用对象表示一些“事物”，例如一个用户、一篇博客、一个评论，或者一封邮件。每个对象都属于一个<strong>类(class)</strong>，这个类定义了属性或与对象关联的数据。<code>user</code>类的对象可能包含姓名、性别、年龄和Email地址。</p>
<p>在关系型数据库中，我们经常将相同类的对象存储在一个表里，因为它们有着相同的结构。同理，在Elasticsearch中，我们使用相同<strong>类型(type)</strong>的文档表示相同的“事物”，因为他们的数据结构也是相同的。</p>
<p>每个<strong>类型(type)</strong>都有自己的<strong>映射(mapping)</strong>或者结构定义，就像传统数据库表中的列一样。所有类型下的文档被存储在同一个索引下，但是类型的<strong>映射(mapping)</strong>会告诉Elasticsearch不同的文档如何被索引。 我们将会在《映射》章节探讨如何定义和管理映射，但是现在我们将依赖Elasticsearch去自动处理数据结构。</p>
<p><code>_type</code>的名字可以是大写或小写，不能包含下划线或逗号。我们将使用<code>blog</code>做为类型名。</p>
<h3 id="id"><a href="#id" class="headerlink" title="_id"></a><code>_id</code></h3><p><strong>id</strong>仅仅是一个字符串，它与<code>_index</code>和<code>_type</code>组合时，就可以在Elasticsearch中唯一标识一个文档。当创建一个文档，你可以自定义<code>_id</code>，也可以让Elasticsearch帮你自动生成。</p>
<h2 id="3-2-索引一个文档"><a href="#3-2-索引一个文档" class="headerlink" title="3.2 索引一个文档"></a>3.2 索引一个文档</h2><h3 id="自定义ID"><a href="#自定义ID" class="headerlink" title="自定义ID"></a><strong>自定义ID</strong></h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">PUT /website/blog/123</span><br><span class="line">&#123;</span><br><span class="line">  &quot;title&quot;: &quot;My first blog entry&quot;,</span><br><span class="line">  &quot;text&quot;:  &quot;Just trying this out...&quot;,</span><br><span class="line">  &quot;date&quot;:  &quot;2014/01/01&quot;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>Elasticsearch的响应：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">&#123;</span><br><span class="line">   &quot;_index&quot;: &quot;website&quot;,</span><br><span class="line">   &quot;_type&quot;: &quot;blog&quot;,</span><br><span class="line">   &quot;_id&quot;: &quot;123&quot;,</span><br><span class="line">   &quot;_version&quot;: 1,</span><br><span class="line">   &quot;result&quot;: &quot;created&quot;,</span><br><span class="line">   &quot;_shards&quot;: &#123;</span><br><span class="line">      &quot;total&quot;: 2,</span><br><span class="line">      &quot;successful&quot;: 1,</span><br><span class="line">      &quot;failed&quot;: 0</span><br><span class="line">   &#125;,</span><br><span class="line">   &quot;created&quot;: true</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p><code>_version</code> ：Elasticsearch中每个文档都有版本号，每当文档变化（包括删除）都会使<code>_version</code>增加。</p>
<h3 id="自增ID"><a href="#自增ID" class="headerlink" title="自增ID"></a>自增ID</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">POST /website/blog/</span><br><span class="line">&#123;</span><br><span class="line">  &quot;title&quot;: &quot;My second blog entry&quot;,</span><br><span class="line">  &quot;text&quot;:  &quot;Still trying this out...&quot;,</span><br><span class="line">  &quot;date&quot;:  &quot;2014/01/01&quot;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>自动生成的ID有22个字符长，URL-safe, Base64-encoded string universally unique identifiers, 或者叫 <a href="http://en.wikipedia.org/wiki/Uuid" target="_blank" rel="noopener">UUIDs</a>。</p>
<h2 id="3-3-检索"><a href="#3-3-检索" class="headerlink" title="3.3 检索"></a>3.3 检索</h2><p>想要从Elasticsearch中获取文档，我们使用同样的<code>_index</code>、<code>_type</code>、<code>_id</code>，但是HTTP方法改为<code>GET</code>：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">GET /website/blog/123?pretty</span><br></pre></td></tr></table></figure>
<blockquote>
<h3 id="pretty"><a href="#pretty" class="headerlink" title="pretty"></a><code>pretty</code></h3><p>在任意的查询字符串中增加<code>pretty</code>参数，类似于上面的例子。会让Elasticsearch<strong>美化输出(pretty-print)</strong>JSON响应以便更加容易阅读。<code>_source</code>字段不会被美化，它的样子与我们输入的一致。</p>
</blockquote>
<p><code>{&quot;found&quot;: true}</code>。这意味着文档已经找到。</p>
<p>如果我们请求一个不存在的文档，依旧会得到一个JSON，不过<code>found</code>值变成了<code>false</code>。</p>
<p>此外，HTTP响应状态码也会变成<code>&#39;404 Not Found&#39;</code>代替<code>&#39;200 OK&#39;</code>。我们可以在<code>curl</code>后加<code>-i</code>参数得到响应头：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">curl -i -XGET http://localhost:9200/website/blog/124?pretty</span><br></pre></td></tr></table></figure>
<h3 id="检索文档的一部分"><a href="#检索文档的一部分" class="headerlink" title="检索文档的一部分"></a>检索文档的一部分</h3><p>通常，<code>GET</code>请求将返回文档的全部，存储在<code>_source</code>参数中。但是可能你感兴趣的字段只是<code>title</code>。请求个别字段可以使用<code>_source</code>参数。多个字段可以使用逗号分隔：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">GET /website/blog/123?_source=title,text</span><br></pre></td></tr></table></figure>
<p>或者你只想得到<code>_source</code>字段而不要其他的元数据，你可以这样请求：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">GET /website/blog/123/_source</span><br></pre></td></tr></table></figure>
<h2 id="3-4-更新整个文档"><a href="#3-4-更新整个文档" class="headerlink" title="3.4 更新整个文档"></a>3.4 更新整个文档</h2><p>文档在Elasticsearch中是不可变的——我们不能修改他们。如果需要更新已存在的文档，我们可以使用《索引文档》章节提到的<code>index</code> API <em>重建索引(reindex)</em> 或者替换掉它。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">PUT /website/blog/123</span><br><span class="line">&#123;</span><br><span class="line">  &quot;title&quot;: &quot;My first blog entry&quot;,</span><br><span class="line">  &quot;text&quot;:  &quot;I am starting to get the hang of this...&quot;,</span><br><span class="line">  &quot;date&quot;:  &quot;2014/01/02&quot;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>在响应中，我们可以看到Elasticsearch把<code>_version</code>增加了，且<code>result</code>是updated</p>
<p><code>update</code> API。这个API <em>似乎</em> 允许你修改文档的局部，但事实上Elasticsearch遵循与之前所说完全相同的过程，这个过程如下：</p>
<ol>
<li>从旧文档中检索JSON</li>
<li>修改它</li>
<li>删除旧文档</li>
<li>索引新文档</li>
</ol>
<p>唯一的不同是<code>update</code> API完成这一过程只需要一个客户端请求既可，不再需要<code>get</code>和<code>index</code>请求了。</p>
<h2 id="3-5-创建新文档"><a href="#3-5-创建新文档" class="headerlink" title="3.5 创建新文档"></a>3.5 创建新文档</h2><p>请记住<code>_index</code>、<code>_type</code>、<code>_id</code>三者唯一确定一个文档。所以要想保证文档是新加入的，最简单的方式是使用<code>POST</code>方法让Elasticsearch自动生成唯一<code>_id</code>：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">POST /website/blog/</span><br><span class="line">&#123; ... &#125;</span><br></pre></td></tr></table></figure>
<p>如果要确保是create操作</p>
<p>1）使用<code>op_type</code>查询参数：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">PUT /website/blog/123?op_type=create</span><br><span class="line">&#123; ... &#125;</span><br></pre></td></tr></table></figure>
<p>2）在URL后加<code>/_create</code>做为端点：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">PUT /website/blog/123/_create</span><br><span class="line">&#123; ... &#125;</span><br></pre></td></tr></table></figure>
<p>如果包含相同的<code>_index</code>、<code>_type</code>和<code>_id</code>的文档已经存在，Elasticsearch将返回<code>409 Conflict</code>响应状态码</p>
<h2 id="3-6-删除文档"><a href="#3-6-删除文档" class="headerlink" title="3.6 删除文档"></a>3.6 删除文档</h2><p>使用<code>DELETE</code>方法：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">DELETE /website/blog/123</span><br></pre></td></tr></table></figure>
<blockquote>
<p>删除一个文档也不会立即从磁盘上移除，它只是被标记成已删除。Elasticsearch将会在你之后添加更多索引的时候才会在后台进行删除内容的清理。</p>
</blockquote>
<h2 id="3-7-Mapping"><a href="#3-7-Mapping" class="headerlink" title="3.7 Mapping"></a>3.7 Mapping</h2><p><a href="http://m635674608.iteye.com/blog/2259804" target="_blank" rel="noopener">ElasticSearch的Mapping之字段类型</a></p>
<p>（一）核心数据类型： </p>
<p>（1）string： 默认会被分词，一个完整示例如下 </p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">&quot;status&quot;: &#123;  </span><br><span class="line">         &quot;type&quot;:  &quot;string&quot;, //字符串类型  </span><br><span class="line">         &quot;index&quot;: &quot;analyzed&quot;//分词，不分词是：not_analyzed ，设置成no，字段将不会被索引  </span><br><span class="line">         &quot;analyzer&quot;:&quot;ik&quot;//指定分词器  </span><br><span class="line">         &quot;boost&quot;:1.23//字段级别的分数加权  </span><br><span class="line">          &quot;doc_values&quot;:false//对not_analyzed字段，默认都是开启，分词字段不能使用，对排序和聚合能提升较大性能，节约内存  </span><br><span class="line">           &quot;fielddata&quot;:&#123;&quot;format&quot;:&quot;disabled&quot;&#125;//针对分词字段，参与排序或聚合时能提高性能，不分词字段统一建议使用doc_value  </span><br><span class="line">           &quot;fields&quot;:&#123;&quot;raw&quot;:&#123;&quot;type&quot;:&quot;string&quot;,&quot;index&quot;:&quot;not_analyzed&quot;&#125;&#125; //可以对一个字段提供多种索引模式，同一个字段的值，一个分词，一个不分词  </span><br><span class="line">           &quot;ignore_above&quot;:100 //超过100个字符的文本，将会被忽略，不被索引  </span><br><span class="line">           &quot;include_in_all&quot;:ture//设置是否此字段包含在_all字段中，默认是true，除非index设置成no选项  </span><br><span class="line">           &quot;index_options&quot;:&quot;docs&quot;//4个可选参数docs（索引文档号） ,freqs（文档号+词频），positions（文档号+词频+位置，通常用来距离查询），offsets（文档号+词频+位置+偏移量，通常被使用在高亮字段）分词字段默认是position，其他的默认是docs  </span><br><span class="line">           &quot;norms&quot;:&#123;&quot;enable&quot;:true,&quot;loading&quot;:&quot;lazy&quot;&#125;//分词字段默认配置，不分词字段：默认&#123;&quot;enable&quot;:false&#125;，存储长度因子和索引时boost，建议对需要参与评分字段使用 ，会额外增加内存消耗量  </span><br><span class="line">            &quot;null_value&quot;:&quot;NULL&quot;//设置一些缺失字段的初始化值，只有string可以使用，分词字段的null值也会被分词  </span><br><span class="line">            &quot;position_increament_gap&quot;:0//影响距离查询或近似查询，可以设置在多值字段的数据上火分词字段上，查询时可指定slop间隔，默认值是100  </span><br><span class="line">             &quot;store&quot;:false//是否单独设置此字段的是否存储而从_source字段中分离，默认是false，只能搜索，不能获取值  </span><br><span class="line">              &quot;search_analyzer&quot;:&quot;ik&quot;//设置搜索时的分词器，默认跟ananlyzer是一致的，比如index时用standard+ngram，搜索时用standard用来完成自动提示功能  </span><br><span class="line">               &quot;similarity&quot;:&quot;BM25&quot;//默认是TF/IDF算法，指定一个字段评分策略，仅仅对字符串型和分词类型有效  </span><br><span class="line">               &quot;term_vector&quot;:&quot;no&quot;//默认不存储向量信息，支持参数yes（term存储），with_positions（term+位置）,with_offsets（term+偏移量），with_positions_offsets(term+位置+偏移量) 对快速高亮fast vector highlighter能提升性能，但开启又会加大索引体积，不适合大数据量用  </span><br><span class="line">       &#125;</span><br></pre></td></tr></table></figure>
<h1 id="4、结构化查询DSL"><a href="#4、结构化查询DSL" class="headerlink" title="4、结构化查询DSL"></a>4、结构化查询DSL</h1><p>match 相当于and</p>
<p>should 相当于or</p>
<p>must_not 相当于not</p>
<h2 id="Query"><a href="#Query" class="headerlink" title="Query"></a>Query</h2><p>精确查询</p>
<h2 id="Match"><a href="#Match" class="headerlink" title="Match"></a>Match</h2><p><a href="https://www.elastic.co/guide/en/elasticsearch/reference/current/query-dsl.html" target="_blank" rel="noopener">https://www.elastic.co/guide/en/elasticsearch/reference/current/query-dsl.html</a></p>
<p>match查询</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">GET /_search</span><br><span class="line">&#123;</span><br><span class="line">    &quot;query&quot;: &#123;</span><br><span class="line">        &quot;match&quot; : &#123;</span><br><span class="line">            &quot;message&quot; : &quot;this is a test&quot;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h2 id="Filter"><a href="#Filter" class="headerlink" title="Filter"></a>Filter</h2><p>判断某个字段不为空</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">&quot;filter&quot;: [</span><br><span class="line">        &#123; &quot;script&quot;:&#123;&quot;script&quot;:&quot;doc[&apos;interests&apos;].values.length==60&quot;&#125; &#125;  </span><br><span class="line">      ]</span><br></pre></td></tr></table></figure>
<h2 id="should"><a href="#should" class="headerlink" title="should"></a>should</h2><h1 id="5、聚合统计"><a href="#5、聚合统计" class="headerlink" title="5、聚合统计"></a>5、聚合统计</h1><h2 id="对查询的结果聚合"><a href="#对查询的结果聚合" class="headerlink" title="对查询的结果聚合"></a>对查询的结果聚合</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">GET iclick_persona/iclick/_search</span><br><span class="line">&#123;</span><br><span class="line">  &quot;query&quot;: &#123; </span><br><span class="line">    &quot;bool&quot;: &#123; </span><br><span class="line">      &quot;must&quot;: [</span><br><span class="line">        &#123; &quot;term&quot;: &#123; &quot;articles.domains&quot;:   &quot;www.baby-kingdom.com&quot;        &#125;&#125;, </span><br><span class="line">        &#123; &quot;match&quot;: &#123; &quot;province&quot;: &quot;HK&quot; &#125;&#125;,</span><br><span class="line">        &#123;&quot;match&quot;: &#123;&quot;interests&quot;: &quot;20&quot;&#125;&#125;</span><br><span class="line">      ]</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;,</span><br><span class="line">  &quot;aggs&quot;: &#123;</span><br><span class="line">    &quot;interests&quot;: &#123;</span><br><span class="line">      &quot;terms&quot;: &#123;&quot;field&quot;: &quot;interests&quot;,</span><br><span class="line">        &quot;size&quot;: 50</span><br><span class="line">      &#125; </span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>统计月活跃度</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line">GET iclick_persona/iclick/_search</span><br><span class="line">&#123;</span><br><span class="line">  &quot;query&quot;: &#123; </span><br><span class="line">    &quot;bool&quot;: &#123; </span><br><span class="line">      &quot;must&quot;: [</span><br><span class="line">        &#123; &quot;term&quot;: &#123; &quot;articles.domains&quot;:   &quot;www.baby-kingdom.com&quot; &#125;&#125;, </span><br><span class="line">        &#123; &quot;term&quot;: &#123; &quot;province&quot;: &quot;HK&quot; &#125;&#125;</span><br><span class="line">      ],</span><br><span class="line">      &quot;filter&quot;: &#123;</span><br><span class="line">        &quot;range&quot;: &#123;</span><br><span class="line">          &quot;create_time&quot;: &#123;&quot;gte&quot; : &quot;2017-08-10&quot;&#125;</span><br><span class="line">        &#125;</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;,</span><br><span class="line">  &quot;aggs&quot;: &#123;</span><br><span class="line">    &quot;create_time&quot;: &#123;</span><br><span class="line">      &quot;terms&quot;: &#123;&quot;field&quot;: &quot;create_time&quot;,&quot;size&quot;: 50,&quot;order&quot;: &#123;</span><br><span class="line">        &quot;_term&quot;: &quot;asc&quot;</span><br><span class="line">      &#125;</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>看香港的人群每天有多少</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line">GET iclick_persona/iclick/_search?size=0</span><br><span class="line">&#123;</span><br><span class="line">  &quot;query&quot;: &#123; </span><br><span class="line">    &quot;bool&quot;: &#123; </span><br><span class="line">      &quot;must&quot;: [</span><br><span class="line">        &#123; &quot;match&quot;: &#123; &quot;province&quot;: &quot;HK&quot; &#125;&#125;</span><br><span class="line">      ]</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;,</span><br><span class="line">  &quot;aggs&quot;: &#123;</span><br><span class="line">    &quot;dates&quot;: &#123;</span><br><span class="line">      &quot;terms&quot;: &#123;</span><br><span class="line">        &quot;field&quot;: &quot;create_time&quot;,</span><br><span class="line">        &quot;size&quot;: 100,</span><br><span class="line">        &quot;order&quot;: &#123;</span><br><span class="line">          &quot;_term&quot;: &quot;asc&quot;</span><br><span class="line">        &#125;</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h2 id="DELETE"><a href="#DELETE" class="headerlink" title="DELETE"></a>DELETE</h2><p>按条件删除</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line">POST iclick_persona/iclick/_delete_by_query</span><br><span class="line">&#123;</span><br><span class="line">  &quot;query&quot;: &#123;</span><br><span class="line">    &quot;bool&quot;: &#123;</span><br><span class="line">      &quot;must&quot;: [</span><br><span class="line">        &#123;</span><br><span class="line">          &quot;term&quot;: &#123;</span><br><span class="line">            &quot;create_time&quot;: &#123;</span><br><span class="line">              &quot;value&quot;: &quot;2017-07-15&quot;</span><br><span class="line">            &#125;</span><br><span class="line">          &#125;</span><br><span class="line">        &#125;,</span><br><span class="line">        &#123;</span><br><span class="line">          &quot;term&quot;: &#123;</span><br><span class="line">            &quot;province&quot;: &#123;</span><br><span class="line">              &quot;value&quot;: &quot;HK&quot;</span><br><span class="line">            &#125;</span><br><span class="line">          &#125;</span><br><span class="line">        &#125;</span><br><span class="line">      ]</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h1 id="keyword和text区别"><a href="#keyword和text区别" class="headerlink" title="keyword和text区别"></a>keyword和text区别</h1><p><a href="http://blog.csdn.net/lionel_fengj/article/details/78367570" target="_blank" rel="noopener">[ElasticSearch]数据类型keyword和text的区别</a></p>
<p>在 ES2.x 版本字符串数据是没有 keyword 和 text 类型的，只有string类型，ES更新到5版本后，取消了 string 数据类型，代替它的是 keyword 和 text 数据类型。</p>
<p>Text 数据类型被用来索引长文本，比如说电子邮件的主体部分或者一款产品的介绍。这些文本会被分析，在建立索引前会将这些文本进行分词，转化为词的组合，建立索引。允许 ES来检索这些词语。text 数据类型不能用来排序和聚合。</p>
<p>Keyword不需要进行分词。可以被用来检索过滤、排序和聚合。keyword 类型字段只能用本身来进行检索。</p>
<p>默认是text类型。</p>
<h2 id="match"><a href="#match" class="headerlink" title="match"></a>match</h2><p>最简单的一个match例子：</p>
<p>查询和”我的宝马多少马力”这个查询语句匹配的文档。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">&#123;</span><br><span class="line">  &quot;query&quot;: &#123;</span><br><span class="line">    &quot;match&quot;: &#123;</span><br><span class="line">        &quot;content&quot; : &#123;</span><br><span class="line">            &quot;query&quot; : &quot;我的宝马多少马力&quot;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>上面的查询匹配就会进行分词，比如”宝马多少马力”会被分词为”宝马 多少 马力”, 所有有关”宝马 多少 马力”, 那么所有包含这三个词中的一个或多个的文档就会被搜索出来。<br>并且根据lucene的评分机制(TF/IDF)来进行评分。</p>
<h2 id="match-phrase"><a href="#match-phrase" class="headerlink" title="match_phrase"></a>match_phrase</h2><p>比如上面一个例子，一个文档”我的保时捷马力不错”也会被搜索出来，那么想要精确匹配所有同时包含”宝马 多少 马力”的文档怎么做？就要使用 match_phrase 了</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">&#123;</span><br><span class="line">  &quot;query&quot;: &#123;</span><br><span class="line">    &quot;match_phrase&quot;: &#123;</span><br><span class="line">        &quot;content&quot; : &#123;</span><br><span class="line">            &quot;query&quot; : &quot;我的宝马多少马力&quot;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>完全匹配可能比较严，我们会希望有个可调节因子，少匹配一个也满足，那就需要使用到slop。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">&#123;</span><br><span class="line">  &quot;query&quot;: &#123;</span><br><span class="line">    &quot;match_phrase&quot;: &#123;</span><br><span class="line">        &quot;content&quot; : &#123;</span><br><span class="line">            &quot;query&quot; : &quot;我的宝马多少马力&quot;,</span><br><span class="line">            &quot;slop&quot; : 1</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h2 id="multi-match"><a href="#multi-match" class="headerlink" title="multi_match"></a>multi_match</h2><p>如果我们希望两个字段进行匹配，其中一个字段有这个文档就满足的话，使用multi_match</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">&#123;</span><br><span class="line">  &quot;query&quot;: &#123;</span><br><span class="line">    &quot;multi_match&quot;: &#123;</span><br><span class="line">        &quot;query&quot; : &quot;我的宝马多少马力&quot;,</span><br><span class="line">        &quot;fields&quot; : [&quot;title&quot;, &quot;content&quot;]</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>但是multi_match就涉及到匹配评分的问题了。</p>
<h2 id="best-fields"><a href="#best-fields" class="headerlink" title="best_fields"></a>best_fields</h2><p>我们希望完全匹配的文档占的评分比较高，则需要使用best_fields</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">&#123;</span><br><span class="line">  &quot;query&quot;: &#123;</span><br><span class="line">    &quot;multi_match&quot;: &#123;</span><br><span class="line">      &quot;query&quot;: &quot;我的宝马发动机多少&quot;,</span><br><span class="line">      &quot;type&quot;: &quot;best_fields&quot;,</span><br><span class="line">      &quot;fields&quot;: [</span><br><span class="line">        &quot;tag&quot;,</span><br><span class="line">        &quot;content&quot;</span><br><span class="line">      ],</span><br><span class="line">      &quot;tie_breaker&quot;: 0.3</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>意思就是完全匹配”宝马 发动机”的文档评分会比较靠前，如果只匹配宝马的文档评分乘以0.3的系数</p>
<h2 id="most-fields"><a href="#most-fields" class="headerlink" title="most_fields"></a>most_fields</h2><p>我们希望越多字段匹配的文档评分越高，就要使用most_fields</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">&#123;</span><br><span class="line">  &quot;query&quot;: &#123;</span><br><span class="line">    &quot;multi_match&quot;: &#123;</span><br><span class="line">      &quot;query&quot;: &quot;我的宝马发动机多少&quot;,</span><br><span class="line">      &quot;type&quot;: &quot;most_fields&quot;,</span><br><span class="line">      &quot;fields&quot;: [</span><br><span class="line">        &quot;tag&quot;,</span><br><span class="line">        &quot;content&quot;</span><br><span class="line">      ]</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h2 id="cross-fields"><a href="#cross-fields" class="headerlink" title="cross_fields"></a>cross_fields</h2><p>我们会希望这个词条的分词词汇是分配到不同字段中的，那么就使用cross_fields</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">&#123;</span><br><span class="line">  &quot;query&quot;: &#123;</span><br><span class="line">    &quot;multi_match&quot;: &#123;</span><br><span class="line">      &quot;query&quot;: &quot;我的宝马发动机多少&quot;,</span><br><span class="line">      &quot;type&quot;: &quot;cross_fields&quot;,</span><br><span class="line">      &quot;fields&quot;: [</span><br><span class="line">        &quot;tag&quot;,</span><br><span class="line">        &quot;content&quot;</span><br><span class="line">      ]</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h2 id="term"><a href="#term" class="headerlink" title="term"></a>term</h2><p>term是代表完全匹配，即不进行分词器分析，文档中必须包含整个搜索的词汇</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">&#123;</span><br><span class="line">  &quot;query&quot;: &#123;</span><br><span class="line">    &quot;term&quot;: &#123;</span><br><span class="line">      &quot;content&quot;: &quot;汽车保养&quot;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>查出的所有文档都包含”汽车保养”这个词组的词汇。</p>
<p>使用term要确定的是这个字段是否“被分析”(analyzed)，默认的字符串是被分析的。</p>
<p>拿官网上的例子举例：</p>
<p>mapping是这样的：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line">PUT my_index</span><br><span class="line">&#123;</span><br><span class="line">  &quot;mappings&quot;: &#123;</span><br><span class="line">    &quot;my_type&quot;: &#123;</span><br><span class="line">      &quot;properties&quot;: &#123;</span><br><span class="line">        &quot;full_text&quot;: &#123;</span><br><span class="line">          &quot;type&quot;:  &quot;string&quot;</span><br><span class="line">        &#125;,</span><br><span class="line">        &quot;exact_value&quot;: &#123;</span><br><span class="line">          &quot;type&quot;:  &quot;string&quot;,</span><br><span class="line">          &quot;index&quot;: &quot;not_analyzed&quot;</span><br><span class="line">        &#125;</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">PUT my_index/my_type/1</span><br><span class="line">&#123;</span><br><span class="line">  &quot;full_text&quot;:   &quot;Quick Foxes!&quot;,</span><br><span class="line">  &quot;exact_value&quot;: &quot;Quick Foxes!&quot;  </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>其中的full_text是被分析过的，所以full_text的索引中存的就是[quick, foxes]，而extra_value中存的是[Quick Foxes!]。</p>
<p>那下面的几个请求：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">GET my_index/my_type/_search</span><br><span class="line">&#123;</span><br><span class="line">  &quot;query&quot;: &#123;</span><br><span class="line">    &quot;term&quot;: &#123;</span><br><span class="line">      &quot;exact_value&quot;: &quot;Quick Foxes!&quot;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>请求的出数据，因为完全匹配</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">GET my_index/my_type/_search</span><br><span class="line">&#123;</span><br><span class="line">  &quot;query&quot;: &#123;</span><br><span class="line">    &quot;term&quot;: &#123;</span><br><span class="line">      &quot;full_text&quot;: &quot;Quick Foxes!&quot;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>请求不出数据的，因为full_text分词后的结果中没有[Quick Foxes!]这个分词。</p>
<h3 id="对查询的结果排序"><a href="#对查询的结果排序" class="headerlink" title="对查询的结果排序"></a>对查询的结果排序</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">GET iclick_persona/iclick/_search</span><br><span class="line">&#123;</span><br><span class="line">  &quot;query&quot;: &#123;</span><br><span class="line">    &quot;bool&quot;: &#123;</span><br><span class="line">      &quot;must&quot;: [</span><br><span class="line">        &#123;&quot;term&quot;: &#123;</span><br><span class="line">          &quot;articles.domains&quot;: &#123;</span><br><span class="line">            &quot;value&quot;: &quot;play.google.com&quot;</span><br><span class="line">          &#125;</span><br><span class="line">        &#125;&#125;</span><br><span class="line">      ]</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;, &quot;sort&quot;: [</span><br><span class="line">    &#123;</span><br><span class="line">      &quot;create_time&quot;: &#123;</span><br><span class="line">        &quot;order&quot;: &quot;desc&quot;</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">  ]</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h2 id="bool"><a href="#bool" class="headerlink" title="bool"></a>bool</h2><p>联合查询: must,should,must_not</p>
<p>如果我们想要请求”content中带宝马，但是tag中不带宝马”这样类似的需求，就需要用到bool联合查询。<br>联合查询就会使用到must,should,must_not三种关键词。</p>
<p>这三个可以这么理解</p>
<ul>
<li>must: 文档必须完全匹配条件</li>
<li>should: should下面会带一个以上的条件，至少满足一个条件，这个文档就符合should</li>
<li>must_not: 文档必须不匹配条件</li>
</ul>
<p>比如上面那个需求：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">&#123;</span><br><span class="line">  &quot;query&quot;: &#123;</span><br><span class="line">    &quot;bool&quot;: &#123;</span><br><span class="line">      &quot;must&quot;: &#123;</span><br><span class="line">        &quot;term&quot;: &#123;</span><br><span class="line">          &quot;content&quot;: &quot;宝马&quot;</span><br><span class="line">        &#125;</span><br><span class="line">      &#125;,</span><br><span class="line">      &quot;must_not&quot;: &#123;</span><br><span class="line">        &quot;term&quot;: &#123;</span><br><span class="line">          &quot;tags&quot;: &quot;宝马&quot;</span><br><span class="line">        &#125;</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h2 id="多条件查询"><a href="#多条件查询" class="headerlink" title="多条件查询"></a>多条件查询</h2><p>比如要实现 a &amp;&amp; (b=0 || b=1)这样的需求，则通过嵌套bool来实现，例如</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br></pre></td><td class="code"><pre><span class="line">GET news_v1/_search</span><br><span class="line">&#123;</span><br><span class="line">  &quot;size&quot;: 20,</span><br><span class="line">  &quot;query&quot;: &#123;</span><br><span class="line">    &quot;bool&quot;: &#123;</span><br><span class="line">      &quot;must&quot;: [</span><br><span class="line">        &#123;</span><br><span class="line">          &quot;multi_match&quot;: &#123;</span><br><span class="line">            &quot;query&quot;: &quot;美白&quot;,</span><br><span class="line">            &quot;fields&quot;: [</span><br><span class="line">              &quot;meta.description&quot;,</span><br><span class="line">              &quot;title&quot;</span><br><span class="line">            ]</span><br><span class="line">          &#125;</span><br><span class="line">        &#125;,</span><br><span class="line">        &#123;</span><br><span class="line">        &quot;bool&quot;: &#123;</span><br><span class="line">            &quot;should&quot;: [</span><br><span class="line">              &#123;</span><br><span class="line">                &quot;term&quot;: &#123;</span><br><span class="line">                  &quot;lang&quot;: &#123;</span><br><span class="line">                    &quot;value&quot;: &quot;zh-hk&quot;</span><br><span class="line">                  &#125;</span><br><span class="line">                &#125;</span><br><span class="line">              &#125;,</span><br><span class="line">              &#123;</span><br><span class="line">                &quot;term&quot;: &#123;</span><br><span class="line">                  &quot;lang&quot;: &#123;</span><br><span class="line">                    &quot;value&quot;: &quot;en&quot;</span><br><span class="line">                  &#125;</span><br><span class="line">                &#125;</span><br><span class="line">              &#125;</span><br><span class="line">            ]</span><br><span class="line">          &#125;</span><br><span class="line">        &#125;</span><br><span class="line">      ]</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;,</span><br><span class="line">  &quot;ext&quot;: &#123;&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h2 id="自定义排序"><a href="#自定义排序" class="headerlink" title="自定义排序"></a>自定义排序</h2><p>ES自带的排序默认只是可以对数值字段，日期字段或者是字符串字段进行排序，那么，如果我们就是要人为的让包含字段A的排在包含字段B的前面，当前的方式无法满足。</p>
<p>于是需要寻求另一种方式来解决，将给定的A和B转换成数值1和2 从而就能够达到要求的排序。而且是在得分相同的情况才会进行的排序方式！通过脚本实现。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line">GET _search  </span><br><span class="line">&#123;  </span><br><span class="line">  &quot;_source&quot;: &#123;  </span><br><span class="line">    &quot;include&quot;: [&quot;title.Value&quot;,&quot;dataType&quot;,&quot;_score&quot;]  </span><br><span class="line">  &#125;,   </span><br><span class="line">  &quot;query&quot;: &#123;  </span><br><span class="line">    &quot;bool&quot;: &#123;  </span><br><span class="line">      &quot;should&quot;: [  </span><br><span class="line">        &#123;  </span><br><span class="line">          &quot;query_string&quot;: &#123;  </span><br><span class="line">            &quot;default_field&quot;: &quot;title.Value&quot;,  </span><br><span class="line">            &quot;query&quot;: &quot;盆地^10  Unconformity&quot;  </span><br><span class="line">          &#125;  </span><br><span class="line">        &#125;  </span><br><span class="line">      ]  </span><br><span class="line">    &#125;  </span><br><span class="line">  &#125;,  </span><br><span class="line">    &quot;sort&quot; : &#123;  </span><br><span class="line">      &quot;_score&quot;:&#123;  </span><br><span class="line">        &quot;order&quot; : &quot;dese&quot;  </span><br><span class="line">      &#125;,  </span><br><span class="line">    &quot;_script&quot; : &#123;   </span><br><span class="line">        &quot;script&quot; : &quot;&apos;区带资源量数据&apos; in doc[&apos;dataType&apos;].values?2 :(&apos;其它相关资料5&apos; in doc[&apos;dataType&apos;].values? 1 :3)&quot;,  </span><br><span class="line">        &quot;type&quot; : &quot;string&quot;,  </span><br><span class="line">        &quot;order&quot; : &quot;asc&quot;  </span><br><span class="line">    &#125;  </span><br><span class="line">  &#125;  </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h2 id="按条件删除"><a href="#按条件删除" class="headerlink" title="按条件删除"></a>按条件删除</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">POST iclick_persona/iclick/_delete_by_query</span><br></pre></td></tr></table></figure>
<h1 id="ES的java-api"><a href="#ES的java-api" class="headerlink" title="ES的java api"></a>ES的java api</h1><h2 id="连接到ES"><a href="#连接到ES" class="headerlink" title="连接到ES"></a>连接到ES</h2><p>创建一个客户端连接</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">import org.elasticsearch.client.transport.TransportClient;</span><br><span class="line">import org.elasticsearch.common.settings.Settings;</span><br><span class="line">import org.elasticsearch.common.transport.InetSocketTransportAddress;</span><br><span class="line">import org.elasticsearch.transport.client.PreBuiltTransportClient;</span><br><span class="line"></span><br><span class="line">TransportClient client = new PreBuiltTransportClient(Settings.EMPTY)</span><br><span class="line">				.addTransportAddress(new InetSocketTransportAddress(InetAddress</span><br><span class="line">						.getByName(&quot;10.1.1.111&quot;), 9300));</span><br></pre></td></tr></table></figure>
<h2 id="创建索引并写入数据"><a href="#创建索引并写入数据" class="headerlink" title="创建索引并写入数据"></a>创建索引并写入数据</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">import org.datanucleus.store.rdbms.request.BulkRequest;</span><br><span class="line">import org.elasticsearch.action.index.IndexResponse;</span><br></pre></td></tr></table></figure>
<p>若是单个插入索引</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">// 创建es索引</span><br><span class="line">IndexResponse response = client.prepareIndex(&quot;movie&quot;, &quot;bt&quot;)</span><br><span class="line">.setSource(JSON.toJSONString(obj)).get();</span><br></pre></td></tr></table></figure>
<p>若是批量插入索引</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line">String line = null;</span><br><span class="line">		JSONObject obj = null;</span><br><span class="line">		</span><br><span class="line">		TransportClient client = new PreBuiltTransportClient(Settings.EMPTY)</span><br><span class="line">		.addTransportAddress(new InetSocketTransportAddress(InetAddress</span><br><span class="line">				.getByName(&quot;10.1.1.111&quot;), 9300));</span><br><span class="line">		</span><br><span class="line">		//批量插入索引</span><br><span class="line">		BulkRequestBuilder brq = client.prepareBulk();</span><br><span class="line">		</span><br><span class="line">		File file = new File(&quot;f:\\data_utf8.json&quot;);</span><br><span class="line">		int cnt = 0;</span><br><span class="line">		if (file.exists() &amp;&amp; file.isFile()) &#123;</span><br><span class="line">			InputStreamReader isr = new InputStreamReader(new FileInputStream(</span><br><span class="line">					file));</span><br><span class="line">			BufferedReader br = new BufferedReader(isr);</span><br><span class="line">			while ((line = br.readLine()) != null) &#123;</span><br><span class="line">				obj = JSON.parseObject(line);</span><br><span class="line">				</span><br><span class="line">				brq.add(client.prepareIndex(&quot;btmovie&quot;, &quot;bt&quot;).setSource(JSON.toJSONString(obj)));</span><br><span class="line">				cnt ++;</span><br><span class="line">				</span><br><span class="line">				if (cnt%1000 == 0)</span><br><span class="line">					System.out.println(cnt);</span><br><span class="line">			&#125;</span><br><span class="line">		&#125;</span><br><span class="line">		</span><br><span class="line">		brq.execute().actionGet();</span><br><span class="line">		</span><br><span class="line">		</span><br><span class="line">		System.out.println(&quot;done&quot;);</span><br></pre></td></tr></table></figure>
<h1 id="disable-coord"><a href="#disable-coord" class="headerlink" title="disable_coord"></a>disable_coord</h1><p>true：多个关键词命中，打分会累加</p>
<blockquote>
<ul>
<li>if coord factor is enabled (by default “disable_coord”: false) then it means: <em>if we have more search keywords in text then this result would be more relevant and will get higher score</em>.</li>
<li>if coord factor is disabled(“disable_coord”: true) then it means: <em>no matter how many keywords we have in search text it will be counted just once.</em></li>
</ul>
</blockquote>
<h1 id="minimum-should-match"><a href="#minimum-should-match" class="headerlink" title="minimum_should_match"></a>minimum_should_match</h1><p>在multi_match中，minimum_should_match</p>
<h1 id="相关度控制原理"><a href="#相关度控制原理" class="headerlink" title="相关度控制原理"></a>相关度控制原理</h1><p><a href="http://blog.csdn.net/xyh930929/article/details/72378690?utm_source=itdadao&amp;utm_medium=referral" target="_blank" rel="noopener">http://blog.csdn.net/xyh930929/article/details/72378690?utm_source=itdadao&amp;utm_medium=referral</a></p>
<h1 id="analyzer"><a href="#analyzer" class="headerlink" title="analyzer"></a>analyzer</h1><p>english_custom</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br></pre></td><td class="code"><pre><span class="line">&quot;analysis&quot;: &#123;</span><br><span class="line">          &quot;filter&quot;: &#123;</span><br><span class="line">            &quot;english_stemmer&quot;: &#123;</span><br><span class="line">              &quot;type&quot;: &quot;stemmer&quot;,</span><br><span class="line">              &quot;language&quot;: &quot;english&quot;</span><br><span class="line">            &#125;,</span><br><span class="line">            &quot;english_stop&quot;: &#123;</span><br><span class="line">              &quot;type&quot;: &quot;stop&quot;,</span><br><span class="line">              &quot;stopwords&quot;: &quot;_english_&quot;</span><br><span class="line">            &#125;,</span><br><span class="line">            &quot;english_possessive_stemmer&quot;: &#123;</span><br><span class="line">              &quot;type&quot;: &quot;stemmer&quot;,</span><br><span class="line">              &quot;language&quot;: &quot;possessive_english&quot;</span><br><span class="line">            &#125;</span><br><span class="line">          &#125;,</span><br><span class="line">          &quot;analyzer&quot;: &#123;</span><br><span class="line">            &quot;cjk_custom&quot;: &#123;</span><br><span class="line">              &quot;filter&quot;: [</span><br><span class="line">                &quot;cjk_width&quot;,</span><br><span class="line">                &quot;lowercase&quot;,</span><br><span class="line">                &quot;cjk_bigram&quot;,</span><br><span class="line">                &quot;english_stop&quot;,</span><br><span class="line">                &quot;asciifolding&quot;</span><br><span class="line">              ],</span><br><span class="line">              &quot;tokenizer&quot;: &quot;standard&quot;</span><br><span class="line">            &#125;,</span><br><span class="line">            &quot;english_custom&quot;: &#123;</span><br><span class="line">              &quot;filter&quot;: [</span><br><span class="line">                &quot;english_possessive_stemmer&quot;,</span><br><span class="line">                &quot;lowercase&quot;,</span><br><span class="line">                &quot;english_stop&quot;,</span><br><span class="line">                &quot;english_stemmer&quot;,</span><br><span class="line">                &quot;asciifolding&quot;</span><br><span class="line">              ],</span><br><span class="line">              &quot;tokenizer&quot;: &quot;standard&quot;</span><br><span class="line">            &#125;</span><br><span class="line">          &#125;</span><br><span class="line">        &#125;</span><br></pre></td></tr></table></figure>

          
        
      
    </div>

    

    
    
    

    

    
      
    
    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  

  <article class="post post-type-normal" itemscope="" itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="https://schwimmer.github.io/2017/07/12/机器学习/集成学习/">

    <span hidden itemprop="author" itemscope="" itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Schwimmer">
      <meta itemprop="description" content="Record and Think!">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope="" itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Schwimmer's Blog">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                
                <a href="/2017/07/12/机器学习/集成学习/" class="post-title-link" itemprop="url">集成学习</a>
              
            
          </h1>
        

        <div class="post-meta">

          
          
          

          
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              

              
                
              

              <time title="创建时间：2017-07-12 11:49:53" itemprop="dateCreated datePublished" datetime="2017-07-12T11:49:53+08:00">2017-07-12</time>
            </span>
          

          
            

            
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="fa fa-calendar-check-o"></i>
                </span>
                
                  <span class="post-meta-item-text">更新于</span>
                
                <time title="修改时间：2018-08-16 16:41:49" itemprop="dateModified" datetime="2018-08-16T16:41:49+08:00">2018-08-16</time>
              </span>
            
          

          
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope="" itemtype="http://schema.org/Thing"><a href="/categories/机器学习/" itemprop="url" rel="index"><span itemprop="name">机器学习</span></a></span>

                
                
              
            </span>
          

          
            
            
              
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="fa fa-comment-o"></i>
                </span>
            
                <span class="post-meta-item-text">评论数：</span>
                <a href="/2017/07/12/机器学习/集成学习/#comments" itemprop="discussionUrl">
                  <span class="post-comments-count disqus-comment-count" data-disqus-identifier="2017/07/12/机器学习/集成学习/" itemprop="commentCount"></span>
                </a>
              </span>
            
          

          
          

          

          <br>
          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>个体学习器一般是弱学习器。</p>
<blockquote>
<p> 弱学习器是指泛华性能略优于随机猜测的学习器，例如二分上略高于50%的学习器。</p>
</blockquote>
<p>要获得好的集成，个体学习器应“好而不同”，即个体学习器要有一定的<strong>准确性和多样性</strong>（学习器之间有差异）。</p>
<p>理论上，假设个体学习器的误差是相互独立，那么随着学习器数量增大，集成的错误率将指数下降，最终趋向于零。</p>
<p>但实际上不可能相互独立。且<strong>准确性和多样性本身就是矛盾的</strong>，追求准确性就要牺牲多样性。所以<strong>如何产生并结合“好而不同”的学习器，是集成学习研究的核心</strong>。</p>
<p>根据集成的方式不同，</p>
<p>1）个体学习器存在强依赖性，必须串行生成，如Boosting；</p>
<p>2）个体学习器间不存在强依赖关系，可同时并行生成，如Bagging和随机森林。</p>
<h1 id="mic或stacking方法"><a href="#mic或stacking方法" class="headerlink" title="mic或stacking方法"></a>mic或stacking方法</h1><p><a href="https://blog.csdn.net/sb19931201/article/details/56315689?locationNum=1&amp;fps=1" target="_blank" rel="noopener">https://blog.csdn.net/sb19931201/article/details/56315689?locationNum=1&amp;fps=1</a> 从这篇帖子来</p>
<p><a href="https://blog.csdn.net/a358463121/article/details/53054686#t18" target="_blank" rel="noopener">https://blog.csdn.net/a358463121/article/details/53054686#t18</a></p>
<p><a href="https://zhuanlan.zhihu.com/jlbookworm" target="_blank" rel="noopener">https://zhuanlan.zhihu.com/jlbookworm</a></p>
<p><a href="https://blog.csdn.net/wstcjf/article/details/77989963" target="_blank" rel="noopener">https://blog.csdn.net/wstcjf/article/details/77989963</a> 文章的思路有点问题？</p>
<p><a href="https://blog.csdn.net/xiaoliuzz/article/details/79298841" target="_blank" rel="noopener">https://blog.csdn.net/xiaoliuzz/article/details/79298841</a></p>
<p><a href="https://blog.csdn.net/yc1203968305/article/details/73526615" target="_blank" rel="noopener">https://blog.csdn.net/yc1203968305/article/details/73526615</a></p>
<p><a href="https://www.cnblogs.com/zhizhan/p/5051881.html" target="_blank" rel="noopener">https://www.cnblogs.com/zhizhan/p/5051881.html</a></p>
<p><a href="https://mlwave.com/kaggle-ensembling-guide/" target="_blank" rel="noopener">https://mlwave.com/kaggle-ensembling-guide/</a></p>
<h1 id="Stacking"><a href="#Stacking" class="headerlink" title="Stacking"></a>Stacking</h1><p><a href="http://tech.ifeng.com/a/20170929/44704115_0.shtml" target="_blank" rel="noopener">Kaggle机器学习之模型融合（stacking）心得</a></p>
<p><a href="https://www.kaggle.com/arthurtok/introduction-to-ensembling-stacking-in-python" target="_blank" rel="noopener">Introduction to Ensembling/Stacking in Python</a> </p>
<p><a href="https://www.kdnuggets.com/2017/02/stacking-models-imropved-predictions.html" target="_blank" rel="noopener">Stacking Models for Improved Predictions</a></p>
<h2 id="使用sklearn进行集成学习——理论"><a href="#使用sklearn进行集成学习——理论" class="headerlink" title="使用sklearn进行集成学习——理论"></a><a href="https://www.cnblogs.com/jasonfreak/p/5657196.html" target="_blank" rel="noopener">使用sklearn进行集成学习——理论</a></h2><p>1 前言<br>2 集成学习是什么？<br>3 偏差和方差<br>　　3.1 模型的偏差和方差是什么？<br>　　3.2 bagging的偏差和方差<br>　　3.3 boosting的偏差和方差<br>　　3.4 模型的独立性<br>　　3.5 小结<br>4 Gradient Boosting<br>　　4.1 拟合残差<br>　　4.2 拟合反向梯度<br>　　　　4.2.1 契机：引入损失函数<br>　　　　4.2.2 难题一：任意损失函数的最优化<br>　　　　4.2.3 难题二：无法对测试样本计算反向梯度<br>　　4.3 常见的损失函数<br>　　4.4 步子太大容易扯着蛋：缩减<br>　　4.5 初始模型<br>　　4.5 Gradient Tree Boosting<br>　　4.6 小结<br>5 总结<br>6 参考资料</p>
<hr>
<h1 id="1-前言"><a href="#1-前言" class="headerlink" title="1 前言"></a>1 前言</h1><p>　　很多人在竞赛（Kaggle，天池等）或工程实践中使用了集成学习（例如，RF、GTB等），确实也取得了不错的效果，在保证准确度的同时也提升了模型防止过拟合的能力。但是，我们真的用对了集成学习吗？</p>
<p>　　sklearn提供了sklearn.ensemble库，支持众多集成学习算法和模型。恐怕大多数人使用这些工具时，要么使用默认参数，要么根据模型在测试集上的性能试探性地进行调参（当然，完全不懂的参数还是不动算了），要么将调参的工作丢给调参算法（网格搜索等）。这样并不能真正地称为“会”用sklearn进行集成学习。</p>
<p>　　我认为，学会调参是进行集成学习工作的前提。然而，第一次遇到这些算法和模型时，肯定会被其丰富的参数所吓到，要知道，教材上教的伪代码可没这么多参数啊！！！没关系，暂时，我们只要记住一句话：参数可分为两种，一种是影响模型在训练集上的准确度或影响防止过拟合能力的参数；另一种不影响这两者的其他参数。模型在样本总体上的准确度（后简称准确度）由其在训练集上的准确度及其防止过拟合的能力所共同决定，所以在调参时，我们主要对第一种参数进行调整，最终达到的效果是：模型在训练集上的准确度和防止过拟合能力的大和谐！</p>
<p>　　本篇博文将详细阐述模型参数背后的理论知识，在下篇博文中，我们将对最热门的两个模型Random Forrest和Gradient Tree Boosting（含分类和回归，所以共4个模型）进行具体的参数讲解。如果你实在无法静下心来学习理论，你也可以在下篇博文中找到最直接的调参指导，虽然我不赞同这么做。</p>
<hr>
<h1 id="2-集成学习是什么？"><a href="#2-集成学习是什么？" class="headerlink" title="2 集成学习是什么？"></a>2 集成学习是什么？</h1><p>　　我们还是花一点时间来说明一下集成学习是什么，如果对此有一定基础的同学可以跳过本节。简单来说，集成学习是一种技术框架，其按照不同的思路来组合基础模型，从而达到其利断金的目的。</p>
<p>　　目前，有三种常见的集成学习框架：bagging，boosting和stacking。国内，南京大学的周志华教授对集成学习有很深入的研究，其在09年发表的一篇概述性论文<a href="http://cs.nju.edu.cn/zhouzh/zhouzh.files/publication/springerEBR09.pdf" target="_blank" rel="noopener">《</a><a href="http://cs.nju.edu.cn/zhouzh/zhouzh.files/publication/springerEBR09.pdf" target="_blank" rel="noopener">Ensemble Learning》</a>对这三种集成学习框架有了明确的定义，概括如下：</p>
<p> 　　bagging：从训练集从进行子抽样组成每个基模型所需要的子训练集，对所有基模型预测的结果进行综合产生最终的预测结果：</p>
<p><img src="https://images2015.cnblogs.com/blog/927391/201607/927391-20160717135005498-1140287801.jpg" alt="img"></p>
<p>　　boosting：训练过程为阶梯状，基模型按次序一一进行训练（实现上可以做到并行），基模型的训练集按照某种策略每次都进行一定的转化。对所有基模型预测的结果进行线性综合产生最终的预测结果：</p>
<p><img src="https://images2015.cnblogs.com/blog/927391/201607/927391-20160717135023373-1810846145.jpg" alt="img"></p>
<p>　　stacking：将训练好的所有基模型对训练基进行预测，第j个基模型对第i个训练样本的预测值将作为新的训练集中第i个样本的第j个特征值，最后基于新的训练集进行训练。同理，预测的过程也要先经过所有基模型的预测形成新的测试集，最后再对测试集进行预测：</p>
<p><img src="https://images2015.cnblogs.com/blog/927391/201607/927391-20160716073722420-208134951.jpg" alt="img"></p>
<p>　　有了这些基本概念之后，直觉将告诉我们，由于不再是单一的模型进行预测，所以模型有了“集思广益”的能力，也就不容易产生过拟合现象。但是，直觉是不可靠的，接下来我们将从模型的偏差和方差入手，彻底搞清楚这一问题。</p>
<hr>
<h1 id="3-偏差和方差"><a href="#3-偏差和方差" class="headerlink" title="3 偏差和方差"></a>3 偏差和方差</h1><p>　　广义的偏差（bias）描述的是预测值和真实值之间的差异，方差（variance）描述距的是预测值作为随机变量的离散程度。<a href="http://scott.fortmann-roe.com/docs/BiasVariance.html" target="_blank" rel="noopener">《Understanding the Bias-Variance Tradeoff》</a>当中有一副图形象地向我们展示了偏差和方差的关系：</p>
<p><img src="https://images2015.cnblogs.com/blog/927391/201607/927391-20160716124330623-527064401.jpg" alt="img"></p>
<h2 id="3-1-模型的偏差和方差是什么？"><a href="#3-1-模型的偏差和方差是什么？" class="headerlink" title="3.1 模型的偏差和方差是什么？"></a>3.1 模型的偏差和方差是什么？</h2><p>　　模型的偏差是一个相对来说简单的概念：训练出来的模型在训练集上的准确度。</p>
<p>　　要解释模型的方差，首先需要重新审视模型：模型是随机变量。设样本容量为n的训练集为随机变量的集合(X1, X2, …, Xn)，那么模型是以这些随机变量为输入的随机变量函数（其本身仍然是随机变量）：F(X1, X2, …, Xn)。抽样的随机性带来了模型的随机性。</p>
<p>　　定义随机变量的值的差异是计算方差的前提条件，通常来说，我们遇到的都是数值型的随机变量，数值之间的差异再明显不过（减法运算）。但是，模型的差异性呢？我们可以理解模型的差异性为模型的结构差异，例如：线性模型中权值向量的差异，树模型中树的结构差异等。在研究模型方差的问题上，我们并不需要对方差进行定量计算，只需要知道其概念即可。</p>
<p>　　研究模型的方差有什么现实的意义呢？我们认为方差越大的模型越容易过拟合：假设有两个训练集A和B，经过A训练的模型Fa与经过B训练的模型Fb差异很大，这意味着Fa在类A的样本集合上有更好的性能，而Fb反之，这便是我们所说的过拟合现象。</p>
<p>　　我们常说集成学习框架中的基模型是弱模型，通常来说弱模型是偏差高（在训练集上准确度低）方差小（防止过拟合能力强）的模型。但是，并不是所有集成学习框架中的基模型都是弱模型。bagging和stacking中的基模型为强模型（偏差低方差高），boosting中的基模型为弱模型。</p>
<p>　　在bagging和boosting框架中，通过计算基模型的期望和方差，我们可以得到模型整体的期望和方差。为了简化模型，我们假设基模型的权重、方差及两两间的相关系数相等。由于bagging和boosting的基模型都是线性组成的，那么有：</p>
<p> <img src="https://images2015.cnblogs.com/blog/927391/201607/927391-20160716145131217-650617034.png" alt="img"></p>
<h2 id="3-2-bagging的偏差和方差"><a href="#3-2-bagging的偏差和方差" class="headerlink" title="3.2 bagging的偏差和方差"></a>3.2 bagging的偏差和方差</h2><p>　　对于bagging来说，每个基模型的权重等于1/m且期望近似相等（子训练集都是从原训练集中进行子抽样），故我们可以进一步化简得到：</p>
<p><img src="https://images2015.cnblogs.com/blog/927391/201607/927391-20160716145206701-383430284.png" alt="img"></p>
<p>　　根据上式我们可以看到，整体模型的期望近似于基模型的期望，这也就意味着整体模型的偏差和基模型的偏差近似。同时，整体模型的方差小于等于基模型的方差（当相关性为1时取等号），随着基模型数（m）的增多，整体模型的方差减少，从而防止过拟合的能力增强，模型的准确度得到提高。但是，模型的准确度一定会无限逼近于1吗？并不一定，当基模型数增加到一定程度时，方差公式第二项的改变对整体方差的作用很小，防止过拟合的能力达到极限，这便是准确度的极限了。另外，在此我们还知道了为什么bagging中的基模型一定要为强模型，否则就会导致整体模型的偏差度低，即准确度低。</p>
<p>　　Random Forest是典型的基于bagging框架的模型，其在bagging的基础上，进一步降低了模型的方差。Random Fores中基模型是树模型，在树的内部节点分裂过程中，不再是将所有特征，而是随机抽样一部分特征纳入分裂的候选项。这样一来，基模型之间的相关性降低，从而在方差公式中，第一项显著减少，第二项稍微增加，整体方差仍是减少。</p>
<h2 id="3-3-boosting的偏差和方差"><a href="#3-3-boosting的偏差和方差" class="headerlink" title="3.3 boosting的偏差和方差"></a>3.3 boosting的偏差和方差</h2><p>　　对于boosting来说，基模型的训练集抽样是强相关的，那么模型的相关系数近似等于1，故我们也可以针对boosting化简公式为：</p>
<p><img src="https://images2015.cnblogs.com/blog/927391/201607/927391-20160717142500264-1717908455.png" alt="img"></p>
<p>　　通过观察整体方差的表达式，我们容易发现，若基模型不是弱模型，其方差相对较大，这将导致整体模型的方差很大，即无法达到防止过拟合的效果。因此，boosting框架中的基模型必须为弱模型。</p>
<p>　　因为基模型为弱模型，导致了每个基模型的准确度都不是很高（因为其在训练集上的准确度不高）。随着基模型数的增多，整体模型的期望值增加，更接近真实值，因此，整体模型的准确度提高。但是准确度一定会无限逼近于1吗？仍然并不一定，因为训练过程中准确度的提高的主要功臣是整体模型在训练集上的准确度提高，而随着训练的进行，整体模型的方差变大，导致防止过拟合的能力变弱，最终导致了准确度反而有所下降。</p>
<p>　　基于boosting框架的Gradient Tree Boosting模型中基模型也为树模型，同Random Forrest，我们也可以对特征进行随机抽样来使基模型间的相关性降低，从而达到减少方差的效果。</p>
<h2 id="3-4-模型的独立性"><a href="#3-4-模型的独立性" class="headerlink" title="3.4 模型的独立性"></a>3.4 模型的独立性</h2><p>　　聪明的读者这时肯定要问了，如何衡量基模型的独立性？我们说过，抽样的随机性决定了模型的随机性，如果两个模型的训练集抽样过程不独立，则两个模型则不独立。这时便有一个天大的陷阱在等着我们：bagging中基模型的训练样本都是独立的随机抽样，但是基模型却不独立呢？</p>
<p>　　我们讨论模型的随机性时，抽样是针对于样本的整体。而bagging中的抽样是针对于训练集（整体的子集），所以并不能称其为对整体的独立随机抽样。那么到底bagging中基模型的相关性体现在哪呢？在知乎问答<a href="https://www.zhihu.com/question/26760839" target="_blank" rel="noopener">《为什么说bagging是减少variance，而boosting是减少bias?》</a>中请教用户<a href="https://www.zhihu.com/people/guo-ni-he" target="_blank" rel="noopener">“过拟合”</a>后，我总结bagging的抽样为两个过程：</p>
<ol>
<li>样本抽样：整体模型F(X1, X2, …, Xn)中各输入随机变量（X1, X2, …, Xn）对样本的抽样</li>
<li>子抽样：从整体模型F(X1, X2, …, Xn)中随机抽取若干输入随机变量成为基模型的输入随机变量</li>
</ol>
<p>　　假若在子抽样的过程中，两个基模型抽取的输入随机变量有一定的重合，那么这两个基模型对整体样本的抽样将不再独立，这时基模型之间便具有了相关性。</p>
<h2 id="3-5-小结"><a href="#3-5-小结" class="headerlink" title="3.5 小结"></a>3.5 小结</h2><p>　　还记得调参的目标吗：模型在训练集上的准确度和防止过拟合能力的大和谐！为此，我们目前做了一些什么工作呢？</p>
<ol>
<li>使用模型的偏差和方差来描述其在训练集上的准确度和防止过拟合的能力</li>
<li>对于bagging来说，整体模型的偏差和基模型近似，随着训练的进行，整体模型的方差降低</li>
<li>对于boosting来说，整体模型的初始偏差较高，方差较低，随着训练的进行，整体模型的偏差降低（虽然也不幸地伴随着方差增高），当训练过度时，因方差增高，整体模型的准确度反而降低</li>
<li>整体模型的偏差和方差与基模型的偏差和方差息息相关</li>
</ol>
<p>　　这下总算有点开朗了，那些让我们抓狂的参数，现在可以粗略地分为两类了：控制整体训练过程的参数和基模型的参数，这两类参数都在影响着模型在训练集上的准确度以及防止过拟合的能力。</p>
<hr>
<h1 id="4-Gradient-Boosting"><a href="#4-Gradient-Boosting" class="headerlink" title="4 Gradient Boosting"></a>4 Gradient Boosting</h1><p>　　对基于Gradient Boosting框架的模型的进行调试时，我们会遇到一个重要的概念：损失函数。在本节中，我们将把损失函数的“今生来世”讲个清楚！</p>
<p>　　基于boosting框架的整体模型可以用线性组成式来描述，其中h<a href="x">i</a>为基模型与其权值的乘积：</p>
<p><img src="https://images2015.cnblogs.com/blog/927391/201607/927391-20160717144731264-398372888.png" alt="img"></p>
<p>　　根据上式，整体模型的训练目标是使预测值F(x)逼近真实值y，也就是说要让每一个基模型的预测值逼近各自要预测的部分真实值。由于要同时考虑所有基模型，导致了整体模型的训练变成了一个非常复杂的问题。所以，研究者们想到了一个贪心的解决手段：每次只训练一个基模型。那么，现在改写整体模型为迭代式：</p>
<p><img src="https://images2015.cnblogs.com/blog/927391/201607/927391-20160717144844795-1514741556.png" alt="img"></p>
<p>　　这样一来，每一轮迭代中，只要集中解决一个基模型的训练问题：使F<a href="x">i</a>逼近真实值y。</p>
<h2 id="4-1-拟合残差"><a href="#4-1-拟合残差" class="headerlink" title="4.1 拟合残差"></a>4.1 拟合残差</h2><p>　　使F<a href="x">i</a>逼近真实值，其实就是使h<a href="x">i</a>逼近真实值和上一轮迭代的预测值F<a href="x">i-1</a>之差，即残差（y-F<a href="x">i-1</a>）。最直接的做法是构建基模型来拟合残差，在博文<a href="http://blog.csdn.net/w28971023/article/details/8240756" target="_blank" rel="noopener">《GBDT（MART） 迭代决策树入门教程 | 简介》</a>中，作者举了一个生动的例子来说明通过基模型拟合残差，最终达到整体模型F(x)逼近真实值。</p>
<p>　　研究者发现，残差其实是最小均方损失函数的关于预测值的反向梯度：</p>
<p><img src="https://images2015.cnblogs.com/blog/927391/201607/927391-20160717152356576-837065946.png" alt="img"></p>
<p>　　也就是说，若F<a href="x">i-1</a>加上拟合了反向梯度的h<a href="x">i</a>得到F<a href="x">i</a>，该值可能将导致平方差损失函数降低，预测的准确度提高！这显然不是巧合，但是研究者们野心更大，希望能够创造出一种对任意损失函数都可行的训练方法，那么仅仅拟合残差是不恰当的了。</p>
<h2 id="4-2-拟合反向梯度"><a href="#4-2-拟合反向梯度" class="headerlink" title="4.2 拟合反向梯度"></a>4.2 拟合反向梯度</h2><h3 id="4-2-1-契机：引入任意损失函数"><a href="#4-2-1-契机：引入任意损失函数" class="headerlink" title="4.2.1 契机：引入任意损失函数"></a>4.2.1 契机：引入任意损失函数</h3><p>　　引入任意损失函数后，我们可以定义整体模型的迭代式如下：</p>
<p><img src="https://images2015.cnblogs.com/blog/927391/201607/927391-20160717155418592-692164582.png" alt="img"></p>
<p>　　在这里，损失函数被定义为<a href="https://zh.wikipedia.org/wiki/%E6%B3%9B%E5%87%BD" target="_blank" rel="noopener">泛函</a>。</p>
<h3 id="4-2-2-难题一：任意损失函数的最优化"><a href="#4-2-2-难题一：任意损失函数的最优化" class="headerlink" title="4.2.2 难题一：任意损失函数的最优化"></a>4.2.2 难题一：任意损失函数的最优化</h3><p>　　对任意损失函数（且是泛函）的最优化是困难的。我们需要打破思维的枷锁，将整体损失函数L’定义为n元普通函数（n为样本容量），损失函数L定义为2元普通函数（记住！！！这里的损失函数不再是泛函！！！）：</p>
<p><img src="https://images2015.cnblogs.com/blog/927391/201607/927391-20160717161734873-1080465986.png" alt="img"></p>
<p>　　我们不妨使用<a href="https://en.wikipedia.org/wiki/Method_of_steepest_descent" target="_blank" rel="noopener">梯度最速下降法</a>来解决整体损失函数L’最小化的问题，先求整体损失函数的反向梯度：</p>
<p><img src="https://images2015.cnblogs.com/blog/927391/201607/927391-20160717161743857-1762234391.png" alt="img"></p>
<p>　　假设已知样本x的当前预测值为F<a href="x">i-1</a>，下一步将预测值按照反向梯度，依照步长为r[i]，进行更新：</p>
<p><img src="https://images2015.cnblogs.com/blog/927391/201607/927391-20160717162353389-352979333.png" alt="img"></p>
<p>　　步长r[i]不是固定值，而是设计为：</p>
<p><img src="https://images2015.cnblogs.com/blog/927391/201607/927391-20160717162221748-1981866230.png" alt="img"></p>
<h3 id="4-2-3-难题二：无法对测试样本计算反向梯度"><a href="#4-2-3-难题二：无法对测试样本计算反向梯度" class="headerlink" title="4.2.3 难题二：无法对测试样本计算反向梯度"></a>4.2.3 难题二：无法对测试样本计算反向梯度</h3><p>　　问题又来了，由于测试样本中y是未知的，所以无法求反向梯度。这正是Gradient Boosting框架中的基模型闪亮登场的时刻！在第i轮迭代中，我们创建训练集如下：</p>
<p><img src="https://images2015.cnblogs.com/blog/927391/201607/927391-20160717162908686-1639692645.png" alt="img"></p>
<p>　　也就是说，让基模型拟合反向梯度函数，这样我们就可以做到只输入x这一个参数，就可求出其对应的反向梯度了（当然，通过基模型预测出来的反向梯度并不是准确的，这也提供了泛化整体模型的机会）。</p>
<p>　　综上，假设第i轮迭代中，根据新训练集训练出来的基模型为f<a href="x">i</a>，那么最终的迭代公式为：</p>
<p><img src="https://images2015.cnblogs.com/blog/927391/201607/927391-20160717171931342-64219972.png" alt="img"></p>
<h2 id="4-3-常见的损失函数"><a href="#4-3-常见的损失函数" class="headerlink" title="4.3 常见的损失函数"></a>4.3 常见的损失函数</h2><p>　　ls：最小均方回归中用到的损失函数。在之前我们已经谈到，从拟合残差的角度来说，残差即是该损失函数的反向梯度值（所以又称反向梯度为伪残差）。不同的是，从拟合残差的角度来说，步长是无意义的。该损失函数是sklearn中Gradient Tree Boosting回归模型默认的损失函数。</p>
<p>　　deviance：<a href="http://www.duzelong.com/wordpress/201507/archives1326/" target="_blank" rel="noopener">逻辑回归</a>中用到的损失函数。熟悉逻辑回归的读者肯定还记得，逻辑回归本质是求极大似然解，其认为样本服从几何分布，样本属于某类别的概率可以logistic函数表达。所以，如果该损失函数可用在多类别的分类问题上，故其是sklearn中Gradient Tree Boosting分类模型默认的损失函数。</p>
<p>　　exponential：指数损失函数，表达式为：</p>
<p><img src="https://images2015.cnblogs.com/blog/927391/201607/927391-20160717164817170-1319916901.png" alt="img"></p>
<p>　　对该损失函数求反向梯度得：</p>
<p><img src="https://images2015.cnblogs.com/blog/927391/201607/927391-20160717165216123-16910201.png" alt="img"></p>
<p>　　这时，在第i轮迭代中，新训练集如下：</p>
<p> <img src="https://images2015.cnblogs.com/blog/927391/201607/927391-20160717165246186-1781792701.png" alt="img"></p>
<p>　　脑袋里有什么东西浮出水面了吧？让我们看看<a href="http://breezedeus.github.io/2015/07/12/breezedeus-adaboost-exponential-loss.html" target="_blank" rel="noopener">Adaboost算法</a>中，第i轮迭代中第j个样本权值的更新公式：</p>
<p><img src="https://images2015.cnblogs.com/blog/927391/201607/927391-20160717170109811-1251363012.png" alt="img"></p>
<p>　　样本的权值什么时候会用到呢？计算第i轮损失函数的时候会用到：</p>
<p><img src="https://images2015.cnblogs.com/blog/927391/201607/927391-20160717170902529-315971230.png" alt="img"></p>
<p>　　让我们再回过头来，看看使用指数损失函数的Gradient Boosting计算第i轮损失函数：</p>
<p><img src="https://images2015.cnblogs.com/blog/927391/201607/927391-20160717171050389-2042221750.png" alt="img"></p>
<p>　　天呐，两个公式就差了一个对权值的归一项。这并不是巧合，当损失函数是指数损失时，Gradient Boosting相当于二分类的Adaboost算法。是的，指数损失仅能用于二分类的情况。</p>
<h2 id="4-4-步子太大容易扯着蛋：缩减"><a href="#4-4-步子太大容易扯着蛋：缩减" class="headerlink" title="4.4 步子太大容易扯着蛋：缩减"></a>4.4 步子太大容易扯着蛋：缩减</h2><p>　　缩减也是一个相对显见的概念，也就是说使用Gradient Boosting时，每次学习的步长缩减一点。这有什么好处呢？缩减思想认为每次走一小步，多走几次，更容易逼近真实值。如果步子迈大了，使用最速下降法时，容易迈过最优点。将缩减代入迭代公式：</p>
<p><img src="https://images2015.cnblogs.com/blog/927391/201607/927391-20160717172203889-897514111.png" alt="img"></p>
<p> 　　缩减需要配合基模型数一起使用，当缩减率v降低时，基模型数要配合增大，这样才能提高模型的准确度。</p>
<h2 id="4-5-初始模型"><a href="#4-5-初始模型" class="headerlink" title="4.5 初始模型"></a>4.5 初始模型</h2><p>　　还有一个不那么起眼的问题，初始模型F<a href="x">0</a>是什么呢？如果没有定义初始模型，整体模型的迭代式一刻都无法进行！所以，我们定义初始模型为：</p>
<p><img src="https://images2015.cnblogs.com/blog/927391/201607/927391-20160717172644920-1113326686.png" alt="img"></p>
<p>　　根据上式可知，对于不同的损失函数来说，初始模型也是不一样的。对所有的样本来说，根据初始模型预测出来的值都一样。</p>
<h2 id="4-5-Gradient-Tree-Boosting"><a href="#4-5-Gradient-Tree-Boosting" class="headerlink" title="4.5 Gradient Tree Boosting"></a>4.5 Gradient Tree Boosting</h2><p>　　终于到了备受欢迎的Gradient Tree Boosting模型了！但是，可讲的却已经不多了。我们已经知道了该模型的基模型是树模型，并且可以通过对特征的随机抽样进一步减少整体模型的方差。我们可以在维基百科的<a href="https://en.wikipedia.org/wiki/Gradient_boosting" target="_blank" rel="noopener">Gradient Boosting</a>词条中找到其伪代码实现。</p>
<h2 id="4-6-小结"><a href="#4-6-小结" class="headerlink" title="4.6 小结"></a>4.6 小结</h2><p>　　到此，读者应当很清楚Gradient Boosting中的损失函数有什么意义了。要说偏差描述了模型在训练集准确度，则损失函数则是描述该准确度的间接量纲。也就是说，模型采用不同的损失函数，其训练过程会朝着不同的方向进行！</p>
<hr>
<h1 id="5-总结"><a href="#5-总结" class="headerlink" title="5 总结"></a>5 总结</h1><p>　　磨刀不误砍柴功，我们花了这么多时间来学习必要的理论，我强调一次：必要的理论！集成学习模型的调参工作的核心就是找到合适的参数，能够使整体模型在训练集上的准确度和防止过拟合的能力达到协调，从而达到在样本总体上的最佳准确度。有了本文的理论知识铺垫，在下篇中，我们将对Random Forest和Gradient Tree Boosting中的每个参数进行详细阐述，同时也有一些小试验证明我们的结论。</p>
<hr>
<h1 id="6-参考资料"><a href="#6-参考资料" class="headerlink" title="6 参考资料"></a>6 参考资料</h1><ol>
<li><a href="http://cs.nju.edu.cn/zhouzh/zhouzh.files/publication/springerEBR09.pdf" target="_blank" rel="noopener">《</a><a href="http://cs.nju.edu.cn/zhouzh/zhouzh.files/publication/springerEBR09.pdf" target="_blank" rel="noopener">Ensemble Learning》</a></li>
<li><a href="http://scott.fortmann-roe.com/docs/BiasVariance.html" target="_blank" rel="noopener">《Understanding the Bias-Variance Tradeoff》</a></li>
<li><a href="https://www.zhihu.com/question/26760839" target="_blank" rel="noopener">《为什么说bagging是减少variance，而boosting是减少bias?》</a></li>
<li><a href="http://blog.csdn.net/w28971023/article/details/8240756" target="_blank" rel="noopener">《GBDT（MART） 迭代决策树入门教程 | 简介》</a></li>
<li><a href="https://zh.wikipedia.org/wiki/%E6%B3%9B%E5%87%BD" target="_blank" rel="noopener">泛函</a></li>
<li><a href="https://en.wikipedia.org/wiki/Method_of_steepest_descent" target="_blank" rel="noopener">梯度最速下降法</a></li>
<li><a href="http://www.duzelong.com/wordpress/201507/archives1326/" target="_blank" rel="noopener">《logistic regression(二分类、多分类)》</a></li>
<li><a href="http://breezedeus.github.io/2015/07/12/breezedeus-adaboost-exponential-loss.html" target="_blank" rel="noopener">《Adaboost与指数损失》</a></li>
</ol>
<h2 id="使用sklearn进行集成学习——实践"><a href="#使用sklearn进行集成学习——实践" class="headerlink" title="使用sklearn进行集成学习——实践"></a><a href="https://www.cnblogs.com/jasonfreak/p/5720137.html" target="_blank" rel="noopener">使用sklearn进行集成学习——实践</a></h2><h1 id="目录"><a href="#目录" class="headerlink" title="目录"></a>目录</h1><p>1 Random Forest和Gradient Tree Boosting参数详解<br>2 如何调参？<br>　　2.1 调参的目标：偏差和方差的协调<br>　　2.2 参数对整体模型性能的影响<br>　　2.3 一个朴实的方案：贪心的坐标下降法<br>　　　　2.3.1 Random Forest调参案例：Digit Recognizer<br>　　　　　　2.3.1.1 调整过程影响类参数<br>　　　　　　2.3.1.2 调整子模型影响类参数<br>　　　　2.3.2 Gradient Tree Boosting调参案例：Hackathon3.x<br>　　　　　　2.3.2.1 调整过程影响类参数<br>　　　　　　2.3.2.2 调整子模型影响类参数<br>　　　　　　2.3.2.3 杀一记回马枪<br>　　2.4 “局部最优解”（温馨提示：看到这里有彩蛋！）<br>　　2.5 类别不均衡的陷阱<br>3 总结<br>4 参考资料</p>
<hr>
<h1 id="1-Random-Forest和Gradient-Tree-Boosting参数详解"><a href="#1-Random-Forest和Gradient-Tree-Boosting参数详解" class="headerlink" title="1 Random Forest和Gradient Tree Boosting参数详解"></a>1 Random Forest和Gradient Tree Boosting参数详解</h1><p>　　在sklearn.ensemble库中，我们可以找到Random Forest分类和回归的实现：RandomForestClassifier和RandomForestRegression，Gradient Tree Boosting分类和回归的实现：GradientBoostingClassifier和GradientBoostingRegression。有了这些模型后，立马上手操练起来？少侠请留步！且听我说一说，使用这些模型时常遇到的问题：</p>
<ul>
<li>明明模型调教得很好了，可是效果离我的想象总有些偏差？——模型训练的第一步就是要定好目标，往错误的方向走太多也是后退。</li>
<li>凭直觉调了某个参数，可是居然没有任何作用，有时甚至起到反作用？——定好目标后，接下来就是要确定哪些参数是影响目标的，其对目标是正影响还是负影响，影响的大小。</li>
<li>感觉训练结束遥遥无期，sklearn只是个在小数据上的玩具？——虽然sklearn并不是基于分布式计算环境而设计的，但我们还是可以通过某些策略提高训练的效率。</li>
<li>模型开始训练了，但是训练到哪一步了呢？——饱暖思淫欲啊，目标，性能和效率都得了满足后，我们有时还需要有别的追求，例如训练过程的输出，袋外得分计算等等。</li>
</ul>
<p>　　通过总结这些常见的问题，我们可以把模型的参数分为4类：目标类、性能类、效率类和附加类。下表详细地展示了4个模型参数的意义：</p>
<div class="table-container">
<table>
<thead>
<tr>
<th><strong>参数</strong></th>
<th><strong>类型</strong></th>
<th><strong>RandomForestClassifier</strong></th>
<th><strong>RandomForestRegressor</strong></th>
<th><strong>GradientBoostingClassifier</strong></th>
<th><strong>GradientBoostingRegressor</strong></th>
</tr>
</thead>
<tbody>
<tr>
<td>loss</td>
<td>目标</td>
<td></td>
<td></td>
<td>损失函数● exponential：模型等同AdaBoost★ deviance：和Logistic Regression的损失函数一致</td>
<td>损失函数● exponential：模型等同AdaBoost★ deviance：和Logistic Regression的损失函数一致</td>
</tr>
<tr>
<td>alpha</td>
<td>目标</td>
<td></td>
<td></td>
<td>损失函数为huber或quantile的时，alpha为损失函数中的参数</td>
<td>损失函数为huber或quantile的时，alpha为损失函数中的参数</td>
</tr>
<tr>
<td>class_weight</td>
<td>目标</td>
<td>类别的权值</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>n_estimators</td>
<td>性能</td>
<td>子模型的数量● int：个数★ 10：默认值</td>
<td>子模型的数量● int：个数★ 10：默认值</td>
<td>子模型的数量● int：个数★ 100：默认值</td>
<td>子模型的数量● int：个数★ 100：默认值</td>
</tr>
<tr>
<td>learning_rate</td>
<td>性能</td>
<td></td>
<td></td>
<td>学习率（缩减）</td>
<td>学习率（缩减）</td>
</tr>
<tr>
<td>criterion</td>
<td>性能</td>
<td>判断节点是否继续分裂采用的计算方法● entropy★ gini</td>
<td>判断节点是否继续分裂采用的计算方法★ mse</td>
<td></td>
<td></td>
</tr>
<tr>
<td>max_features</td>
<td>性能</td>
<td>节点分裂时参与判断的最大特征数● int：个数● float：占所有特征的百分比★ auto：所有特征数的开方● sqrt：所有特征数的开方● log2：所有特征数的log2值● None：等于所有特征数</td>
<td>节点分裂时参与判断的最大特征数● int：个数● float：占所有特征的百分比★ auto：所有特征数的开方● sqrt：所有特征数的开方● log2：所有特征数的log2值● None：等于所有特征数</td>
<td>节点分裂时参与判断的最大特征数● int：个数● float：占所有特征的百分比● auto：所有特征数的开方● sqrt：所有特征数的开方● log2：所有特征数的log2值★ None：等于所有特征数</td>
<td>节点分裂时参与判断的最大特征数● int：个数● float：占所有特征的百分比● auto：所有特征数的开方● sqrt：所有特征数的开方● log2：所有特征数的log2值★ None：等于所有特征数</td>
</tr>
<tr>
<td>max_depth</td>
<td>性能</td>
<td>最大深度，如果max_leaf_nodes参数指定，则忽略● int：深度★ None：树会生长到所有叶子都分到一个类，或者某节点所代表的样本数已小于min_samples_split</td>
<td>最大深度，如果max_leaf_nodes参数指定，则忽略● int：深度★ None：树会生长到所有叶子都分到一个类，或者某节点所代表的样本数已小于min_samples_split</td>
<td>最大深度，如果max_leaf_nodes参数指定，则忽略● int：深度★ 3：默认值</td>
<td>最大深度，如果max_leaf_nodes参数指定，则忽略● int：深度★ 3：默认值</td>
</tr>
<tr>
<td>min_samples_split</td>
<td>性能</td>
<td>分裂所需的最小样本数● int：样本数★ 2：默认值</td>
<td>分裂所需的最小样本数● int：样本数★ 2：默认值</td>
<td>分裂所需的最小样本数● int：样本数★ 2：默认值</td>
<td>分裂所需的最小样本数● int：样本数★ 2：默认值</td>
</tr>
<tr>
<td>min_samples_leaf</td>
<td>性能</td>
<td>叶节点最小样本数● int：样本数★ 1：默认值</td>
<td>叶节点最小样本数● int：样本数★ 1：默认值</td>
<td>叶节点最小样本数● int：样本数★ 1：默认值</td>
<td>叶节点最小样本数● int：样本数★ 1：默认值</td>
</tr>
<tr>
<td>min_weight_fraction_leaf</td>
<td>性能</td>
<td>叶节点最小样本权重总值● float：权重总值★ 0：默认值</td>
<td>叶节点最小样本权重总值● float：权重总值★ 0：默认值</td>
<td>叶节点最小样本权重总值● float：权重总值★ 0：默认值</td>
<td>叶节点最小样本权重总值● float：权重总值★ 0：默认值</td>
</tr>
<tr>
<td>max_leaf_nodes</td>
<td>性能</td>
<td>最大叶节点数● int：个数★ None：不限制叶节点数</td>
<td>最大叶节点数● int：个数★ None：不限制叶节点数</td>
<td>最大叶节点数● int：个数★ None：不限制叶节点数</td>
<td>最大叶节点数● int：个数★ None：不限制叶节点数</td>
</tr>
<tr>
<td>bootstrap</td>
<td>性能</td>
<td>是否bootstrap对样本抽样● False：子模型的样本一致，子模型间强相关★ True：默认值</td>
<td>是否bootstrap对样本抽样● False：子模型的样本一致，子模型间强相关★ True：默认值</td>
<td></td>
<td></td>
</tr>
<tr>
<td>subsample</td>
<td>性能</td>
<td></td>
<td></td>
<td>子采样率● float：采样率★ 1.0：默认值</td>
<td>子采样率● float：采样率★ 1.0：默认值</td>
</tr>
<tr>
<td>init</td>
<td>性能</td>
<td></td>
<td></td>
<td>初始子模型</td>
<td>初始子模型</td>
</tr>
<tr>
<td>n_jobs</td>
<td>效率</td>
<td>并行数● int：个数● -1：跟CPU核数一致★ 1:默认值</td>
<td>并行数● int：个数● -1：跟CPU核数一致★ 1:默认值</td>
<td></td>
<td></td>
</tr>
<tr>
<td>warm_start</td>
<td>效率</td>
<td>是否热启动，如果是，则下一次训练是以追加树的形式进行● bool：热启动★ False：默认值</td>
<td>是否热启动，如果是，则下一次训练是以追加树的形式进行● bool：热启动★ False：默认值</td>
<td>是否热启动，如果是，则下一次训练是以追加树的形式进行● bool：热启动★ False：默认值</td>
<td>是否热启动，如果是，则下一次训练是以追加树的形式进行● bool：热启动★ False：默认值</td>
</tr>
<tr>
<td>presort</td>
<td>效率</td>
<td></td>
<td></td>
<td>是否预排序,预排序可以加速查找最佳分裂点，对于稀疏数据不管用● Bool★ auto：非稀疏数据则预排序，若稀疏数据则不预排序</td>
<td>是否预排序,预排序可以加速查找最佳分裂点，对于稀疏数据不管用● Bool★ auto：非稀疏数据则预排序，若稀疏数据则不预排序</td>
</tr>
<tr>
<td>oob_score</td>
<td>附加</td>
<td>是否计算<a href="http://scikit-learn.org/stable/auto_examples/ensemble/plot_ensemble_oob.html" target="_blank" rel="noopener">袋外得分</a>★ False：默认值</td>
<td>是否计算<a href="http://scikit-learn.org/stable/auto_examples/ensemble/plot_ensemble_oob.html" target="_blank" rel="noopener">袋外得分</a>★ False：默认值</td>
<td></td>
<td></td>
</tr>
<tr>
<td>random_state</td>
<td>附加</td>
<td>随机器对象</td>
<td>随机器对象</td>
<td>随机器对象</td>
<td>随机器对象</td>
</tr>
<tr>
<td>verbose</td>
<td>附加</td>
<td>日志冗长度● int：冗长度★ 0：不输出训练过程● 1：偶尔输出● &gt;1：对每个子模型都输出</td>
<td>日志冗长度● int：冗长度★ 0：不输出训练过程● 1：偶尔输出● &gt;1：对每个子模型都输出</td>
<td>日志冗长度● int：冗长度★ 0：不输出训练过程● 1：偶尔输出● &gt;1：对每个子模型都输出</td>
<td>日志冗长度● int：冗长度★ 0：不输出训练过程● 1：偶尔输出● &gt;1：对每个子模型都输出</td>
</tr>
</tbody>
</table>
</div>
<p><em># ★：默认值</em></p>
<p>　　不难发现，基于bagging的Random Forest模型和基于boosting的Gradient Tree Boosting模型有不少共同的参数，然而某些参数的默认值又相差甚远。在<a href="http://www.cnblogs.com/jasonfreak/p/5657196.html" target="_blank" rel="noopener">《使用sklearn进行集成学习——理论》</a>一文中，我们对bagging和boosting两种集成学习技术有了初步的了解。Random Forest的子模型都拥有较低的偏差，整体模型的训练过程旨在降低方差，故其需要较少的子模型（n_estimators默认值为10）且子模型不为弱模型（max_depth的默认值为None），同时，降低子模型间的相关度可以起到减少整体模型的方差的效果（max_features的默认值为auto）。另一方面，Gradient Tree Boosting的子模型都拥有较低的方差，整体模型的训练过程旨在降低偏差，故其需要较多的子模型（n_estimators默认值为100）且子模型为弱模型（max_depth的默认值为3），但是降低子模型间的相关度不能显著减少整体模型的方差（max_features的默认值为None）。</p>
<hr>
<h1 id="2-如何调参？"><a href="#2-如何调参？" class="headerlink" title="2 如何调参？"></a>2 如何调参？</h1><p>　　聪明的读者应当要发问了：”博主，就算你列出来每个参数的意义，然并卵啊！我还是不知道无从下手啊！”</p>
<p>　　参数分类的目的在于缩小调参的范围，首先我们要明确训练的目标，把目标类的参数定下来。接下来，我们需要根据数据集的大小，考虑是否采用一些提高训练效率的策略，否则一次训练就三天三夜，法国人孩子都生出来了。然后，我们终于进入到了重中之重的环节：调整那些影响整体模型性能的参数。</p>
<h2 id="2-1-调参的目标：偏差和方差的协调"><a href="#2-1-调参的目标：偏差和方差的协调" class="headerlink" title="2.1 调参的目标：偏差和方差的协调"></a>2.1 调参的目标：偏差和方差的协调</h2><p>　　同样在<a href="http://www.cnblogs.com/jasonfreak/p/5657196.html" target="_blank" rel="noopener">《使用sklearn进行集成学习——理论》</a>中，我们已讨论过偏差和方差是怎样影响着模型的性能——准确度。调参的目标就是为了达到整体模型的偏差和方差的大和谐！进一步，这些参数又可分为两类：过程影响类及子模型影响类。在子模型不变的前提下，某些参数可以通过改变训练的过程，从而影响模型的性能，诸如：“子模型数”（n_estimators）、“学习率”（learning_rate）等。另外，我们还可以通过改变子模型性能来影响整体模型的性能，诸如：“最大树深度”（max_depth）、“分裂条件”（criterion）等。正由于bagging的训练过程旨在降低方差，而boosting的训练过程旨在降低偏差，过程影响类的参数能够引起整体模型性能的大幅度变化。一般来说，在此前提下，我们继续微调子模型影响类的参数，从而进一步提高模型的性能。</p>
<h2 id="2-2-参数对整体模型性能的影响"><a href="#2-2-参数对整体模型性能的影响" class="headerlink" title="2.2 参数对整体模型性能的影响"></a>2.2 参数对整体模型性能的影响</h2><p>　　假设模型是一个多元函数F，其输出值为模型的准确度。我们可以固定其他参数，从而对某个参数对整体模型性能的影响进行分析：是正影响还是负影响，影响的单调性？</p>
<p>　　对Random Forest来说，增加“子模型数”（n_estimators）可以明显降低整体模型的方差，且不会对子模型的偏差和方差有任何影响。模型的准确度会随着“子模型数”的增加而提高。由于减少的是整体模型方差公式的第二项，故准确度的提高有一个上限。在不同的场景下，“分裂条件”（criterion）对模型的准确度的影响也不一样，该参数需要在实际运用时灵活调整。调整“最大叶节点数”（max_leaf_nodes）以及“最大树深度”（max_depth）之一，可以粗粒度地调整树的结构：叶节点越多或者树越深，意味着子模型的偏差越低，方差越高；同时，调整“分裂所需最小样本数”（min_samples_split）、“叶节点最小样本数”（min_samples_leaf）及“叶节点最小权重总值”（min_weight_fraction_leaf），可以更细粒度地调整树的结构：分裂所需样本数越少或者叶节点所需样本越少，也意味着子模型越复杂。一般来说，我们总采用bootstrap对样本进行子采样来降低子模型之间的关联度，从而降低整体模型的方差。适当地减少“分裂时考虑的最大特征数”（max_features），给子模型注入了另外的随机性，同样也达到了降低子模型之间关联度的效果。但是一味地降低该参数也是不行的，因为分裂时可选特征变少，模型的偏差会越来越大。在下图中，我们可以看到这些参数对Random Forest整体模型性能的影响：</p>
<p><img src="http://images2015.cnblogs.com/blog/927391/201607/927391-20160731184710919-487730249.jpg" alt="img"></p>
<p>　　对Gradient Tree Boosting来说，“子模型数”（n_estimators）和“学习率”（learning_rate）需要联合调整才能尽可能地提高模型的准确度：想象一下，A方案是走4步，每步走3米，B方案是走5步，每步走2米，哪个方案可以更接近10米远的终点？同理，子模型越复杂，对应整体模型偏差低，方差高，故“最大叶节点数”（max_leaf_nodes）、“最大树深度”（max_depth）等控制子模型结构的参数是与Random Forest一致的。类似“分裂时考虑的最大特征数”（max_features），降低“子采样率”（subsample），也会造成子模型间的关联度降低，整体模型的方差减小，但是当子采样率低到一定程度时，子模型的偏差增大，将引起整体模型的准确度降低。还记得“初始模型”（init）是什么吗？不同的损失函数有不一样的初始模型定义，通常，初始模型是一个更加弱的模型（以“平均”情况来预测），虽说支持自定义，大多数情况下保持默认即可。在下图中，我们可以看到这些参数对Gradient Tree Boosting整体模型性能的影响：</p>
<p><img src="http://images2015.cnblogs.com/blog/927391/201607/927391-20160731184748841-69767136.jpg" alt="img"></p>
<h2 id="2-3-一个朴实的方案：贪心的坐标下降法"><a href="#2-3-一个朴实的方案：贪心的坐标下降法" class="headerlink" title="2.3 一个朴实的方案：贪心的坐标下降法"></a>2.3 一个朴实的方案：贪心的坐标下降法</h2><p>　　到此为止，我们终于知道需要调整哪些参数，对于单个参数，我们也知道怎么调整才能提升性能。然而，表示模型的函数F并不是一元函数，这些参数需要共同调整才能得到全局最优解。也就是说，把这些参数丢给调参算法（诸如Grid Search）咯？对于小数据集，我们还能这么任性，但是参数组合爆炸，在大数据集上，或许我的子子孙孙能够看到训练结果吧。实际上网格搜索也不一定能得到全局最优解，而另一些研究者从解优化问题的角度尝试解决调参问题。</p>
<p>　　<a href="https://zh.wikipedia.org/wiki/%E5%9D%90%E6%A0%87%E4%B8%8B%E9%99%8D%E6%B3%95" target="_blank" rel="noopener">坐标下降法</a>是一类优化算法，其最大的优势在于不用计算待优化的目标函数的梯度。我们最容易想到一种特别朴实的类似于坐标下降法的方法，与坐标下降法不同的是，其不是循环使用各个参数进行调整，而是贪心地选取了对整体模型性能影响最大的参数。参数对整体模型性能的影响力是动态变化的，故每一轮坐标选取的过程中，这种方法在对每个坐标的下降方向进行一次直线搜索（line search）。首先，找到那些能够提升整体模型性能的参数，其次确保提升是单调或近似单调的。这意味着，我们筛选出来的参数是对整体模型性能有正影响的，且这种影响不是偶然性的，要知道，训练过程的随机性也会导致整体模型性能的细微区别，而这种区别是不具有单调性的。最后，在这些筛选出来的参数中，选取影响最大的参数进行调整即可。</p>
<p>　　无法对整体模型性能进行量化，也就谈不上去比较参数影响整体模型性能的程度。是的，我们还没有一个准确的方法来量化整体模型性能，只能通过交叉验证来近似计算整体模型性能。然而交叉验证也存在随机性，假设我们以验证集上的平均准确度作为整体模型的准确度，我们还得关心在各个验证集上准确度的变异系数，如果变异系数过大，则平均值作为整体模型的准确度也是不合适的。在接下来的案例分析中，我们所谈及的整体模型性能均是指平均准确度，请各位留心。</p>
<h3 id="2-3-1-Random-Forest调参案例：Digit-Recognizer"><a href="#2-3-1-Random-Forest调参案例：Digit-Recognizer" class="headerlink" title="2.3.1 Random Forest调参案例：Digit Recognizer"></a>2.3.1 Random Forest调参案例：Digit Recognizer</h3><p>　　在这里，我们选取Kaggle上101教学赛中的<a href="https://www.kaggle.com/c/digit-recognizer" target="_blank" rel="noopener">Digit Recognizer</a>作为案例来演示对RandomForestClassifier调参的过程。当然，我们也不要傻乎乎地手工去设定不同的参数，然后训练模型。借助sklearn.grid_search库中的GridSearchCV类，不仅可以自动化调参，同时还可以对每一种参数组合进行交叉验证计算平均准确度。</p>
<h4 id="2-3-1-1-调整过程影响类参数"><a href="#2-3-1-1-调整过程影响类参数" class="headerlink" title="2.3.1.1 调整过程影响类参数"></a>2.3.1.1 调整过程影响类参数</h4><p>　　首先，我们需要对过程影响类参数进行调整，而Random Forest的过程影响类参数只有“子模型数”（n_estimators）。“子模型数”的默认值为10，在此基础上，我们以10为单位，考察取值范围在1至201的调参情况：</p>
<p><img src="http://images2015.cnblogs.com/blog/927391/201607/927391-20160730162932106-838038825.png" alt="img"></p>
<p><em># 左图为模型在验证集上的平均准确度，右图为准确度的变异系数。横轴为参数的取值。</em></p>
<p>　　通过上图我们可以看到，随着“子模型数”的增加，整体模型的方差减少，其防止过拟合的能力增强，故整体模型的准确度提高。当“子模型数”增加到40以上时，准确度的提升逐渐不明显。考虑到训练的效率，最终我们选择“子模型数”为200。此时，在Kaggle上提交结果，得分为：0.96500，很凑合。</p>
<h4 id="2-3-1-2-调整子模型影响类参数"><a href="#2-3-1-2-调整子模型影响类参数" class="headerlink" title="2.3.1.2 调整子模型影响类参数"></a>2.3.1.2 调整子模型影响类参数</h4><p>　　在设定“子模型数”（n_estimators）为200的前提下，我们依次对子模型影响类的参数对整体模型性能的影响力进行分析。</p>
<p>　　对“分裂条件”（criterion）分别取值gini和entropy，得到调参结果如下：</p>
<p><img src="http://images2015.cnblogs.com/blog/927391/201607/927391-20160730165700763-1666232416.png" alt="img"></p>
<p>　　显见，在此问题中，“分裂条件”保持默认值gini更加合适。</p>
<p>　　对“分裂时参与判断的最大特征数”（max_feature）以1为单位，设定取值范围为28至47，得到调参结果如下：</p>
<p><img src="http://images2015.cnblogs.com/blog/927391/201607/927391-20160730170223903-942174073.png" alt="img"></p>
<p>　　</p>
<p>　　“分裂时参与判断的最大特征数”的默认值auto，即总特征数（sqrt(784)=28）的开方。通过提升该参数，整体模型的准确度得到了提升。可见，该参数的默认值过小，导致了子模型的偏差过大，从而整体模型的偏差过大。同时，我们还注意到，该参数对整体模型性能的影响是近似单调的：从28到38，模型的准确度逐步抖动提升。所以，我们可考虑将该参数纳入下一步的调参工作。</p>
<p>　　对“最大深度”（max_depth）以10为单位，设定取值范围为10到100，得到调参结果如下：</p>
<p><img src="http://images2015.cnblogs.com/blog/927391/201607/927391-20160730171248153-89195782.png" alt="img"></p>
<p>　　随着树的深度加深，子模型的偏差减少，整体模型的准确度得到提升。从理论上来说，子模型训练的后期，随着方差增大，子模型的准确度稍微降低，从而影响整体模型的准确度降低。看图中，似乎取值范围从40到60的情况可以印证这一观点。不妨以1为单位，设定取值范围为40到59，更加细致地分析：</p>
<p><img src="http://images2015.cnblogs.com/blog/927391/201607/927391-20160730171849434-652571651.png" alt="img"></p>
<p>　　有点傻眼了，怎么跟预想的不太一样？为什么模型准确度的变化在40到59之间没有鲜明的“规律”了？要分析这个问题，我们得先思考一下，少一层子节点对子模型意味着什么？若少的那一层给原子模型带来的是方差增大，则新子模型会准确度提高；若少的那一层给原子模型带来的是偏差减小，则新子模型会准确度降低。所以，细粒度的层次变化既可能使整体模型的准确度提升，也可能使整体模型的准确度降低。从而也说明了，该参数更适合进行粗粒度的调整。在训练的现阶段，“抖动”现象的发生说明，此时对该参数的调整已不太合适了。</p>
<p>　　对“分裂所需的最小样本数”（min_samples_split）以1为单位，设定取值范围为2到11，得到调参的结果：</p>
<p><img src="http://images2015.cnblogs.com/blog/927391/201607/927391-20160730173505919-181940029.png" alt="img"></p>
<p>　　我们看到，随着分裂所需的最小样本数的增加，子模型的结构变得越来越简单，理论上来说，首先应当因方差减小导致整体模型的准确度提升。但是，在训练的现阶段，子模型的偏差增大的幅度比方差减小的幅度更大，所以整体模型的准确度持续下降。该参数的默认值为2，调参后，最优解保持2不变。</p>
<p>　　对“叶节点最小样本数”（min_samples_leaf）以1为单位，设定取值范围为1到10，得到调参结果如下：</p>
<p><img src="http://images2015.cnblogs.com/blog/927391/201607/927391-20160730174140309-373143237.png" alt="img"></p>
<p>　　同“分裂所需的最小样本数”，该参数也在调参后，保持最优解1不变。</p>
<p>　　对“最大叶节点数”（max_leaf_nodes）以100为单位，设定取值范围为2500到3400，得到调参结果如下：</p>
<p><img src="http://images2015.cnblogs.com/blog/927391/201607/927391-20160730174432372-770058569.png" alt="img"></p>
<p>　　类似于“最大深度”，该参数的增大会带来模型准确的提升，可是由于后期“不规律”的抖动，我们暂时不进行处理。</p>
<p>　　通过对以上参数的调参情况，我们可以总结如下：</p>
<div class="table-container">
<table>
<thead>
<tr>
<th>参数</th>
<th>默认值准确度</th>
<th>调整后最佳准确度</th>
<th>提升幅度</th>
</tr>
</thead>
<tbody>
<tr>
<td>分裂条件（criterion）</td>
<td>0.964023809524</td>
<td>0.964023809524</td>
<td>0</td>
</tr>
<tr>
<td>分裂时参与判断的最大特征数（max_feature）</td>
<td>0.963380952381</td>
<td>0.964428571429</td>
<td>0.00104762</td>
</tr>
<tr>
<td>最大深度（max_depth）</td>
<td></td>
<td></td>
<td>抖动</td>
</tr>
<tr>
<td>分裂所需的最小样本数（min_samples_split）</td>
<td>0.963976190476</td>
<td>0.963976190476</td>
<td>0</td>
</tr>
<tr>
<td>叶节点最小样本数（min_samples_leaf）</td>
<td>0.963595238095</td>
<td>0.963595238095</td>
<td>0</td>
</tr>
<tr>
<td>最大叶节点数（max_leaf_nodes）</td>
<td></td>
<td></td>
<td>抖动</td>
</tr>
</tbody>
</table>
</div>
<p>　　接下来，我们固定分裂时参与判断的最大特征（max_features）为38，在Kaggle上提交一次结果：0.96671，比上一次调参好了0.00171，基本与我们预期的提升效果一致。</p>
<p>　　还需要继续下一轮坐标下降式调参吗？一般来说没有太大的必要，在本轮中出现了两个发生抖动现象的参数，而其他参数的调整均没有提升整体模型的性能。还是得老调重弹：数据和特征决定了机器学习的上限，而模型和算法只是逼近这个上限而已。在DR竞赛中，与其期待通过对RandomForestClassifier调参来进一步提升整体模型的性能，不如挖掘出更有价值的特征，或者使用自带特征挖掘技能的模型（正如此题，图分类的问题更适合用神经网络来学习）。但是，在这里，我们还是可以自信地说，通过贪心的坐标下降法，比那些用网格搜索法穷举所有参数组合，自以为得到最优解的朋友们更进了一步。</p>
<h3 id="2-3-2-Gradient-Tree-Boosting调参案例：Hackathon3-x"><a href="#2-3-2-Gradient-Tree-Boosting调参案例：Hackathon3-x" class="headerlink" title="2.3.2 Gradient Tree Boosting调参案例：Hackathon3.x"></a>2.3.2 Gradient Tree Boosting调参案例：Hackathon3.x</h3><p>　　在这里，我们选取Analytics Vidhya上的<a href="https://datahack.analyticsvidhya.com/contest/data-hackathon-3x/" target="_blank" rel="noopener">Hackathon3.x</a>作为案例来演示对GradientBoostingClassifier调参的过程。</p>
<h4 id="2-3-2-1-调整过程影响类参数"><a href="#2-3-2-1-调整过程影响类参数" class="headerlink" title="2.3.2.1 调整过程影响类参数"></a>2.3.2.1 调整过程影响类参数</h4><p>　　GradientBoostingClassifier的过程影响类参数有“子模型数”（n_estimators）和“学习率”（learning_rate），我们可以使用GridSearchCV找到关于这两个参数的最优解。慢着！这里留了一个很大的陷阱：“子模型数”和“学习率”带来的性能提升是不均衡的，在前期会比较高，在后期会比较低，如果一开始我们将这两个参数调成最优，这样很容易陷入一个“局部最优解”。在目标函数都不确定的情况下（如是否凸？），谈局部最优解就是耍流氓，本文中“局部最优解”指的是调整各参数都无明显性能提升的一种状态，所以打了引号。下图中展示了这个两个参数的调参结果：</p>
<p><img src="http://images2015.cnblogs.com/blog/927391/201607/927391-20160731161516950-670327363.png" alt="img"></p>
<p><em># 图中颜色越深表示整体模型的性能越高</em></p>
<p>　　在此，我们先直觉地选择“子模型数”为60，“学习率”为0.1，此时的整体模型性能（平均准确度为0.8253）不是最好，但是也不差，良好水准。</p>
<h4 id="2-3-2-2-调整子模型影响类参数"><a href="#2-3-2-2-调整子模型影响类参数" class="headerlink" title="2.3.2.2 调整子模型影响类参数"></a>2.3.2.2 调整子模型影响类参数</h4><p>　　对子模型影响类参数的调整与Random Forest类似。最终我们对参数的调整如下：</p>
<div class="table-container">
<table>
<thead>
<tr>
<th>子模型数n_estimators</th>
<th>学习率learning_rate</th>
<th>叶节点最小样本数min_samples_leaf</th>
<th>最大深度max_depth</th>
<th>子采样率subsample</th>
<th>分裂时参与判断的最大特征数max_feature</th>
</tr>
</thead>
<tbody>
<tr>
<td>60</td>
<td>0.1</td>
<td>12</td>
<td>4</td>
<td>0.77</td>
<td>10</td>
</tr>
</tbody>
</table>
</div>
<p>　　到此，整体模型性能为0.8313，与workbench（0.8253）相比，提升了约0.006。</p>
<h4 id="2-3-2-3-杀一记回马枪"><a href="#2-3-2-3-杀一记回马枪" class="headerlink" title="2.3.2.3 杀一记回马枪"></a>2.3.2.3 杀一记回马枪</h4><p>　　还记得一开始我们对“子模型数”（n_estimators）和“学习率”（learning_rate）手下留情了吗？现在我们可以回过头来，调整这两个参数，调整的方法为成倍地放大“子模型数”，对应成倍地缩小“学习率”（learning_rate）。通过该方法，本例中整体模型性能又提升了约0.002。</p>
<h2 id="2-4-“局部最优解”"><a href="#2-4-“局部最优解”" class="headerlink" title="2.4 “局部最优解”"></a>2.4 “局部最优解”</h2><p>　　目前来说，在调参工作中，广泛使用的仍是一些经验法则。<a href="https://www.analyticsvidhya.com/blog/author/aarshay/" target="_blank" rel="noopener">Aarshay Jain</a>对Gradient Tree Boosting总结了一套<a href="https://www.analyticsvidhya.com/blog/2016/02/complete-guide-parameter-tuning-gradient-boosting-gbm-python/" target="_blank" rel="noopener">调参方法</a>，其核心思想在于：对过程影响类参数进行调整，毕竟它们对整体模型性能的影响最大，然后依据经验，在其他参数中选择对整体模型性能影响最大的参数，进行下一步调参。这种方法的关键是依照对整体模型性能的影响力给参数排序，然后按照该顺序对的参数进行调整。如何衡量参数对整体模型性能的影响力呢？基于经验，Aarshay提出他的见解：“最大叶节点数”（max_leaf_nodes）和“最大树深度”（max_depth）对整体模型性能的影响大于“分裂所需最小样本数”（min_samples_split）、“叶节点最小样本数”（min_samples_leaf）及“叶节点最小权重总值”（min_weight_fraction_leaf），而“分裂时考虑的最大特征数”（max_features）的影响力最小。</p>
<p>　　Aarshay提出的方法和贪心的坐标下降法最大的区别在于前者在调参之前就依照对整体模型性能的影响力给参数排序，而后者是一种“很自然”的贪心过程。还记得2.3.2.1小节中我们讨论过“子模型数”（n_estimators）和“学习率”（learning_rate）的调参问题吗？同理，贪心的坐标下降法容易陷入“局部最优解”。对Random Forest调参时会稍微好一点，因为当“子模型数”调到最佳状态时，有时就只剩下诸如““分裂时参与判断的最大特征数”等Aarshay认为影响力最小的参数可调了。但是，对Gradient Tree Boosting调参时，遇到“局部最优解”的可能性就大得多。</p>
<p>　　Aarshay同样对Hackathon3.x进行了调参试验，由于特征提取方式的差异，参数赋值相同的情况下，本文的整体模型性能仍与其相差0.007左右（唉，不得不再说一次，特征工程真的很重要）。首先，在过程影响类参数的选择上，Aarshay的方法与贪心的坐标下降法均选择了“子模型数”为60，“学习率”为0.1。接下来，Aarshay按照其定义的参数对整体模型性能的影响力，按序依次对参数进行调整。当子模型影响类参数确定完成后，Aarshay的方法提升了约0.008的整体模型性能，略胜于贪心的坐标下降法的0.006。但是，回过头来继续调试“子模型数”和“学习率”之后，Aarshay的方法又提升了约0.01的整体模型性能，远胜于贪心的坐标下降法的0.002。</p>
<p>　　诶！诶！诶！少侠请住手！你说我为什么要在这篇博文中介绍这种“无用”的贪心的坐标下降法？首先，这种方法很容易凭直觉就想到。人们往往花了很多的时间去搞懂模型的参数是什么含义，对整体模型性能有什么影响，搞懂这些已经不易了，所以接下来很多人选择了最直观的贪心的坐标下降法。通过一个实例，我们更容易记住这种方法的局限性。除了作为反面教材，贪心的坐标下降法就没有意义了吗？不难看到，Aarshay的方法仍有改进的地方，在依次对参数进行调整时，还是需要像贪心的坐标下降法中一样对参数的“动态”影响力进行分析一下，如果这种影响力是“抖动”的，可有可无的，那么我们就不需要对该参数进行调整。</p>
<h2 id="2-5-类别不均衡的陷阱"><a href="#2-5-类别不均衡的陷阱" class="headerlink" title="2.5 类别不均衡的陷阱"></a>2.5 类别不均衡的陷阱</h2><p>　　哈哈哈，这篇博文再次留了个陷阱，此段文字并不是跟全文一起发布！有人要说了，按照我的描述，Aarshay的调参试验不可再现啊！其实，我故意没说Aarshay的另一个关键处理：调参前的参数初始值。因为Hackathon3.x是一个类别不均衡的问题，所以如果直接先调试“最大深度”（max_depth），会发现其会保持默认值3作为最优解，而后面的调参中，“分裂所需最小样本数”（min_samples_split）、“叶节点最小样本数”（min_samples_leaf）再怎么调都没有很大作用。这是因为，正例样本远远小于反例，所以在低深度时，子模型就可能已经对正例过拟合了。所以，在类别不均衡时，只有先确定“叶节点最小样本数”（min_samples_leaf），再确定“分裂所需最小样本数”（min_samples_split），才能确定“最大深度”。而Aarshay设定的初始值，则以经验和直觉避开了这个险恶的陷阱。</p>
<p>　　如果实在觉得经验和直觉不靠谱，我还尝试了一种策略：首先，我们需要初步地调一次“子采样率”（subsample）和“分裂时考虑的最大特征数”（max_features），在此基础上依次调好“叶节点最小样本数”（min_samples_leaf）、“分裂所需最小样本数”（min_samples_split）以及“最大深度”（max_depth）。然后，按照Aarshay的方法，按影响力从大到小再调一次。通过这种方法，整体模型性能在未等比缩放过程影响类参数前，已达到约0.8352左右，比workbench相比，提升了约0.1，与Aarshay的调参试验差不多，甚至更好一点点。</p>
<p>　　回过头来，我们再次看看贪心的坐标下降法是怎么掉入这个陷阱的。在确定过程影响类参数后，贪心的坐标下降法按照“动态”的对整体模型性能的影响力大小，选择了“叶节点最小样本数”进行调参。这一步看似和上一段的描述是一致的，但是，一般来说，含随机性（“子采样率”和“分裂时考虑的最大特征数”先初步调过）的“叶节点最小样本数”要大于无随机性。举个例来说，因为增加了随机性，导致了子采样后，某子样本中只有一个正例，且其可以通过唯一的特征将其分类，但是这个特征并不是所有正例的共性，所以此时就要求“叶节点最小样本数”需要比无随机性时大。对贪心的坐标下降来说，“子采样率”和“分裂时考虑的最大特征数”在当下，对整体模型性能的影响比不上“叶节点最小样本数”，所以栽了个大跟头。</p>
<hr>
<h2 id="3-总结"><a href="#3-总结" class="headerlink" title="3 总结"></a>3 总结</h2><p>　　在这篇博文中，我一反常态，花了大部分时间去试验和说明一个有瑕疵的方案。数据挖掘的工作中的方法和技巧，有很大一部分暂时还未被严谨地证明，所以有很大部分人，特别是刚入门的小青年们（也包括曾经的我），误以为其是一门玄学。实际上，尽管没有被严谨地证明，我们还是可以通过试验、分析，特别是与现有方法进行对比，得到一个近似的合理性论证。</p>
<p>　　另外，小伙伴们你们有什么独到的调参方法吗？请不要有丝毫吝啬，狠狠地将你们的独门绝技全释放在我身上吧，请大胆留言，残酷批评！</p>
<hr>
<h2 id="4-参考资料"><a href="#4-参考资料" class="headerlink" title="4 参考资料"></a>4 参考资料</h2><ol>
<li><a href="http://www.cnblogs.com/jasonfreak/p/5657196.html" target="_blank" rel="noopener">《使用sklearn进行集成学习——理论》</a></li>
<li><a href="https://www.analyticsvidhya.com/blog/2016/02/complete-guide-parameter-tuning-gradient-boosting-gbm-python/" target="_blank" rel="noopener">Complete Guide to Parameter Tuning in Gradient Boosting (GBM) in Python</a></li>
<li><a href="https://zh.wikipedia.org/wiki/%E5%9D%90%E6%A0%87%E4%B8%8B%E9%99%8D%E6%B3%95" target="_blank" rel="noopener">坐标下降法</a></li>
<li><a href="https://www.kaggle.com/c/digit-recognizer" target="_blank" rel="noopener">Digit Recognizer</a></li>
<li><a href="https://datahack.analyticsvidhya.com/contest/data-hackathon-3x/" target="_blank" rel="noopener">Hackathon3.x</a></li>
</ol>

          
        
      
    </div>

    

    
    
    

    

    
      
    
    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
  </section>

  
  <nav class="pagination">
    <a class="extend prev" rel="prev" href="/page/27/"><i class="fa fa-angle-left" aria-label="上一页"></i></a><a class="page-number" href="/">1</a><span class="space">&hellip;</span><a class="page-number" href="/page/27/">27</a><span class="page-number current">28</span><a class="page-number" href="/page/29/">29</a><span class="space">&hellip;</span><a class="page-number" href="/page/31/">31</a><a class="extend next" rel="next" href="/page/29/"><i class="fa fa-angle-right" aria-label="下一页"></i></a>
  </nav>



          </div>
          

        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    <div class="sidebar-inner">

      

      

      <div class="site-overview-wrap sidebar-panel sidebar-panel-active">
        <div class="site-overview">
          <div class="site-author motion-element" itemprop="author" itemscope="" itemtype="http://schema.org/Person">
            
              <p class="site-author-name" itemprop="name">Schwimmer</p>
              <div class="site-description motion-element" itemprop="description">Record and Think!</div>
          </div>

          
            <nav class="site-state motion-element">
              
                <div class="site-state-item site-state-posts">
                
                  <a href="/archives/">
                
                    <span class="site-state-item-count">308</span>
                    <span class="site-state-item-name">日志</span>
                  </a>
                </div>
              

              
                
                
                <div class="site-state-item site-state-categories">
                  
                    
                      <a href="/categories/">
                    
                  
                    
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                    <span class="site-state-item-count">25</span>
                    <span class="site-state-item-name">分类</span>
                  </a>
                </div>
              

              
                
                
                <div class="site-state-item site-state-tags">
                  
                    
                      <a href="/tags/">
                    
                  
                    
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                    <span class="site-state-item-count">61</span>
                    <span class="site-state-item-name">标签</span>
                  </a>
                </div>
              
            </nav>
          

          

          

          

          

          
          

          
            
          
          

        </div>
      </div>

      

      

    </div>
  </aside>
  


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <div class="copyright">&copy; <span itemprop="copyrightYear">2019</span>
  <span class="with-love" id="animate">
    <i class="fa fa-user"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">Schwimmer</span>

  

  
</div>


  <div class="powered-by">由 <a href="https://hexo.io" class="theme-link" rel="noopener" target="_blank">Hexo</a> 强力驱动 v3.9.0</div>



  <span class="post-meta-divider">|</span>



  <div class="theme-info">主题 – <a href="https://theme-next.org" class="theme-link" rel="noopener" target="_blank">NexT.Mist</a> v7.2.0</div>




        
<div class="busuanzi-count">
  <script async src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>

  
    <span class="post-meta-item-icon">
      <i class="fa fa-user"></i>
    </span>
    <span class="site-uv" title="总访客量">
      <span class="busuanzi-value" id="busuanzi_value_site_uv"></span>
    </span>
  

  
    <span class="post-meta-divider">|</span>
  

  
    <span class="post-meta-item-icon">
      <i class="fa fa-eye"></i>
    </span>
    <span class="site-pv" title="总访问量">
      <span class="busuanzi-value" id="busuanzi_value_site_pv"></span>
    </span>
  
</div>









        
      </div>
    </footer>

    
      <div class="back-to-top">
        <i class="fa fa-arrow-up"></i>
        
      </div>
    

    

    
      <div>
        
  <script>
    window._bd_share_config = {
      "common": {
        "bdText": "",
        "bdMini": "1",
        "bdMiniList": false,
        "bdPic": ""
      },
      "image": {
        "viewList": ["tsina", "douban", "sqq", "qzone", "weixin", "twi", "fbook"],
        "viewText": "分享到：",
        "viewSize": "16"
      },
      "slide": {
        "bdImg": "5",
        "bdPos": "left",
        "bdTop": "100"
      }
    }
  </script>

<script>
  with(document)0[(getElementsByTagName('head')[0]||body).appendChild(createElement('script')).src='//bdimg.share.baidu.com/static/api/js/share.js?cdnversion='+~(-new Date()/36e5)];
</script>

      </div>
    

    
  </div>

  

<script>
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>


























  
  <script src="/lib/jquery/index.js?v=3.4.1"></script>

  
  <script src="/lib/velocity/velocity.min.js?v=1.2.1"></script>

  
  <script src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>


  


  <script src="/js/utils.js?v=7.2.0"></script>

  <script src="/js/motion.js?v=7.2.0"></script>



  
  


  <script src="/js/schemes/muse.js?v=7.2.0"></script>




  

  


  <script src="/js/next-boot.js?v=7.2.0"></script>


  

  

  

  
  
<script>
  function loadCount() {
    var d = document, s = d.createElement('script');
    s.src = 'https://https-schwimmer-github-io.disqus.com/count.js';
    s.id = 'dsq-count-scr';
    (d.head || d.body).appendChild(s);
  }
  // defer loading until the whole page loading is completed
  window.addEventListener('load', loadCount, false);
</script>







  
  <script>
    // Popup Window;
    var isfetched = false;
    var isXml = true;
    // Search DB path;
    var search_path = "search.xml";
    if (search_path.length === 0) {
      search_path = "search.xml";
    } else if (/json$/i.test(search_path)) {
      isXml = false;
    }
    var path = "/" + search_path;
    // monitor main search box;

    var onPopupClose = function (e) {
      $('.popup').hide();
      $('#local-search-input').val('');
      $('.search-result-list').remove();
      $('#no-result').remove();
      $(".local-search-pop-overlay").remove();
      $('body').css('overflow', '');
    }

    function proceedsearch() {
      $("body")
        .append('<div class="search-popup-overlay local-search-pop-overlay"></div>')
        .css('overflow', 'hidden');
      $('.search-popup-overlay').click(onPopupClose);
      $('.popup').toggle();
      var $localSearchInput = $('#local-search-input');
      $localSearchInput.attr("autocapitalize", "none");
      $localSearchInput.attr("autocorrect", "off");
      $localSearchInput.focus();
    }

    // search function;
    var searchFunc = function(path, search_id, content_id) {
      'use strict';

      // start loading animation
      $("body")
        .append('<div class="search-popup-overlay local-search-pop-overlay">' +
          '<div id="search-loading-icon">' +
          '<i class="fa fa-spinner fa-pulse fa-5x fa-fw"></i>' +
          '</div>' +
          '</div>')
        .css('overflow', 'hidden');
      $("#search-loading-icon").css('margin', '20% auto 0 auto').css('text-align', 'center');

      

      $.ajax({
        url: path,
        dataType: isXml ? "xml" : "json",
        async: true,
        success: function(res) {
          // get the contents from search data
          isfetched = true;
          $('.popup').detach().appendTo('.header-inner');
          var datas = isXml ? $("entry", res).map(function() {
            return {
              title: $("title", this).text(),
              content: $("content",this).text(),
              url: $("url" , this).text()
            };
          }).get() : res;
          var input = document.getElementById(search_id);
          var resultContent = document.getElementById(content_id);
          var inputEventFunction = function() {
            var searchText = input.value.trim().toLowerCase();
            var keywords = searchText.split(/[\s\-]+/);
            if (keywords.length > 1) {
              keywords.push(searchText);
            }
            var resultItems = [];
            if (searchText.length > 0) {
              // perform local searching
              datas.forEach(function(data) {
                var isMatch = false;
                var hitCount = 0;
                var searchTextCount = 0;
                var title = data.title.trim();
                var titleInLowerCase = title.toLowerCase();
                var content = data.content.trim().replace(/<[^>]+>/g,"");
                
                var contentInLowerCase = content.toLowerCase();
                var articleUrl = decodeURIComponent(data.url).replace(/\/{2,}/g, '/');
                var indexOfTitle = [];
                var indexOfContent = [];
                // only match articles with not empty titles
                if(title != '') {
                  keywords.forEach(function(keyword) {
                    function getIndexByWord(word, text, caseSensitive) {
                      var wordLen = word.length;
                      if (wordLen === 0) {
                        return [];
                      }
                      var startPosition = 0, position = [], index = [];
                      if (!caseSensitive) {
                        text = text.toLowerCase();
                        word = word.toLowerCase();
                      }
                      while ((position = text.indexOf(word, startPosition)) > -1) {
                        index.push({position: position, word: word});
                        startPosition = position + wordLen;
                      }
                      return index;
                    }

                    indexOfTitle = indexOfTitle.concat(getIndexByWord(keyword, titleInLowerCase, false));
                    indexOfContent = indexOfContent.concat(getIndexByWord(keyword, contentInLowerCase, false));
                  });
                  if (indexOfTitle.length > 0 || indexOfContent.length > 0) {
                    isMatch = true;
                    hitCount = indexOfTitle.length + indexOfContent.length;
                  }
                }

                // show search results

                if (isMatch) {
                  // sort index by position of keyword

                  [indexOfTitle, indexOfContent].forEach(function (index) {
                    index.sort(function (itemLeft, itemRight) {
                      if (itemRight.position !== itemLeft.position) {
                        return itemRight.position - itemLeft.position;
                      } else {
                        return itemLeft.word.length - itemRight.word.length;
                      }
                    });
                  });

                  // merge hits into slices

                  function mergeIntoSlice(text, start, end, index) {
                    var item = index[index.length - 1];
                    var position = item.position;
                    var word = item.word;
                    var hits = [];
                    var searchTextCountInSlice = 0;
                    while (position + word.length <= end && index.length != 0) {
                      if (word === searchText) {
                        searchTextCountInSlice++;
                      }
                      hits.push({position: position, length: word.length});
                      var wordEnd = position + word.length;

                      // move to next position of hit

                      index.pop();
                      while (index.length != 0) {
                        item = index[index.length - 1];
                        position = item.position;
                        word = item.word;
                        if (wordEnd > position) {
                          index.pop();
                        } else {
                          break;
                        }
                      }
                    }
                    searchTextCount += searchTextCountInSlice;
                    return {
                      hits: hits,
                      start: start,
                      end: end,
                      searchTextCount: searchTextCountInSlice
                    };
                  }

                  var slicesOfTitle = [];
                  if (indexOfTitle.length != 0) {
                    slicesOfTitle.push(mergeIntoSlice(title, 0, title.length, indexOfTitle));
                  }

                  var slicesOfContent = [];
                  while (indexOfContent.length != 0) {
                    var item = indexOfContent[indexOfContent.length - 1];
                    var position = item.position;
                    var word = item.word;
                    // cut out 100 characters
                    var start = position - 20;
                    var end = position + 80;
                    if(start < 0){
                      start = 0;
                    }
                    if (end < position + word.length) {
                      end = position + word.length;
                    }
                    if(end > content.length){
                      end = content.length;
                    }
                    slicesOfContent.push(mergeIntoSlice(content, start, end, indexOfContent));
                  }

                  // sort slices in content by search text's count and hits' count

                  slicesOfContent.sort(function (sliceLeft, sliceRight) {
                    if (sliceLeft.searchTextCount !== sliceRight.searchTextCount) {
                      return sliceRight.searchTextCount - sliceLeft.searchTextCount;
                    } else if (sliceLeft.hits.length !== sliceRight.hits.length) {
                      return sliceRight.hits.length - sliceLeft.hits.length;
                    } else {
                      return sliceLeft.start - sliceRight.start;
                    }
                  });

                  // select top N slices in content

                  var upperBound = parseInt('1');
                  if (upperBound >= 0) {
                    slicesOfContent = slicesOfContent.slice(0, upperBound);
                  }

                  // highlight title and content

                  function highlightKeyword(text, slice) {
                    var result = '';
                    var prevEnd = slice.start;
                    slice.hits.forEach(function (hit) {
                      result += text.substring(prevEnd, hit.position);
                      var end = hit.position + hit.length;
                      result += '<b class="search-keyword">' + text.substring(hit.position, end) + '</b>';
                      prevEnd = end;
                    });
                    result += text.substring(prevEnd, slice.end);
                    return result;
                  }

                  var resultItem = '';

                  if (slicesOfTitle.length != 0) {
                    resultItem += "<li><a href='" + articleUrl + "' class='search-result-title'>" + highlightKeyword(title, slicesOfTitle[0]) + "</a>";
                  } else {
                    resultItem += "<li><a href='" + articleUrl + "' class='search-result-title'>" + title + "</a>";
                  }

                  slicesOfContent.forEach(function (slice) {
                    resultItem += "<a href='" + articleUrl + "'>" +
                      "<p class=\"search-result\">" + highlightKeyword(content, slice) +
                      "...</p>" + "</a>";
                  });

                  resultItem += "</li>";
                  resultItems.push({
                    item: resultItem,
                    searchTextCount: searchTextCount,
                    hitCount: hitCount,
                    id: resultItems.length
                  });
                }
              })
            };
            if (keywords.length === 1 && keywords[0] === "") {
              resultContent.innerHTML = '<div id="no-result"><i class="fa fa-search fa-5x"></i></div>'
            } else if (resultItems.length === 0) {
              resultContent.innerHTML = '<div id="no-result"><i class="fa fa-frown-o fa-5x"></i></div>'
            } else {
              resultItems.sort(function (resultLeft, resultRight) {
                if (resultLeft.searchTextCount !== resultRight.searchTextCount) {
                  return resultRight.searchTextCount - resultLeft.searchTextCount;
                } else if (resultLeft.hitCount !== resultRight.hitCount) {
                  return resultRight.hitCount - resultLeft.hitCount;
                } else {
                  return resultRight.id - resultLeft.id;
                }
              });
              var searchResultList = '<ul class=\"search-result-list\">';
              resultItems.forEach(function (result) {
                searchResultList += result.item;
              })
              searchResultList += "</ul>";
              resultContent.innerHTML = searchResultList;
            }
          }

          if ('auto' === 'auto') {
            input.addEventListener('input', inputEventFunction);
          } else {
            $('.search-icon').click(inputEventFunction);
            input.addEventListener('keypress', function (event) {
              if (event.keyCode === 13) {
                inputEventFunction();
              }
            });
          }

          // remove loading animation
          $(".local-search-pop-overlay").remove();
          $('body').css('overflow', '');

          proceedsearch();
        }
      });
    }

    // handle and trigger popup window;
    $('.popup-trigger').click(function(e) {
      e.stopPropagation();
      if (isfetched === false) {
        searchFunc(path, 'local-search-input', 'local-search-result');
      } else {
        proceedsearch();
      };
    });

    $('.popup-btn-close').click(onPopupClose);
    $('.popup').click(function(e){
      e.stopPropagation();
    });
    $(document).on('keyup', function (event) {
      var shouldDismissSearchPopup = event.which === 27 &&
        $('.search-popup').is(':visible');
      if (shouldDismissSearchPopup) {
        onPopupClose();
      }
    });
  </script>





  

  

  
  

  
  
    
      
    
      
    
      
    
      
    
      
    
      
    
      
    
      
    
      
    
      
    
  

  
    
      <script type="text/x-mathjax-config">
  

  MathJax.Hub.Config({
    tex2jax: {
      inlineMath: [ ['$', '$'], ['\\(', '\\)'] ],
      processEscapes: true,
      skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
    },
    TeX: {
      
      equationNumbers: {
        autoNumber: 'AMS'
      }
    }
  });
  MathJax.Hub.Register.StartupHook('TeX Jax Ready', function() {
    MathJax.InputJax.TeX.prefilterHooks.Add(function(data) {
      if (data.display) {
        var next = data.script.nextSibling;
        while (next && next.nodeName.toLowerCase() === '#text') { next = next.nextSibling }
        if (next && next.nodeName.toLowerCase() === 'br') { next.parentNode.removeChild(next) }
      }
    });
  });
</script>

<script type="text/x-mathjax-config">
  MathJax.Hub.Queue(function() {
    var all = MathJax.Hub.getAllJax(), i;
    for (i = 0; i < all.length; i += 1) {
      document.getElementById(all[i].inputID + '-Frame').parentNode.className += ' has-jax';
    }
  });
</script>
<script src="//cdn.jsdelivr.net/npm/mathjax@2/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script><!-- hexo-inject:begin --><!-- Begin: Injected MathJax -->
<script type="text/x-mathjax-config">
  MathJax.Hub.Config({"tex2jax":{"inlineMath":[["$","$"],["\\(","\\)"]],"skipTags":["script","noscript","style","textarea","pre","code"],"processEscapes":true},"TeX":{"equationNumbers":{"autoNumber":"AMS"}}});
</script>

<script type="text/x-mathjax-config">
  MathJax.Hub.Queue(function() {
    var all = MathJax.Hub.getAllJax(), i;
    for(i=0; i < all.length; i += 1) {
      all[i].SourceElement().parentNode.className += ' has-jax';
    }
  });
</script>

<script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js">
</script>
<!-- End: Injected MathJax -->
<!-- hexo-inject:end -->

    
  


  

  

  

  

  

  

  

  

  

  

  

</body>
</html>
