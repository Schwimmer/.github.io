<!DOCTYPE html>












  


<html class="theme-next mist use-motion" lang="zh-CN">
<head>
  <!-- hexo-inject:begin --><!-- hexo-inject:end --><meta charset="UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=edge"/>
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2"/>
<meta name="theme-color" content="#222"/>






















<link rel="stylesheet" href="/lib/font-awesome/css/font-awesome.min.css?v=4.7.0"/>

<link rel="stylesheet" href="/css/main.css?v=7.2.0"/>


  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png?v=7.2.0">


  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png?v=7.2.0">


  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png?v=7.2.0">


  <link rel="mask-icon" href="/images/logo.svg?v=7.2.0" color="#222">







<script id="hexo.configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '/',
    scheme: 'Mist',
    version: '7.2.0',
    sidebar: {"position":"left","display":"post","offset":12,"onmobile":false,"dimmer":false},
    back2top: true,
    back2top_sidebar: false,
    fancybox: false,
    fastclick: false,
    lazyload: false,
    tabs: true,
    motion: {"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},
    algolia: {
      applicationID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    }
  };
</script>


  




  <meta name="description" content="Record and Think!">
<meta property="og:type" content="website">
<meta property="og:title" content="Schwimmer&#39;s Blog">
<meta property="og:url" content="https://schwimmer.github.io/page/28/index.html">
<meta property="og:site_name" content="Schwimmer&#39;s Blog">
<meta property="og:description" content="Record and Think!">
<meta property="og:locale" content="zh-CN">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Schwimmer&#39;s Blog">
<meta name="twitter:description" content="Record and Think!">





  
  
  <link rel="canonical" href="https://schwimmer.github.io/page/28/"/>



<script id="page.configurations">
  CONFIG.page = {
    sidebar: "",
  };
</script>

  <title>Schwimmer's Blog</title>
  




  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-143240576-1"></script>
  <script>
    var host = window.location.hostname;
    if (host !== "localhost" || !true) {
      window.dataLayer = window.dataLayer || [];
      function gtag(){dataLayer.push(arguments);}
      gtag('js', new Date());
      gtag('config', 'UA-143240576-1');
    }
  </script>









  <noscript>
  <style>
  .use-motion .motion-element,
  .use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-title { opacity: initial; }

  .use-motion .logo,
  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript><!-- hexo-inject:begin --><!-- hexo-inject:end -->

</head>

<body itemscope itemtype="http://schema.org/WebPage" lang="zh-CN">

  
  
    
  

  <!-- hexo-inject:begin --><!-- hexo-inject:end --><div class="container sidebar-position-left 
  page-home">
    <div class="headband"></div>

    <header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-wrapper">
  <div class="site-meta">
    

    <div class="custom-logo-site-title">
      <a href="/" class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">Schwimmer's Blog</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
    
    
  </div>

  <div class="site-nav-toggle">
    <button aria-label="切换导航栏">
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
    </button>
  </div>
</div>



<nav class="site-nav">
  
    <ul id="menu" class="menu">
      
        
        
        
          
          <li class="menu-item menu-item-home">

    
    
      
    

    

    <a href="/" rel="section"><i class="menu-item-icon fa fa-fw fa-home"></i> <br/>首页</a>

  </li>
        
        
        
          
          <li class="menu-item menu-item-tags">

    
    
      
    

    

    <a href="/tags/" rel="section"><i class="menu-item-icon fa fa-fw fa-tags"></i> <br/>标签</a>

  </li>
        
        
        
          
          <li class="menu-item menu-item-categories">

    
    
      
    

    

    <a href="/categories/" rel="section"><i class="menu-item-icon fa fa-fw fa-th"></i> <br/>分类</a>

  </li>
        
        
        
          
          <li class="menu-item menu-item-archives">

    
    
      
    

    

    <a href="/archives/" rel="section"><i class="menu-item-icon fa fa-fw fa-archive"></i> <br/>归档</a>

  </li>

      
      
    </ul>
  

  
    

  

  
</nav>



  



</div>
    </header>

    


    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          
          <div id="content" class="content">
            
  <section id="posts" class="posts-expand">
    
      

  

  
  
  

  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="https://schwimmer.github.io/2017/08/12/机器学习/NLP/Gensim-Tutorials/"/>

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Schwimmer"/>
      <meta itemprop="description" content="Record and Think!"/>
      <meta itemprop="image" content="/images/avatar.gif"/>
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Schwimmer's Blog"/>
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                
                <a href="/2017/08/12/机器学习/NLP/Gensim-Tutorials/" class="post-title-link" itemprop="url">Gensim-Tutorials</a>
              
            
          </h1>
        

        <div class="post-meta">

          
          
          

          
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              

              
                
              

              <time title="创建时间：2017-08-12 11:49:53" itemprop="dateCreated datePublished" datetime="2017-08-12T11:49:53+08:00">2017-08-12</time>
            </span>
          

          
            

            
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="fa fa-calendar-check-o"></i>
                </span>
                
                  <span class="post-meta-item-text">更新于</span>
                
                <time title="修改时间：2018-02-01 23:21:31" itemprop="dateModified" datetime="2018-02-01T23:21:31+08:00">2018-02-01</time>
              </span>
            
          

          
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing"><a href="/categories/NLP/" itemprop="url" rel="index"><span itemprop="name">NLP</span></a></span>

                
                
              
            </span>
          

          
            
            
              
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="fa fa-comment-o"></i>
                </span>
            
                <span class="post-meta-item-text">评论数：</span>
                <a href="/2017/08/12/机器学习/NLP/Gensim-Tutorials/#comments" itemprop="discussionUrl">
                  <span class="post-comments-count disqus-comment-count" data-disqus-identifier="2017/08/12/机器学习/NLP/Gensim-Tutorials/" itemprop="commentCount"></span>
                </a>
              </span>
            
          

          
          

          

          <br/>
          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p><a href="http://radimrehurek.com/gensim/tutorial.html" target="_blank" rel="noopener">http://radimrehurek.com/gensim/tutorial.html</a></p>
<p>Gensim 使用Python标准logging模块来记录log，使用方法是</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">import logging</div><div class="line">logging.basicConfig(format=&apos;%(asctime)s : %(levelname)s : %(message)s&apos;, level=logging.INFO)</div></pre></td></tr></table></figure>

          
        
      
    </div>

    

    
    
    

    

    
      
    
    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="https://schwimmer.github.io/2017/08/12/机器学习/NLP/NLP代码片段/"/>

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Schwimmer"/>
      <meta itemprop="description" content="Record and Think!"/>
      <meta itemprop="image" content="/images/avatar.gif"/>
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Schwimmer's Blog"/>
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                
                <a href="/2017/08/12/机器学习/NLP/NLP代码片段/" class="post-title-link" itemprop="url">NLP代码片段</a>
              
            
          </h1>
        

        <div class="post-meta">

          
          
          

          
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              

              
                
              

              <time title="创建时间：2017-08-12 11:49:53" itemprop="dateCreated datePublished" datetime="2017-08-12T11:49:53+08:00">2017-08-12</time>
            </span>
          

          
            

            
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="fa fa-calendar-check-o"></i>
                </span>
                
                  <span class="post-meta-item-text">更新于</span>
                
                <time title="修改时间：2018-03-31 10:28:31" itemprop="dateModified" datetime="2018-03-31T10:28:31+08:00">2018-03-31</time>
              </span>
            
          

          
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing"><a href="/categories/NLP/" itemprop="url" rel="index"><span itemprop="name">NLP</span></a></span>

                
                
              
            </span>
          

          
            
            
              
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="fa fa-comment-o"></i>
                </span>
            
                <span class="post-meta-item-text">评论数：</span>
                <a href="/2017/08/12/机器学习/NLP/NLP代码片段/#comments" itemprop="discussionUrl">
                  <span class="post-comments-count disqus-comment-count" data-disqus-identifier="2017/08/12/机器学习/NLP/NLP代码片段/" itemprop="commentCount"></span>
                </a>
              </span>
            
          

          
          

          

          <br/>
          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1 id="根据标点拆分句子"><a href="#根据标点拆分句子" class="headerlink" title="根据标点拆分句子"></a>根据标点拆分句子</h1><p><code>[AtomSplit.java](../../../../gitlab/user-gene/nlp/src/main/java/com/buzzinate/nlp/segment/AtomSplit.java)</code></p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div></pre></td><td class="code"><pre><div class="line">	<span class="function"><span class="keyword">public</span> <span class="keyword">static</span> List&lt;String&gt; <span class="title">splitSentences</span><span class="params">(String text)</span> <span class="keyword">throws</span> IOException </span>&#123;</div><div class="line">		List&lt;String&gt; result = <span class="keyword">new</span> ArrayList&lt;String&gt;();</div><div class="line">		<span class="keyword">int</span> last = <span class="number">0</span>;</div><div class="line">		<span class="keyword">for</span> (Term term: Segment.split(text, ToAnalysis.USE_USER_DEFINE)) &#123;</div><div class="line">			<span class="keyword">if</span> (sentenceNatures.contains(term.getNatrue().natureStr) &amp;&amp; !isWhiteSpace(term.getName())) &#123;</div><div class="line">				<span class="keyword">if</span> (term.getOffe() &gt; last) &#123;</div><div class="line">					String snippet = text.substring(last, term.getOffe()).trim();  </div><div class="line">					<span class="keyword">if</span> (snippet.length() &gt; <span class="number">0</span>) result.add(snippet);</div><div class="line">				&#125;</div><div class="line">				last = term.getOffe() + term.getName().length();</div><div class="line">			&#125;</div><div class="line">		&#125;</div><div class="line">		<span class="keyword">if</span> (text.length() &gt; last) &#123;</div><div class="line">			String snippet = text.substring(last, text.length()).trim();  </div><div class="line">			<span class="keyword">if</span> (snippet.length() &gt; <span class="number">0</span>) result.add(snippet);</div><div class="line">		&#125;</div><div class="line">		<span class="keyword">return</span> result;</div><div class="line">	&#125;</div><div class="line"></div><div class="line"><span class="function"><span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">boolean</span> <span class="title">isWhiteSpace</span><span class="params">(String term)</span> </span>&#123;</div><div class="line">		<span class="keyword">return</span> term.length() == <span class="number">1</span> &amp;&amp; (Character.isWhitespace(term.charAt(<span class="number">0</span>)) || term.charAt(<span class="number">0</span>) == <span class="string">'-'</span>);</div><div class="line">	&#125;</div></pre></td></tr></table></figure>
<h1 id="给每个字符标记类型"><a href="#给每个字符标记类型" class="headerlink" title="给每个字符标记类型"></a>给每个字符标记类型</h1><p><code>[AtomSplit.java](../../../../gitlab/user-gene/nlp/src/main/java/com/buzzinate/nlp/segment/AtomSplit.java)</code></p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div></pre></td><td class="code"><pre><div class="line"><span class="comment">/**</span></div><div class="line"> * 给每个字符标记类型，如</div><div class="line"> * [2011(AT_NUM), -(AT_PUNC), 34(AT_NUM), -(AT_PUNC), 43(AT_NUM),  (AT_PUNC), 为(AT_CHINESE), 中(AT_CHINESE), 国(AT_CHINESE)]</div><div class="line"> * <span class="doctag">@param</span> text</div><div class="line"> * <span class="doctag">@return</span></div><div class="line"> */</div><div class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">static</span> List&lt;Atom&gt; <span class="title">split</span><span class="params">(String text)</span> </span>&#123;</div><div class="line">	List&lt;Atom&gt; result = <span class="keyword">new</span> ArrayList&lt;Atom&gt;();</div><div class="line">	<span class="keyword">int</span> last = <span class="number">0</span>;</div><div class="line">	AtomType t = AtomType.AT_LETTER;</div><div class="line">	<span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; text.length(); i++) &#123;</div><div class="line">		<span class="keyword">char</span> ch = text.charAt(i);</div><div class="line">		<span class="keyword">if</span> (TextUtil.isAlphaOrDigit(ch) || ch == <span class="string">'\''</span> || ch == <span class="string">'.'</span>) &#123;</div><div class="line">			<span class="keyword">if</span> (i == last) &#123;</div><div class="line">				t = AtomType.AT_LETTER;</div><div class="line">				<span class="keyword">if</span> (Character.isDigit(ch)) t = AtomType.AT_NUM;</div><div class="line">			&#125;</div><div class="line">		&#125; <span class="keyword">else</span> <span class="keyword">if</span> (Character.isLetter(ch)) &#123;</div><div class="line">			<span class="keyword">if</span> (i &gt; last) result.add(<span class="keyword">new</span> Atom(text.substring(last, i), t));</div><div class="line">			result.add(<span class="keyword">new</span> Atom(text.substring(i, i+<span class="number">1</span>), AtomType.AT_CHINESE));</div><div class="line">			last = i + <span class="number">1</span>;</div><div class="line">		&#125; <span class="keyword">else</span> &#123;</div><div class="line">			<span class="keyword">if</span> (i &gt; last) result.add(<span class="keyword">new</span> Atom(text.substring(last, i), t));</div><div class="line">			<span class="keyword">if</span> (t != AtomType.AT_LETTER || !isConnectChar(ch)) result.add(<span class="keyword">new</span> Atom(text.substring(i, i+<span class="number">1</span>), AtomType.AT_PUNC));</div><div class="line">			last = i + <span class="number">1</span>;</div><div class="line">		&#125;</div><div class="line">	&#125;</div><div class="line">	<span class="keyword">if</span> (text.length() &gt; last) result.add(<span class="keyword">new</span> Atom(text.substring(last, text.length()), t));</div><div class="line">	<span class="keyword">return</span> result;</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<h1 id="判断字符串的语言"><a href="#判断字符串的语言" class="headerlink" title="判断字符串的语言"></a>判断字符串的语言</h1><p>有两个开源的项目可以使用。一个是Apache Tika，一个是language-detection。language-detection是google Code上开源的一个语言检测软件包，不折不扣的日货，但使用起来非常方便，其project链接如下：<a href="http://code.google.com/p/language-detection" target="_blank" rel="noopener">http://code.google.com/p/language-detection</a>。基本上，你只需要引用langdetect.jar和其依赖的jsonic-1.3.0.jar（也是日货）即可</p>
<p><code>/rocket-iaudience-api/src/main/java/com/iclick/rocket/iaudience/api/common/LanguageDetectUtil.java</code></p>
<h2 id="判断中文字符"><a href="#判断中文字符" class="headerlink" title="判断中文字符"></a>判断中文字符</h2><figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">Character.isLetter()</div></pre></td></tr></table></figure>
<h2 id="判断是否为英文或数字"><a href="#判断是否为英文或数字" class="headerlink" title="判断是否为英文或数字"></a>判断是否为英文或数字</h2><figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div></pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">boolean</span> <span class="title">isAlphaOrDigit</span><span class="params">(<span class="keyword">char</span> ch)</span> </span>&#123;</div><div class="line">	<span class="keyword">if</span> (ch &gt;= <span class="string">'a'</span> &amp;&amp; ch &lt;= <span class="string">'z'</span>)</div><div class="line">		<span class="keyword">return</span> <span class="keyword">true</span>;</div><div class="line">	<span class="keyword">if</span> (ch &gt;= <span class="string">'A'</span> &amp;&amp; ch &lt;= <span class="string">'Z'</span>)</div><div class="line">		<span class="keyword">return</span> <span class="keyword">true</span>;</div><div class="line">	<span class="keyword">if</span> (ch &gt;= <span class="string">'0'</span> &amp;&amp; ch &lt;= <span class="string">'9'</span>)</div><div class="line">		<span class="keyword">return</span> <span class="keyword">true</span>;</div><div class="line">	<span class="keyword">return</span> <span class="keyword">false</span>;</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<h1 id="去除停用词"><a href="#去除停用词" class="headerlink" title="去除停用词"></a>去除停用词</h1><p>java</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line">ArrayList&lt;String&gt; wordSet = new ArrayList&lt;String&gt;();</div><div class="line">// 自动去除停用词</div><div class="line">		for (Term term : NotionalTokenizer.segment(simplePhrase)) &#123;</div><div class="line">			wordSet.add(term.word);</div><div class="line">		&#125;</div></pre></td></tr></table></figure>
<p>python参考gensim</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div></pre></td><td class="code"><pre><div class="line">documents = [&quot;Human machine interface for lab abc computer applications&quot;,</div><div class="line">             &quot;A survey of user opinion of computer system response time&quot;,</div><div class="line">             &quot;The EPS user interface management system&quot;,</div><div class="line">             &quot;System and human system engineering testing of EPS&quot;,              </div><div class="line">             &quot;Relation of user perceived response time to error measurement&quot;,</div><div class="line">             &quot;The generation of random binary unordered trees&quot;,</div><div class="line">             &quot;The intersection graph of paths in trees&quot;,</div><div class="line">             &quot;Graph minors IV Widths of trees and well quasi ordering&quot;,</div><div class="line">             &quot;Graph minors A survey&quot;]</div><div class="line">#停用词</div><div class="line">stoplist = set(&apos;for a of the and to in&apos;.split())</div><div class="line">texts = [ [word for word in document.lower().split() if word not in stoplist ]</div><div class="line">         for document in documents ]</div><div class="line">         </div><div class="line">#删除仅出现一次的词</div><div class="line">from collections import defaultdict</div><div class="line">frequency = defaultdict(int)</div><div class="line">for text in texts:</div><div class="line">    for token in text:</div><div class="line">        frequency[token] += 1</div><div class="line">texts = [[token for token in text if frequency[token] &gt; 1 ] for text in texts]</div></pre></td></tr></table></figure>
<h1 id="分词"><a href="#分词" class="headerlink" title="分词"></a>分词</h1><p>python用jieba</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">import</span> jieba</div><div class="line">sentences = [<span class="string">"我喜欢吃土豆"</span>,<span class="string">"土豆是个百搭的东西"</span>,<span class="string">"我不喜欢今天雾霾的北京"</span>]</div><div class="line">words=[]</div><div class="line"><span class="keyword">for</span> doc <span class="keyword">in</span> sentences:</div><div class="line"><span class="comment"># 结巴分词返回的是一个generator，要用list()转成list</span></div><div class="line">    words.append(list(jieba.cut(doc)))</div><div class="line"><span class="keyword">print</span> words</div></pre></td></tr></table></figure>
<p>java用hanlp</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line">ArrayList&lt;String&gt; wordSet = new ArrayList&lt;String&gt;();</div><div class="line">// 自动去除停用词</div><div class="line">		for (Term term : NotionalTokenizer.segment(simplePhrase)) &#123;</div><div class="line">			wordSet.add(term.word);</div><div class="line">		&#125;</div></pre></td></tr></table></figure>
<h1 id="英文词干化"><a href="#英文词干化" class="headerlink" title="英文词干化"></a>英文词干化</h1>
          
        
      
    </div>

    

    
    
    

    

    
      
    
    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="https://schwimmer.github.io/2017/07/12/算法与数据结构/动态规划讲解/"/>

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Schwimmer"/>
      <meta itemprop="description" content="Record and Think!"/>
      <meta itemprop="image" content="/images/avatar.gif"/>
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Schwimmer's Blog"/>
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                
                <a href="/2017/07/12/算法与数据结构/动态规划讲解/" class="post-title-link" itemprop="url">动态规划理论</a>
              
            
          </h1>
        

        <div class="post-meta">

          
          
          

          
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              

              
                
              

              <time title="创建时间：2017-07-12 11:49:53" itemprop="dateCreated datePublished" datetime="2017-07-12T11:49:53+08:00">2017-07-12</time>
            </span>
          

          
            

            
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="fa fa-calendar-check-o"></i>
                </span>
                
                  <span class="post-meta-item-text">更新于</span>
                
                <time title="修改时间：2019-06-03 09:22:50" itemprop="dateModified" datetime="2019-06-03T09:22:50+08:00">2019-06-03</time>
              </span>
            
          

          
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing"><a href="/categories/算法与数据结构/" itemprop="url" rel="index"><span itemprop="name">算法与数据结构</span></a></span>

                
                
              
            </span>
          

          
            
            
              
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="fa fa-comment-o"></i>
                </span>
            
                <span class="post-meta-item-text">评论数：</span>
                <a href="/2017/07/12/算法与数据结构/动态规划讲解/#comments" itemprop="discussionUrl">
                  <span class="post-comments-count disqus-comment-count" data-disqus-identifier="2017/07/12/算法与数据结构/动态规划讲解/" itemprop="commentCount"></span>
                </a>
              </span>
            
          

          
          

          

          <br/>
          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1 id="动态规划理论讲解"><a href="#动态规划理论讲解" class="headerlink" title="动态规划理论讲解"></a>动态规划理论讲解</h1><p>[TOC]</p>
<h1 id="基础理论"><a href="#基础理论" class="headerlink" title="基础理论"></a>基础理论</h1><p><strong>什么是动态规划？什么时候要用动态规划？怎么使用动态规划？</strong></p>
<p><strong>1、什么是动态规划？</strong> </p>
<p>求解决策过程<strong>最优化</strong>的数学方法。把<strong>多阶段过程转化为一系列单阶段</strong>问题，利用各阶段之间的关系，逐个求解，创立了解决这类过程优化问题的新方法——动态规划。</p>
<p><strong>2、什么时候要用动态规划？</strong></p>
<p>如果要求一个问题的<strong>最优解</strong>（通常是最大值或者最小值），而且该问题能够<strong>分解成若干个子问题，并且小问题之间也存在重叠的子问题</strong>，则考虑采用动态规划。</p>
<p><strong>3、怎么使用动态规划？</strong> </p>
<ol>
<li>判题题意是否为找出一个问题的最优解 </li>
<li>从上往下分析问题，大问题可以分解为子问题，子问题中还有更小的子问题 </li>
<li>从下往上分析问题 ，找出这些问题之间的关联（状态转移方程） </li>
<li>讨论边界的初始条件</li>
<li>解决问题（通常使用数组进行迭代求出最优解）</li>
</ol>
<h1 id="代表算法-硬币问题"><a href="#代表算法-硬币问题" class="headerlink" title="代表算法-硬币问题"></a>代表算法-硬币问题</h1><h2 id="问题描述"><a href="#问题描述" class="headerlink" title="问题描述"></a>问题描述</h2><p>假设有 1 元，3 元，5 元的硬币若干（无限），现在需要凑出 11 元，问如何组合才能使硬币的数量最少？</p>
<h2 id="问题分析"><a href="#问题分析" class="headerlink" title="问题分析"></a>问题分析</h2><p>乍看之下，我们简单的运用一下心算就能解出需要 2 个 5 元和 1 个 1 元的解。当然这里只是列出了这个问题比较简单的情况。当硬币的币制或者种类变化，并且需要凑出的总价值变大时，就很难靠简单的计算得出结论了。贪心算法可以在一定的程度上得出较优解，但不是每次都能得出最优解。</p>
<p>这里运用动态规划的思路解决该问题。按照一般思路，我们先从最基本的情况来一步一步地推导。</p>
<p>我们先假设一个函数 <em>d(i)</em> 来表示需要凑出 <em>i</em> 的总价值需要的最少硬币数量。</p>
<ol>
<li>当 <em>i = 0</em> 时，很显然我们可以知道 <em>d(0) = 0</em>。因为不要凑钱了嘛，当然也不需要任何硬币了。<strong>注意这是很重要的一步，其后所有的结果都从这一步延伸开来</strong>。</li>
<li>当 <em>i = 1</em> 时，因为我们有 1 元的硬币，所以直接在第 1 步的基础上，加上 1 个 1 元硬币，得出 <em>d(1) = 1</em>。</li>
<li>当 <em>i = 2</em> 时，因为我们并没有 2 元的硬币，所以只能拿 1 元的硬币来凑。在第 2 步的基础上，加上 1 个 1 元硬币，得出 <em>d(2) = 2</em>。</li>
<li>当 <em>i = 3</em> 时，我们可以在第 3 步的基础上加上 1 个 1 元硬币，得到 <em>3</em> 这个结果。但其实我们有 3 元硬币，所以这一步的最优结果不是建立在第 3 步的结果上得来的，而是应该建立在第 1 步上，加上 1 个 3 元硬币，得到 <em>d(3) = 1</em>。</li>
</ol>
<p>接着就不再举例了，我们来分析一下。可以看出，除了第 1 步这个看似基本的公理外，其他往后的结果都是建立在它之前得到的某一步的最优解上，加上 1 个硬币得到。得出：</p>
<p><em>d(i) = d(j) + 1</em></p>
<p>这里 <em>j &lt; i</em>。通俗地讲，我们需要凑出 <em>i</em> 元，就在凑出 <em>j</em> 的结果上再加上某一个硬币就行了。</p>
<p>那这里我们加上的是哪个硬币呢。嗯，其实很简单，把每个硬币试一下就行了：</p>
<ol>
<li>假设最后加上的是 1 元硬币，那 <em>d(i) = d(j) + 1 = d(i - 1) + 1</em>。</li>
<li>假设最后加上的是 3 元硬币，那 <em>d(i) = d(j) + 1 = d(i - 3) + 1</em>。</li>
<li>假设最后加上的是 5 元硬币，那 <em>d(i) = d(j) + 1 = d(i - 5) + 1</em>。</li>
</ol>
<p>我们分别计算出 <em>d(i - 1) + 1</em>，<em>d(i - 3) + 1</em>，<em>d(i - 5) + 1</em> 的值，取其中的最小值，即为最优解，也就是 <em>d(i)</em>。</p>
<p>最后公式：</p>
<p><img src="/2017/07/12/算法与数据结构/动态规划讲解/Users/david/david/00projects/00markdown/pic/1046505-20161024143029437-524511140.png" alt="img"></p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">MinCoins</span> </span>&#123;</div><div class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;</div><div class="line">        <span class="keyword">int</span>[] coins = &#123; <span class="number">1</span>, <span class="number">3</span>, <span class="number">5</span> &#125;;</div><div class="line">        <span class="keyword">int</span> value = <span class="number">11</span>;</div><div class="line">        CoinDp(value, coins);</div><div class="line">    &#125;</div><div class="line"></div><div class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">CoinDp</span><span class="params">(<span class="keyword">int</span> n, <span class="keyword">int</span>[] coinValue)</span> </span>&#123;</div><div class="line">        <span class="keyword">int</span> count = <span class="number">0</span>;<span class="comment">// 记录执行次数</span></div><div class="line">        <span class="keyword">int</span>[] min = <span class="keyword">new</span> <span class="keyword">int</span>[n + <span class="number">1</span>]; <span class="comment">// 用来存储得到n块钱需要的硬币数的最小值</span></div><div class="line">        min[<span class="number">0</span>] = <span class="number">0</span>;</div><div class="line">        <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">1</span>; i &lt;= n; i++) &#123;</div><div class="line">            min[i] = Integer.MAX_VALUE;<span class="comment">// 初始化数组中的每个值都是最大的整数</span></div><div class="line">            <span class="keyword">for</span> (<span class="keyword">int</span> j = <span class="number">0</span>; j &lt; coinValue.length; j++) &#123;</div><div class="line">                count++;</div><div class="line">                <span class="keyword">if</span> (i &gt;= coinValue[j] &amp;&amp; min[i] &gt; min[i - coinValue[j]] + <span class="number">1</span>) &#123;</div><div class="line">                    min[i] = min[i - coinValue[j]] + <span class="number">1</span>;</div><div class="line">                &#125;</div><div class="line">            &#125;</div><div class="line">            System.out.println(<span class="string">"获取"</span> + i + <span class="string">"块钱，最少需要的硬币数："</span> + min[i] + <span class="string">",执行的次数："</span> + count);</div><div class="line">        &#125;</div><div class="line">        System.out.println(min[n]);</div><div class="line">    &#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<p>参考：</p>
<p><a href="https://blog.csdn.net/weixin_38278878/article/details/80037455" target="_blank" rel="noopener">https://blog.csdn.net/weixin_38278878/article/details/80037455</a></p>
<p><a href="https://www.cnblogs.com/snowInPluto/p/5992846.html" target="_blank" rel="noopener">https://www.cnblogs.com/snowInPluto/p/5992846.html</a></p>
<p><a href="https://www.cnblogs.com/wuyuegb2312/p/3281264.html" target="_blank" rel="noopener">https://www.cnblogs.com/wuyuegb2312/p/3281264.html</a></p>

          
        
      
    </div>

    

    
    
    

    

    
      
    
    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="https://schwimmer.github.io/2017/07/12/算法与数据结构/最长公共子串/"/>

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Schwimmer"/>
      <meta itemprop="description" content="Record and Think!"/>
      <meta itemprop="image" content="/images/avatar.gif"/>
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Schwimmer's Blog"/>
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                
                <a href="/2017/07/12/算法与数据结构/最长公共子串/" class="post-title-link" itemprop="url">最长公共子串</a>
              
            
          </h1>
        

        <div class="post-meta">

          
          
          

          
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              

              
                
              

              <time title="创建时间：2017-07-12 11:49:53" itemprop="dateCreated datePublished" datetime="2017-07-12T11:49:53+08:00">2017-07-12</time>
            </span>
          

          
            

            
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="fa fa-calendar-check-o"></i>
                </span>
                
                  <span class="post-meta-item-text">更新于</span>
                
                <time title="修改时间：2018-03-17 20:50:31" itemprop="dateModified" datetime="2018-03-17T20:50:31+08:00">2018-03-17</time>
              </span>
            
          

          
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing"><a href="/categories/算法与数据结构/" itemprop="url" rel="index"><span itemprop="name">算法与数据结构</span></a></span>

                
                
              
            </span>
          

          
            
            
              
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="fa fa-comment-o"></i>
                </span>
            
                <span class="post-meta-item-text">评论数：</span>
                <a href="/2017/07/12/算法与数据结构/最长公共子串/#comments" itemprop="discussionUrl">
                  <span class="post-comments-count disqus-comment-count" data-disqus-identifier="2017/07/12/算法与数据结构/最长公共子串/" itemprop="commentCount"></span>
                </a>
              </span>
            
          

          
          

          

          <br/>
          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>找出最长子串，需要知道子串的<strong>起始位置</strong>和子串的<strong>长度</strong>。</p>
<p>因此，维护一个二维数组，存放两个字符串的字符关系，再创建两个变量存放index和maxLen。</p>
<p><img src="https://segmentfault.com/img/remote/1460000007963599?w=684&amp;h=644" alt=""></p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div></pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">static</span> String <span class="title">findLcsNew</span><span class="params">(String str1, String str2)</span> </span>&#123;</div><div class="line">		<span class="keyword">int</span> len1, len2;</div><div class="line">		len1 = str1.length();</div><div class="line">		len2 = str2.length();</div><div class="line">		</div><div class="line">		<span class="keyword">int</span> maxLen = <span class="number">0</span>, index = <span class="number">0</span>;</div><div class="line">		<span class="keyword">int</span>[][] arr = <span class="keyword">new</span> <span class="keyword">int</span>[len1 + <span class="number">1</span>][len2 + <span class="number">1</span>];</div><div class="line">		</div><div class="line">		<span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; len1; i++) &#123;</div><div class="line">			<span class="keyword">for</span> (<span class="keyword">int</span> j = <span class="number">0</span>; j &lt; len2; j++) &#123;</div><div class="line">				<span class="keyword">if</span> ( i == <span class="number">0</span> || j == <span class="number">0</span> ) &#123;</div><div class="line">                  <span class="comment">// 第一行和第一列都是0</span></div><div class="line">					arr[i][j] = <span class="number">0</span>;</div><div class="line">				&#125; <span class="keyword">else</span> &#123;</div><div class="line">                  <span class="comment">// 该字符和上一个字符均相等时</span></div><div class="line">					<span class="keyword">if</span> (str1.charAt(i) == str2.charAt(j) &amp;&amp; str1.charAt(i-<span class="number">1</span>) == str2.charAt(j-<span class="number">1</span>)) &#123;</div><div class="line">						arr[i][j] = arr[i-<span class="number">1</span>][j-<span class="number">1</span>] + <span class="number">1</span>;</div><div class="line">					&#125; <span class="keyword">else</span> &#123;</div><div class="line">						arr[i][j] = <span class="number">0</span>;</div><div class="line">					&#125;</div><div class="line">				&#125;</div><div class="line">				</div><div class="line">				<span class="keyword">if</span> (arr[i][j] &gt; maxLen) &#123;</div><div class="line">					maxLen = arr[i][j];</div><div class="line">					index = i;</div><div class="line">				&#125;</div><div class="line">			&#125;</div><div class="line">		&#125;</div><div class="line">		</div><div class="line">		String newStr = str1.substring(index - maxLen, index + <span class="number">1</span>);</div><div class="line">		</div><div class="line">		<span class="keyword">return</span> newStr;</div><div class="line">	&#125;</div></pre></td></tr></table></figure>
<p>也可以用一维数组实现，同时可以记录多个相同长度的最长子串</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div></pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">static</span> String <span class="title">findLcs</span><span class="params">(String str1, String str2)</span> </span>&#123;</div><div class="line">	StringBuffer buff = <span class="keyword">new</span> StringBuffer();</div><div class="line">	<span class="keyword">int</span> i, j;</div><div class="line">	<span class="keyword">int</span> len1, len2;</div><div class="line">	len1 = str1.length();</div><div class="line">	len2 = str2.length();</div><div class="line">	<span class="keyword">int</span> maxLen = len1 &gt; len2 ? len1 : len2;</div><div class="line">	<span class="keyword">int</span>[] max = <span class="keyword">new</span> <span class="keyword">int</span>[maxLen];</div><div class="line">	<span class="keyword">int</span>[] maxIndex = <span class="keyword">new</span> <span class="keyword">int</span>[maxLen];</div><div class="line">	<span class="keyword">int</span>[] c = <span class="keyword">new</span> <span class="keyword">int</span>[maxLen];</div><div class="line"></div><div class="line">	<span class="keyword">for</span> (i = <span class="number">0</span>; i &lt; len2; i++) &#123;</div><div class="line">		<span class="keyword">for</span> (j = len1 - <span class="number">1</span>; j &gt;= <span class="number">0</span>; j--) &#123;</div><div class="line">			<span class="keyword">if</span> (str2.charAt(i) == str1.charAt(j)) &#123;</div><div class="line">				<span class="keyword">if</span> ((i == <span class="number">0</span>) || (j == <span class="number">0</span>))</div><div class="line">					c[j] = <span class="number">1</span>;</div><div class="line">				<span class="keyword">else</span></div><div class="line">					c[j] = c[j - <span class="number">1</span>] + <span class="number">1</span>;</div><div class="line">			&#125; <span class="keyword">else</span> &#123;</div><div class="line">				c[j] = <span class="number">0</span>;</div><div class="line">			&#125;</div><div class="line"></div><div class="line">			<span class="keyword">if</span> (c[j] &gt; max[<span class="number">0</span>]) &#123; <span class="comment">// 如果是大于那暂时只有一个是最长的,而且要把后面的清0;</span></div><div class="line">				max[<span class="number">0</span>] = c[j];</div><div class="line">				maxIndex[<span class="number">0</span>] = j;</div><div class="line"></div><div class="line">				<span class="keyword">for</span> (<span class="keyword">int</span> k = <span class="number">1</span>; k &lt; maxLen; k++) &#123;</div><div class="line">					max[k] = <span class="number">0</span>;</div><div class="line">					maxIndex[k] = <span class="number">0</span>;</div><div class="line">				&#125;</div><div class="line">			&#125; <span class="keyword">else</span> <span class="keyword">if</span> (c[j] == max[<span class="number">0</span>]) &#123; <span class="comment">// 有多个是相同长度的子串</span></div><div class="line">				<span class="keyword">for</span> (<span class="keyword">int</span> k = <span class="number">1</span>; k &lt; maxLen; k++) &#123;</div><div class="line">					<span class="keyword">if</span> (max[k] == <span class="number">0</span>) &#123;</div><div class="line">						max[k] = c[j];</div><div class="line">						maxIndex[k] = j;</div><div class="line">						<span class="keyword">break</span>; <span class="comment">// 在后面加一个就要退出循环了</span></div><div class="line">					&#125;</div><div class="line"></div><div class="line">				&#125;</div><div class="line">			&#125;</div><div class="line">		&#125;</div><div class="line">	&#125;</div><div class="line"></div><div class="line">	<span class="keyword">for</span> (j = <span class="number">0</span>; j &lt; maxLen; j++) &#123;</div><div class="line">		<span class="keyword">if</span> (max[j] &gt; <span class="number">0</span>) &#123;</div><div class="line">			<span class="keyword">for</span> (i = maxIndex[j] - max[j] + <span class="number">1</span>; i &lt;= maxIndex[j]; i++)</div><div class="line">				buff.append(str1.charAt(i));			</div><div class="line">		&#125;</div><div class="line">	&#125;</div><div class="line">	<span class="keyword">return</span> buff.toString();</div><div class="line">&#125;</div></pre></td></tr></table></figure>

          
        
      
    </div>

    

    
    
    

    

    
      
    
    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="https://schwimmer.github.io/2017/07/12/机器学习/模型集成/"/>

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Schwimmer"/>
      <meta itemprop="description" content="Record and Think!"/>
      <meta itemprop="image" content="/images/avatar.gif"/>
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Schwimmer's Blog"/>
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                
                <a href="/2017/07/12/机器学习/模型集成/" class="post-title-link" itemprop="url">模型集成</a>
              
            
          </h1>
        

        <div class="post-meta">

          
          
          

          
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              

              
                
              

              <time title="创建时间：2017-07-12 11:49:53" itemprop="dateCreated datePublished" datetime="2017-07-12T11:49:53+08:00">2017-07-12</time>
            </span>
          

          
            

            
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="fa fa-calendar-check-o"></i>
                </span>
                
                  <span class="post-meta-item-text">更新于</span>
                
                <time title="修改时间：2018-02-11 09:26:22" itemprop="dateModified" datetime="2018-02-11T09:26:22+08:00">2018-02-11</time>
              </span>
            
          

          
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing"><a href="/categories/机器学习/" itemprop="url" rel="index"><span itemprop="name">机器学习</span></a></span>

                
                
              
            </span>
          

          
            
            
              
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="fa fa-comment-o"></i>
                </span>
            
                <span class="post-meta-item-text">评论数：</span>
                <a href="/2017/07/12/机器学习/模型集成/#comments" itemprop="discussionUrl">
                  <span class="post-comments-count disqus-comment-count" data-disqus-identifier="2017/07/12/机器学习/模型集成/" itemprop="commentCount"></span>
                </a>
              </span>
            
          

          
          

          

          <br/>
          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p><a href="https://www.jiqizhixin.com/articles/2018-01-14-8" target="_blank" rel="noopener">每个Kaggle冠军的获胜法门：揭秘Python中的模型集成</a></p>
<p><img src="https://image.jiqizhixin.com/uploads/wangeditor/c897487a-bf02-4023-9355-24c747d7ef62/43133image%20(1" alt="">.png)</p>
<p>Example Schematics of an ensemble.  An input array X is fed through two proprocessing pipelines and then to a set of base learners f(i). The ensemble combines all base learner predictions into a final prediction array P. </p>
<p>By the end of the post, you will:</p>
<ul>
<li>understand the fundamentals of ensembles</li>
<li>know how to code them</li>
<li>understand the main pitfalls and drawbacks of ensembles</li>
</ul>
<h2 id="Predicting-Republican-and-Democratic-donations"><a href="#Predicting-Republican-and-Democratic-donations" class="headerlink" title="Predicting Republican and Democratic donations"></a>Predicting Republican and Democratic donations</h2><p>we’ll use a data set on U.S. political contributions. The <a href="https://github.com/fivethirtyeight/data/tree/master/science-giving" target="_blank" rel="noopener">original data set</a> was prepared by <a href="https://fivethirtyeight.com/contributors/ben-wieder/" target="_blank" rel="noopener">Ben Wieder</a> at <a href="https://fivethirtyeight.com/" target="_blank" rel="noopener">FiveThirtyEight</a>, who dug around the U.S. government’s political contribution registry and found that when <a href="https://fivethirtyeight.com/features/when-scientists-donate-to-politicians-its-usually-to-democrats/" target="_blank" rel="noopener">scientists donate to politician, it’s usually to Democrats</a>.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</div><div class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</div><div class="line"></div><div class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</div><div class="line">%matplotlib inline</div><div class="line"></div><div class="line"><span class="comment">### Import data</span></div><div class="line"><span class="comment"># Always good to set a seed for reproducibility</span></div><div class="line">SEED = <span class="number">222</span></div><div class="line">np.random.seed(SEED)</div><div class="line"></div><div class="line">df = pd.read_csv(<span class="string">'input.csv'</span>)</div><div class="line"></div><div class="line"><span class="comment">### Training and test set</span></div><div class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> train_test_split</div><div class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> roc_auc_score</div><div class="line"></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">get_train_test</span><span class="params">(test_size=<span class="number">0.95</span>)</span>:</span></div><div class="line">    <span class="string">"""Split Data into train and test sets."""</span></div><div class="line">    y = <span class="number">1</span> * (df.cand_pty_affiliation == <span class="string">"REP"</span>)</div><div class="line">    X = df.drop([<span class="string">"cand_pty_affiliation"</span>], axis=<span class="number">1</span>)</div><div class="line">    X = pd.get_dummies(X, sparse=<span class="keyword">True</span>)</div><div class="line">    X.drop(X.columns[X.std() == <span class="number">0</span>], axis=<span class="number">1</span>, inplace=<span class="keyword">True</span>)</div><div class="line">    <span class="keyword">return</span> train_test_split(X, y, test_size=test_size, random_state=SEED)</div><div class="line"></div><div class="line">xtrain, xtest, ytrain, ytest = get_train_test()</div><div class="line"></div><div class="line"><span class="comment"># A look at the data</span></div><div class="line">print(<span class="string">"\nExample data:"</span>)</div><div class="line">df.head()</div><div class="line"></div><div class="line">df.cand_pty_affiliation.value_counts(normalize=<span class="keyword">True</span>).plot(</div><div class="line">    kind=<span class="string">"bar"</span>, title=<span class="string">"Share of No. donations"</span>)</div><div class="line">plt.show()</div></pre></td></tr></table></figure>
<p>This claim is based on the observation on the share of donations being made to Republicans and Democrats. However, there’s plenty more that can be said: for instance, which scientific discipline is most likely to make a Republican donation, and which state is most likely to make Democratic donations? We will go one step further and <em>predict</em> whether a donation is most likely to be a to a Republican or Democrat.</p>
<h2 id="What-is-an-ensemble"><a href="#What-is-an-ensemble" class="headerlink" title="What is an ensemble?"></a>What is an ensemble?</h2><p>Combining predictions from several models averages out idiosyncratic errors and yield better overall predictions.</p>
<p>How to combine predictions?</p>
<p>Machine learning is remarkably similar in classification problems: <strong>taking the most common class label prediction is equivalent to a majority voting rule</strong>. But there are many other ways to combine predictions, and more generally we can use a <strong>model to <em>learn</em></strong> how to best combine predictions.</p>
<h3 id="Understanding-ensembles-by-combining-decision-trees"><a href="#Understanding-ensembles-by-combining-decision-trees" class="headerlink" title="Understanding ensembles by combining decision trees"></a>Understanding ensembles by combining decision trees</h3><p>The deeper the tree, the more complex the patterns it can capture, but the <strong>more prone</strong> to overfitting it will be. Because of this, we will need an alternative way of building complex models of decision trees, and an ensemble of different decision trees is one such way.</p>
<p>We’ll use the below helper function to visualize our decision rules:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">import</span> pydotplus  <span class="comment"># you can install pydotplus with: pip install pydotplus </span></div><div class="line"><span class="keyword">from</span> IPython.display <span class="keyword">import</span> Image</div><div class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> roc_auc_score</div><div class="line"><span class="keyword">from</span> sklearn.tree <span class="keyword">import</span> DecisionTreeClassifier, export_graphviz</div><div class="line"></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">print_graph</span><span class="params">(clf, feature_names)</span>:</span></div><div class="line">    <span class="string">"""Print decision tree."""</span></div><div class="line">    graph = export_graphviz(</div><div class="line">        clf,</div><div class="line">        label=<span class="string">"root"</span>,</div><div class="line">        proportion=<span class="keyword">True</span>,</div><div class="line">        impurity=<span class="keyword">False</span>, </div><div class="line">        out_file=<span class="keyword">None</span>, </div><div class="line">        feature_names=feature_names,</div><div class="line">        class_names=&#123;<span class="number">0</span>: <span class="string">"D"</span>, <span class="number">1</span>: <span class="string">"R"</span>&#125;,</div><div class="line">        filled=<span class="keyword">True</span>,</div><div class="line">        rounded=<span class="keyword">True</span></div><div class="line">    )</div><div class="line">    graph = pydotplus.graph_from_dot_data(graph)  </div><div class="line">    <span class="keyword">return</span> Image(graph.create_png())</div></pre></td></tr></table></figure>

          
        
      
    </div>

    

    
    
    

    

    
      
    
    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="https://schwimmer.github.io/2017/07/12/机器学习/NLP/网页关键词提取/"/>

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Schwimmer"/>
      <meta itemprop="description" content="Record and Think!"/>
      <meta itemprop="image" content="/images/avatar.gif"/>
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Schwimmer's Blog"/>
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                
                <a href="/2017/07/12/机器学习/NLP/网页关键词提取/" class="post-title-link" itemprop="url">网页关键词提取</a>
              
            
          </h1>
        

        <div class="post-meta">

          
          
          

          
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              

              
                
              

              <time title="创建时间：2017-07-12 11:49:53" itemprop="dateCreated datePublished" datetime="2017-07-12T11:49:53+08:00">2017-07-12</time>
            </span>
          

          
            

            
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="fa fa-calendar-check-o"></i>
                </span>
                
                  <span class="post-meta-item-text">更新于</span>
                
                <time title="修改时间：2018-03-31 10:28:31" itemprop="dateModified" datetime="2018-03-31T10:28:31+08:00">2018-03-31</time>
              </span>
            
          

          
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing"><a href="/categories/NLP/" itemprop="url" rel="index"><span itemprop="name">NLP</span></a></span>

                
                
              
            </span>
          

          
            
            
              
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="fa fa-comment-o"></i>
                </span>
            
                <span class="post-meta-item-text">评论数：</span>
                <a href="/2017/07/12/机器学习/NLP/网页关键词提取/#comments" itemprop="discussionUrl">
                  <span class="post-comments-count disqus-comment-count" data-disqus-identifier="2017/07/12/机器学习/NLP/网页关键词提取/" itemprop="commentCount"></span>
                </a>
              </span>
            
          

          
          

          

          <br/>
          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>代码位于<code>nlp</code> 项目</p>
<h1 id="jsoup解析html的DOM"><a href="#jsoup解析html的DOM" class="headerlink" title="jsoup解析html的DOM"></a>jsoup解析html的DOM</h1><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">Document doc =Jsoup.connect(url).userAgent(&quot;Mozilla&quot;).get();</div></pre></td></tr></table></figure>
<h1 id="提取网页"><a href="#提取网页" class="headerlink" title="提取网页"></a>提取网页</h1><p><code>getPageDetail</code>获取网页提取的结果，返回<code>WebPageInfo</code>类，该类包括</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">public</span> String domain;</div><div class="line"><span class="keyword">public</span> String url;</div><div class="line"><span class="keyword">public</span> String rawTitle;</div><div class="line"><span class="keyword">public</span> String title;</div><div class="line"><span class="keyword">public</span> String content;</div><div class="line"><span class="keyword">public</span> String summary;</div><div class="line"><span class="keyword">public</span> HashMap&lt;String, String&gt; meta;</div><div class="line"><span class="keyword">public</span> HashMap&lt;String, List&lt;String&gt;&gt; calculation;</div><div class="line"><span class="keyword">public</span> <span class="keyword">long</span> freq = <span class="number">1</span>;</div><div class="line"><span class="keyword">public</span> String createTime;</div></pre></td></tr></table></figure>
<p><code>meta_desc</code>，来自网页meta的<code>description</code>元素</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">meta.put(&quot;description&quot;, meta_desc);</div></pre></td></tr></table></figure>
<p><code>meta_keywords</code>，来自网页meta的<code>keywords</code> </p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">meta.put(&quot;keywords&quot;, meta_keywords);</div></pre></td></tr></table></figure>
<h2 id="标题"><a href="#标题" class="headerlink" title="标题"></a>标题</h2><p><code>rawTitle=doc.title()</code></p>
<p><code>title</code>，通过<code>ExtractUtil.extractTitle(doc.body(), rawTitle)</code>进一步抽取。目的是去掉标题中的无关信息，如网站信息等</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div></pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">extractTitle</span></span>(root: <span class="type">Element</span>, rawTitle:<span class="type">String</span>): <span class="type">String</span> = &#123;</div><div class="line">    <span class="keyword">if</span>(<span class="type">StringUtils</span>.isBlank(rawTitle)) </div><div class="line">      <span class="keyword">return</span> <span class="string">""</span>;</div><div class="line">    <span class="keyword">val</span> titleCnt = <span class="keyword">new</span> <span class="type">HashMap</span>[<span class="type">String</span>, <span class="type">Int</span>] <span class="keyword">with</span> <span class="type">HashMapUtil</span>.<span class="type">IntHashMap</span>[<span class="type">String</span>]</div><div class="line">    titleCnt.adjustOrPut(te.extract(rawTitle).trim, <span class="number">1</span>, <span class="number">1</span>)</div><div class="line">    titleCnt.adjustOrPut(te.extractFirst(rawTitle).trim, <span class="number">1</span>, <span class="number">1</span>)</div><div class="line">    </div><div class="line">    <span class="keyword">val</span> tq = <span class="keyword">new</span> <span class="type">PriorityQueue</span>[<span class="type">String</span>](<span class="number">2</span>)</div><div class="line">    extractTitle0(root, rawTitle, <span class="number">1</span>, tq)</div><div class="line">    <span class="keyword">for</span> (candidate &lt;- tq.values) titleCnt.adjustOrPut(candidate.trim, <span class="number">1</span>, <span class="number">1</span>)</div><div class="line">    </div><div class="line">    <span class="keyword">var</span> maxCnt = <span class="number">0</span></div><div class="line">    <span class="keyword">var</span> title = rawTitle</div><div class="line">    titleCnt.foreach &#123; <span class="keyword">case</span> (candidate, cnt) =&gt;</div><div class="line">      <span class="keyword">if</span> (maxCnt &lt; cnt) &#123;</div><div class="line">        maxCnt = cnt</div><div class="line">        title = candidate</div><div class="line">      &#125;</div><div class="line">      <span class="keyword">if</span> (maxCnt == cnt &amp;&amp; candidate.length &gt; title.length) title = candidate</div><div class="line">    &#125;</div><div class="line">    </div><div class="line">    title</div><div class="line">  &#125;</div></pre></td></tr></table></figure>
<p><code>te.extract</code>，</p>
<p>首先要<code>split</code>。通过判断unicode字符的类别（<a href="http://blog.csdn.net/weixin_36082485/article/details/53154065" target="_blank" rel="noopener">Unicode字符类</a>）来分割标题 </p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; title.length(); i++) &#123;</div><div class="line">			<span class="keyword">char</span> ch = title.charAt(i);</div><div class="line">			<span class="keyword">int</span> type = Character.getType(ch);</div><div class="line">  			<span class="comment">// 标点，前引号</span></div><div class="line">			<span class="keyword">if</span> (type == Character.INITIAL_QUOTE_PUNCTUATION) quoteCnt++;</div><div class="line">  			<span class="comment">// 标点，开始</span></div><div class="line">			<span class="keyword">if</span> (type == Character.START_PUNCTUATION) quoteCnt++;</div><div class="line">			<span class="keyword">if</span> (quoteCnt == <span class="number">0</span> &amp;&amp; !lastLetter &amp;&amp; !lastDigit &amp;&amp; splitChars.contains(ch)) &#123;</div><div class="line">				parts.add(title.substring(last, i));</div><div class="line">				last = i + <span class="number">1</span>;</div><div class="line">			&#125;</div><div class="line">  			<span class="comment">// 标点，后引号</span></div><div class="line">			<span class="keyword">if</span> (type == Character.FINAL_QUOTE_PUNCTUATION) quoteCnt--;</div><div class="line">  			<span class="comment">// 标点，结束</span></div><div class="line">			<span class="keyword">if</span> (type == Character.END_PUNCTUATION) quoteCnt--;</div><div class="line">			<span class="keyword">if</span> (ch &gt;= <span class="string">'A'</span> &amp;&amp; ch &lt;= <span class="string">'Z'</span> || ch &gt;= <span class="string">'a'</span> &amp;&amp; ch &lt;= <span class="string">'z'</span>) lastLetter = <span class="keyword">true</span>;</div><div class="line">			<span class="keyword">else</span> lastLetter = <span class="keyword">false</span>;</div><div class="line">			<span class="keyword">if</span> (Character.isDigit(ch)) lastDigit = <span class="keyword">true</span>;</div><div class="line">			<span class="keyword">else</span> <span class="keyword">if</span> (!splitChars.contains(ch)) lastDigit = <span class="keyword">false</span>;</div><div class="line">		&#125;</div></pre></td></tr></table></figure>
<p>然后提取最长的part。提取的原则是，</p>
<p>1、如果出现不重要的字符前缀后缀<code>ignoreSuffixes</code>、<code>ignorePrefixes</code>，降低part的长度</p>
<p>2、第一个part的长度翻倍，可能是考虑到真的标题往往出现在第一块，如</p>
<p><code>清润饮食“熄灭”冬季之火 - 素食 - 大渡网-佛教资讯，生活，人文，心灵感悟，佛艺时尚杂志，佛教音乐，佛教常识，佛教视频</code></p>
<p><code>从草根到精英——大陆网络民族主义流变-观点评论-时事评论-四月网-青年思想门户-M4.CN</code></p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">private</span> <span class="keyword">static</span> List&lt;String&gt; ignoreSuffixes = Arrays.asList(<span class="string">"频道"</span>, <span class="string">"站"</span>, <span class="string">"网"</span>, <span class="string">"报"</span>, <span class="string">"集"</span>, <span class="string">"公司"</span>, <span class="string">".com"</span>, <span class="string">".cn"</span>, <span class="string">"平台"</span>, <span class="string">"门户"</span>, <span class="string">"博客"</span>, <span class="string">"精选"</span>, <span class="string">"博客精选"</span>);</div><div class="line">	<span class="keyword">private</span> <span class="keyword">static</span> List&lt;String&gt; ignorePrefixes = Arrays.asList(<span class="string">"Powered by"</span>);</div><div class="line">	<span class="keyword">private</span> <span class="keyword">static</span> HashSet&lt;Character&gt; splitChars = <span class="keyword">new</span> HashSet&lt;Character&gt;(Arrays.asList(<span class="string">'|'</span>, <span class="string">'_'</span>, <span class="string">'-'</span>, <span class="string">'—'</span>, <span class="string">'－'</span>, <span class="string">'&lt;'</span>, <span class="string">'&gt;'</span>, <span class="string">'«'</span>, <span class="string">'»'</span>));</div><div class="line"></div><div class="line"></div><div class="line"><span class="function"><span class="keyword">private</span> String <span class="title">getLongestPart</span><span class="params">(List&lt;String&gt; parts)</span> </span>&#123;</div><div class="line">		<span class="keyword">double</span> longestNumWords = <span class="number">0</span>;</div><div class="line">		String longestPart = <span class="string">""</span>;</div><div class="line">		<span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; parts.size(); i++) &#123;</div><div class="line">			String p = parts.get(i).trim();</div><div class="line">			</div><div class="line">			<span class="keyword">int</span> ignoreCount = <span class="number">0</span>;</div><div class="line">			<span class="keyword">for</span> (String is: ignoreSuffixes) <span class="keyword">if</span> (p.toLowerCase().endsWith(is)) ignoreCount++;</div><div class="line">			<span class="keyword">for</span> (String ip: ignorePrefixes) <span class="keyword">if</span> (p.toLowerCase().startsWith(ip)) ignoreCount++;</div><div class="line">			<span class="keyword">int</span> colonCnt = StringUtils.countMatches(p, <span class="string">","</span>);</div><div class="line">			<span class="keyword">if</span> (colonCnt &gt; <span class="number">0</span>) ignoreCount += colonCnt - <span class="number">1</span>;</div><div class="line">			colonCnt = StringUtils.countMatches(p, <span class="string">"，"</span>);</div><div class="line">			<span class="keyword">if</span> (colonCnt &gt; <span class="number">0</span>) ignoreCount += colonCnt - <span class="number">1</span>;</div><div class="line">			<span class="keyword">double</span> numWords = TextUtil.countNumWords(p);</div><div class="line">			numWords = numWords / (<span class="number">1</span> + <span class="number">2</span> * ignoreCount);</div><div class="line">			<span class="keyword">if</span> (i == <span class="number">0</span>) numWords = numWords * <span class="number">2</span>;</div><div class="line">            <span class="keyword">if</span> (numWords &gt; longestNumWords) &#123;</div><div class="line">            	longestNumWords = numWords;</div><div class="line">            	longestPart = p;</div><div class="line">            &#125;</div><div class="line">		&#125;</div><div class="line">		<span class="keyword">if</span> (longestPart.length() == <span class="number">0</span>) <span class="keyword">return</span> <span class="string">""</span>;</div><div class="line">		<span class="keyword">else</span> <span class="keyword">return</span> longestPart.trim();</div><div class="line">	&#125;</div></pre></td></tr></table></figure>
<p><code>extractTitle0(root, rawTitle, 1, tq)</code> </p>
<p>传入root和刚才提取的rawTitle，递归遍历root的各个head元素，<code>h</code>，<code>title</code>，每种赋值不同权重。再寻找与rawTitle的最长公共子串。</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">private</span> <span class="function"><span class="keyword">def</span> <span class="title">extractTitle0</span></span>(node: <span class="type">Node</span>, title: <span class="type">String</span>, weight: <span class="type">Double</span>, tq: <span class="type">PriorityQueue</span>[<span class="type">String</span>], depth: <span class="type">Int</span> = <span class="number">0</span>): <span class="type">Unit</span> = &#123;</div><div class="line">    node <span class="keyword">match</span> &#123;</div><div class="line">      <span class="keyword">case</span> textNode: <span class="type">TextNode</span> =&gt; &#123;</div><div class="line">        <span class="keyword">val</span> text = textNode.text.trim</div><div class="line">        <span class="keyword">if</span> (text.length &gt; <span class="number">0</span>) &#123;</div><div class="line">          <span class="keyword">val</span> lcs = <span class="type">TextUtil</span>.findLcs(title, text)</div><div class="line">          <span class="keyword">val</span> nwords = <span class="type">TextUtil</span>.countNumWords(lcs)</div><div class="line">          <span class="keyword">val</span> pos = title.indexOf(lcs)</div><div class="line">          <span class="keyword">if</span> (pos != <span class="number">-1</span> &amp;&amp; nwords &gt; <span class="number">0</span>) &#123;</div><div class="line">            tq.add(nwords * weight / (<span class="number">1</span> + math.log(<span class="number">2</span> + pos)), lcs)</div><div class="line">          &#125;</div><div class="line">        &#125; </div><div class="line">      &#125;</div><div class="line">      <span class="keyword">case</span> e: <span class="type">Element</span> =&gt; &#123;</div><div class="line">        <span class="keyword">var</span> w = weight</div><div class="line">        <span class="keyword">if</span> (e.tagName.startsWith(<span class="string">"h"</span>)) w = w * <span class="number">1.2</span></div><div class="line">        <span class="keyword">if</span> (e.tagName == <span class="string">"a"</span>) w = w / <span class="number">2</span></div><div class="line">        <span class="keyword">if</span> (e.className.contains(<span class="string">"title"</span>)) w = w * <span class="number">1.5</span></div><div class="line">        <span class="keyword">if</span> (e.tagName != <span class="string">"title"</span> &amp;&amp; !isNegativeBlock(e.className + <span class="string">" "</span> + e.id) &amp;&amp; depth &lt; <span class="type">Extract_STOP_DEPTH</span>) &#123;</div><div class="line">          <span class="keyword">for</span> (n &lt;- e.childNodes.asScala) extractTitle0(n, title, w, tq, depth + <span class="number">1</span>)</div><div class="line">        &#125;</div><div class="line">      &#125;</div><div class="line">      <span class="keyword">case</span> _ =&gt; &#123;&#125;</div><div class="line">    &#125;</div><div class="line">  &#125;</div></pre></td></tr></table></figure>
<p>通过以上方法提取出各种title后，选出出现频率最高的作为最终的title。</p>
<h2 id="content"><a href="#content" class="headerlink" title="content"></a>content</h2><figure class="highlight scala"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div></pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">extractContent</span></span>(url: <span class="type">String</span>, doc: <span class="type">Document</span>): <span class="type">List</span>[<span class="type">String</span>] = &#123;</div><div class="line">    <span class="keyword">val</span> rawTitle = doc.title</div><div class="line">    <span class="keyword">if</span>(doc.body == <span class="literal">null</span>)</div><div class="line">      <span class="keyword">return</span> <span class="literal">null</span></div><div class="line">    <span class="type">ExtractUtil</span>.cleanup(doc.body)</div><div class="line">    <span class="keyword">val</span> title = <span class="type">ExtractUtil</span>.extractTitle(doc.body, rawTitle)</div><div class="line">    <span class="keyword">val</span> metaKeywords = <span class="type">ExtractUtil</span>.extractMeta(doc, <span class="string">"keywords"</span>)</div><div class="line"></div><div class="line">    <span class="keyword">val</span> blocks = <span class="type">ExtractUtil</span>.extractBlocks(doc, title) map &#123; block =&gt;</div><div class="line">      <span class="type">SnippetBlock</span>(block.snippets map &#123; snippet =&gt; <span class="type">TextProcess</span>.normalize(urlReg.matcher(snippet).replaceAll(<span class="string">""</span>)) &#125;, block.score, block.isArticle, block.imgs)</div><div class="line">    &#125;</div><div class="line"></div><div class="line">    <span class="keyword">val</span> normalTitle = <span class="type">TextUtil</span>.fillText(title)</div><div class="line">    <span class="keyword">val</span> normalRawTitle = <span class="type">TextUtil</span>.fillText(doc.title)</div><div class="line"></div><div class="line">    <span class="keyword">val</span> allsnippets = blocks.filter(_.isArticle).flatMap &#123; b =&gt; b.snippets &#125;</div><div class="line">    <span class="keyword">return</span> allsnippets;</div><div class="line">  &#125;</div></pre></td></tr></table></figure>
<h3 id="清洗doc"><a href="#清洗doc" class="headerlink" title="清洗doc"></a>清洗doc</h3><p><code>ExtractUtil.cleanup(doc.body)</code></p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div></pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">cleanup</span></span>(root: <span class="type">Element</span>): <span class="type">Unit</span> = &#123;</div><div class="line">    <span class="keyword">val</span> cleanNodes = <span class="keyword">for</span> &#123;</div><div class="line">      e &lt;- root.getAllElements.asScala</div><div class="line">      <span class="keyword">if</span> <span class="type">INVALID_TAGS</span>.contains(e.tagName) || e.attr(<span class="string">"style"</span>).contains(<span class="string">"display:none"</span>)</div><div class="line">    &#125; <span class="keyword">yield</span> e</div><div class="line">    <span class="keyword">for</span> (cn &lt;- cleanNodes) cn.remove</div><div class="line">  &#125;</div></pre></td></tr></table></figure>
<h3 id="提取title、metakeywords"><a href="#提取title、metakeywords" class="headerlink" title="提取title、metakeywords"></a>提取title、metakeywords</h3><h3 id="提取blocks"><a href="#提取blocks" class="headerlink" title="提取blocks"></a>提取blocks</h3><figure class="highlight scala"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div></pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">extractBlocks</span></span>(doc: <span class="type">Document</span>, title: <span class="type">String</span>): <span class="type">List</span>[<span class="type">SnippetBlock</span>] = &#123;</div><div class="line">    <span class="keyword">val</span> blocks = <span class="keyword">new</span> <span class="type">ListBuffer</span>[<span class="type">BlockDetail</span>]</div><div class="line">    <span class="keyword">val</span> bd = <span class="keyword">new</span> <span class="type">BlockDetailBuffer</span></div><div class="line">    extractBlocks(doc.body, blocks, bd)</div><div class="line">    <span class="keyword">if</span> (bd.isDefined) blocks += bd.result</div><div class="line">    calcScore(title, blocks.result filterNot(b =&gt; hasICP(b))) ++ <span class="type">List</span>(<span class="type">SnippetBlock</span>(<span class="type">List</span>(extractMeta(doc, <span class="string">"keywords"</span>)), <span class="number">1</span>d, <span class="literal">true</span>, <span class="type">List</span>()), <span class="type">SnippetBlock</span>(<span class="type">List</span>(extractMeta(doc, <span class="string">"description"</span>)), <span class="number">0</span>d, <span class="literal">false</span>, <span class="type">List</span>()))</div><div class="line">  &#125;</div></pre></td></tr></table></figure>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">private</span> <span class="function"><span class="keyword">def</span> <span class="title">extractBlocks</span></span>(root: <span class="type">Node</span>, blocks: <span class="type">ListBuffer</span>[<span class="type">BlockDetail</span>], bd: <span class="type">BlockDetailBuffer</span>, inLink: <span class="type">Boolean</span> = <span class="literal">false</span>, depth: <span class="type">Int</span> = <span class="number">0</span>): <span class="type">Unit</span> = &#123;</div><div class="line">  root <span class="keyword">match</span> &#123;</div><div class="line">    <span class="keyword">case</span> tn: <span class="type">TextNode</span> =&gt; &#123;</div><div class="line">      <span class="keyword">val</span> text = <span class="type">StringUtils</span>.replace(tn.text, <span class="string">"\u00a0"</span>, <span class="string">" "</span>).trim</div><div class="line">      <span class="keyword">if</span> (text.length &gt; <span class="number">0</span>) bd.add(text, inLink)</div><div class="line">    &#125;</div><div class="line">    <span class="keyword">case</span> e: <span class="type">Element</span> =&gt; &#123;</div><div class="line">      <span class="keyword">val</span> isLink = inLink || (e.tagName == <span class="string">"a"</span>) </div><div class="line">      <span class="keyword">if</span>(depth &lt; <span class="type">Extract_STOP_DEPTH</span>)&#123;</div><div class="line">      	e.childNodes.asScala foreach &#123; c =&gt; extractBlocks(c, blocks, bd, isLink, depth + <span class="number">1</span>) &#125;</div><div class="line">      &#125;</div><div class="line">      </div><div class="line">      <span class="keyword">if</span> (e.tagName == <span class="string">"img"</span> || e.tagName == <span class="string">"embed"</span>) &#123;</div><div class="line">        bd.addImg(e)</div><div class="line">      &#125;</div><div class="line">      <span class="keyword">if</span> (e.isBlock) &#123;</div><div class="line">        <span class="keyword">if</span> (bd.isDefined) blocks += bd.result</div><div class="line">        bd.clear</div><div class="line">      &#125;</div><div class="line">    &#125;</div><div class="line">    <span class="keyword">case</span> _ =&gt; &#123;&#125;</div><div class="line">  &#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<p>提取每个TextNode的文本，放到<code>BlockDetailBuffer</code>中。将每个<code>BlockDetailBuffer</code>的内容放到<code>BlockDetail</code>的list <code>blocks</code>中。</p>
<p>过滤掉包含<code>icp备</code>或<code>icp证</code>的文本，再对所有的blocks计算打分<code>calcScore</code></p>
<p>最后提取所有是文本的snippet，作为content</p>
<h3 id="提取keywords"><a href="#提取keywords" class="headerlink" title="提取keywords"></a>提取keywords</h3><p>同样是先clean，提取title、metaKeyword，</p>
<p>再提取blocks</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">val</span> blocks:<span class="type">List</span>[<span class="type">SnippetBlock</span>] =  <span class="type">ExtractUtil</span>.extractBlocks(doc, title).map &#123; block =&gt;</div><div class="line">      &#123;</div><div class="line">              <span class="type">SnippetBlock</span>(block.snippets map &#123; snippet =&gt; <span class="type">TextProcess</span>.normalize(urlReg.matcher(snippet).replaceAll(<span class="string">""</span>)) &#125;, block.score, block.isArticle, block.imgs)</div><div class="line"></div><div class="line">	      <span class="keyword">val</span> temp  = block.snippets map &#123; snippet =&gt; <span class="type">TextProcess</span>.normalize(urlReg.matcher(snippet).replaceAll(<span class="string">""</span>)) &#125;</div><div class="line">	      maxLen += temp.map(<span class="type">AtomSplit</span>.count(_)).sum	</div><div class="line">	      <span class="keyword">val</span> retVal:<span class="type">SnippetBlock</span> = <span class="keyword">if</span>(maxLen &lt; <span class="type">MAX_CONTENT_LENGTH</span> || maxflag)&#123;<span class="type">SnippetBlock</span>(temp, block.score, block.isArticle, block.imgs)&#125; <span class="keyword">else</span> <span class="literal">null</span></div><div class="line">	      <span class="keyword">if</span>(maxLen &gt; <span class="type">MAX_CONTENT_LENGTH</span>)&#123;</div><div class="line">	        maxflag = <span class="literal">false</span></div><div class="line">	      &#125;</div><div class="line">	      retVal</div><div class="line">      &#125;</div><div class="line">    &#125;.filter( _ != <span class="literal">null</span>)</div></pre></td></tr></table></figure>
<h4 id="dlg"><a href="#dlg" class="headerlink" title="dlg"></a>dlg</h4><p>再提取dlg</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">val dlg = DlgExtractor.extract(normalTitle, TextUtil.fillText(doc.title), blocks, 6)/*.filter(_._2 &gt; 1.0)*/</div></pre></td></tr></table></figure>
<p>分词后，计算每个词的权重，</p>
<p>First of all, for any web page, we can use jsoup to  obtain the Document Object Model (DOM) , which can access all the HTML elements of it.</p>
<p>After that，we clean up  HTML elements by drop some invalid or useless tags, such as the tags with “display:none” property. </p>
<p>At last, We extract the Content and Keywords of HTML. </p>
<p>For extracting Content, we iterate through the DOM tree to find all TextNode elements, extract the text and take them as the Snippets. Then we calculate the scores of all Snippets, and get the available Snippets as Content.</p>
<p>For extracing Keywords, besides the Snippets from TextNode elements, we also collect the title, keywords and description from <meta> tag, store them as Blocks.   For every Block, we segment words to generate the corpus by ansj_seg, and calculate the weight of every word using TFIDF. Finally, we get the TOP 10 words as Keywords of web page.</p>
<p>我们解析了10万左右的网页，根据解析的网页content打上safe和unsafe的label，后期我们会对safe和unsafe进一步细分。</p>
<p>训练过程：我们载入所有含标签的训练样本，由于fasttext提供了适用于各种语言的Word2Vec预向量集，将网页内容转为词向量，通过fasttext训练出模型并保存到本地。</p>
<p>预测过程：载入模型到内存，当输入一个网页的content后，转为词向量，根据模型给出safe或unsafe的分类结果。</p>
<p>We have analyzed some 100 thousand web pages, classified text in categories, such as safe and unsafe by content of these web pages, and we will extent more categories in future.</p>
<p>In order to train the text classifier model, we load all samples containing a training sentence per line along with the labels, and transfer all words to vectors using  pre-trained word vectors model published by fastText.  Then we use the code from Github to run the training program. Once the model was trained, we save it on disk as a file.</p>
<p>When input a content of web page, we transfer it to word vectors and run the prediction program, as a result we get the category of this web page.</p>

          
        
      
    </div>

    

    
    
    

    

    
      
    
    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="https://schwimmer.github.io/2017/07/12/机器学习/用scikit-learn生成测试数据集/"/>

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Schwimmer"/>
      <meta itemprop="description" content="Record and Think!"/>
      <meta itemprop="image" content="/images/avatar.gif"/>
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Schwimmer's Blog"/>
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                
                <a href="/2017/07/12/机器学习/用scikit-learn生成测试数据集/" class="post-title-link" itemprop="url">用scikit-learn生成测试数据集</a>
              
            
          </h1>
        

        <div class="post-meta">

          
          
          

          
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              

              
                
              

              <time title="创建时间：2017-07-12 11:49:53" itemprop="dateCreated datePublished" datetime="2017-07-12T11:49:53+08:00">2017-07-12</time>
            </span>
          

          
            

            
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="fa fa-calendar-check-o"></i>
                </span>
                
                  <span class="post-meta-item-text">更新于</span>
                
                <time title="修改时间：2018-07-04 23:22:59" itemprop="dateModified" datetime="2018-07-04T23:22:59+08:00">2018-07-04</time>
              </span>
            
          

          
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing"><a href="/categories/机器学习/" itemprop="url" rel="index"><span itemprop="name">机器学习</span></a></span>

                
                
              
            </span>
          

          
            
            
              
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="fa fa-comment-o"></i>
                </span>
            
                <span class="post-meta-item-text">评论数：</span>
                <a href="/2017/07/12/机器学习/用scikit-learn生成测试数据集/#comments" itemprop="discussionUrl">
                  <span class="post-comments-count disqus-comment-count" data-disqus-identifier="2017/07/12/机器学习/用scikit-learn生成测试数据集/" itemprop="commentCount"></span>
                </a>
              </span>
            
          

          
          

          

          <br/>
          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>转自<a href="https://www.jiqizhixin.com/articles/2018-02-05-2" target="_blank" rel="noopener">https://www.jiqizhixin.com/articles/2018-02-05-2</a></p>
<h1 id="分类测试问题"><a href="#分类测试问题" class="headerlink" title="分类测试问题"></a>分类测试问题</h1><p>将看三个分类问题：blobs、moons 和 circles。</p>
<h2 id="线性分类"><a href="#线性分类" class="headerlink" title="线性分类"></a>线性分类</h2><p> make_blobs() 函数可被用于生成具有高斯分布的 blobs 点。你可以控制生成 blobs 的数量，生成样本的数量以及一系列其他属性。考虑到 blobs 的线性可分性质，该问题也适用于线性分类问题。</p>
<p>下面的例子是一个多类分类预测问题，它生成了一个具有三个 blobs 的 2D 样本数据集。每个数据有两个输入和 0、1 或 2 个类的值。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">from</span> sklearn.datasets.samples_generator <span class="keyword">import</span> make_blobs</div><div class="line"><span class="keyword">from</span> matplotlib <span class="keyword">import</span> pyplot</div><div class="line"><span class="keyword">from</span> pandas <span class="keyword">import</span> DataFrame</div><div class="line"><span class="comment"># generate 2d classification dataset</span></div><div class="line">X, y = make_blobs(n_samples=<span class="number">100</span>, centers=<span class="number">3</span>, n_features=<span class="number">2</span>)</div><div class="line"><span class="comment"># dict中定义三个key，分别是坐标和label，再通过dict创建DataFrame</span></div><div class="line">df = DataFrame(dict(x=X[:,<span class="number">0</span>], y=X[:,<span class="number">1</span>], label=y))</div><div class="line">colors = &#123;<span class="number">0</span>:<span class="string">'red'</span>, <span class="number">1</span>:<span class="string">'blue'</span>, <span class="number">2</span>:<span class="string">'green'</span>&#125;</div><div class="line">fig, ax = pyplot.subplots()</div><div class="line"><span class="comment">#groupby可以通过传入需要分组的参数实现对数据的分组</span></div><div class="line">grouped = df.groupby(<span class="string">'label'</span>)</div><div class="line"><span class="keyword">for</span> key, group <span class="keyword">in</span> grouped:</div><div class="line">   group.plot(ax=ax, kind=<span class="string">'scatter'</span>, x=<span class="string">'x'</span>, y=<span class="string">'y'</span>, label=key, color=colors[key])</div><div class="line">pyplot.show()</div></pre></td></tr></table></figure>
<h2 id="非线性分类"><a href="#非线性分类" class="headerlink" title="非线性分类"></a>非线性分类</h2><p>make_moons() 函数用于二进制分类并且将生成一个漩涡模式，或者两个 moons。你可以控制 moon 形状中的噪声量，以及要生产的样本数量。</p>
<p>这个测试问题适用于能够学习非线性类边界的算法。下面的例子生成了一个中等噪音的 moon 数据集。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">from</span> sklearn.datasets <span class="keyword">import</span> make_moons</div><div class="line"><span class="keyword">from</span> matplotlib <span class="keyword">import</span> pyplot</div><div class="line"><span class="keyword">from</span> pandas <span class="keyword">import</span> DataFrame</div><div class="line"><span class="comment"># generate 2d classification dataset</span></div><div class="line">X, y = make_moons(n_samples=<span class="number">100</span>, noise=<span class="number">0.1</span>)</div><div class="line"><span class="comment"># scatter plot, dots colored by class value</span></div><div class="line">df = DataFrame(dict(x=X[:,<span class="number">0</span>], y=X[:,<span class="number">1</span>], label=y))</div><div class="line">colors = &#123;<span class="number">0</span>:<span class="string">'red'</span>, <span class="number">1</span>:<span class="string">'blue'</span>&#125;</div><div class="line">fig, ax = pyplot.subplots()</div><div class="line">grouped = df.groupby(<span class="string">'label'</span>)</div><div class="line"><span class="keyword">for</span> key, group <span class="keyword">in</span> grouped:</div><div class="line">   group.plot(ax=ax, kind=<span class="string">'scatter'</span>, x=<span class="string">'x'</span>, y=<span class="string">'y'</span>, label=key, color=colors[key])</div><div class="line">pyplot.show()</div></pre></td></tr></table></figure>
<p>make_circles() 函数生成一个数据集落入同心圆的二进制分类问题。再一次地，与 moons 测试问题一样，你可以控制形状中的噪声量。该测试问题适用于可以学习复杂的非线性流行的算法。下面的例子中生成了一个具有一定噪音的 circles 数据集。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">from</span> sklearn.datasets <span class="keyword">import</span> make_circles</div><div class="line"><span class="keyword">from</span> matplotlib <span class="keyword">import</span> pyplot</div><div class="line"><span class="keyword">from</span> pandas <span class="keyword">import</span> DataFrame</div><div class="line"><span class="comment"># generate 2d classification dataset</span></div><div class="line">X, y = make_circles(n_samples=<span class="number">100</span>, noise=<span class="number">0.05</span>)</div><div class="line"><span class="comment"># scatter plot, dots colored by class value</span></div><div class="line">df = DataFrame(dict(x=X[:,<span class="number">0</span>], y=X[:,<span class="number">1</span>], label=y))</div><div class="line">colors = &#123;<span class="number">0</span>:<span class="string">'red'</span>, <span class="number">1</span>:<span class="string">'blue'</span>&#125;</div><div class="line">fig, ax = pyplot.subplots()</div><div class="line">grouped = df.groupby(<span class="string">'label'</span>)</div><div class="line"><span class="keyword">for</span> key, group <span class="keyword">in</span> grouped:</div><div class="line">   group.plot(ax=ax, kind=<span class="string">'scatter'</span>, x=<span class="string">'x'</span>, y=<span class="string">'y'</span>, label=key, color=colors[key])</div><div class="line">pyplot.show()</div></pre></td></tr></table></figure>
<h1 id="回归测试问题"><a href="#回归测试问题" class="headerlink" title="回归测试问题"></a>回归测试问题</h1><h2 id="线性回归"><a href="#线性回归" class="headerlink" title="线性回归"></a>线性回归</h2><p>make_regression() 函数将创建一个输入和输出具有线性关系的数据集。你可以配置样本数量，输入特征数量，噪声级别等等。该数据集适用于可以学习线性回归函数的算法。</p>
<p>下面的例子将生成 100 个示例，他们具有适度的噪声，都有一个输入特征和一个输出特征。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">from</span> sklearn.datasets <span class="keyword">import</span> make_regression</div><div class="line"><span class="keyword">from</span> matplotlib <span class="keyword">import</span> pyplot</div><div class="line"><span class="comment"># generate regression dataset</span></div><div class="line">X, y = make_regression(n_samples=<span class="number">100</span>, n_features=<span class="number">1</span>, noise=<span class="number">0.1</span>)</div><div class="line"><span class="comment"># plot regression dataset</span></div><div class="line">pyplot.scatter(X,y)</div><div class="line">pyplot.show()</div></pre></td></tr></table></figure>
<p>通过这些测试集可以：</p>
<ul>
<li><strong>比较算法</strong>。选择一个测试问题，并比较该问题的一系列算法并汇报性能。</li>
<li><strong>放大问题</strong>。选择一个测试问题并探索将其放大，用级数法来可视化结果，也可以探索一个特定算法模型技能和问题规模。</li>
</ul>
<p>代码见<code>blogcodes\sclearn_testDataset.py</code></p>

          
        
      
    </div>

    

    
    
    

    

    
      
    
    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="https://schwimmer.github.io/2017/07/12/工具和环境/vim命令/"/>

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Schwimmer"/>
      <meta itemprop="description" content="Record and Think!"/>
      <meta itemprop="image" content="/images/avatar.gif"/>
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Schwimmer's Blog"/>
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                
                <a href="/2017/07/12/工具和环境/vim命令/" class="post-title-link" itemprop="url">vim命令</a>
              
            
          </h1>
        

        <div class="post-meta">

          
          
          

          
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              

              
                
              

              <time title="创建时间：2017-07-12 11:49:53" itemprop="dateCreated datePublished" datetime="2017-07-12T11:49:53+08:00">2017-07-12</time>
            </span>
          

          
            

            
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="fa fa-calendar-check-o"></i>
                </span>
                
                  <span class="post-meta-item-text">更新于</span>
                
                <time title="修改时间：2018-01-30 16:39:52" itemprop="dateModified" datetime="2018-01-30T16:39:52+08:00">2018-01-30</time>
              </span>
            
          

          
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing"><a href="/categories/工具和环境/" itemprop="url" rel="index"><span itemprop="name">工具和环境</span></a></span>

                
                
              
            </span>
          

          
            
            
              
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="fa fa-comment-o"></i>
                </span>
            
                <span class="post-meta-item-text">评论数：</span>
                <a href="/2017/07/12/工具和环境/vim命令/#comments" itemprop="discussionUrl">
                  <span class="post-comments-count disqus-comment-count" data-disqus-identifier="2017/07/12/工具和环境/vim命令/" itemprop="commentCount"></span>
                </a>
              </span>
            
          

          
          

          

          <br/>
          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1 id="查找并删除"><a href="#查找并删除" class="headerlink" title="查找并删除"></a>查找并删除</h1><p>:g/要删除的内容/d</p>
<p>查找</p>
<p>/要查找的</p>
<p>按n就是下一个</p>
<p>删除一行</p>
<p>dd</p>
<p>查找匹配的个数</p>
<p>:%s/refering_site/&amp;/gn</p>
<p>或</p>
<p>:%s/17779//gn</p>
<p>:%s/“opxcreativeid”:16650//gn</p>
<h1 id="查找并替换"><a href="#查找并替换" class="headerlink" title="查找并替换"></a>查找并替换</h1><p>%s/源字符串/目的字符串/g</p>
<p>如</p>
<p>:%s/\/home\/weinan/\/opt\/pig_home\/bshare_etl/g</p>
<p>:%s/gpadmin/gpxmo/g</p>
<p>:%s/\t-1/\t1/g</p>
<p>:%s/“//g</p>
<p>:%s/16-06-28/16-06-29/g</p>
<h1 id="多行变1行"><a href="#多行变1行" class="headerlink" title="多行变1行"></a>多行变1行</h1><p>大写V选中行+shift J</p>
<h1 id="替换每行的行首、行尾"><a href="#替换每行的行首、行尾" class="headerlink" title="替换每行的行首、行尾"></a>替换每行的行首、行尾</h1><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">:1,$ s/^/HELLO/g</div><div class="line">:1,$ s/$/WORLD/g</div></pre></td></tr></table></figure>
<h1 id="sh文件的编码转成unix"><a href="#sh文件的编码转成unix" class="headerlink" title="sh文件的编码转成unix"></a>sh文件的编码转成unix</h1><p>查看用<code>:set fileformat</code></p>
<p>修改用<code>:set fileformat=unix</code></p>
<h1 id="编码从latin1转成utf8"><a href="#编码从latin1转成utf8" class="headerlink" title="编码从latin1转成utf8"></a>编码从latin1转成utf8</h1><p>:e ++enc=cp936<br>:set fileencoding=utf-8</p>

          
        
      
    </div>

    

    
    
    

    

    
      
    
    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="https://schwimmer.github.io/2017/07/12/机器学习/计算广告/广告反作弊/"/>

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Schwimmer"/>
      <meta itemprop="description" content="Record and Think!"/>
      <meta itemprop="image" content="/images/avatar.gif"/>
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Schwimmer's Blog"/>
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                
                <a href="/2017/07/12/机器学习/计算广告/广告反作弊/" class="post-title-link" itemprop="url">广告反作弊</a>
              
            
          </h1>
        

        <div class="post-meta">

          
          
          

          
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              

              
                
              

              <time title="创建时间：2017-07-12 11:49:53" itemprop="dateCreated datePublished" datetime="2017-07-12T11:49:53+08:00">2017-07-12</time>
            </span>
          

          
            

            
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="fa fa-calendar-check-o"></i>
                </span>
                
                  <span class="post-meta-item-text">更新于</span>
                
                <time title="修改时间：2018-03-17 20:50:31" itemprop="dateModified" datetime="2018-03-17T20:50:31+08:00">2018-03-17</time>
              </span>
            
          

          
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing"><a href="/categories/计算广告/" itemprop="url" rel="index"><span itemprop="name">计算广告</span></a></span>

                
                
              
            </span>
          

          
            
            
              
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="fa fa-comment-o"></i>
                </span>
            
                <span class="post-meta-item-text">评论数：</span>
                <a href="/2017/07/12/机器学习/计算广告/广告反作弊/#comments" itemprop="discussionUrl">
                  <span class="post-comments-count disqus-comment-count" data-disqus-identifier="2017/07/12/机器学习/计算广告/广告反作弊/" itemprop="commentCount"></span>
                </a>
              </span>
            
          

          
          

          

          <br/>
          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>秒针发布过《互联网广告反作弊技术白皮书》</p>
<p>腾讯灯塔联手秒针、AdMaster发布</p>
<h1 id="腾讯《2017广告反欺诈白皮书》"><a href="#腾讯《2017广告反欺诈白皮书》" class="headerlink" title="腾讯《2017广告反欺诈白皮书》"></a>腾讯《2017广告反欺诈白皮书》</h1><p>日均校验40亿广告请求，识别的作弊比率在15%左右。部分行业和campaign中，作弊率有60%。</p>
<h2 id="欺诈手段"><a href="#欺诈手段" class="headerlink" title="欺诈手段"></a>欺诈手段</h2><ul>
<li>虚假流量。</li>
</ul>
<p>某APP在地推时，新增用户暴涨。95%的新增用户的共同特征：</p>
<p><strong>ROM编译机名称一致；指令逃逸差异数与正常用户不一致；CPU结构为X86，为PC机模拟器；文件系统类型的差异度与正常用户不一致</strong>。</p>
<p>某APP的新增用户中，工作室批量刷量的特征有：</p>
<p><strong>安装时间具有明显的规律；手机APP安装数量一致；明显的地域集中性</strong>。</p>
<p>2.2 黑产技术</p>
<p>1、广告作弊类型分类</p>
<p>1）模拟器刷量：电脑模拟器刷量、手机软件模拟刷量、脚本刷量（录制行为跑循环任务）。</p>
<p>2）真假机用户：储备大量手机或者sim卡，利用数据线push命令到手机，手机执行命令。</p>
<p>3）静默安装（真机真用户假行为）。人工方式或网络传播方式将木马/具有再分发能力的应用植入到用户手机，形成僵尸网络，在用户无感知的情况下，完成App的下载、激活和删除等一系列操作。</p>
<p>4）羊毛党（真机真用户真行为假动机）：登录一次就删除应用、使用时长极短、留存率极低。在大部份的情况下，这种用户对业务的健康发展并无太大价值。</p>
<p>5）广告素材、篇幅偷换（不可见）。“1 像素广告”指在用户的手机屏幕上只展示1个像素大小的广告。这种广告，用户看不见，但统计工具可以统计到，仍然会作为曝光广告与广告主结算，给广告主带来经济损失。</p>
<p>6）以次充好（不匹配）。部分媒体会将广告主原本定向的一线城市用户偷偷换成二三线城市用户，达到以次充好的目的。</p>
<h2 id="应对方法"><a href="#应对方法" class="headerlink" title="应对方法"></a>应对方法</h2><p>2.3 反作弊技术</p>
<p>1）用户群体数据检测。低阶技术，常见方式有：</p>
<p><strong>a.看留存率</strong>。真实的用户的留存曲线是一条平滑的指数衰减曲线，如果发现留存曲线存在陡升陡降的异常波动，则判断刷量者干预了数据。</p>
<p><strong>b.看用户终端、网络信息</strong>。如根据经验分析渠道新增用户或者启动用户的设备排名;2G、3G、4G的使用比例分布是否正常等。</p>
<p><strong>c.看用户注册信息</strong>。比如说注册昵称的分布和规律等。</p>
<p>以上操作均效率低下。</p>
<p>2）用户行为特征分析</p>
<p><strong>a.单个指标</strong>。与黑IP库进行比对，是否为黑名单IP、是否为代理IP;与IMEI库进行对比，是否为为黑IMEI;</p>
<p><strong>b.群体指标</strong>。用户的IP、IMEI、机型、OS、位置信息、运营商、接入方式的<strong>分布</strong>是否符合先验数据的分布</p>
<p><strong>c.设备一致性验证</strong>。CPU、制造商、MAC地址、IMEI、机型、操作系统的一致性验证。</p>
<p>简单粗暴，没有黑白转换机制，误判率高。</p>
<p><strong>这些方法容易被刷量者利用</strong>。在某电商专业Android app游戏激活、注册、留存、付费、应用市场好评平台上，买主只需要很小的代价，即可刷出完全符合正常用户规律的留存率、IP分布机型分布使用时长等。</p>
<p>3）终端特征分析+云端交叉验证</p>
<p>“查”模型负责找寻黑产界的新型作弊方式，提升整体模型的覆盖率</p>
<p>“杀”模型负责准确识别恶意份子</p>
<p>“验”模型通过多业务交叉验证，负责保证“查”、“杀”模型的准确率</p>
<p><strong>终端识别模块</strong>（灯塔SDK稽核模块）:该模块主要是采用机器学习算法选取系统中所有可用的信息作为特征，然后对这些特征进行运算得到该<strong>设备的指纹，</strong>可以有效识别手机模拟器、修改系统参数等行为。</p>
<p><strong>基于规则的识别模块</strong>（业务自有模块）:该模块一般是通过业务经验及对历史可疑渠道的总结形成的<strong>反作弊规则</strong>，可以理解为多维组合规则，一般需根据业务成本、对渠道的容忍度<strong>设置关键变量的阈值</strong>。</p>
<p><strong>基于数据挖掘的识别模块</strong>（灯塔云端模块）:该模块主要从硬件信息、用户活跃、用户行为进行多维度、多业务交叉验证，分别计算每个维度下面的不同特征值，结合决策树、LR、贝叶斯网络等多种算法进行精准的定位。<strong>分类</strong></p>
<p>为了增强识别的准确性和稳定性，模块之间、模块内部均采用集成学习方法的思想，其核心思想是在模块内对同一个训练集训练不同的分类器，然后把这些分类器结合起来构成一个最终的分类器，而每一个模块可以针对不同的作弊手段进行识别，再把模块与模块结合，才能识别所有的作弊手段。    </p>
<h1 id="admaster《广告反欺诈研究报告》2016"><a href="#admaster《广告反欺诈研究报告》2016" class="headerlink" title="admaster《广告反欺诈研究报告》2016"></a>admaster《广告反欺诈研究报告》2016</h1><p>今年 1 月 29 日和 3 月 2 日,宝洁公司首席品牌官 Marc Pritchard 分别在美国互动广告局(Interactive<br>Advertising Bureau, IAB)和美国广告主协会(Association of National Advertisers, ANA)两个年度<br>重要峰会上进行主题发言,针对数字广告透明度和可见性标准的言论引发了全球营销圈和数字行业的热议。<br>宝洁呼吁业界在四个方面采取行动:</p>
<ol>
<li>数字广告采纳一套统一的可见性测量标准;</li>
<li>贯彻第三方测评机构</li>
</ol>
<p>的验证审核;</p>
<ol>
<li>提倡全面透明的代理公司合同机制;</li>
<li>预防广告欺诈。</li>
</ol>
<p>AdMaster先后推出了 BlueAir、定投识别 (VOA)、监播实录 (SNAP) 等技术产品,逐步建立了“全方位、深层次、多角度”的广告反欺诈解决方案。尤其在程序化购买中,AdMaster 在投放前预判 (Pre-bid),即事前广告反欺诈技术。</p>
<p><strong>BlueAir</strong>可以对智能电视IP、地域、频次以及User Agent等维度的异常流量进行甄别，将行为逻辑上不正常的设备加入黑名单，从而保障广告投放的安全。同时，与海信、康佳、创维、欢网等硬件厂家共同建立智能电视设备白名单，以便从设备维度进一步甄别流量真实性。</p>
<p><strong>定投识别</strong></p>
<p><strong>监播实录</strong></p>
<p><strong>投放前预判</strong>。在流量请求、广告未展现时,根据历史流量质量进行排查,从而提前避免广告在无效流量上的投放。</p>
<h2 id="无效流量类型"><a href="#无效流量类型" class="headerlink" title="无效流量类型"></a>无效流量类型</h2><p>1、广告可见性问题引发的低质量流量</p>
<p>目前媒体的环境导致广告不易可见。AdMaster 在 AdServing 广告投放管理技术上能够实现广告可见性的预估判断。在多种广告形式的后测方面,通过独创的模型评估广告可见性表现。</p>
<p>2、机器人无效流量（Non-Human Traffic）</p>
<p>从最初的 cookie 和 IP不变的前提下,反复刷新页面和点击广告,造成广告曝光和点击的增加,到通过木马或者恶意程序控制海量人肉刷机、伪造大量 IP 与设备信息进行模拟访问、或将 IP 和 cookie、User Agent 一起进行轮替的流量造假方式,都属于机器人无效流量。</p>
<p><strong>BlueAir</strong> 广告反欺诈技术能够结合历史异常数据,能够在流量请求、广告未展现时,即根据历史流量质量判断此流量的质量,在投放前通过 <strong>Pre-bid</strong> 判断出流量的异常,杜绝流量造假现象发生。</p>
<p>3、视频类无效流量</p>
<p>(1)针对剧目投偏现象,AdMaster <strong>定投识别</strong> (VOA) 功能通过 Referrer/ 剧目 ID 等方式解析 广告曝光时所<br><strong>播放剧目名称</strong>,并与广告主定投的剧目内容进行匹配。在移动端定投评估中,高诚信度的视频媒体也提供高度<br>配合。剧目投偏比例,一目了然。</p>
<p>(2)针对时有发生的曝光代码调用,但是素材未正确展示的广告欺诈现象,AdMaster 利用<strong>监播实录</strong> (SNAP)<br>功能,采用类似于“神秘访客”概念的方法从海量抽样监测,将视频内容播放前的所有贴片内容录制下来,并<br>通过图像识别与适当的素材进行对比,判断素材是否被正确展示,以及是否按照要求展示。</p>
<p>4、智能电视无效流量</p>
<p>支持智能电视广告的监测模式一般有 3 种 : 分别是第三方 SDK 监测、C2S 和 S2S 两种 API。前两种相比 S2S 更为安全,也更容易监测流量异常情况,可以说 C2S API 是智能电视广告监测安全的起点和基础(S2S API 传输方式目前很难识别无效流量)。</p>
<h1 id="inmobi《移动广告反作弊白皮书》"><a href="#inmobi《移动广告反作弊白皮书》" class="headerlink" title="inmobi《移动广告反作弊白皮书》"></a>inmobi《移动广告反作弊白皮书》</h1><p>没技术</p>
<p>反作弊措施</p>
<p>1）剔除自动流量。</p>
<p>识别机器人脚本，分析展示和点击的质量。</p>
<p>2）数据信号双重检测。</p>
<p>将媒体共享的人群信息和从SDK收集的信息比对，对所有无效信息定位和删除。</p>
<p>[部分有关 广告联盟作弊 与反作弊资料收集]（<a href="http://cwiki.apachecn.org/pages/viewpage.action?pageId=4882639）" target="_blank" rel="noopener">http://cwiki.apachecn.org/pages/viewpage.action?pageId=4882639）</a></p>
<p>roadmap中，AD fraud的业界措施</p>
<p>监控广告投放的效果；</p>
<p>保存曝光设备的ip</p>
<p>记录用户在landing页的行为</p>
<p>网页分析</p>
<p><strong>基于数据挖掘的识别模块</strong>（灯塔云端模块）:该模块主要从硬件信息、用户活跃、用户行为进行多维度、多业务交叉验证，分别计算每个维度下面的不同特征值，结合决策树、LR、贝叶斯网络等多种算法进行精准的定位。为了增强识别的准确性和稳定性，模块之间、模块内部均采用集成学习方法的思想，其核心思想是在模块内对同一个训练集训练不同的分类器，然后把这些分类器结合起来构成一个最终的分类器，而每一个模块可以针对不同的作弊手段进行识别，再把模块与模块结合，才能识别所有的作弊手段。</p>
<p>这个方法未来肯定要实现的，大致是通过集成学习的方式，综合硬件信息，网页特征，用户行为</p>
<p>最初我们只有url信息，提取url的特征判断投放的网页是否安全；</p>
<p>后面对每条</p>
<p>前期，通过分析url内容，判断网页是否安全，是否为虚假网页，网页内容与广告品牌是否有冲突。</p>
<p>后面，分析曝光的详细信息，包括设备信息，用户特征，判断是否为作弊流量；分析网页元素和广告位置，判断广告可见性。</p>
<p>再后面，在对url和黑名单有一定积累的基础上，在投放或竞价前检测投放环境，主动识别和屏蔽非安全流量</p>

          
        
      
    </div>

    

    
    
    

    

    
      
    
    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="https://schwimmer.github.io/2017/07/12/机器学习/集成学习/"/>

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Schwimmer"/>
      <meta itemprop="description" content="Record and Think!"/>
      <meta itemprop="image" content="/images/avatar.gif"/>
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Schwimmer's Blog"/>
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                
                <a href="/2017/07/12/机器学习/集成学习/" class="post-title-link" itemprop="url">集成学习</a>
              
            
          </h1>
        

        <div class="post-meta">

          
          
          

          
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              

              
                
              

              <time title="创建时间：2017-07-12 11:49:53" itemprop="dateCreated datePublished" datetime="2017-07-12T11:49:53+08:00">2017-07-12</time>
            </span>
          

          
            

            
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="fa fa-calendar-check-o"></i>
                </span>
                
                  <span class="post-meta-item-text">更新于</span>
                
                <time title="修改时间：2018-08-16 16:41:49" itemprop="dateModified" datetime="2018-08-16T16:41:49+08:00">2018-08-16</time>
              </span>
            
          

          
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing"><a href="/categories/机器学习/" itemprop="url" rel="index"><span itemprop="name">机器学习</span></a></span>

                
                
              
            </span>
          

          
            
            
              
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="fa fa-comment-o"></i>
                </span>
            
                <span class="post-meta-item-text">评论数：</span>
                <a href="/2017/07/12/机器学习/集成学习/#comments" itemprop="discussionUrl">
                  <span class="post-comments-count disqus-comment-count" data-disqus-identifier="2017/07/12/机器学习/集成学习/" itemprop="commentCount"></span>
                </a>
              </span>
            
          

          
          

          

          <br/>
          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>个体学习器一般是弱学习器。</p>
<blockquote>
<p> 弱学习器是指泛华性能略优于随机猜测的学习器，例如二分上略高于50%的学习器。</p>
</blockquote>
<p>要获得好的集成，个体学习器应“好而不同”，即个体学习器要有一定的<strong>准确性和多样性</strong>（学习器之间有差异）。</p>
<p>理论上，假设个体学习器的误差是相互独立，那么随着学习器数量增大，集成的错误率将指数下降，最终趋向于零。</p>
<p>但实际上不可能相互独立。且<strong>准确性和多样性本身就是矛盾的</strong>，追求准确性就要牺牲多样性。所以<strong>如何产生并结合“好而不同”的学习器，是集成学习研究的核心</strong>。</p>
<p>根据集成的方式不同，</p>
<p>1）个体学习器存在强依赖性，必须串行生成，如Boosting；</p>
<p>2）个体学习器间不存在强依赖关系，可同时并行生成，如Bagging和随机森林。</p>
<h1 id="mic或stacking方法"><a href="#mic或stacking方法" class="headerlink" title="mic或stacking方法"></a>mic或stacking方法</h1><p><a href="https://blog.csdn.net/sb19931201/article/details/56315689?locationNum=1&amp;fps=1" target="_blank" rel="noopener">https://blog.csdn.net/sb19931201/article/details/56315689?locationNum=1&amp;fps=1</a> 从这篇帖子来</p>
<p><a href="https://blog.csdn.net/a358463121/article/details/53054686#t18" target="_blank" rel="noopener">https://blog.csdn.net/a358463121/article/details/53054686#t18</a></p>
<p><a href="https://zhuanlan.zhihu.com/jlbookworm" target="_blank" rel="noopener">https://zhuanlan.zhihu.com/jlbookworm</a></p>
<p><a href="https://blog.csdn.net/wstcjf/article/details/77989963" target="_blank" rel="noopener">https://blog.csdn.net/wstcjf/article/details/77989963</a> 文章的思路有点问题？</p>
<p><a href="https://blog.csdn.net/xiaoliuzz/article/details/79298841" target="_blank" rel="noopener">https://blog.csdn.net/xiaoliuzz/article/details/79298841</a></p>
<p><a href="https://blog.csdn.net/yc1203968305/article/details/73526615" target="_blank" rel="noopener">https://blog.csdn.net/yc1203968305/article/details/73526615</a></p>
<p><a href="https://www.cnblogs.com/zhizhan/p/5051881.html" target="_blank" rel="noopener">https://www.cnblogs.com/zhizhan/p/5051881.html</a></p>
<p><a href="https://mlwave.com/kaggle-ensembling-guide/" target="_blank" rel="noopener">https://mlwave.com/kaggle-ensembling-guide/</a></p>
<h1 id="Stacking"><a href="#Stacking" class="headerlink" title="Stacking"></a>Stacking</h1><p><a href="http://tech.ifeng.com/a/20170929/44704115_0.shtml" target="_blank" rel="noopener">Kaggle机器学习之模型融合（stacking）心得</a></p>
<p><a href="https://www.kaggle.com/arthurtok/introduction-to-ensembling-stacking-in-python" target="_blank" rel="noopener">Introduction to Ensembling/Stacking in Python</a> </p>
<p><a href="https://www.kdnuggets.com/2017/02/stacking-models-imropved-predictions.html" target="_blank" rel="noopener">Stacking Models for Improved Predictions</a></p>
<h2 id="使用sklearn进行集成学习——理论"><a href="#使用sklearn进行集成学习——理论" class="headerlink" title="使用sklearn进行集成学习——理论"></a><a href="https://www.cnblogs.com/jasonfreak/p/5657196.html" target="_blank" rel="noopener">使用sklearn进行集成学习——理论</a></h2><p>1 前言<br>2 集成学习是什么？<br>3 偏差和方差<br>　　3.1 模型的偏差和方差是什么？<br>　　3.2 bagging的偏差和方差<br>　　3.3 boosting的偏差和方差<br>　　3.4 模型的独立性<br>　　3.5 小结<br>4 Gradient Boosting<br>　　4.1 拟合残差<br>　　4.2 拟合反向梯度<br>　　　　4.2.1 契机：引入损失函数<br>　　　　4.2.2 难题一：任意损失函数的最优化<br>　　　　4.2.3 难题二：无法对测试样本计算反向梯度<br>　　4.3 常见的损失函数<br>　　4.4 步子太大容易扯着蛋：缩减<br>　　4.5 初始模型<br>　　4.5 Gradient Tree Boosting<br>　　4.6 小结<br>5 总结<br>6 参考资料</p>
<hr>
<h1 id="1-前言"><a href="#1-前言" class="headerlink" title="1 前言"></a>1 前言</h1><p>　　很多人在竞赛（Kaggle，天池等）或工程实践中使用了集成学习（例如，RF、GTB等），确实也取得了不错的效果，在保证准确度的同时也提升了模型防止过拟合的能力。但是，我们真的用对了集成学习吗？</p>
<p>　　sklearn提供了sklearn.ensemble库，支持众多集成学习算法和模型。恐怕大多数人使用这些工具时，要么使用默认参数，要么根据模型在测试集上的性能试探性地进行调参（当然，完全不懂的参数还是不动算了），要么将调参的工作丢给调参算法（网格搜索等）。这样并不能真正地称为“会”用sklearn进行集成学习。</p>
<p>　　我认为，学会调参是进行集成学习工作的前提。然而，第一次遇到这些算法和模型时，肯定会被其丰富的参数所吓到，要知道，教材上教的伪代码可没这么多参数啊！！！没关系，暂时，我们只要记住一句话：参数可分为两种，一种是影响模型在训练集上的准确度或影响防止过拟合能力的参数；另一种不影响这两者的其他参数。模型在样本总体上的准确度（后简称准确度）由其在训练集上的准确度及其防止过拟合的能力所共同决定，所以在调参时，我们主要对第一种参数进行调整，最终达到的效果是：模型在训练集上的准确度和防止过拟合能力的大和谐！</p>
<p>　　本篇博文将详细阐述模型参数背后的理论知识，在下篇博文中，我们将对最热门的两个模型Random Forrest和Gradient Tree Boosting（含分类和回归，所以共4个模型）进行具体的参数讲解。如果你实在无法静下心来学习理论，你也可以在下篇博文中找到最直接的调参指导，虽然我不赞同这么做。</p>
<hr>
<h1 id="2-集成学习是什么？"><a href="#2-集成学习是什么？" class="headerlink" title="2 集成学习是什么？"></a>2 集成学习是什么？</h1><p>　　我们还是花一点时间来说明一下集成学习是什么，如果对此有一定基础的同学可以跳过本节。简单来说，集成学习是一种技术框架，其按照不同的思路来组合基础模型，从而达到其利断金的目的。</p>
<p>　　目前，有三种常见的集成学习框架：bagging，boosting和stacking。国内，南京大学的周志华教授对集成学习有很深入的研究，其在09年发表的一篇概述性论文<a href="http://cs.nju.edu.cn/zhouzh/zhouzh.files/publication/springerEBR09.pdf" target="_blank" rel="noopener">《</a><a href="http://cs.nju.edu.cn/zhouzh/zhouzh.files/publication/springerEBR09.pdf" target="_blank" rel="noopener">Ensemble Learning》</a>对这三种集成学习框架有了明确的定义，概括如下：</p>
<p> 　　bagging：从训练集从进行子抽样组成每个基模型所需要的子训练集，对所有基模型预测的结果进行综合产生最终的预测结果：</p>
<p><img src="https://images2015.cnblogs.com/blog/927391/201607/927391-20160717135005498-1140287801.jpg" alt="img"></p>
<p>　　boosting：训练过程为阶梯状，基模型按次序一一进行训练（实现上可以做到并行），基模型的训练集按照某种策略每次都进行一定的转化。对所有基模型预测的结果进行线性综合产生最终的预测结果：</p>
<p><img src="https://images2015.cnblogs.com/blog/927391/201607/927391-20160717135023373-1810846145.jpg" alt="img"></p>
<p>　　stacking：将训练好的所有基模型对训练基进行预测，第j个基模型对第i个训练样本的预测值将作为新的训练集中第i个样本的第j个特征值，最后基于新的训练集进行训练。同理，预测的过程也要先经过所有基模型的预测形成新的测试集，最后再对测试集进行预测：</p>
<p><img src="https://images2015.cnblogs.com/blog/927391/201607/927391-20160716073722420-208134951.jpg" alt="img"></p>
<p>　　有了这些基本概念之后，直觉将告诉我们，由于不再是单一的模型进行预测，所以模型有了“集思广益”的能力，也就不容易产生过拟合现象。但是，直觉是不可靠的，接下来我们将从模型的偏差和方差入手，彻底搞清楚这一问题。</p>
<hr>
<h1 id="3-偏差和方差"><a href="#3-偏差和方差" class="headerlink" title="3 偏差和方差"></a>3 偏差和方差</h1><p>　　广义的偏差（bias）描述的是预测值和真实值之间的差异，方差（variance）描述距的是预测值作为随机变量的离散程度。<a href="http://scott.fortmann-roe.com/docs/BiasVariance.html" target="_blank" rel="noopener">《Understanding the Bias-Variance Tradeoff》</a>当中有一副图形象地向我们展示了偏差和方差的关系：</p>
<p><img src="https://images2015.cnblogs.com/blog/927391/201607/927391-20160716124330623-527064401.jpg" alt="img"></p>
<h2 id="3-1-模型的偏差和方差是什么？"><a href="#3-1-模型的偏差和方差是什么？" class="headerlink" title="3.1 模型的偏差和方差是什么？"></a>3.1 模型的偏差和方差是什么？</h2><p>　　模型的偏差是一个相对来说简单的概念：训练出来的模型在训练集上的准确度。</p>
<p>　　要解释模型的方差，首先需要重新审视模型：模型是随机变量。设样本容量为n的训练集为随机变量的集合(X1, X2, …, Xn)，那么模型是以这些随机变量为输入的随机变量函数（其本身仍然是随机变量）：F(X1, X2, …, Xn)。抽样的随机性带来了模型的随机性。</p>
<p>　　定义随机变量的值的差异是计算方差的前提条件，通常来说，我们遇到的都是数值型的随机变量，数值之间的差异再明显不过（减法运算）。但是，模型的差异性呢？我们可以理解模型的差异性为模型的结构差异，例如：线性模型中权值向量的差异，树模型中树的结构差异等。在研究模型方差的问题上，我们并不需要对方差进行定量计算，只需要知道其概念即可。</p>
<p>　　研究模型的方差有什么现实的意义呢？我们认为方差越大的模型越容易过拟合：假设有两个训练集A和B，经过A训练的模型Fa与经过B训练的模型Fb差异很大，这意味着Fa在类A的样本集合上有更好的性能，而Fb反之，这便是我们所说的过拟合现象。</p>
<p>　　我们常说集成学习框架中的基模型是弱模型，通常来说弱模型是偏差高（在训练集上准确度低）方差小（防止过拟合能力强）的模型。但是，并不是所有集成学习框架中的基模型都是弱模型。bagging和stacking中的基模型为强模型（偏差低方差高），boosting中的基模型为弱模型。</p>
<p>　　在bagging和boosting框架中，通过计算基模型的期望和方差，我们可以得到模型整体的期望和方差。为了简化模型，我们假设基模型的权重、方差及两两间的相关系数相等。由于bagging和boosting的基模型都是线性组成的，那么有：</p>
<p> <img src="https://images2015.cnblogs.com/blog/927391/201607/927391-20160716145131217-650617034.png" alt="img"></p>
<h2 id="3-2-bagging的偏差和方差"><a href="#3-2-bagging的偏差和方差" class="headerlink" title="3.2 bagging的偏差和方差"></a>3.2 bagging的偏差和方差</h2><p>　　对于bagging来说，每个基模型的权重等于1/m且期望近似相等（子训练集都是从原训练集中进行子抽样），故我们可以进一步化简得到：</p>
<p><img src="https://images2015.cnblogs.com/blog/927391/201607/927391-20160716145206701-383430284.png" alt="img"></p>
<p>　　根据上式我们可以看到，整体模型的期望近似于基模型的期望，这也就意味着整体模型的偏差和基模型的偏差近似。同时，整体模型的方差小于等于基模型的方差（当相关性为1时取等号），随着基模型数（m）的增多，整体模型的方差减少，从而防止过拟合的能力增强，模型的准确度得到提高。但是，模型的准确度一定会无限逼近于1吗？并不一定，当基模型数增加到一定程度时，方差公式第二项的改变对整体方差的作用很小，防止过拟合的能力达到极限，这便是准确度的极限了。另外，在此我们还知道了为什么bagging中的基模型一定要为强模型，否则就会导致整体模型的偏差度低，即准确度低。</p>
<p>　　Random Forest是典型的基于bagging框架的模型，其在bagging的基础上，进一步降低了模型的方差。Random Fores中基模型是树模型，在树的内部节点分裂过程中，不再是将所有特征，而是随机抽样一部分特征纳入分裂的候选项。这样一来，基模型之间的相关性降低，从而在方差公式中，第一项显著减少，第二项稍微增加，整体方差仍是减少。</p>
<h2 id="3-3-boosting的偏差和方差"><a href="#3-3-boosting的偏差和方差" class="headerlink" title="3.3 boosting的偏差和方差"></a>3.3 boosting的偏差和方差</h2><p>　　对于boosting来说，基模型的训练集抽样是强相关的，那么模型的相关系数近似等于1，故我们也可以针对boosting化简公式为：</p>
<p><img src="https://images2015.cnblogs.com/blog/927391/201607/927391-20160717142500264-1717908455.png" alt="img"></p>
<p>　　通过观察整体方差的表达式，我们容易发现，若基模型不是弱模型，其方差相对较大，这将导致整体模型的方差很大，即无法达到防止过拟合的效果。因此，boosting框架中的基模型必须为弱模型。</p>
<p>　　因为基模型为弱模型，导致了每个基模型的准确度都不是很高（因为其在训练集上的准确度不高）。随着基模型数的增多，整体模型的期望值增加，更接近真实值，因此，整体模型的准确度提高。但是准确度一定会无限逼近于1吗？仍然并不一定，因为训练过程中准确度的提高的主要功臣是整体模型在训练集上的准确度提高，而随着训练的进行，整体模型的方差变大，导致防止过拟合的能力变弱，最终导致了准确度反而有所下降。</p>
<p>　　基于boosting框架的Gradient Tree Boosting模型中基模型也为树模型，同Random Forrest，我们也可以对特征进行随机抽样来使基模型间的相关性降低，从而达到减少方差的效果。</p>
<h2 id="3-4-模型的独立性"><a href="#3-4-模型的独立性" class="headerlink" title="3.4 模型的独立性"></a>3.4 模型的独立性</h2><p>　　聪明的读者这时肯定要问了，如何衡量基模型的独立性？我们说过，抽样的随机性决定了模型的随机性，如果两个模型的训练集抽样过程不独立，则两个模型则不独立。这时便有一个天大的陷阱在等着我们：bagging中基模型的训练样本都是独立的随机抽样，但是基模型却不独立呢？</p>
<p>　　我们讨论模型的随机性时，抽样是针对于样本的整体。而bagging中的抽样是针对于训练集（整体的子集），所以并不能称其为对整体的独立随机抽样。那么到底bagging中基模型的相关性体现在哪呢？在知乎问答<a href="https://www.zhihu.com/question/26760839" target="_blank" rel="noopener">《为什么说bagging是减少variance，而boosting是减少bias?》</a>中请教用户<a href="https://www.zhihu.com/people/guo-ni-he" target="_blank" rel="noopener">“过拟合”</a>后，我总结bagging的抽样为两个过程：</p>
<ol>
<li>样本抽样：整体模型F(X1, X2, …, Xn)中各输入随机变量（X1, X2, …, Xn）对样本的抽样</li>
<li>子抽样：从整体模型F(X1, X2, …, Xn)中随机抽取若干输入随机变量成为基模型的输入随机变量</li>
</ol>
<p>　　假若在子抽样的过程中，两个基模型抽取的输入随机变量有一定的重合，那么这两个基模型对整体样本的抽样将不再独立，这时基模型之间便具有了相关性。</p>
<h2 id="3-5-小结"><a href="#3-5-小结" class="headerlink" title="3.5 小结"></a>3.5 小结</h2><p>　　还记得调参的目标吗：模型在训练集上的准确度和防止过拟合能力的大和谐！为此，我们目前做了一些什么工作呢？</p>
<ol>
<li>使用模型的偏差和方差来描述其在训练集上的准确度和防止过拟合的能力</li>
<li>对于bagging来说，整体模型的偏差和基模型近似，随着训练的进行，整体模型的方差降低</li>
<li>对于boosting来说，整体模型的初始偏差较高，方差较低，随着训练的进行，整体模型的偏差降低（虽然也不幸地伴随着方差增高），当训练过度时，因方差增高，整体模型的准确度反而降低</li>
<li>整体模型的偏差和方差与基模型的偏差和方差息息相关</li>
</ol>
<p>　　这下总算有点开朗了，那些让我们抓狂的参数，现在可以粗略地分为两类了：控制整体训练过程的参数和基模型的参数，这两类参数都在影响着模型在训练集上的准确度以及防止过拟合的能力。</p>
<hr>
<h1 id="4-Gradient-Boosting"><a href="#4-Gradient-Boosting" class="headerlink" title="4 Gradient Boosting"></a>4 Gradient Boosting</h1><p>　　对基于Gradient Boosting框架的模型的进行调试时，我们会遇到一个重要的概念：损失函数。在本节中，我们将把损失函数的“今生来世”讲个清楚！</p>
<p>　　基于boosting框架的整体模型可以用线性组成式来描述，其中h<a href="x">i</a>为基模型与其权值的乘积：</p>
<p><img src="https://images2015.cnblogs.com/blog/927391/201607/927391-20160717144731264-398372888.png" alt="img"></p>
<p>　　根据上式，整体模型的训练目标是使预测值F(x)逼近真实值y，也就是说要让每一个基模型的预测值逼近各自要预测的部分真实值。由于要同时考虑所有基模型，导致了整体模型的训练变成了一个非常复杂的问题。所以，研究者们想到了一个贪心的解决手段：每次只训练一个基模型。那么，现在改写整体模型为迭代式：</p>
<p><img src="https://images2015.cnblogs.com/blog/927391/201607/927391-20160717144844795-1514741556.png" alt="img"></p>
<p>　　这样一来，每一轮迭代中，只要集中解决一个基模型的训练问题：使F<a href="x">i</a>逼近真实值y。</p>
<h2 id="4-1-拟合残差"><a href="#4-1-拟合残差" class="headerlink" title="4.1 拟合残差"></a>4.1 拟合残差</h2><p>　　使F<a href="x">i</a>逼近真实值，其实就是使h<a href="x">i</a>逼近真实值和上一轮迭代的预测值F<a href="x">i-1</a>之差，即残差（y-F<a href="x">i-1</a>）。最直接的做法是构建基模型来拟合残差，在博文<a href="http://blog.csdn.net/w28971023/article/details/8240756" target="_blank" rel="noopener">《GBDT（MART） 迭代决策树入门教程 | 简介》</a>中，作者举了一个生动的例子来说明通过基模型拟合残差，最终达到整体模型F(x)逼近真实值。</p>
<p>　　研究者发现，残差其实是最小均方损失函数的关于预测值的反向梯度：</p>
<p><img src="https://images2015.cnblogs.com/blog/927391/201607/927391-20160717152356576-837065946.png" alt="img"></p>
<p>　　也就是说，若F<a href="x">i-1</a>加上拟合了反向梯度的h<a href="x">i</a>得到F<a href="x">i</a>，该值可能将导致平方差损失函数降低，预测的准确度提高！这显然不是巧合，但是研究者们野心更大，希望能够创造出一种对任意损失函数都可行的训练方法，那么仅仅拟合残差是不恰当的了。</p>
<h2 id="4-2-拟合反向梯度"><a href="#4-2-拟合反向梯度" class="headerlink" title="4.2 拟合反向梯度"></a>4.2 拟合反向梯度</h2><h3 id="4-2-1-契机：引入任意损失函数"><a href="#4-2-1-契机：引入任意损失函数" class="headerlink" title="4.2.1 契机：引入任意损失函数"></a>4.2.1 契机：引入任意损失函数</h3><p>　　引入任意损失函数后，我们可以定义整体模型的迭代式如下：</p>
<p><img src="https://images2015.cnblogs.com/blog/927391/201607/927391-20160717155418592-692164582.png" alt="img"></p>
<p>　　在这里，损失函数被定义为<a href="https://zh.wikipedia.org/wiki/%E6%B3%9B%E5%87%BD" target="_blank" rel="noopener">泛函</a>。</p>
<h3 id="4-2-2-难题一：任意损失函数的最优化"><a href="#4-2-2-难题一：任意损失函数的最优化" class="headerlink" title="4.2.2 难题一：任意损失函数的最优化"></a>4.2.2 难题一：任意损失函数的最优化</h3><p>　　对任意损失函数（且是泛函）的最优化是困难的。我们需要打破思维的枷锁，将整体损失函数L’定义为n元普通函数（n为样本容量），损失函数L定义为2元普通函数（记住！！！这里的损失函数不再是泛函！！！）：</p>
<p><img src="https://images2015.cnblogs.com/blog/927391/201607/927391-20160717161734873-1080465986.png" alt="img"></p>
<p>　　我们不妨使用<a href="https://en.wikipedia.org/wiki/Method_of_steepest_descent" target="_blank" rel="noopener">梯度最速下降法</a>来解决整体损失函数L’最小化的问题，先求整体损失函数的反向梯度：</p>
<p><img src="https://images2015.cnblogs.com/blog/927391/201607/927391-20160717161743857-1762234391.png" alt="img"></p>
<p>　　假设已知样本x的当前预测值为F<a href="x">i-1</a>，下一步将预测值按照反向梯度，依照步长为r[i]，进行更新：</p>
<p><img src="https://images2015.cnblogs.com/blog/927391/201607/927391-20160717162353389-352979333.png" alt="img"></p>
<p>　　步长r[i]不是固定值，而是设计为：</p>
<p><img src="https://images2015.cnblogs.com/blog/927391/201607/927391-20160717162221748-1981866230.png" alt="img"></p>
<h3 id="4-2-3-难题二：无法对测试样本计算反向梯度"><a href="#4-2-3-难题二：无法对测试样本计算反向梯度" class="headerlink" title="4.2.3 难题二：无法对测试样本计算反向梯度"></a>4.2.3 难题二：无法对测试样本计算反向梯度</h3><p>　　问题又来了，由于测试样本中y是未知的，所以无法求反向梯度。这正是Gradient Boosting框架中的基模型闪亮登场的时刻！在第i轮迭代中，我们创建训练集如下：</p>
<p><img src="https://images2015.cnblogs.com/blog/927391/201607/927391-20160717162908686-1639692645.png" alt="img"></p>
<p>　　也就是说，让基模型拟合反向梯度函数，这样我们就可以做到只输入x这一个参数，就可求出其对应的反向梯度了（当然，通过基模型预测出来的反向梯度并不是准确的，这也提供了泛化整体模型的机会）。</p>
<p>　　综上，假设第i轮迭代中，根据新训练集训练出来的基模型为f<a href="x">i</a>，那么最终的迭代公式为：</p>
<p><img src="https://images2015.cnblogs.com/blog/927391/201607/927391-20160717171931342-64219972.png" alt="img"></p>
<h2 id="4-3-常见的损失函数"><a href="#4-3-常见的损失函数" class="headerlink" title="4.3 常见的损失函数"></a>4.3 常见的损失函数</h2><p>　　ls：最小均方回归中用到的损失函数。在之前我们已经谈到，从拟合残差的角度来说，残差即是该损失函数的反向梯度值（所以又称反向梯度为伪残差）。不同的是，从拟合残差的角度来说，步长是无意义的。该损失函数是sklearn中Gradient Tree Boosting回归模型默认的损失函数。</p>
<p>　　deviance：<a href="http://www.duzelong.com/wordpress/201507/archives1326/" target="_blank" rel="noopener">逻辑回归</a>中用到的损失函数。熟悉逻辑回归的读者肯定还记得，逻辑回归本质是求极大似然解，其认为样本服从几何分布，样本属于某类别的概率可以logistic函数表达。所以，如果该损失函数可用在多类别的分类问题上，故其是sklearn中Gradient Tree Boosting分类模型默认的损失函数。</p>
<p>　　exponential：指数损失函数，表达式为：</p>
<p><img src="https://images2015.cnblogs.com/blog/927391/201607/927391-20160717164817170-1319916901.png" alt="img"></p>
<p>　　对该损失函数求反向梯度得：</p>
<p><img src="https://images2015.cnblogs.com/blog/927391/201607/927391-20160717165216123-16910201.png" alt="img"></p>
<p>　　这时，在第i轮迭代中，新训练集如下：</p>
<p> <img src="https://images2015.cnblogs.com/blog/927391/201607/927391-20160717165246186-1781792701.png" alt="img"></p>
<p>　　脑袋里有什么东西浮出水面了吧？让我们看看<a href="http://breezedeus.github.io/2015/07/12/breezedeus-adaboost-exponential-loss.html" target="_blank" rel="noopener">Adaboost算法</a>中，第i轮迭代中第j个样本权值的更新公式：</p>
<p><img src="https://images2015.cnblogs.com/blog/927391/201607/927391-20160717170109811-1251363012.png" alt="img"></p>
<p>　　样本的权值什么时候会用到呢？计算第i轮损失函数的时候会用到：</p>
<p><img src="https://images2015.cnblogs.com/blog/927391/201607/927391-20160717170902529-315971230.png" alt="img"></p>
<p>　　让我们再回过头来，看看使用指数损失函数的Gradient Boosting计算第i轮损失函数：</p>
<p><img src="https://images2015.cnblogs.com/blog/927391/201607/927391-20160717171050389-2042221750.png" alt="img"></p>
<p>　　天呐，两个公式就差了一个对权值的归一项。这并不是巧合，当损失函数是指数损失时，Gradient Boosting相当于二分类的Adaboost算法。是的，指数损失仅能用于二分类的情况。</p>
<h2 id="4-4-步子太大容易扯着蛋：缩减"><a href="#4-4-步子太大容易扯着蛋：缩减" class="headerlink" title="4.4 步子太大容易扯着蛋：缩减"></a>4.4 步子太大容易扯着蛋：缩减</h2><p>　　缩减也是一个相对显见的概念，也就是说使用Gradient Boosting时，每次学习的步长缩减一点。这有什么好处呢？缩减思想认为每次走一小步，多走几次，更容易逼近真实值。如果步子迈大了，使用最速下降法时，容易迈过最优点。将缩减代入迭代公式：</p>
<p><img src="https://images2015.cnblogs.com/blog/927391/201607/927391-20160717172203889-897514111.png" alt="img"></p>
<p> 　　缩减需要配合基模型数一起使用，当缩减率v降低时，基模型数要配合增大，这样才能提高模型的准确度。</p>
<h2 id="4-5-初始模型"><a href="#4-5-初始模型" class="headerlink" title="4.5 初始模型"></a>4.5 初始模型</h2><p>　　还有一个不那么起眼的问题，初始模型F<a href="x">0</a>是什么呢？如果没有定义初始模型，整体模型的迭代式一刻都无法进行！所以，我们定义初始模型为：</p>
<p><img src="https://images2015.cnblogs.com/blog/927391/201607/927391-20160717172644920-1113326686.png" alt="img"></p>
<p>　　根据上式可知，对于不同的损失函数来说，初始模型也是不一样的。对所有的样本来说，根据初始模型预测出来的值都一样。</p>
<h2 id="4-5-Gradient-Tree-Boosting"><a href="#4-5-Gradient-Tree-Boosting" class="headerlink" title="4.5 Gradient Tree Boosting"></a>4.5 Gradient Tree Boosting</h2><p>　　终于到了备受欢迎的Gradient Tree Boosting模型了！但是，可讲的却已经不多了。我们已经知道了该模型的基模型是树模型，并且可以通过对特征的随机抽样进一步减少整体模型的方差。我们可以在维基百科的<a href="https://en.wikipedia.org/wiki/Gradient_boosting" target="_blank" rel="noopener">Gradient Boosting</a>词条中找到其伪代码实现。</p>
<h2 id="4-6-小结"><a href="#4-6-小结" class="headerlink" title="4.6 小结"></a>4.6 小结</h2><p>　　到此，读者应当很清楚Gradient Boosting中的损失函数有什么意义了。要说偏差描述了模型在训练集准确度，则损失函数则是描述该准确度的间接量纲。也就是说，模型采用不同的损失函数，其训练过程会朝着不同的方向进行！</p>
<hr>
<h1 id="5-总结"><a href="#5-总结" class="headerlink" title="5 总结"></a>5 总结</h1><p>　　磨刀不误砍柴功，我们花了这么多时间来学习必要的理论，我强调一次：必要的理论！集成学习模型的调参工作的核心就是找到合适的参数，能够使整体模型在训练集上的准确度和防止过拟合的能力达到协调，从而达到在样本总体上的最佳准确度。有了本文的理论知识铺垫，在下篇中，我们将对Random Forest和Gradient Tree Boosting中的每个参数进行详细阐述，同时也有一些小试验证明我们的结论。</p>
<hr>
<h1 id="6-参考资料"><a href="#6-参考资料" class="headerlink" title="6 参考资料"></a>6 参考资料</h1><ol>
<li><a href="http://cs.nju.edu.cn/zhouzh/zhouzh.files/publication/springerEBR09.pdf" target="_blank" rel="noopener">《</a><a href="http://cs.nju.edu.cn/zhouzh/zhouzh.files/publication/springerEBR09.pdf" target="_blank" rel="noopener">Ensemble Learning》</a></li>
<li><a href="http://scott.fortmann-roe.com/docs/BiasVariance.html" target="_blank" rel="noopener">《Understanding the Bias-Variance Tradeoff》</a></li>
<li><a href="https://www.zhihu.com/question/26760839" target="_blank" rel="noopener">《为什么说bagging是减少variance，而boosting是减少bias?》</a></li>
<li><a href="http://blog.csdn.net/w28971023/article/details/8240756" target="_blank" rel="noopener">《GBDT（MART） 迭代决策树入门教程 | 简介》</a></li>
<li><a href="https://zh.wikipedia.org/wiki/%E6%B3%9B%E5%87%BD" target="_blank" rel="noopener">泛函</a></li>
<li><a href="https://en.wikipedia.org/wiki/Method_of_steepest_descent" target="_blank" rel="noopener">梯度最速下降法</a></li>
<li><a href="http://www.duzelong.com/wordpress/201507/archives1326/" target="_blank" rel="noopener">《logistic regression(二分类、多分类)》</a></li>
<li><a href="http://breezedeus.github.io/2015/07/12/breezedeus-adaboost-exponential-loss.html" target="_blank" rel="noopener">《Adaboost与指数损失》</a></li>
</ol>
<h2 id="使用sklearn进行集成学习——实践"><a href="#使用sklearn进行集成学习——实践" class="headerlink" title="使用sklearn进行集成学习——实践"></a><a href="https://www.cnblogs.com/jasonfreak/p/5720137.html" target="_blank" rel="noopener">使用sklearn进行集成学习——实践</a></h2><h1 id="目录"><a href="#目录" class="headerlink" title="目录"></a>目录</h1><p>1 Random Forest和Gradient Tree Boosting参数详解<br>2 如何调参？<br>　　2.1 调参的目标：偏差和方差的协调<br>　　2.2 参数对整体模型性能的影响<br>　　2.3 一个朴实的方案：贪心的坐标下降法<br>　　　　2.3.1 Random Forest调参案例：Digit Recognizer<br>　　　　　　2.3.1.1 调整过程影响类参数<br>　　　　　　2.3.1.2 调整子模型影响类参数<br>　　　　2.3.2 Gradient Tree Boosting调参案例：Hackathon3.x<br>　　　　　　2.3.2.1 调整过程影响类参数<br>　　　　　　2.3.2.2 调整子模型影响类参数<br>　　　　　　2.3.2.3 杀一记回马枪<br>　　2.4 “局部最优解”（温馨提示：看到这里有彩蛋！）<br>　　2.5 类别不均衡的陷阱<br>3 总结<br>4 参考资料</p>
<hr>
<h1 id="1-Random-Forest和Gradient-Tree-Boosting参数详解"><a href="#1-Random-Forest和Gradient-Tree-Boosting参数详解" class="headerlink" title="1 Random Forest和Gradient Tree Boosting参数详解"></a>1 Random Forest和Gradient Tree Boosting参数详解</h1><p>　　在sklearn.ensemble库中，我们可以找到Random Forest分类和回归的实现：RandomForestClassifier和RandomForestRegression，Gradient Tree Boosting分类和回归的实现：GradientBoostingClassifier和GradientBoostingRegression。有了这些模型后，立马上手操练起来？少侠请留步！且听我说一说，使用这些模型时常遇到的问题：</p>
<ul>
<li>明明模型调教得很好了，可是效果离我的想象总有些偏差？——模型训练的第一步就是要定好目标，往错误的方向走太多也是后退。</li>
<li>凭直觉调了某个参数，可是居然没有任何作用，有时甚至起到反作用？——定好目标后，接下来就是要确定哪些参数是影响目标的，其对目标是正影响还是负影响，影响的大小。</li>
<li>感觉训练结束遥遥无期，sklearn只是个在小数据上的玩具？——虽然sklearn并不是基于分布式计算环境而设计的，但我们还是可以通过某些策略提高训练的效率。</li>
<li>模型开始训练了，但是训练到哪一步了呢？——饱暖思淫欲啊，目标，性能和效率都得了满足后，我们有时还需要有别的追求，例如训练过程的输出，袋外得分计算等等。</li>
</ul>
<p>　　通过总结这些常见的问题，我们可以把模型的参数分为4类：目标类、性能类、效率类和附加类。下表详细地展示了4个模型参数的意义：</p>
<div class="table-container">
<table>
<thead>
<tr>
<th><strong>参数</strong></th>
<th><strong>类型</strong></th>
<th><strong>RandomForestClassifier</strong></th>
<th><strong>RandomForestRegressor</strong></th>
<th><strong>GradientBoostingClassifier</strong></th>
<th><strong>GradientBoostingRegressor</strong></th>
</tr>
</thead>
<tbody>
<tr>
<td>loss</td>
<td>目标</td>
<td></td>
<td></td>
<td>损失函数● exponential：模型等同AdaBoost★ deviance：和Logistic Regression的损失函数一致</td>
<td>损失函数● exponential：模型等同AdaBoost★ deviance：和Logistic Regression的损失函数一致</td>
</tr>
<tr>
<td>alpha</td>
<td>目标</td>
<td></td>
<td></td>
<td>损失函数为huber或quantile的时，alpha为损失函数中的参数</td>
<td>损失函数为huber或quantile的时，alpha为损失函数中的参数</td>
</tr>
<tr>
<td>class_weight</td>
<td>目标</td>
<td>类别的权值</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>n_estimators</td>
<td>性能</td>
<td>子模型的数量● int：个数★ 10：默认值</td>
<td>子模型的数量● int：个数★ 10：默认值</td>
<td>子模型的数量● int：个数★ 100：默认值</td>
<td>子模型的数量● int：个数★ 100：默认值</td>
</tr>
<tr>
<td>learning_rate</td>
<td>性能</td>
<td></td>
<td></td>
<td>学习率（缩减）</td>
<td>学习率（缩减）</td>
</tr>
<tr>
<td>criterion</td>
<td>性能</td>
<td>判断节点是否继续分裂采用的计算方法● entropy★ gini</td>
<td>判断节点是否继续分裂采用的计算方法★ mse</td>
<td></td>
<td></td>
</tr>
<tr>
<td>max_features</td>
<td>性能</td>
<td>节点分裂时参与判断的最大特征数● int：个数● float：占所有特征的百分比★ auto：所有特征数的开方● sqrt：所有特征数的开方● log2：所有特征数的log2值● None：等于所有特征数</td>
<td>节点分裂时参与判断的最大特征数● int：个数● float：占所有特征的百分比★ auto：所有特征数的开方● sqrt：所有特征数的开方● log2：所有特征数的log2值● None：等于所有特征数</td>
<td>节点分裂时参与判断的最大特征数● int：个数● float：占所有特征的百分比● auto：所有特征数的开方● sqrt：所有特征数的开方● log2：所有特征数的log2值★ None：等于所有特征数</td>
<td>节点分裂时参与判断的最大特征数● int：个数● float：占所有特征的百分比● auto：所有特征数的开方● sqrt：所有特征数的开方● log2：所有特征数的log2值★ None：等于所有特征数</td>
</tr>
<tr>
<td>max_depth</td>
<td>性能</td>
<td>最大深度，如果max_leaf_nodes参数指定，则忽略● int：深度★ None：树会生长到所有叶子都分到一个类，或者某节点所代表的样本数已小于min_samples_split</td>
<td>最大深度，如果max_leaf_nodes参数指定，则忽略● int：深度★ None：树会生长到所有叶子都分到一个类，或者某节点所代表的样本数已小于min_samples_split</td>
<td>最大深度，如果max_leaf_nodes参数指定，则忽略● int：深度★ 3：默认值</td>
<td>最大深度，如果max_leaf_nodes参数指定，则忽略● int：深度★ 3：默认值</td>
</tr>
<tr>
<td>min_samples_split</td>
<td>性能</td>
<td>分裂所需的最小样本数● int：样本数★ 2：默认值</td>
<td>分裂所需的最小样本数● int：样本数★ 2：默认值</td>
<td>分裂所需的最小样本数● int：样本数★ 2：默认值</td>
<td>分裂所需的最小样本数● int：样本数★ 2：默认值</td>
</tr>
<tr>
<td>min_samples_leaf</td>
<td>性能</td>
<td>叶节点最小样本数● int：样本数★ 1：默认值</td>
<td>叶节点最小样本数● int：样本数★ 1：默认值</td>
<td>叶节点最小样本数● int：样本数★ 1：默认值</td>
<td>叶节点最小样本数● int：样本数★ 1：默认值</td>
</tr>
<tr>
<td>min_weight_fraction_leaf</td>
<td>性能</td>
<td>叶节点最小样本权重总值● float：权重总值★ 0：默认值</td>
<td>叶节点最小样本权重总值● float：权重总值★ 0：默认值</td>
<td>叶节点最小样本权重总值● float：权重总值★ 0：默认值</td>
<td>叶节点最小样本权重总值● float：权重总值★ 0：默认值</td>
</tr>
<tr>
<td>max_leaf_nodes</td>
<td>性能</td>
<td>最大叶节点数● int：个数★ None：不限制叶节点数</td>
<td>最大叶节点数● int：个数★ None：不限制叶节点数</td>
<td>最大叶节点数● int：个数★ None：不限制叶节点数</td>
<td>最大叶节点数● int：个数★ None：不限制叶节点数</td>
</tr>
<tr>
<td>bootstrap</td>
<td>性能</td>
<td>是否bootstrap对样本抽样● False：子模型的样本一致，子模型间强相关★ True：默认值</td>
<td>是否bootstrap对样本抽样● False：子模型的样本一致，子模型间强相关★ True：默认值</td>
<td></td>
<td></td>
</tr>
<tr>
<td>subsample</td>
<td>性能</td>
<td></td>
<td></td>
<td>子采样率● float：采样率★ 1.0：默认值</td>
<td>子采样率● float：采样率★ 1.0：默认值</td>
</tr>
<tr>
<td>init</td>
<td>性能</td>
<td></td>
<td></td>
<td>初始子模型</td>
<td>初始子模型</td>
</tr>
<tr>
<td>n_jobs</td>
<td>效率</td>
<td>并行数● int：个数● -1：跟CPU核数一致★ 1:默认值</td>
<td>并行数● int：个数● -1：跟CPU核数一致★ 1:默认值</td>
<td></td>
<td></td>
</tr>
<tr>
<td>warm_start</td>
<td>效率</td>
<td>是否热启动，如果是，则下一次训练是以追加树的形式进行● bool：热启动★ False：默认值</td>
<td>是否热启动，如果是，则下一次训练是以追加树的形式进行● bool：热启动★ False：默认值</td>
<td>是否热启动，如果是，则下一次训练是以追加树的形式进行● bool：热启动★ False：默认值</td>
<td>是否热启动，如果是，则下一次训练是以追加树的形式进行● bool：热启动★ False：默认值</td>
</tr>
<tr>
<td>presort</td>
<td>效率</td>
<td></td>
<td></td>
<td>是否预排序,预排序可以加速查找最佳分裂点，对于稀疏数据不管用● Bool★ auto：非稀疏数据则预排序，若稀疏数据则不预排序</td>
<td>是否预排序,预排序可以加速查找最佳分裂点，对于稀疏数据不管用● Bool★ auto：非稀疏数据则预排序，若稀疏数据则不预排序</td>
</tr>
<tr>
<td>oob_score</td>
<td>附加</td>
<td>是否计算<a href="http://scikit-learn.org/stable/auto_examples/ensemble/plot_ensemble_oob.html" target="_blank" rel="noopener">袋外得分</a>★ False：默认值</td>
<td>是否计算<a href="http://scikit-learn.org/stable/auto_examples/ensemble/plot_ensemble_oob.html" target="_blank" rel="noopener">袋外得分</a>★ False：默认值</td>
<td></td>
<td></td>
</tr>
<tr>
<td>random_state</td>
<td>附加</td>
<td>随机器对象</td>
<td>随机器对象</td>
<td>随机器对象</td>
<td>随机器对象</td>
</tr>
<tr>
<td>verbose</td>
<td>附加</td>
<td>日志冗长度● int：冗长度★ 0：不输出训练过程● 1：偶尔输出● &gt;1：对每个子模型都输出</td>
<td>日志冗长度● int：冗长度★ 0：不输出训练过程● 1：偶尔输出● &gt;1：对每个子模型都输出</td>
<td>日志冗长度● int：冗长度★ 0：不输出训练过程● 1：偶尔输出● &gt;1：对每个子模型都输出</td>
<td>日志冗长度● int：冗长度★ 0：不输出训练过程● 1：偶尔输出● &gt;1：对每个子模型都输出</td>
</tr>
</tbody>
</table>
</div>
<p><em># ★：默认值</em></p>
<p>　　不难发现，基于bagging的Random Forest模型和基于boosting的Gradient Tree Boosting模型有不少共同的参数，然而某些参数的默认值又相差甚远。在<a href="http://www.cnblogs.com/jasonfreak/p/5657196.html" target="_blank" rel="noopener">《使用sklearn进行集成学习——理论》</a>一文中，我们对bagging和boosting两种集成学习技术有了初步的了解。Random Forest的子模型都拥有较低的偏差，整体模型的训练过程旨在降低方差，故其需要较少的子模型（n_estimators默认值为10）且子模型不为弱模型（max_depth的默认值为None），同时，降低子模型间的相关度可以起到减少整体模型的方差的效果（max_features的默认值为auto）。另一方面，Gradient Tree Boosting的子模型都拥有较低的方差，整体模型的训练过程旨在降低偏差，故其需要较多的子模型（n_estimators默认值为100）且子模型为弱模型（max_depth的默认值为3），但是降低子模型间的相关度不能显著减少整体模型的方差（max_features的默认值为None）。</p>
<hr>
<h1 id="2-如何调参？"><a href="#2-如何调参？" class="headerlink" title="2 如何调参？"></a>2 如何调参？</h1><p>　　聪明的读者应当要发问了：”博主，就算你列出来每个参数的意义，然并卵啊！我还是不知道无从下手啊！”</p>
<p>　　参数分类的目的在于缩小调参的范围，首先我们要明确训练的目标，把目标类的参数定下来。接下来，我们需要根据数据集的大小，考虑是否采用一些提高训练效率的策略，否则一次训练就三天三夜，法国人孩子都生出来了。然后，我们终于进入到了重中之重的环节：调整那些影响整体模型性能的参数。</p>
<h2 id="2-1-调参的目标：偏差和方差的协调"><a href="#2-1-调参的目标：偏差和方差的协调" class="headerlink" title="2.1 调参的目标：偏差和方差的协调"></a>2.1 调参的目标：偏差和方差的协调</h2><p>　　同样在<a href="http://www.cnblogs.com/jasonfreak/p/5657196.html" target="_blank" rel="noopener">《使用sklearn进行集成学习——理论》</a>中，我们已讨论过偏差和方差是怎样影响着模型的性能——准确度。调参的目标就是为了达到整体模型的偏差和方差的大和谐！进一步，这些参数又可分为两类：过程影响类及子模型影响类。在子模型不变的前提下，某些参数可以通过改变训练的过程，从而影响模型的性能，诸如：“子模型数”（n_estimators）、“学习率”（learning_rate）等。另外，我们还可以通过改变子模型性能来影响整体模型的性能，诸如：“最大树深度”（max_depth）、“分裂条件”（criterion）等。正由于bagging的训练过程旨在降低方差，而boosting的训练过程旨在降低偏差，过程影响类的参数能够引起整体模型性能的大幅度变化。一般来说，在此前提下，我们继续微调子模型影响类的参数，从而进一步提高模型的性能。</p>
<h2 id="2-2-参数对整体模型性能的影响"><a href="#2-2-参数对整体模型性能的影响" class="headerlink" title="2.2 参数对整体模型性能的影响"></a>2.2 参数对整体模型性能的影响</h2><p>　　假设模型是一个多元函数F，其输出值为模型的准确度。我们可以固定其他参数，从而对某个参数对整体模型性能的影响进行分析：是正影响还是负影响，影响的单调性？</p>
<p>　　对Random Forest来说，增加“子模型数”（n_estimators）可以明显降低整体模型的方差，且不会对子模型的偏差和方差有任何影响。模型的准确度会随着“子模型数”的增加而提高。由于减少的是整体模型方差公式的第二项，故准确度的提高有一个上限。在不同的场景下，“分裂条件”（criterion）对模型的准确度的影响也不一样，该参数需要在实际运用时灵活调整。调整“最大叶节点数”（max_leaf_nodes）以及“最大树深度”（max_depth）之一，可以粗粒度地调整树的结构：叶节点越多或者树越深，意味着子模型的偏差越低，方差越高；同时，调整“分裂所需最小样本数”（min_samples_split）、“叶节点最小样本数”（min_samples_leaf）及“叶节点最小权重总值”（min_weight_fraction_leaf），可以更细粒度地调整树的结构：分裂所需样本数越少或者叶节点所需样本越少，也意味着子模型越复杂。一般来说，我们总采用bootstrap对样本进行子采样来降低子模型之间的关联度，从而降低整体模型的方差。适当地减少“分裂时考虑的最大特征数”（max_features），给子模型注入了另外的随机性，同样也达到了降低子模型之间关联度的效果。但是一味地降低该参数也是不行的，因为分裂时可选特征变少，模型的偏差会越来越大。在下图中，我们可以看到这些参数对Random Forest整体模型性能的影响：</p>
<p><img src="http://images2015.cnblogs.com/blog/927391/201607/927391-20160731184710919-487730249.jpg" alt="img"></p>
<p>　　对Gradient Tree Boosting来说，“子模型数”（n_estimators）和“学习率”（learning_rate）需要联合调整才能尽可能地提高模型的准确度：想象一下，A方案是走4步，每步走3米，B方案是走5步，每步走2米，哪个方案可以更接近10米远的终点？同理，子模型越复杂，对应整体模型偏差低，方差高，故“最大叶节点数”（max_leaf_nodes）、“最大树深度”（max_depth）等控制子模型结构的参数是与Random Forest一致的。类似“分裂时考虑的最大特征数”（max_features），降低“子采样率”（subsample），也会造成子模型间的关联度降低，整体模型的方差减小，但是当子采样率低到一定程度时，子模型的偏差增大，将引起整体模型的准确度降低。还记得“初始模型”（init）是什么吗？不同的损失函数有不一样的初始模型定义，通常，初始模型是一个更加弱的模型（以“平均”情况来预测），虽说支持自定义，大多数情况下保持默认即可。在下图中，我们可以看到这些参数对Gradient Tree Boosting整体模型性能的影响：</p>
<p><img src="http://images2015.cnblogs.com/blog/927391/201607/927391-20160731184748841-69767136.jpg" alt="img"></p>
<h2 id="2-3-一个朴实的方案：贪心的坐标下降法"><a href="#2-3-一个朴实的方案：贪心的坐标下降法" class="headerlink" title="2.3 一个朴实的方案：贪心的坐标下降法"></a>2.3 一个朴实的方案：贪心的坐标下降法</h2><p>　　到此为止，我们终于知道需要调整哪些参数，对于单个参数，我们也知道怎么调整才能提升性能。然而，表示模型的函数F并不是一元函数，这些参数需要共同调整才能得到全局最优解。也就是说，把这些参数丢给调参算法（诸如Grid Search）咯？对于小数据集，我们还能这么任性，但是参数组合爆炸，在大数据集上，或许我的子子孙孙能够看到训练结果吧。实际上网格搜索也不一定能得到全局最优解，而另一些研究者从解优化问题的角度尝试解决调参问题。</p>
<p>　　<a href="https://zh.wikipedia.org/wiki/%E5%9D%90%E6%A0%87%E4%B8%8B%E9%99%8D%E6%B3%95" target="_blank" rel="noopener">坐标下降法</a>是一类优化算法，其最大的优势在于不用计算待优化的目标函数的梯度。我们最容易想到一种特别朴实的类似于坐标下降法的方法，与坐标下降法不同的是，其不是循环使用各个参数进行调整，而是贪心地选取了对整体模型性能影响最大的参数。参数对整体模型性能的影响力是动态变化的，故每一轮坐标选取的过程中，这种方法在对每个坐标的下降方向进行一次直线搜索（line search）。首先，找到那些能够提升整体模型性能的参数，其次确保提升是单调或近似单调的。这意味着，我们筛选出来的参数是对整体模型性能有正影响的，且这种影响不是偶然性的，要知道，训练过程的随机性也会导致整体模型性能的细微区别，而这种区别是不具有单调性的。最后，在这些筛选出来的参数中，选取影响最大的参数进行调整即可。</p>
<p>　　无法对整体模型性能进行量化，也就谈不上去比较参数影响整体模型性能的程度。是的，我们还没有一个准确的方法来量化整体模型性能，只能通过交叉验证来近似计算整体模型性能。然而交叉验证也存在随机性，假设我们以验证集上的平均准确度作为整体模型的准确度，我们还得关心在各个验证集上准确度的变异系数，如果变异系数过大，则平均值作为整体模型的准确度也是不合适的。在接下来的案例分析中，我们所谈及的整体模型性能均是指平均准确度，请各位留心。</p>
<h3 id="2-3-1-Random-Forest调参案例：Digit-Recognizer"><a href="#2-3-1-Random-Forest调参案例：Digit-Recognizer" class="headerlink" title="2.3.1 Random Forest调参案例：Digit Recognizer"></a>2.3.1 Random Forest调参案例：Digit Recognizer</h3><p>　　在这里，我们选取Kaggle上101教学赛中的<a href="https://www.kaggle.com/c/digit-recognizer" target="_blank" rel="noopener">Digit Recognizer</a>作为案例来演示对RandomForestClassifier调参的过程。当然，我们也不要傻乎乎地手工去设定不同的参数，然后训练模型。借助sklearn.grid_search库中的GridSearchCV类，不仅可以自动化调参，同时还可以对每一种参数组合进行交叉验证计算平均准确度。</p>
<h4 id="2-3-1-1-调整过程影响类参数"><a href="#2-3-1-1-调整过程影响类参数" class="headerlink" title="2.3.1.1 调整过程影响类参数"></a>2.3.1.1 调整过程影响类参数</h4><p>　　首先，我们需要对过程影响类参数进行调整，而Random Forest的过程影响类参数只有“子模型数”（n_estimators）。“子模型数”的默认值为10，在此基础上，我们以10为单位，考察取值范围在1至201的调参情况：</p>
<p><img src="http://images2015.cnblogs.com/blog/927391/201607/927391-20160730162932106-838038825.png" alt="img"></p>
<p><em># 左图为模型在验证集上的平均准确度，右图为准确度的变异系数。横轴为参数的取值。</em></p>
<p>　　通过上图我们可以看到，随着“子模型数”的增加，整体模型的方差减少，其防止过拟合的能力增强，故整体模型的准确度提高。当“子模型数”增加到40以上时，准确度的提升逐渐不明显。考虑到训练的效率，最终我们选择“子模型数”为200。此时，在Kaggle上提交结果，得分为：0.96500，很凑合。</p>
<h4 id="2-3-1-2-调整子模型影响类参数"><a href="#2-3-1-2-调整子模型影响类参数" class="headerlink" title="2.3.1.2 调整子模型影响类参数"></a>2.3.1.2 调整子模型影响类参数</h4><p>　　在设定“子模型数”（n_estimators）为200的前提下，我们依次对子模型影响类的参数对整体模型性能的影响力进行分析。</p>
<p>　　对“分裂条件”（criterion）分别取值gini和entropy，得到调参结果如下：</p>
<p><img src="http://images2015.cnblogs.com/blog/927391/201607/927391-20160730165700763-1666232416.png" alt="img"></p>
<p>　　显见，在此问题中，“分裂条件”保持默认值gini更加合适。</p>
<p>　　对“分裂时参与判断的最大特征数”（max_feature）以1为单位，设定取值范围为28至47，得到调参结果如下：</p>
<p><img src="http://images2015.cnblogs.com/blog/927391/201607/927391-20160730170223903-942174073.png" alt="img"></p>
<p>　　</p>
<p>　　“分裂时参与判断的最大特征数”的默认值auto，即总特征数（sqrt(784)=28）的开方。通过提升该参数，整体模型的准确度得到了提升。可见，该参数的默认值过小，导致了子模型的偏差过大，从而整体模型的偏差过大。同时，我们还注意到，该参数对整体模型性能的影响是近似单调的：从28到38，模型的准确度逐步抖动提升。所以，我们可考虑将该参数纳入下一步的调参工作。</p>
<p>　　对“最大深度”（max_depth）以10为单位，设定取值范围为10到100，得到调参结果如下：</p>
<p><img src="http://images2015.cnblogs.com/blog/927391/201607/927391-20160730171248153-89195782.png" alt="img"></p>
<p>　　随着树的深度加深，子模型的偏差减少，整体模型的准确度得到提升。从理论上来说，子模型训练的后期，随着方差增大，子模型的准确度稍微降低，从而影响整体模型的准确度降低。看图中，似乎取值范围从40到60的情况可以印证这一观点。不妨以1为单位，设定取值范围为40到59，更加细致地分析：</p>
<p><img src="http://images2015.cnblogs.com/blog/927391/201607/927391-20160730171849434-652571651.png" alt="img"></p>
<p>　　有点傻眼了，怎么跟预想的不太一样？为什么模型准确度的变化在40到59之间没有鲜明的“规律”了？要分析这个问题，我们得先思考一下，少一层子节点对子模型意味着什么？若少的那一层给原子模型带来的是方差增大，则新子模型会准确度提高；若少的那一层给原子模型带来的是偏差减小，则新子模型会准确度降低。所以，细粒度的层次变化既可能使整体模型的准确度提升，也可能使整体模型的准确度降低。从而也说明了，该参数更适合进行粗粒度的调整。在训练的现阶段，“抖动”现象的发生说明，此时对该参数的调整已不太合适了。</p>
<p>　　对“分裂所需的最小样本数”（min_samples_split）以1为单位，设定取值范围为2到11，得到调参的结果：</p>
<p><img src="http://images2015.cnblogs.com/blog/927391/201607/927391-20160730173505919-181940029.png" alt="img"></p>
<p>　　我们看到，随着分裂所需的最小样本数的增加，子模型的结构变得越来越简单，理论上来说，首先应当因方差减小导致整体模型的准确度提升。但是，在训练的现阶段，子模型的偏差增大的幅度比方差减小的幅度更大，所以整体模型的准确度持续下降。该参数的默认值为2，调参后，最优解保持2不变。</p>
<p>　　对“叶节点最小样本数”（min_samples_leaf）以1为单位，设定取值范围为1到10，得到调参结果如下：</p>
<p><img src="http://images2015.cnblogs.com/blog/927391/201607/927391-20160730174140309-373143237.png" alt="img"></p>
<p>　　同“分裂所需的最小样本数”，该参数也在调参后，保持最优解1不变。</p>
<p>　　对“最大叶节点数”（max_leaf_nodes）以100为单位，设定取值范围为2500到3400，得到调参结果如下：</p>
<p><img src="http://images2015.cnblogs.com/blog/927391/201607/927391-20160730174432372-770058569.png" alt="img"></p>
<p>　　类似于“最大深度”，该参数的增大会带来模型准确的提升，可是由于后期“不规律”的抖动，我们暂时不进行处理。</p>
<p>　　通过对以上参数的调参情况，我们可以总结如下：</p>
<div class="table-container">
<table>
<thead>
<tr>
<th>参数</th>
<th>默认值准确度</th>
<th>调整后最佳准确度</th>
<th>提升幅度</th>
</tr>
</thead>
<tbody>
<tr>
<td>分裂条件（criterion）</td>
<td>0.964023809524</td>
<td>0.964023809524</td>
<td>0</td>
</tr>
<tr>
<td>分裂时参与判断的最大特征数（max_feature）</td>
<td>0.963380952381</td>
<td>0.964428571429</td>
<td>0.00104762</td>
</tr>
<tr>
<td>最大深度（max_depth）</td>
<td></td>
<td></td>
<td>抖动</td>
</tr>
<tr>
<td>分裂所需的最小样本数（min_samples_split）</td>
<td>0.963976190476</td>
<td>0.963976190476</td>
<td>0</td>
</tr>
<tr>
<td>叶节点最小样本数（min_samples_leaf）</td>
<td>0.963595238095</td>
<td>0.963595238095</td>
<td>0</td>
</tr>
<tr>
<td>最大叶节点数（max_leaf_nodes）</td>
<td></td>
<td></td>
<td>抖动</td>
</tr>
</tbody>
</table>
</div>
<p>　　接下来，我们固定分裂时参与判断的最大特征（max_features）为38，在Kaggle上提交一次结果：0.96671，比上一次调参好了0.00171，基本与我们预期的提升效果一致。</p>
<p>　　还需要继续下一轮坐标下降式调参吗？一般来说没有太大的必要，在本轮中出现了两个发生抖动现象的参数，而其他参数的调整均没有提升整体模型的性能。还是得老调重弹：数据和特征决定了机器学习的上限，而模型和算法只是逼近这个上限而已。在DR竞赛中，与其期待通过对RandomForestClassifier调参来进一步提升整体模型的性能，不如挖掘出更有价值的特征，或者使用自带特征挖掘技能的模型（正如此题，图分类的问题更适合用神经网络来学习）。但是，在这里，我们还是可以自信地说，通过贪心的坐标下降法，比那些用网格搜索法穷举所有参数组合，自以为得到最优解的朋友们更进了一步。</p>
<h3 id="2-3-2-Gradient-Tree-Boosting调参案例：Hackathon3-x"><a href="#2-3-2-Gradient-Tree-Boosting调参案例：Hackathon3-x" class="headerlink" title="2.3.2 Gradient Tree Boosting调参案例：Hackathon3.x"></a>2.3.2 Gradient Tree Boosting调参案例：Hackathon3.x</h3><p>　　在这里，我们选取Analytics Vidhya上的<a href="https://datahack.analyticsvidhya.com/contest/data-hackathon-3x/" target="_blank" rel="noopener">Hackathon3.x</a>作为案例来演示对GradientBoostingClassifier调参的过程。</p>
<h4 id="2-3-2-1-调整过程影响类参数"><a href="#2-3-2-1-调整过程影响类参数" class="headerlink" title="2.3.2.1 调整过程影响类参数"></a>2.3.2.1 调整过程影响类参数</h4><p>　　GradientBoostingClassifier的过程影响类参数有“子模型数”（n_estimators）和“学习率”（learning_rate），我们可以使用GridSearchCV找到关于这两个参数的最优解。慢着！这里留了一个很大的陷阱：“子模型数”和“学习率”带来的性能提升是不均衡的，在前期会比较高，在后期会比较低，如果一开始我们将这两个参数调成最优，这样很容易陷入一个“局部最优解”。在目标函数都不确定的情况下（如是否凸？），谈局部最优解就是耍流氓，本文中“局部最优解”指的是调整各参数都无明显性能提升的一种状态，所以打了引号。下图中展示了这个两个参数的调参结果：</p>
<p><img src="http://images2015.cnblogs.com/blog/927391/201607/927391-20160731161516950-670327363.png" alt="img"></p>
<p><em># 图中颜色越深表示整体模型的性能越高</em></p>
<p>　　在此，我们先直觉地选择“子模型数”为60，“学习率”为0.1，此时的整体模型性能（平均准确度为0.8253）不是最好，但是也不差，良好水准。</p>
<h4 id="2-3-2-2-调整子模型影响类参数"><a href="#2-3-2-2-调整子模型影响类参数" class="headerlink" title="2.3.2.2 调整子模型影响类参数"></a>2.3.2.2 调整子模型影响类参数</h4><p>　　对子模型影响类参数的调整与Random Forest类似。最终我们对参数的调整如下：</p>
<div class="table-container">
<table>
<thead>
<tr>
<th>子模型数n_estimators</th>
<th>学习率learning_rate</th>
<th>叶节点最小样本数min_samples_leaf</th>
<th>最大深度max_depth</th>
<th>子采样率subsample</th>
<th>分裂时参与判断的最大特征数max_feature</th>
</tr>
</thead>
<tbody>
<tr>
<td>60</td>
<td>0.1</td>
<td>12</td>
<td>4</td>
<td>0.77</td>
<td>10</td>
</tr>
</tbody>
</table>
</div>
<p>　　到此，整体模型性能为0.8313，与workbench（0.8253）相比，提升了约0.006。</p>
<h4 id="2-3-2-3-杀一记回马枪"><a href="#2-3-2-3-杀一记回马枪" class="headerlink" title="2.3.2.3 杀一记回马枪"></a>2.3.2.3 杀一记回马枪</h4><p>　　还记得一开始我们对“子模型数”（n_estimators）和“学习率”（learning_rate）手下留情了吗？现在我们可以回过头来，调整这两个参数，调整的方法为成倍地放大“子模型数”，对应成倍地缩小“学习率”（learning_rate）。通过该方法，本例中整体模型性能又提升了约0.002。</p>
<h2 id="2-4-“局部最优解”"><a href="#2-4-“局部最优解”" class="headerlink" title="2.4 “局部最优解”"></a>2.4 “局部最优解”</h2><p>　　目前来说，在调参工作中，广泛使用的仍是一些经验法则。<a href="https://www.analyticsvidhya.com/blog/author/aarshay/" target="_blank" rel="noopener">Aarshay Jain</a>对Gradient Tree Boosting总结了一套<a href="https://www.analyticsvidhya.com/blog/2016/02/complete-guide-parameter-tuning-gradient-boosting-gbm-python/" target="_blank" rel="noopener">调参方法</a>，其核心思想在于：对过程影响类参数进行调整，毕竟它们对整体模型性能的影响最大，然后依据经验，在其他参数中选择对整体模型性能影响最大的参数，进行下一步调参。这种方法的关键是依照对整体模型性能的影响力给参数排序，然后按照该顺序对的参数进行调整。如何衡量参数对整体模型性能的影响力呢？基于经验，Aarshay提出他的见解：“最大叶节点数”（max_leaf_nodes）和“最大树深度”（max_depth）对整体模型性能的影响大于“分裂所需最小样本数”（min_samples_split）、“叶节点最小样本数”（min_samples_leaf）及“叶节点最小权重总值”（min_weight_fraction_leaf），而“分裂时考虑的最大特征数”（max_features）的影响力最小。</p>
<p>　　Aarshay提出的方法和贪心的坐标下降法最大的区别在于前者在调参之前就依照对整体模型性能的影响力给参数排序，而后者是一种“很自然”的贪心过程。还记得2.3.2.1小节中我们讨论过“子模型数”（n_estimators）和“学习率”（learning_rate）的调参问题吗？同理，贪心的坐标下降法容易陷入“局部最优解”。对Random Forest调参时会稍微好一点，因为当“子模型数”调到最佳状态时，有时就只剩下诸如““分裂时参与判断的最大特征数”等Aarshay认为影响力最小的参数可调了。但是，对Gradient Tree Boosting调参时，遇到“局部最优解”的可能性就大得多。</p>
<p>　　Aarshay同样对Hackathon3.x进行了调参试验，由于特征提取方式的差异，参数赋值相同的情况下，本文的整体模型性能仍与其相差0.007左右（唉，不得不再说一次，特征工程真的很重要）。首先，在过程影响类参数的选择上，Aarshay的方法与贪心的坐标下降法均选择了“子模型数”为60，“学习率”为0.1。接下来，Aarshay按照其定义的参数对整体模型性能的影响力，按序依次对参数进行调整。当子模型影响类参数确定完成后，Aarshay的方法提升了约0.008的整体模型性能，略胜于贪心的坐标下降法的0.006。但是，回过头来继续调试“子模型数”和“学习率”之后，Aarshay的方法又提升了约0.01的整体模型性能，远胜于贪心的坐标下降法的0.002。</p>
<p>　　诶！诶！诶！少侠请住手！你说我为什么要在这篇博文中介绍这种“无用”的贪心的坐标下降法？首先，这种方法很容易凭直觉就想到。人们往往花了很多的时间去搞懂模型的参数是什么含义，对整体模型性能有什么影响，搞懂这些已经不易了，所以接下来很多人选择了最直观的贪心的坐标下降法。通过一个实例，我们更容易记住这种方法的局限性。除了作为反面教材，贪心的坐标下降法就没有意义了吗？不难看到，Aarshay的方法仍有改进的地方，在依次对参数进行调整时，还是需要像贪心的坐标下降法中一样对参数的“动态”影响力进行分析一下，如果这种影响力是“抖动”的，可有可无的，那么我们就不需要对该参数进行调整。</p>
<h2 id="2-5-类别不均衡的陷阱"><a href="#2-5-类别不均衡的陷阱" class="headerlink" title="2.5 类别不均衡的陷阱"></a>2.5 类别不均衡的陷阱</h2><p>　　哈哈哈，这篇博文再次留了个陷阱，此段文字并不是跟全文一起发布！有人要说了，按照我的描述，Aarshay的调参试验不可再现啊！其实，我故意没说Aarshay的另一个关键处理：调参前的参数初始值。因为Hackathon3.x是一个类别不均衡的问题，所以如果直接先调试“最大深度”（max_depth），会发现其会保持默认值3作为最优解，而后面的调参中，“分裂所需最小样本数”（min_samples_split）、“叶节点最小样本数”（min_samples_leaf）再怎么调都没有很大作用。这是因为，正例样本远远小于反例，所以在低深度时，子模型就可能已经对正例过拟合了。所以，在类别不均衡时，只有先确定“叶节点最小样本数”（min_samples_leaf），再确定“分裂所需最小样本数”（min_samples_split），才能确定“最大深度”。而Aarshay设定的初始值，则以经验和直觉避开了这个险恶的陷阱。</p>
<p>　　如果实在觉得经验和直觉不靠谱，我还尝试了一种策略：首先，我们需要初步地调一次“子采样率”（subsample）和“分裂时考虑的最大特征数”（max_features），在此基础上依次调好“叶节点最小样本数”（min_samples_leaf）、“分裂所需最小样本数”（min_samples_split）以及“最大深度”（max_depth）。然后，按照Aarshay的方法，按影响力从大到小再调一次。通过这种方法，整体模型性能在未等比缩放过程影响类参数前，已达到约0.8352左右，比workbench相比，提升了约0.1，与Aarshay的调参试验差不多，甚至更好一点点。</p>
<p>　　回过头来，我们再次看看贪心的坐标下降法是怎么掉入这个陷阱的。在确定过程影响类参数后，贪心的坐标下降法按照“动态”的对整体模型性能的影响力大小，选择了“叶节点最小样本数”进行调参。这一步看似和上一段的描述是一致的，但是，一般来说，含随机性（“子采样率”和“分裂时考虑的最大特征数”先初步调过）的“叶节点最小样本数”要大于无随机性。举个例来说，因为增加了随机性，导致了子采样后，某子样本中只有一个正例，且其可以通过唯一的特征将其分类，但是这个特征并不是所有正例的共性，所以此时就要求“叶节点最小样本数”需要比无随机性时大。对贪心的坐标下降来说，“子采样率”和“分裂时考虑的最大特征数”在当下，对整体模型性能的影响比不上“叶节点最小样本数”，所以栽了个大跟头。</p>
<hr>
<h2 id="3-总结"><a href="#3-总结" class="headerlink" title="3 总结"></a>3 总结</h2><p>　　在这篇博文中，我一反常态，花了大部分时间去试验和说明一个有瑕疵的方案。数据挖掘的工作中的方法和技巧，有很大一部分暂时还未被严谨地证明，所以有很大部分人，特别是刚入门的小青年们（也包括曾经的我），误以为其是一门玄学。实际上，尽管没有被严谨地证明，我们还是可以通过试验、分析，特别是与现有方法进行对比，得到一个近似的合理性论证。</p>
<p>　　另外，小伙伴们你们有什么独到的调参方法吗？请不要有丝毫吝啬，狠狠地将你们的独门绝技全释放在我身上吧，请大胆留言，残酷批评！</p>
<hr>
<h2 id="4-参考资料"><a href="#4-参考资料" class="headerlink" title="4 参考资料"></a>4 参考资料</h2><ol>
<li><a href="http://www.cnblogs.com/jasonfreak/p/5657196.html" target="_blank" rel="noopener">《使用sklearn进行集成学习——理论》</a></li>
<li><a href="https://www.analyticsvidhya.com/blog/2016/02/complete-guide-parameter-tuning-gradient-boosting-gbm-python/" target="_blank" rel="noopener">Complete Guide to Parameter Tuning in Gradient Boosting (GBM) in Python</a></li>
<li><a href="https://zh.wikipedia.org/wiki/%E5%9D%90%E6%A0%87%E4%B8%8B%E9%99%8D%E6%B3%95" target="_blank" rel="noopener">坐标下降法</a></li>
<li><a href="https://www.kaggle.com/c/digit-recognizer" target="_blank" rel="noopener">Digit Recognizer</a></li>
<li><a href="https://datahack.analyticsvidhya.com/contest/data-hackathon-3x/" target="_blank" rel="noopener">Hackathon3.x</a></li>
</ol>

          
        
      
    </div>

    

    
    
    

    

    
      
    
    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
  </section>

  
  <nav class="pagination">
    <a class="extend prev" rel="prev" href="/page/27/"><i class="fa fa-angle-left" aria-label="上一页"></i></a><a class="page-number" href="/">1</a><span class="space">&hellip;</span><a class="page-number" href="/page/27/">27</a><span class="page-number current">28</span><a class="page-number" href="/page/29/">29</a><span class="space">&hellip;</span><a class="page-number" href="/page/32/">32</a><a class="extend next" rel="next" href="/page/29/"><i class="fa fa-angle-right" aria-label="下一页"></i></a>
  </nav>



          </div>
          

        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    <div class="sidebar-inner">

      

      

      <div class="site-overview-wrap sidebar-panel sidebar-panel-active">
        <div class="site-overview">
          <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
            
              <p class="site-author-name" itemprop="name">Schwimmer</p>
              <div class="site-description motion-element" itemprop="description">Record and Think!</div>
          </div>

          
            <nav class="site-state motion-element">
              
                <div class="site-state-item site-state-posts">
                
                  <a href="/archives/">
                
                    <span class="site-state-item-count">313</span>
                    <span class="site-state-item-name">日志</span>
                  </a>
                </div>
              

              
                
                
                <div class="site-state-item site-state-categories">
                  
                    
                      <a href="/categories/">
                    
                  
                    
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                    <span class="site-state-item-count">20</span>
                    <span class="site-state-item-name">分类</span>
                  </a>
                </div>
              

              
                
                
                <div class="site-state-item site-state-tags">
                  
                    
                      <a href="/tags/">
                    
                  
                    
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                    <span class="site-state-item-count">55</span>
                    <span class="site-state-item-name">标签</span>
                  </a>
                </div>
              
            </nav>
          

          

          

          

          

          
          

          
            
          
          

        </div>
      </div>

      

      

    </div>
  </aside>
  


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <div class="copyright">&copy; <span itemprop="copyrightYear">2019</span>
  <span class="with-love" id="animate">
    <i class="fa fa-user"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">Schwimmer</span>

  

  
</div>


  <div class="powered-by">由 <a href="https://hexo.io" class="theme-link" rel="noopener" target="_blank">Hexo</a> 强力驱动 v3.5.0</div>



  <span class="post-meta-divider">|</span>



  <div class="theme-info">主题 – <a href="https://theme-next.org" class="theme-link" rel="noopener" target="_blank">NexT.Mist</a> v7.2.0</div>




        
<div class="busuanzi-count">
  <script async src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>

  
    <span class="post-meta-item-icon">
      <i class="fa fa-user"></i>
    </span>
    <span class="site-uv" title="总访客量">
      <span class="busuanzi-value" id="busuanzi_value_site_uv"></span>
    </span>
  

  
    <span class="post-meta-divider">|</span>
  

  
    <span class="post-meta-item-icon">
      <i class="fa fa-eye"></i>
    </span>
    <span class="site-pv" title="总访问量">
      <span class="busuanzi-value" id="busuanzi_value_site_pv"></span>
    </span>
  
</div>









        
      </div>
    </footer>

    
      <div class="back-to-top">
        <i class="fa fa-arrow-up"></i>
        
      </div>
    

    

    

    
  </div>

  

<script>
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>


























  
  <script src="/lib/jquery/index.js?v=3.4.1"></script>

  
  <script src="/lib/velocity/velocity.min.js?v=1.2.1"></script>

  
  <script src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>


  


  <script src="/js/utils.js?v=7.2.0"></script>

  <script src="/js/motion.js?v=7.2.0"></script>



  
  


  <script src="/js/schemes/muse.js?v=7.2.0"></script>




  

  


  <script src="/js/next-boot.js?v=7.2.0"></script>


  

  

  

  
  
<script>
  function loadCount() {
    var d = document, s = d.createElement('script');
    s.src = 'https://https-schwimmer-github-io.disqus.com/count.js';
    s.id = 'dsq-count-scr';
    (d.head || d.body).appendChild(s);
  }
  // defer loading until the whole page loading is completed
  window.addEventListener('load', loadCount, false);
</script><!-- hexo-inject:begin --><!-- hexo-inject:end -->







  




  

  

  
  

  
  
    
      
    
      
    
      
    
      
    
      
    
      
    
      
    
      
    
      
    
      
    
  

  


  

  

  

  

  

  

  

  

  

  

  

</body>
</html>
