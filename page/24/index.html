<!DOCTYPE html>












  


<html class="theme-next mist use-motion" lang="zh-CN">
<head><meta name="generator" content="Hexo 3.9.0">
  <!-- hexo-inject:begin --><!-- hexo-inject:end --><meta charset="UTF-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">






















<link rel="stylesheet" href="/lib/font-awesome/css/font-awesome.min.css?v=4.7.0">

<link rel="stylesheet" href="/css/main.css?v=7.2.0">


  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png?v=7.2.0">


  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png?v=7.2.0">


  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png?v=7.2.0">


  <link rel="mask-icon" href="/images/logo.svg?v=7.2.0" color="#222">







<script id="hexo.configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '/',
    scheme: 'Mist',
    version: '7.2.0',
    sidebar: {"position":"left","display":"post","offset":12,"onmobile":false,"dimmer":false},
    back2top: true,
    back2top_sidebar: false,
    fancybox: false,
    fastclick: false,
    lazyload: false,
    tabs: true,
    motion: {"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},
    algolia: {
      applicationID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    }
  };
</script>


  




  <meta name="description" content="Record and Think!">
<meta property="og:type" content="website">
<meta property="og:title" content="Schwimmer&#39;s Blog">
<meta property="og:url" content="https://schwimmer.github.io/page/24/index.html">
<meta property="og:site_name" content="Schwimmer&#39;s Blog">
<meta property="og:description" content="Record and Think!">
<meta property="og:locale" content="zh-CN">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Schwimmer&#39;s Blog">
<meta name="twitter:description" content="Record and Think!">





  
  
  <link rel="canonical" href="https://schwimmer.github.io/page/24/">



<script id="page.configurations">
  CONFIG.page = {
    sidebar: "",
  };
</script>

  <title>Schwimmer's Blog</title>
  




  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-143240576-1"></script>
  <script>
    var host = window.location.hostname;
    if (host !== "localhost" || !true) {
      window.dataLayer = window.dataLayer || [];
      function gtag(){dataLayer.push(arguments);}
      gtag('js', new Date());
      gtag('config', 'UA-143240576-1');
    }
  </script>









  <noscript>
  <style>
  .use-motion .motion-element,
  .use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-title { opacity: initial; }

  .use-motion .logo,
  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript><!-- hexo-inject:begin --><!-- hexo-inject:end -->

</head>

<body itemscope="" itemtype="http://schema.org/WebPage" lang="zh-CN">

  
  
    
  

  <!-- hexo-inject:begin --><!-- hexo-inject:end --><div class="container sidebar-position-left 
  page-home">
    <div class="headband"></div>

    <header id="header" class="header" itemscope="" itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-wrapper">
  <div class="site-meta">
    

    <div class="custom-logo-site-title">
      <a href="/" class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">Schwimmer's Blog</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
    
    
  </div>

  <div class="site-nav-toggle">
    <button aria-label="切换导航栏">
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
    </button>
  </div>
</div>



<nav class="site-nav">
  
    <ul id="menu" class="menu">
      
        
        
        
          
          <li class="menu-item menu-item-home">

    
    
      
    

    

    <a href="/" rel="section"><i class="menu-item-icon fa fa-fw fa-home"></i> <br>首页</a>

  </li>
        
        
        
          
          <li class="menu-item menu-item-tags">

    
    
      
    

    

    <a href="/tags/" rel="section"><i class="menu-item-icon fa fa-fw fa-tags"></i> <br>标签</a>

  </li>
        
        
        
          
          <li class="menu-item menu-item-categories">

    
    
      
    

    

    <a href="/categories/" rel="section"><i class="menu-item-icon fa fa-fw fa-th"></i> <br>分类</a>

  </li>
        
        
        
          
          <li class="menu-item menu-item-archives">

    
    
      
    

    

    <a href="/archives/" rel="section"><i class="menu-item-icon fa fa-fw fa-archive"></i> <br>归档</a>

  </li>

      
      
        <li class="menu-item menu-item-search">
          
            <a href="javascript:;" class="popup-trigger">
          
            
              <i class="menu-item-icon fa fa-search fa-fw"></i> <br>搜索</a>
        </li>
      
    </ul>
  

  
    

  

  
    <div class="site-search">
      
  <div class="popup search-popup local-search-popup">
  <div class="local-search-header clearfix">
    <span class="search-icon">
      <i class="fa fa-search"></i>
    </span>
    <span class="popup-btn-close">
      <i class="fa fa-times-circle"></i>
    </span>
    <div class="local-search-input-wrapper">
      <input autocomplete="off" placeholder="搜索..." spellcheck="false" type="text" id="local-search-input">
    </div>
  </div>
  <div id="local-search-result"></div>
</div>



    </div>
  
</nav>



  



</div>
    </header>

    


    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          
          <div id="content" class="content">
            
  <section id="posts" class="posts-expand">
    
      

  

  
  
  

  

  <article class="post post-type-normal" itemscope="" itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="https://schwimmer.github.io/2018/03/17/机器学习/知识点/">

    <span hidden itemprop="author" itemscope="" itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Schwimmer">
      <meta itemprop="description" content="Record and Think!">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope="" itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Schwimmer's Blog">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                
                <a href="/2018/03/17/机器学习/知识点/" class="post-title-link" itemprop="url">知识点</a>
              
            
          </h1>
        

        <div class="post-meta">

          
          
          

          
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              

              
                
              

              <time title="创建时间：2018-03-17 20:50:31" itemprop="dateCreated datePublished" datetime="2018-03-17T20:50:31+08:00">2018-03-17</time>
            </span>
          

          

          
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope="" itemtype="http://schema.org/Thing"><a href="/categories/机器学习/" itemprop="url" rel="index"><span itemprop="name">机器学习</span></a></span>

                
                
              
            </span>
          

          
            
            
              
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="fa fa-comment-o"></i>
                </span>
            
                <span class="post-meta-item-text">评论数：</span>
                <a href="/2018/03/17/机器学习/知识点/#comments" itemprop="discussionUrl">
                  <span class="post-comments-count disqus-comment-count" data-disqus-identifier="2018/03/17/机器学习/知识点/" itemprop="commentCount"></span>
                </a>
              </span>
            
          

          
          

          

          <br>
          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h3 id="特征选择"><a href="#特征选择" class="headerlink" title="特征选择"></a>特征选择</h3><h1 id="经典算法"><a href="#经典算法" class="headerlink" title="经典算法"></a>经典算法</h1><h2 id="LR"><a href="#LR" class="headerlink" title="LR"></a>LR</h2><p>线性回归模型的映射函数是一个线性方程。逻辑回归要解决分类问题，用logistic function代替线性方程，通过y的取值判断类别，y的取值是一个概率。</p>
<p>优点是，输出是0,1满足概率分布的要求。函数可微。</p>
<p>LR的L2正则</p>
<p>BFGS</p>
<h2 id="贝叶斯"><a href="#贝叶斯" class="headerlink" title="贝叶斯"></a>贝叶斯</h2><p>在多项式模型中：</p>
<blockquote>
<p>在多项式模型中， 设某文档d=(t1,t2,…,tk)，tk是该文档中出现过的单词，允许重复，则</p>
<p>先验概率P(c)= 类c下单词总数（包括重复的）/整个训练样本的单词总数</p>
<p>类条件概率P(tk|c)=(类c下单词tk在各个文档中出现过的次数之和+1)/(类c下单词总数+|V|)</p>
<p>V是训练样本的单词表（即抽取单词，单词出现多次，只算一个），|V|则表示训练样本包含多少种单词。 P(tk|c)可以看作是单词tk在证明d属于类c上提供了多大的证据，而P(c)则可以认为是类别c在整体上占多大比例(有多大可能性)。</p>
</blockquote>
<p>在伯努利模型中：</p>
<blockquote>
<p>P(c)= 类c下文件总数/整个训练样本的文件总数</p>
<p>P(tk|c)=(类c下包含单词tk的文件数+1)/(类c下文件总数+2)</p>
</blockquote>
<p>平滑项是应对没有特征的情况。</p>
<p><a href="http://blog.sina.com.cn/s/blog_15183f5750102vr62.html" target="_blank" rel="noopener">朴素贝叶斯算法的12条建议</a></p>
<h2 id="SVM"><a href="#SVM" class="headerlink" title="SVM"></a>SVM</h2><p>SVM在哪个地方引入的核函数?如果用高斯核可以升到多少维?</p>
<h2 id="BP的推导"><a href="#BP的推导" class="headerlink" title="BP的推导"></a>BP的推导</h2><p>反向传播的原理</p>
<h2 id="随机森林"><a href="#随机森林" class="headerlink" title="随机森林"></a>随机森林</h2><p>解决决策树容易过拟合的缺点。采用多个决策树的投票机制来改善决策树。RF有多个决策树，不能用全样本去训练，要用到采样方法。</p>
<p>1、每棵树选择样本时，通过重采样产生n个样本</p>
<p>2、从m个特征中随机选择k个特征，构建决策树。</p>
<p>3、多数投票制预测</p>
<h2 id="决策树"><a href="#决策树" class="headerlink" title="决策树"></a>决策树</h2><p>IC3，用信息增益找分裂特征。</p>
<p>C4.5，用信息增益比找特征。</p>
<h2 id="GBDT"><a href="#GBDT" class="headerlink" title="GBDT"></a>GBDT</h2><p><a href="http://www.cnblogs.com/ModifyRong/p/7744987.html" target="_blank" rel="noopener">机器学习算法GBDT的面试要点总结-上篇</a></p>
<p><a href="https://www.zhihu.com/question/41354392" target="_blank" rel="noopener">机器学习算法中GBDT和XGBOOST的区别有哪些？</a></p>
<p>推荐系统稍微看看</p>
<p>k折交叉验证中k取值多少有什么关系, 和bias和variance有关系吗?</p>
<p>翻转二叉树</p>
<p>平衡二叉树</p>
<p>hadoop和spark的应用场景</p>
<h3 id="样本倾斜的处理"><a href="#样本倾斜的处理" class="headerlink" title="样本倾斜的处理"></a>样本倾斜的处理</h3><p>样本不均衡的情况下，用AUC会偏高。</p>
<h6 id="分类算法的比较"><a href="#分类算法的比较" class="headerlink" title="分类算法的比较"></a>分类算法的比较</h6><p><a href="https://www.zhihu.com/question/24169940#answer-6100729" target="_blank" rel="noopener">用于数据挖掘的分类算法有哪些，各有何优劣？</a></p>
<h3 id="预测的评价指标"><a href="#预测的评价指标" class="headerlink" title="预测的评价指标"></a>预测的评价指标</h3><p><a href="https://www.zhihu.com/question/30643044" target="_blank" rel="noopener">精确率、召回率、F1 值、ROC、AUC 各自的优缺点是什么？</a></p>
<h4 id="ROC和AUC"><a href="#ROC和AUC" class="headerlink" title="ROC和AUC"></a>ROC和AUC</h4><p>构建一个混淆矩阵</p>
<p>TP FP</p>
<p>FN TN</p>
<p>精确率<code>(tp+tn)/(tp+fp+fn+tn)</code> 分类器对整个样本分类能力，正为正，负为负</p>
<p>准确率 TP/TP+FP 分类器判定为正例中，真正的正例样本比重。</p>
<p>召回率 tp/tp+fn 判定为正例在所有正例的比重</p>
<p>word2vec的原理</p>
<p>如何增量训练</p>
<p>是一个词转向量的工具，语料是收集的百万篇的url。</p>
<p>如何将词转成向量表达的？</p>
<p>模型的目标函数是什么</p>
<script type="math/tex; mode=display">
L=\sum_{w \in C} \log p(w|Context(w))</script><p> 如何推导的？</p>
<blockquote>
<p>ngram模型+对数似然函数</p>
</blockquote>
<p>基于神经网络的模型是如何做的</p>
<blockquote>
<p>输入层是(Context(w),w)的训练样本。输入的时候是n-1个词向量首尾拼接。（词向量还没训练呢是怎么得到的？在[0,1]之间随机取值初始化）</p>
<p>输入层到隐藏层用双曲正切函数作为激活函数。</p>
<p>隐藏层到输出层再用一个线性函数。这样输出的y只是一个普通向量，需要用softmax再做一个归一化处理。</p>
</blockquote>
<p>有了目标函数后，如何构建CBOW网络结构？</p>
<blockquote>
<p>网络结构：</p>
<p>输入层：前后各c个词，共2c个词的词向量。</p>
<p>投影层：向量做sum再取平均。</p>
<p>输出层：输出到Huffman树。每个叶子节点是一个词典中的词。</p>
<p>与神经网络模型的区别：</p>
<p>1）前者是拼接，后者是累加。2）后者没有隐藏层。3）前者是线性结构；后者是树形结构。</p>
</blockquote>
<p>如何利用Huffman树来定义目标函数？</p>
<blockquote>
<p>对于每个词，都存在一个路径，路径上存在分支，将每个分支看成一个二分类，每次分类产生一个概率。将这些概率连乘，就是目标函数。</p>
<p>公式见《NLP/Word2Vec原理》</p>
<p>权重初始化为0，词向量初始化为[0-1]的随机数。权重向量的长度就是所有词*词向量的长度。因为每层都有一个权重。</p>
<p>用了多线程方法加速训练。</p>
</blockquote>
<p>为什么叫层次softmax？</p>
<blockquote>
<p>每层都是一个二分类问题</p>
</blockquote>
<p>为什么同义词的向量也相近</p>
<blockquote>
<p>我理解是上下文接近，对于CBOW，训练每个词后更新的是上下文，对于近义词往往有类似的上下文</p>
</blockquote>
<p>如何计算距一个词最近的向量？</p>
<blockquote>
<p>KD树搜索。（<a href="https://www.cnblogs.com/21207-iHome/p/6084670.html）" target="_blank" rel="noopener">https://www.cnblogs.com/21207-iHome/p/6084670.html）</a></p>
<p>构建方法：任选一个特征（或者数据方差最大的特征，说明分散，越可能不属于同一个区间），以此为坐标轴划分，将最近的点落在坐标轴上。</p>
<p><img src="https://images2015.cnblogs.com/blog/890966/201611/890966-20161123134503362-571302342.png" alt=""></p>
<p>KD树搜索</p>
<p>先从根节点往下找到叶子节点，再回溯，回溯到每层时要判断是否跟另一区间相交。</p>
<p><img src="https://images2015.cnblogs.com/blog/890966/201611/890966-20161123150431143-1520224794.png" alt=""></p>
<p>但是KD是递归查找，效率低。递归效率低是函数调用的开销导致的（函数调用需要准备资源），且有栈溢出的风险。</p>
<p>idistance</p>
<p><a href="https://en.m.wikipedia.org/wiki/IDistance" target="_blank" rel="noopener">https://en.m.wikipedia.org/wiki/IDistance</a></p>
<p>目前线上怎么做的</p>
</blockquote>
<p>如何用word2vec计算句子相似度</p>
<blockquote>
<p>词向量按tfidf权重求mean</p>
<p>也要分应用，需求是topic相关还是语义相关。比如我爱苹果，我不爱苹果，topic相似语义不相似。</p>
<p>如果从词的粒度比较，还要结合上下文，避免一词多义。</p>
</blockquote>
<p>文本分类</p>
<blockquote>
<p>可以直接用fasttext，也可以tfidf+svm</p>
</blockquote>
<p>熵</p>
<p>随机游走算法</p>
<p>动态规划算法</p>
<p>异常检测算法</p>
<h1 id="CTR预测"><a href="#CTR预测" class="headerlink" title="CTR预测"></a>CTR预测</h1><h2 id="如何预测CTR线上的效果"><a href="#如何预测CTR线上的效果" class="headerlink" title="如何预测CTR线上的效果"></a>如何预测CTR线上的效果</h2><p>线下的可以用log loss和AUC</p>
<p><strong>这里要特别强调一下用线上的其它业务指标如点击率、营收、利润、eCPC等等是不能给出CTR预估效果评价的</strong>。这些业务指标，受到整个广告系统其它模块如bid optimization,budget pacing等和外部竞价环境的综合影响，它的变化或者AB test中观察到的不同，不是简单地由于CTR预估变化带来的。换句话说，如果上了一个新的CTR预估模型的实验，发现业务指标变好了，这不等于说CTR预估更准了。一个简单的例子：如果一个CTR预估模型给出的预估总是比上帝视角的完美预估在低CTR区域低估，在高CTR区域高估，那么假设bid是base_bid*pCTR的话，相比完美预估，这个模型会赢得更多的高CTR区域的竞价，输掉更多在低CTR区域的竞价，最后会观察到实验组的CTR反而比完美预估的试验组更高。作者：Jian Xu链接：<a href="https://www.zhihu.com/question/54009615/answer/137820154来源：知乎著作权归作者所有。商业转载请联系作者获得授权，非商业转载请注明出处。" target="_blank" rel="noopener">https://www.zhihu.com/question/54009615/answer/137820154来源：知乎著作权归作者所有。商业转载请联系作者获得授权，非商业转载请注明出处。</a></p>
<h3 id="为什么AUC可以评价CTR"><a href="#为什么AUC可以评价CTR" class="headerlink" title="为什么AUC可以评价CTR"></a>为什么AUC可以评价CTR</h3><p>它和Wilcoxon-Mann-Witney Test是等价的[3]。而Wilcoxon-Mann-Witney Test就是测试任意给一个正类样本和一个负类样本，正类样本的score有多大的概率大于负类样本的score。</p>
<p>如何平衡样本？平衡后的数据不是真实分布</p>
<h6 id="CTR评价"><a href="#CTR评价" class="headerlink" title="CTR评价"></a>CTR评价</h6><p>CTR的评价用logloss和AUC。因为是概率输出，不方便用PR。</p>
<h6 id="点击率各模型优缺点"><a href="#点击率各模型优缺点" class="headerlink" title="点击率各模型优缺点"></a>点击率各模型优缺点</h6><p><a href="https://www.zhihu.com/question/62109451?answer_deleted_redirect=true" target="_blank" rel="noopener">广告点击率模型中，LR, GBDT+LR, FM, DNN等模型的优点和缺点？实际效果如何?</a></p>
<p><a href="http://blog.csdn.net/lilyth_lilyth/article/details/48032119" target="_blank" rel="noopener">CTR预估中GBDT与LR融合方案</a></p>
<p><a href=""><a href="http://blog.csdn.net/bitcarmanlee/article/details/52138970" target="_blank" rel="noopener">CTR点击率预估干货分享</a></a></p>
<p>Ad Click Prediction: a View from the Trenches</p>
<p><img src="https://pic1.zhimg.com/80/v2-7a75ba913f11b4fb483228f70172003a_hd.jpg" alt=""></p>
<p>LR</p>
<p>优点：实现简单</p>
<p>缺点：需要寻找特征。我们也使用了FTRL，但实践中它并不能非常有效的产生稀疏模型，如果模型非常大，会导致同步模型变慢，一样会严重影响效果。</p>
<h6 id="点击率模型中特征如何选择"><a href="#点击率模型中特征如何选择" class="headerlink" title="点击率模型中特征如何选择"></a>点击率模型中特征如何选择</h6><p><a href="http://blog.csdn.net/ariessurfer/article/details/40380051" target="_blank" rel="noopener">广告点击率预估中的特征选择</a></p>
<p>不是看它分布均不均衡，而是看它符不符合原来的分布。如果符合原来的分布，那么训练误差最小化也就意味着整体分布误差的最小化，也就没有必要进行均衡。</p>
<p>如何降维，每个特征都对应的ctr，在构建模型时，根据ctr的区间将属于同一个区间的特征值作为一个特征；随着ctr区间越分越细来迭代。停止条件是不超过所有特征的一半或达到最小区间阈值。</p>
<h6 id="投放中出现的问题"><a href="#投放中出现的问题" class="headerlink" title="投放中出现的问题"></a>投放中出现的问题</h6><h6 id="spark数据倾斜"><a href="#spark数据倾斜" class="headerlink" title="spark数据倾斜"></a>spark数据倾斜</h6><p><a href="https://www.cnblogs.com/hd-zg/p/6089220.html" target="_blank" rel="noopener">https://www.cnblogs.com/hd-zg/p/6089220.html</a></p>
<h6 id="spark资源调优"><a href="#spark资源调优" class="headerlink" title="spark资源调优"></a>spark资源调优</h6><p><a href="http://blog.csdn.net/u012102306/article/details/51637366" target="_blank" rel="noopener">http://blog.csdn.net/u012102306/article/details/51637366</a></p>
<p>我们使用yarn作为资源管理集群。yarn集群管理器根据spark参数，在各个工作节点上，启动一定数量的Executor进程，每个进程有一定的内存和CPU  Core。</p>
<p>在申请到了作业执行所需的资源之后，Driver进程就会开始调度和执行我们编写的作业代码了。Driver将代码拆分为多个stage，为每个stage创建一批task。将这些task分配到各个Executor执行。</p>
<p>SparkConf的一些参数：</p>
<p>spark.sql.shuffle.partitions指partition的数量。SparkSQL在运行时，将一个查询任务分解成多个task，一个task就是一个partition。默认是200个partition，而如果实际集群只能并行3个task，则跑完200个partition要200/3=67次。</p>
<p>spark.network.timeout所有网络通信的超时时间，默认是120s</p>
<h6 id="mapreduce-shuffle过程"><a href="#mapreduce-shuffle过程" class="headerlink" title="mapreduce shuffle过程"></a>mapreduce shuffle过程</h6><p><a href="http://langyu.iteye.com/blog/992916" target="_blank" rel="noopener">http://langyu.iteye.com/blog/992916</a></p>
<p>map过程，阶段，将输入文本做split，并转成<k,v>格式，V的初始值是1</k,v></p>
<p>之后，partitioner可以根据key和value以及reduce的数量来决定map的输出放到那个reduce task。默认是key hash后对reduce取模。</p>
<p>接下来将output写入缓冲区，减少磁盘IO的影响。key，value，partitioner的结果都写入缓冲区。</p>
<p>当缓冲区内容达到一定比例，就调用单独线程溢写到磁盘。溢写前，如果设置了combiner，在这里就要做合并。当溢写启动后，需要对溢写内容的key做sort。</p>
<p>Merge。每次溢写生成一个文件，map task完成后内存缓冲区所有的数据也全部溢写生成一个文件。用Merge合并溢写文件。</p>
<p>reduce</p>
<p>执行之前，拉取每个job中每个map task的最终结果。从不同地方拉过来的做merge。作为reducer的输入，然后执行reducer，结果写入hdfs。</p>
<p>文本分类怎么优化特征</p>
<h6 id="CTR预测怎么优化特征"><a href="#CTR预测怎么优化特征" class="headerlink" title="CTR预测怎么优化特征"></a>CTR预测怎么优化特征</h6><p>选特征，版位id，版位类型，地理位置，曝光时间，ua信息（操作系统，浏览器等），人群特征因为样本稀疏所有没有选</p>
<p>根据直接观察CTR，卡方检验，单特征AUC。</p>
<p>用互信息、卡方检验有没有用</p>
<p>没有CTR的新版位</p>
<p>word2vec新词</p>
<p>es</p>
<p>java api常见操作，从hive导入，从文件导入，中文分词</p>
<p>user-gene，投放，tracking处理的流程图</p>
<p>domain黑名单</p>
<p>DFA算法过滤敏感词</p>
<p>二分查找</p>
<h6 id="特征稀疏怎么做"><a href="#特征稀疏怎么做" class="headerlink" title="特征稀疏怎么做"></a>特征稀疏怎么做</h6><p><a href="https://www.zhihu.com/question/48673581#answer-49246569" target="_blank" rel="noopener">传统的CTR或推荐系统拥有高维特征和稀疏数据，转向深度学习如何</a></p>
<p>如果可用特征值太少，就丢弃；要么就设值为unknown；xgboost有稀疏感知算法</p>
<p>怎么想到age预测算法的</p>
<p>哪些媒体获取？电商，微信</p>
<p>audience的重合度，距离代表相关度</p>
<p>hive的存储，ORC格式，以前用SequenceFile</p>
<p>pig，数据倾斜时的join用replicated，大表放左，其他放右。</p>
<p>动态规划</p>
<p>L1和L2有什么区别</p>
<h2 id="乱序数组找中位数"><a href="#乱序数组找中位数" class="headerlink" title="乱序数组找中位数"></a>乱序数组找中位数</h2><p>快排+二分。取partition后，去掉一半的数字。</p>
<p>直接拿一个素材的点击率当一个维度的特征？</p>
<p>随机森林和GBDT的区别</p>
<h6 id="如何提高召回率或精确率"><a href="#如何提高召回率或精确率" class="headerlink" title="如何提高召回率或精确率"></a>如何提高召回率或精确率</h6><p><a href="https://www.zhihu.com/question/39819838" target="_blank" rel="noopener">如何提高机器学习算法的召回率？（尤其在样本集不平衡时）</a></p>
<h6 id="引擎流程"><a href="#引擎流程" class="headerlink" title="引擎流程"></a>引擎流程</h6><p>用timeslot监控campaign参数变化，预测下一个slot。第一个slot内不投放。</p>
<p>1、计算的参数包括flowbiddingrate、利润区间。</p>
<p>fbr衡量擦camp能投放的量占总量的百分比。比如根据预算，剩余每个slot的预算/每个slot的最大预算；曝光就是每个slot剩余曝光量/最大曝光量。</p>
<p>2、然后预测ctr并计算松弛系数（实际-期望），判断是否可以投放。</p>
<p>3、计算竞价，计算初始值，对于CPM，根据投放和曝光速度进行调整。对于CPC，如果实际CTR较高，通过提高一些小CTR的出价来平滑。</p>
<p>4、通过版位历史价格计算预期利润，统计利润区间分布。根据fbr确定可投放的利润区间。</p>
<p>5、通过投放平衡率计算camp打分。</p>

          
        
      
    </div>

    

    
    
    

    

    
      
    
    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  

  <article class="post post-type-normal" itemscope="" itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="https://schwimmer.github.io/2018/03/17/机器学习/模型的假设条件/">

    <span hidden itemprop="author" itemscope="" itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Schwimmer">
      <meta itemprop="description" content="Record and Think!">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope="" itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Schwimmer's Blog">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                
                <a href="/2018/03/17/机器学习/模型的假设条件/" class="post-title-link" itemprop="url">模型的假设条件</a>
              
            
          </h1>
        

        <div class="post-meta">

          
          
          

          
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              

              
                
              

              <time title="创建时间：2018-03-17 20:50:31" itemprop="dateCreated datePublished" datetime="2018-03-17T20:50:31+08:00">2018-03-17</time>
            </span>
          

          

          
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope="" itemtype="http://schema.org/Thing"><a href="/categories/机器学习/" itemprop="url" rel="index"><span itemprop="name">机器学习</span></a></span>

                
                
              
            </span>
          

          
            
            
              
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="fa fa-comment-o"></i>
                </span>
            
                <span class="post-meta-item-text">评论数：</span>
                <a href="/2018/03/17/机器学习/模型的假设条件/#comments" itemprop="discussionUrl">
                  <span class="post-comments-count disqus-comment-count" data-disqus-identifier="2018/03/17/机器学习/模型的假设条件/" itemprop="commentCount"></span>
                </a>
              </span>
            
          

          
          

          

          <br>
          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <blockquote>
<p>作者：李韶华链接：<a href="https://www.zhihu.com/question/46301335/answer/112354887来源：知乎著作权归作者所有。商业转载请联系作者获得授权，非商业转载请注明出处。" target="_blank" rel="noopener">https://www.zhihu.com/question/46301335/answer/112354887来源：知乎著作权归作者所有。商业转载请联系作者获得授权，非商业转载请注明出处。</a></p>
</blockquote>
<p>理解模型的基本假设，看自己的数据是否符合这种假设。任何模型都是有某种假设的，如果数据不符合这种假设，就不太可能学出有意义的模型并用于预测。</p>
<p>比如LDA（主题模型），假设是在同样一批文档中经常共现的词，语义上往往是相关的。这种特性不仅在自然语言中成立，在一些领域，比如每个人经常访问的网址集合，可能也是成立的，所以LDA也可以拿过去用。但如果数据不符合这个特性，套用LDA就是没有意义的，比如每个球队里的队员，可能并没有因为属于一个球队而具有什么相似性。</p>
<p>再举个例子，CNN（卷积神经网络），它的基本假设是特征的不同维度之间有局部相关性，卷积操作可以抓住这只局部相关性，形成新的特征。比如自然语言里，有重复出现的bigram，或者图像里代表性的局部像素块。不满足这种局部相关性的数据，比如收到的邮件序列，这种局部相关性很弱，那用CNN就不能抓到有用的特征。</p>
<p>最后，高斯copula，在量化金融里曾被广泛使用，把债券之间非高斯的相关性用copula转化成高斯然后拟合。然而这个模型隐含的假设是这种相关性符合瘦尾分布(thin tailed distribution)，即罕见事件发生的概率非常非常低。这个不合理假设导致对黑天鹅事件概率严重低估，曾被视为2008年金融危机的根源之一。</p>

          
        
      
    </div>

    

    
    
    

    

    
      
    
    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  

  <article class="post post-type-normal" itemscope="" itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="https://schwimmer.github.io/2018/03/17/机器学习/样本倾斜/">

    <span hidden itemprop="author" itemscope="" itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Schwimmer">
      <meta itemprop="description" content="Record and Think!">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope="" itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Schwimmer's Blog">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                
                <a href="/2018/03/17/机器学习/样本倾斜/" class="post-title-link" itemprop="url">样本倾斜</a>
              
            
          </h1>
        

        <div class="post-meta">

          
          
          

          
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              

              
                
              

              <time title="创建时间：2018-03-17 20:50:31" itemprop="dateCreated datePublished" datetime="2018-03-17T20:50:31+08:00">2018-03-17</time>
            </span>
          

          

          
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope="" itemtype="http://schema.org/Thing"><a href="/categories/机器学习/" itemprop="url" rel="index"><span itemprop="name">机器学习</span></a></span>

                
                
              
            </span>
          

          
            
            
              
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="fa fa-comment-o"></i>
                </span>
            
                <span class="post-meta-item-text">评论数：</span>
                <a href="/2018/03/17/机器学习/样本倾斜/#comments" itemprop="discussionUrl">
                  <span class="post-comments-count disqus-comment-count" data-disqus-identifier="2018/03/17/机器学习/样本倾斜/" itemprop="commentCount"></span>
                </a>
              </span>
            
          

          
          

          

          <br>
          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <blockquote>
<p> 严重数据倾斜文本分类，比如正反比1:20～100，适合什么model，查准一般要做到多少可以上线？ - 竹间智能 Emotibot的回答 - 知乎</p>
<p> <a href="https://www.zhihu.com/question/59236897/answer/164500508" target="_blank" rel="noopener">https://www.zhihu.com/question/59236897/answer/164500508</a></p>
</blockquote>
<p>首先要<strong>明确对于precision和recall，我们的需求是怎样的</strong> 。对于数据极其不平衡的情况，precision和recall的trade-off尤其显著。通过under-sampling/over-sampling来配平正反例是可以提升recall，但是一定会出现大量的false positive。如果我们认为错杀的成本很高，可以适当地降低对于precision的要求。反之，如果我们追求precision，那么可以采用基于规则的方式，通过对关键词的特征进行过滤，当然这样recall就会很惨。这是一个必须接受的现实。如果将这两种策略结合，最起码可以做这样的尝试：对于高precision的分类器，采取比较高信心的策略，譬如探测出来就直接报告这个用户甚至屏蔽；对于高recall的分类器，可以采取一些warning的措施，不强制做影响用户的操作。</p>
<p>粗暴一点，随机森林+bootstrap效果不错。</p>
<p>或者如果倾斜非常大，可以考虑异常检测的方法。</p>
<h1 id="过采样"><a href="#过采样" class="headerlink" title="过采样"></a>过采样</h1><p> SMOTE算法，插值</p>
<p>高维度不适宜SMOTE。因为高维空间数据倾向于接近互相正交，故两两不相近，所以效果不好。</p>
<h1 id="欠采样"><a href="#欠采样" class="headerlink" title="欠采样"></a>欠采样</h1><h1 id="再缩放-再平衡"><a href="#再缩放-再平衡" class="headerlink" title="再缩放/再平衡"></a>再缩放/再平衡</h1><p>假设训练集是真是样本总体的无偏采样，观测几率就是真实几率。只要分类器的预测几率高于观测几率就应判定为正例，即</p>
<script type="math/tex; mode=display">
\frac {\tilde {y}} {1- \tilde{y}} = \frac y {1-y} × \frac {m^-} {m^+}</script><p><a href="https://www.zhihu.com/question/30860609/answer/167222442" target="_blank" rel="noopener">使用机器学习处理分类问题时，若训练样本比较稀疏，可否向训练语料中增加人工构造样本，以提升模型泛化能力？</a></p>
<p><a href="https://www.zhihu.com/question/66408862/answer/245813803" target="_blank" rel="noopener">如何解决机器学习中样本不均衡问题？</a></p>

          
        
      
    </div>

    

    
    
    

    

    
      
    
    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  

  <article class="post post-type-normal" itemscope="" itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="https://schwimmer.github.io/2018/03/17/机器学习/样本不平衡带来的问题及如何解决/">

    <span hidden itemprop="author" itemscope="" itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Schwimmer">
      <meta itemprop="description" content="Record and Think!">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope="" itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Schwimmer's Blog">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                
                <a href="/2018/03/17/机器学习/样本不平衡带来的问题及如何解决/" class="post-title-link" itemprop="url">样本不平衡带来的问题及如何解决</a>
              
            
          </h1>
        

        <div class="post-meta">

          
          
          

          
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              

              
                
              

              <time title="创建时间：2018-03-17 20:50:31" itemprop="dateCreated datePublished" datetime="2018-03-17T20:50:31+08:00">2018-03-17</time>
            </span>
          

          

          
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope="" itemtype="http://schema.org/Thing"><a href="/categories/机器学习/" itemprop="url" rel="index"><span itemprop="name">机器学习</span></a></span>

                
                
              
            </span>
          

          
            
            
              
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="fa fa-comment-o"></i>
                </span>
            
                <span class="post-meta-item-text">评论数：</span>
                <a href="/2018/03/17/机器学习/样本不平衡带来的问题及如何解决/#comments" itemprop="discussionUrl">
                  <span class="post-comments-count disqus-comment-count" data-disqus-identifier="2018/03/17/机器学习/样本不平衡带来的问题及如何解决/" itemprop="commentCount"></span>
                </a>
              </span>
            
          

          
          

          

          <br>
          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p><a href="https://www.jianshu.com/p/3e8b9f2764c8" target="_blank" rel="noopener">不平衡数据下的机器学习方法简介</a></p>
<p><a href="https://wenku.baidu.com/view/535f51cc09a1284ac850ad02de80d4d8d15a01c2.html" target="_blank" rel="noopener">面向不平衡分类的逻辑回归算法</a></p>
<p>在样本分布及其不均匀的情况下,建议用PRC。。。可以看下这个<a href="https://www.zhihu.com/question/30643044" target="_blank" rel="noopener">精确率、召回率、F1 值、ROC、AUC 各自的优缺点是什么？ - 机器学习</a>里面qian lv的回答</p>
<p><a href="http://blog.csdn.net/heyongluoyao8/article/details/49408131" target="_blank" rel="noopener">在分类中如何处理训练集中不平衡问题</a></p>
<p><a href="https://www.zhihu.com/question/27408423" target="_blank" rel="noopener">确切的知道正样本但负样本不确定，且训练数据正负样本分布极不平衡问题求教？</a></p>
<p><a href="http://blog.csdn.net/heyongluoyao8/article/details/49408131" target="_blank" rel="noopener">在分类中如何处理训练集中不平衡问题</a></p>

          
        
      
    </div>

    

    
    
    

    

    
      
    
    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  

  <article class="post post-type-normal" itemscope="" itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="https://schwimmer.github.io/2018/03/17/机器学习/机器学习模型的比较/">

    <span hidden itemprop="author" itemscope="" itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Schwimmer">
      <meta itemprop="description" content="Record and Think!">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope="" itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Schwimmer's Blog">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                
                <a href="/2018/03/17/机器学习/机器学习模型的比较/" class="post-title-link" itemprop="url">机器学习模型的比较</a>
              
            
          </h1>
        

        <div class="post-meta">

          
          
          

          
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              

              
                
              

              <time title="创建时间：2018-03-17 20:50:31" itemprop="dateCreated datePublished" datetime="2018-03-17T20:50:31+08:00">2018-03-17</time>
            </span>
          

          

          
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope="" itemtype="http://schema.org/Thing"><a href="/categories/机器学习/" itemprop="url" rel="index"><span itemprop="name">机器学习</span></a></span>

                
                
              
            </span>
          

          
            
            
              
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="fa fa-comment-o"></i>
                </span>
            
                <span class="post-meta-item-text">评论数：</span>
                <a href="/2018/03/17/机器学习/机器学习模型的比较/#comments" itemprop="discussionUrl">
                  <span class="post-comments-count disqus-comment-count" data-disqus-identifier="2018/03/17/机器学习/机器学习模型的比较/" itemprop="commentCount"></span>
                </a>
              </span>
            
          

          
          

          

          <br>
          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>转自 用于数据挖掘的分类算法有哪些，各有何优劣？ - Jason Gu的回答 - 知乎<br><a href="https://www.zhihu.com/question/24169940/answer/26952728" target="_blank" rel="noopener">https://www.zhihu.com/question/24169940/answer/26952728</a></p>
<p><a href="https://zhuanlan.zhihu.com/p/27160995" target="_blank" rel="noopener">机器学习经典算法优缺点总结</a></p>
<p>首先看训练集多大，</p>
<p>贝叶斯因为模型简单，所以高偏差低方差。数据量小的时候，贝叶斯更好，因为LR容易过拟合。随着训练集增大，LR能训练出更准确的模型。</p>
<blockquote>
<p>偏差指因模型太简单带来的估计不准确的部分。方差指因模型太复杂带来的不确定性。</p>
</blockquote>
<p>LR相对于贝叶斯，不需要考虑特征是否相关。更容易增量训练。</p>
<p>LR可解释好，某个特征的权重高，则对结果的影响也大。可以在线学习。</p>
<p>决策树容易过拟合，使用剪树枝，或者RF。</p>
<h1 id="Linear-SVM和LR的比较"><a href="#Linear-SVM和LR的比较" class="headerlink" title="Linear SVM和LR的比较"></a>Linear SVM和LR的比较</h1><p><a href="http://www.jishux.com/plus/view-615065-1.html" target="_blank" rel="noopener">http://www.jishux.com/plus/view-615065-1.html</a></p>
<h2 id="从模型解决问题的方式来看"><a href="#从模型解决问题的方式来看" class="headerlink" title="从模型解决问题的方式来看"></a>从模型解决问题的方式来看</h2><p>Linear SVM直观上是trade-off两个量</p>
<ol>
<li>a large margin，就是两类之间可以画多宽的gap ；不妨说是正样本应该在分界平面向左gap/2（称正分界），负样本应该在分解平面向右gap/2（称负分界）</li>
<li>L1 error penalty，对所有不满足上述条件的点做L1 penalty</li>
</ol>
<p>给定一个数据集，一旦完成Linear SVM的求解，所有数据点可以被归成两类</p>
<ol>
<li>一类是落在对应分界平面外并被正确分类的点，比如落在正分界左侧的正样本或落在负分界右侧的负样本</li>
<li>第二类是落在gap里或被错误分类的点。</li>
</ol>
<p>假设一个数据集已经被Linear SVM求解，那么往这个数据集里面增加或者删除更多的一类点并不会改变重新求解的Linear SVM平面。不受数据分布的影响。</p>
<p>求解LR模型过程中，<strong>每一个数据点对分类平面都是有影响的</strong>，它的影响力远离它到分类平面的距离指数递减。换句话说，LR的解是<strong>受数据本身分布</strong>影响的。在实际应用中，如果数据维度很高，LR模型都会配合参数的L1 regularization。</p>
<h2 id="两者的区别"><a href="#两者的区别" class="headerlink" title="两者的区别"></a>两者的区别</h2><p>两个模型对<strong>数据和参数</strong>的敏感程度不同，Linear SVM比较依赖penalty的系数和<strong>数据表达空间的测度</strong>，而（带正则项的）LR<strong>比较依赖对参数做L1 regularization的系数</strong>。但是由于他们或多或少都是线性分类器，所以实际上对低维度数据overfitting的能力都比较有限，相比之下对高维度数据，LR的表现会更加稳定，为什么呢？因为Linear SVM在计算margin有多“宽”的时候是依赖数据表达上的距离测度的，换句话说如果这个测度不好（badly scaled，这种情况在高维数据尤为显著），所求得的所谓Large margin就没有意义了，这个问题即使换用kernel trick（比如用Gaussian kernel）也无法完全避免。所以使用Linear SVM之前一般都需要先对数据做normalization，而求解LR（without regularization）时则不需要或者结果不敏感。</p>
<p>Linear SVM和LR都是线性分类器<br>Linear SVM不直接依赖数据分布，分类平面不受一类点影响；<strong>LR则受所有数据点的影响，如果数据不同类别strongly unbalance一般需要先对数据做balancing</strong>。<br>Linear SVM<strong>依赖数据表达的距离测度，所以需要对数据先做normalization</strong>；LR不受其影响<br>Linear SVM依赖penalty的系数，实验中需要做validation<br>Linear SVM和LR的performance都会收到outlier的影响，其敏感程度而言，谁更好很难下明确结论。</p>
<p><strong>balance的方法</strong></p>
<ol>
<li>调整正、负样本在求cost时的权重，比如按比例加大正样本cost的权重。然而deep learning的训练过程是on-line的因此你需要按照batch中正、负样本的比例调整。</li>
<li>做训练样本选取：如hard negative mining，只用负样本中的一部分。</li>
<li>做训练样本选取：如通过data augmentation扩大正样本数量。</li>
</ol>
<p><strong>过拟合方面</strong></p>
<p>LR容易欠拟合，准确度低。</p>
<p>SVM不太容易过拟合：松弛因子+损失函数形式</p>
<p>注意SVM的求解方法叫拉格朗日乘子法，而对于均方误差的优化方法是最小二乘法。</p>
<h2 id="方法的选择"><a href="#方法的选择" class="headerlink" title="方法的选择"></a>方法的选择</h2><p>在Andrew NG的课里讲到过：</p>
<ol>
<li>如果Feature的数量很大，跟样本数量差不多，这时候选用LR或者是Linear Kernel的SVM</li>
<li>如果Feature的数量比较小，样本数量一般，不算大也不算小，选用SVM+Gaussian Kernel</li>
<li>如果Feature的数量比较小，而样本数量很多，需要手工添加一些feature变成第一种情况</li>
</ol>
<p>当你的数据非常非常非常非常非常大然后完全跑不动SVM的时候，跑LR。SVM适合于小样本学习。多大算是非常非常非常非常非常非常大？ 比如几个G，几万维特征，就勉强算大吧…而实际问题上几万个参数实在完全不算个事儿，太常见了。随随便便就得上spark。读一遍数据就老半天，一天能训练出来的模型就叫高效了。所以在新时代，LR其实反而比以前用的多了=. =</p>
<h2 id="应用场景方面不同"><a href="#应用场景方面不同" class="headerlink" title="应用场景方面不同"></a>应用场景方面不同</h2><p>拟合程度，样本量，</p>
<p>距离测度，数据balance</p>
<p>模型简单易解释</p>
<p>如果数据特征维度高，svm要使用核函数来求解</p>
<p>Note：拉格朗日对偶没有改变最优解，但改变了算法复杂度：原问题—样本维度；对偶问题–样本数量。所以 线性分类&amp;&amp;样本维度&lt;样本数量：原问题求解（liblinear默认）； 非线性–升维—一般导致 样本维度&gt;样本数量：对偶问题求解</p>
<h2 id="SVM适合处理什么样的数据？"><a href="#SVM适合处理什么样的数据？" class="headerlink" title="SVM适合处理什么样的数据？"></a>SVM适合处理什么样的数据？</h2><p>高维稀疏，样本少。【参数只与支持向量有关，数量少，所以需要的样本少，由于参数跟维度没有关系，所以可以处理高维问题】</p>
<h1 id="机器学习算法选择"><a href="#机器学习算法选择" class="headerlink" title="机器学习算法选择"></a>机器学习算法选择</h1><p><a href="http://www.jishux.com/plus/view-615065-1.html" target="_blank" rel="noopener">机器学习算法小结与收割offer遇到的问题</a></p>
<p>随机森林平均来说最强，但也只在9.9%的数据集上拿到了第一，优点是鲜有短板。SVM的平均水平紧随其后，在10.7%的数据集上拿到第一。神经网络（13.2%）和boosting（~9%）表现不错。数据维度越高，随机森林就比AdaBoost强越多，但是整体不及SVM<a href="http://img.jishux.com/jishux/2017/09/26/490ec60ad4bcb6e0992bded7407b26f4d2b11a5d.jpg_.jpg" target="_blank" rel="noopener">2</a>。数据量越大，神经网络就越强。</p>
<h2 id="K近邻"><a href="#K近邻" class="headerlink" title="K近邻"></a>K近邻</h2><p>典型的例子是KNN，它的思路就是——对于待判断的点，找到离它最近的几个数据点，根据它们的类型决定待判断点的类型。</p>
<p>它的特点是完全跟着数据走，没有数学模型可言。</p>
<h2 id="随机森林"><a href="#随机森林" class="headerlink" title="随机森林"></a>随机森林</h2><h3 id="RF与传统bagging的区别"><a href="#RF与传统bagging的区别" class="headerlink" title="RF与传统bagging的区别"></a>RF与传统bagging的区别</h3><p>（1）<strong>样本采样</strong>：RF<strong>有放回</strong>选取和整体样本数目相同的样本，一般bagging用的样本&lt;总体样本数<br>（2）<strong>特征采样</strong>：RF对特征进行采样，BAGGING用全部特征</p>

          
        
      
    </div>

    

    
    
    

    

    
      
    
    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  

  <article class="post post-type-normal" itemscope="" itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="https://schwimmer.github.io/2018/03/17/机器学习/文本分类/">

    <span hidden itemprop="author" itemscope="" itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Schwimmer">
      <meta itemprop="description" content="Record and Think!">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope="" itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Schwimmer's Blog">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                
                <a href="/2018/03/17/机器学习/文本分类/" class="post-title-link" itemprop="url">文本分类</a>
              
            
          </h1>
        

        <div class="post-meta">

          
          
          

          
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              

              
                
              

              <time title="创建时间：2018-03-17 20:50:31" itemprop="dateCreated datePublished" datetime="2018-03-17T20:50:31+08:00">2018-03-17</time>
            </span>
          

          

          
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope="" itemtype="http://schema.org/Thing"><a href="/categories/机器学习/" itemprop="url" rel="index"><span itemprop="name">机器学习</span></a></span>

                
                
              
            </span>
          

          
            
            
              
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="fa fa-comment-o"></i>
                </span>
            
                <span class="post-meta-item-text">评论数：</span>
                <a href="/2018/03/17/机器学习/文本分类/#comments" itemprop="discussionUrl">
                  <span class="post-comments-count disqus-comment-count" data-disqus-identifier="2018/03/17/机器学习/文本分类/" itemprop="commentCount"></span>
                </a>
              </span>
            
          

          
          

          

          <br>
          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            
          
        
      
    </div>

    

    
    
    

    

    
      
    
    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  

  <article class="post post-type-normal" itemscope="" itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="https://schwimmer.github.io/2018/03/17/机器学习/机器学习笔记-熵/">

    <span hidden itemprop="author" itemscope="" itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Schwimmer">
      <meta itemprop="description" content="Record and Think!">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope="" itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Schwimmer's Blog">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                
                <a href="/2018/03/17/机器学习/机器学习笔记-熵/" class="post-title-link" itemprop="url">熵</a>
              
            
          </h1>
        

        <div class="post-meta">

          
          
          

          
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              

              
                
              

              <time title="创建时间：2018-03-17 20:50:31" itemprop="dateCreated datePublished" datetime="2018-03-17T20:50:31+08:00">2018-03-17</time>
            </span>
          

          

          
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope="" itemtype="http://schema.org/Thing"><a href="/categories/机器学习/" itemprop="url" rel="index"><span itemprop="name">机器学习</span></a></span>

                
                
              
            </span>
          

          
            
            
              
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="fa fa-comment-o"></i>
                </span>
            
                <span class="post-meta-item-text">评论数：</span>
                <a href="/2018/03/17/机器学习/机器学习笔记-熵/#comments" itemprop="discussionUrl">
                  <span class="post-comments-count disqus-comment-count" data-disqus-identifier="2018/03/17/机器学习/机器学习笔记-熵/" itemprop="commentCount"></span>
                </a>
              </span>
            
          

          
          

          

          <br>
          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1 id="熵"><a href="#熵" class="headerlink" title="熵"></a>熵</h1><h1 id="1、什么是信息量？"><a href="#1、什么是信息量？" class="headerlink" title="1、什么是信息量？"></a>1、什么是信息量？</h1><p>假设X是一个<strong>离散型随机变量</strong>，其取值集合为X，概率分布函数为$p(x) = P(X=x), x \in X$，定义$X=x_0$的信息量为：</p>
<script type="math/tex; mode=display">
I(x_0) = -log(p(x_0))</script><p>可以理解为，一个事件发生的概率越大，携带的信息量越小。当$p(x_0)=1$时，信息量为0。</p>
<h1 id="2、什么是熵？"><a href="#2、什么是熵？" class="headerlink" title="2、什么是熵？"></a>2、什么是熵？</h1><p>第一，假设存在一个随机变量<img src="https://www.zhihu.com/equation?tex=x" alt="x">，可以问一下自己当我们观测到该随机变量的一个样本时，我们可以接受到多少信息量呢？毫无疑问，当我们被告知一个极不可能发生的事情发生了，那我们就接收到了更多的信息；而当我们观测到一个非常常见的事情发生了，那么我们就接收到了相对较少的信息量。因此信息的量度应该依赖于概率分布<img src="https://www.zhihu.com/equation?tex=p%28x%29" alt="p(x)">，<strong>所以说熵<img src="https://www.zhihu.com/equation?tex=h%28x%29" alt="h(x)">的定义应该是概率的单调函数。</strong> </p>
<p>第二，假设两个随机变量<img src="https://www.zhihu.com/equation?tex=x" alt="x">和<img src="https://www.zhihu.com/equation?tex=y" alt="y">是相互独立的，那么分别观测两个变量得到的信息量应该和同时观测两个变量的信息量是相同的，即：$H(X+Y)=H(X)+H(Y)$ 。而从概率上来讲，两个独立随机变量就意味着$p(x,y)=p(x)p(y)$，所以此处可以得出结论熵的定义<img src="https://www.zhihu.com/equation?tex=h" alt="h">应该是概率<img src="https://www.zhihu.com/equation?tex=p%28x%29" alt="p(x)">的<img src="https://www.zhihu.com/equation?tex=log%0A" alt="log">函数。因此一个随机变量的熵可以使用如下定义：</p>
<p>设$X \in {x_1,x_2,…,x_n} $ 为一个离散随机变量，其概率分布为$P(X=x_i)=p_i$。则X的熵为</p>
<script type="math/tex; mode=display">
H(X)=-\sum_{i=1}^np_i\log p_i</script><p>其中，当$p_i=0$时，熵为0。</p>
<p><strong>此处的负号仅仅是用来保证熵（即信息量）是正数或者为零。而<img src="https://www.zhihu.com/equation?tex=log" alt="log">函数基的选择是任意的</strong>（<em>信息论中基常常选择为2，因此信息的单位为比特bits；而机器学习中基常常选择为自然常数，因此单位常常被称为nats</em>）。</p>
<p><strong>用熵来评价整个随机变量x平均的信息量，而平均最好的量度就是随机变量的期望</strong>。</p>
<p>熵的取值范围是</p>
<script type="math/tex; mode=display">
0 \leq H(X) \leq \log n</script><p>两个随机变量一起发生的熵就是<strong>联合熵</strong></p>
<h1 id="3、条件熵"><a href="#3、条件熵" class="headerlink" title="3、条件熵"></a>3、条件熵</h1><p>设$Y \in {y_1,y_2,…,y_m}$为随机变量，在已知X的条件下，Y的条件熵（conditional entropy）为</p>
<script type="math/tex; mode=display">
H(Y|X) = \sum_{i=1}^n p(x_i)H(Y|X=x_i) = -\sum_{i=1}^np(x_i) \sum_{j=1}^m p(y_j|x_i)\log p(y_j|x_i)</script><p>表示在已知X的条件下，Y的条件概率分布的熵对X的数学期望。</p>
<h1 id="4、交叉熵"><a href="#4、交叉熵" class="headerlink" title="4、交叉熵"></a>4、交叉熵</h1><p>例如：</p>
<blockquote>
<p>箱子里面有小球任意个，但其中1/2是橙色球，1/4是紫色球，1/8是蓝色球及1/8是青色球。我从中拿出一个球，你猜我手中的球是什么颜色的？</p>
</blockquote>
<p>知道了每种颜色小球的比例，比如橙色占比二分之一，如果我猜橙色，很有可能第一次就猜中了。所以，根据策略2，1/2的概率是橙色球，小明需要猜一次，1/4的概率是紫色球，小明需要猜两次，1/8的概率是蓝色球，小明需要猜三次，1/8的概率是青色球，小明需要猜三次，所以小明预期的猜题次数为：</p>
<p>H = 1/2 <em> 1 + 1/4 </em> 2 + 1/8 <em> 3 + 1/8 </em> 3=  1.75</p>
<p>针对概率为p的小球，需要猜球的次数$=log_2 \frac 1 p$ 。例如1/8是蓝色球，次数就是3。则预期的猜题次数就是熵。</p>
<p>因此，每个系统都会有一个真实的概率分布（<strong>真实分布</strong>）。根据真实分布，可以找到一个最优策略，以最小的代价消除系统的不确定性，这个不确定性的值就是熵（比如猜题次数，编码长度）。</p>
<p>如果小明不知道真实分布，认为小球的分布为（1/4，1/4，1/4，1/4），这个分布就是<strong>非真实分布</strong>。此时，小明猜中任何一种颜色的小球都需要猜两次，即1/2 <em> 2 + 1/4 </em> 2 + 1/8 <em> 2 + 1/8 </em> 2 = 2。</p>
<p>当我们使用非最优策略消除系统的不确定性，所需要付出的努力的大小我们该如何去衡量呢？</p>
<p>这就需要引入<strong>交叉熵，其用来衡量在给定的真实分布下，使用非真实分布所指定的策略消除系统的不确定性所需要付出的努力的大小</strong>。</p>
<p>交叉熵的公式为：</p>
<script type="math/tex; mode=display">
H = \sum_{i=1}^N p_i log_2 \frac 1 {q_i}</script><p>其中，$p_i$是真实分布，$q_i$是非真实分布。</p>
<p>因此，交叉熵越低，这个策略就越好，最低的交叉熵也就是使用了真实分布所计算出来的信息熵，因为此时$p_i=q_i$ ，交叉熵 = 信息熵。</p>
<p>这也是为什么在机器学习中的分类算法中，我们总是最小化交叉熵，因为交叉熵越低，就证明由算法所产生的策略最接近最优策略，也间接证明我们算法所算出的非真实分布越接近真实分布。</p>
<h1 id="5、相对熵-KL散度"><a href="#5、相对熵-KL散度" class="headerlink" title="5、相对熵(KL散度)"></a>5、相对熵(KL散度)</h1><p>最后，我们如何去衡量不同策略之间的差异呢？这就需要用到<strong>相对熵，其用来衡量两个取值为正的函数或概率分布之间的差异</strong>，即：</p>
<script type="math/tex; mode=display">
KL(f(x) || g(x)) = \sum_{x \in X} f(x) * log_2 \frac {f(x)} {g(x)}</script><p>现在，假设我们想知道某个策略和最优策略之间的差异，我们就可以用相对熵来衡量这两者之间的差异。即，相对熵 = 某个策略的交叉熵 - 信息熵（根据系统真实分布计算而得的信息熵，为最优策略），公式如下：</p>
<script type="math/tex; mode=display">
KL(p || q) = H(p,q)-H(p) = \sum_{k=1}^N p_k log_2 \frac 1 {q_k} - \sum_{k=1}^N p_k log_2 \frac 1 {p_k} = \sum_{k=1}^N p_k log_2 \frac {p_k} {q_k}</script><p><strong>互信息是相对熵的特殊形式</strong>。如果变量不是独立的，可以通过考察联合概率分布和边缘概率分布乘积之间的相对熵，来判断它们是否接近于相对独立。此时，散度表示为</p>
<p><img src="http://img.blog.csdn.net/20170619101153719?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvcGlwaXNvcnJ5/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/Center" alt=""></p>
<p>这被称为变量 x 和变量 y 之间的互信息( mutual information )。根据 Kullback-Leibler 散度的性质,我们看到 I[x, y] ≥ 0 ,当且仅当 x 和 y 相互独立时等号成立。经过推导，得互信息公式为</p>
<p><img src="http://www.2cto.com/uploadfile/Collfiles/20160617/20160617091445667.png" alt=""></p>
<p>互信息不能归一化，对连续变量计算不方便（连续变量需要先离散化）。最大信息系数首先寻求一种最优离散化方式，然后把互信息取值转换成一种度量方式，取值区间在[0，1]。</p>
<h1 id="6、总结"><a href="#6、总结" class="headerlink" title="6、总结"></a>6、总结</h1><p>熵：衡量不确定性的度量</p>
<p>联合熵：X、Y在一起时的不确定性度量</p>
<p>条件熵：X确定时，Y的不确定性度量。也就是在X发生的前提下，新发生Y带来的熵</p>
<p>交叉熵：衡量p和q的相似性，越小越相似</p>
<p>相对熵：p和q的不相似度量。</p>

          
        
      
    </div>

    

    
    
    

    

    
      
    
    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  

  <article class="post post-type-normal" itemscope="" itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="https://schwimmer.github.io/2018/03/17/机器学习/人群画像/">

    <span hidden itemprop="author" itemscope="" itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Schwimmer">
      <meta itemprop="description" content="Record and Think!">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope="" itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Schwimmer's Blog">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                
                <a href="/2018/03/17/机器学习/人群画像/" class="post-title-link" itemprop="url">人群画像</a>
              
            
          </h1>
        

        <div class="post-meta">

          
          
          

          
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              

              
                
              

              <time title="创建时间：2018-03-17 20:50:31" itemprop="dateCreated datePublished" datetime="2018-03-17T20:50:31+08:00">2018-03-17</time>
            </span>
          

          

          
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope="" itemtype="http://schema.org/Thing"><a href="/categories/机器学习/" itemprop="url" rel="index"><span itemprop="name">机器学习</span></a></span>

                
                
              
            </span>
          

          
            
            
              
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="fa fa-comment-o"></i>
                </span>
            
                <span class="post-meta-item-text">评论数：</span>
                <a href="/2018/03/17/机器学习/人群画像/#comments" itemprop="discussionUrl">
                  <span class="post-comments-count disqus-comment-count" data-disqus-identifier="2018/03/17/机器学习/人群画像/" itemprop="commentCount"></span>
                </a>
              </span>
            
          

          
          

          

          <br>
          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p><a href="https://zhuanlan.zhihu.com/p/27126412" target="_blank" rel="noopener">比你更了解你，浅谈用户画像</a></p>
<p>爱点击的性别预测模型</p>
<p>为什么用朴素贝叶斯？</p>
<p>如何选择特征？</p>
<blockquote>
<p>去除覆盖率低的，去除</p>
</blockquote>
<p>如何解决特征有依赖关系的问题？</p>
<blockquote>
<p>假设，对于同一个一级域名，下面的N级域名中男女分布比例在接近的合并为同一个特征。</p>
</blockquote>
<p>训练集和测试集？</p>
<p>线上效果</p>
<blockquote>
<p>鼎盛时期，平均每个cookie有5个url</p>
</blockquote>

          
        
      
    </div>

    

    
    
    

    

    
      
    
    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  

  <article class="post post-type-normal" itemscope="" itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="https://schwimmer.github.io/2018/03/17/机器学习/sklearn的一些总结/">

    <span hidden itemprop="author" itemscope="" itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Schwimmer">
      <meta itemprop="description" content="Record and Think!">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope="" itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Schwimmer's Blog">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                
                <a href="/2018/03/17/机器学习/sklearn的一些总结/" class="post-title-link" itemprop="url">sklearn的一些总结</a>
              
            
          </h1>
        

        <div class="post-meta">

          
          
          

          
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              

              
                
              

              <time title="创建时间：2018-03-17 20:50:31" itemprop="dateCreated datePublished" datetime="2018-03-17T20:50:31+08:00">2018-03-17</time>
            </span>
          

          

          
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope="" itemtype="http://schema.org/Thing"><a href="/categories/机器学习/" itemprop="url" rel="index"><span itemprop="name">机器学习</span></a></span>

                
                
              
            </span>
          

          
            
            
              
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="fa fa-comment-o"></i>
                </span>
            
                <span class="post-meta-item-text">评论数：</span>
                <a href="/2018/03/17/机器学习/sklearn的一些总结/#comments" itemprop="discussionUrl">
                  <span class="post-comments-count disqus-comment-count" data-disqus-identifier="2018/03/17/机器学习/sklearn的一些总结/" itemprop="commentCount"></span>
                </a>
              </span>
            
          

          
          

          

          <br>
          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>转自 <a href="http://blog.csdn.net/wang1127248268/article/details/53264041" target="_blank" rel="noopener">sklearn的一些总结</a></p>

          
        
      
    </div>

    

    
    
    

    

    
      
    
    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  

  <article class="post post-type-normal" itemscope="" itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="https://schwimmer.github.io/2018/03/17/机器学习/SVD/">

    <span hidden itemprop="author" itemscope="" itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Schwimmer">
      <meta itemprop="description" content="Record and Think!">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope="" itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Schwimmer's Blog">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                
                <a href="/2018/03/17/机器学习/SVD/" class="post-title-link" itemprop="url">SVD</a>
              
            
          </h1>
        

        <div class="post-meta">

          
          
          

          
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              

              
                
              

              <time title="创建时间：2018-03-17 20:50:31" itemprop="dateCreated datePublished" datetime="2018-03-17T20:50:31+08:00">2018-03-17</time>
            </span>
          

          

          
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope="" itemtype="http://schema.org/Thing"><a href="/categories/机器学习/" itemprop="url" rel="index"><span itemprop="name">机器学习</span></a></span>

                
                
              
            </span>
          

          
            
            
              
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="fa fa-comment-o"></i>
                </span>
            
                <span class="post-meta-item-text">评论数：</span>
                <a href="/2018/03/17/机器学习/SVD/#comments" itemprop="discussionUrl">
                  <span class="post-comments-count disqus-comment-count" data-disqus-identifier="2018/03/17/机器学习/SVD/" itemprop="commentCount"></span>
                </a>
              </span>
            
          

          
          

          

          <br>
          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>整理自：</p>
<p><a href="http://www.cnblogs.com/pinard/p/6251584.html" target="_blank" rel="noopener">奇异值分解(SVD)原理与在降维中的应用</a></p>
<p><a href="http://blog.sciencenet.cn/blog-696950-699380.html" target="_blank" rel="noopener">奇异值分解(SVD) —- 线性变换几何意义</a></p>
<p><a href="http://www.cnblogs.com/LeftNotEasy/archive/2011/01/19/svd-and-applications.html" target="_blank" rel="noopener">机器学习中的数学(5)-强大的矩阵奇异值分解(SVD)及其应用</a></p>
<h1 id="特征值和特征分解"><a href="#特征值和特征分解" class="headerlink" title="特征值和特征分解"></a>特征值和特征分解</h1><script type="math/tex; mode=display">
Ax=\lambda x</script><p>其中A是一个n×n的矩阵，x是一个n维向量，则我们说<strong>λ</strong>是矩阵A的一个<strong>特征值</strong>，而<strong>x</strong>是矩阵A的特征值λ所对应的<strong>特征向量</strong>。</p>
<p>而从几何上看，A相当于对向量x进行了拉伸，λ是拉伸的尺度。</p>
<p>前提是A是一个对称矩阵。</p>
<blockquote>
<p><strong>对称矩阵</strong></p>
<p>转置后与原矩阵相等。任意矩阵乘以它的转置也是对称矩阵。</p>
</blockquote>
<p>特征分解时，A必须是方阵。</p>
<p><img src="https://images2015.cnblogs.com/blog/1042406/201701/1042406-20170105115457425-1545975626.png" alt=""></p>
<p>SVD之后，对于奇异值,它跟我们特征分解中的特征值类似，在奇异值矩阵中也是按照从大到小排列，而且奇异值的减少特别的快，在很多情况下，前10%甚至1%的奇异值的和就占了全部的奇异值之和的99%以上的比例。也就是说，我们也可以用最大的k个的奇异值和对应的左右奇异向量来近似描述矩阵。</p>
<script type="math/tex; mode=display">
A_{m \times n} = U_{m \times m}\Sigma_{m \times n} V^T_{n \times n} \approx U_{m \times k}\Sigma_{k \times k} V^T_{k \times n}</script><p>这样，矩阵A就可以近似的表示为</p>
<p><img src="https://images2015.cnblogs.com/blog/1042406/201701/1042406-20170105140822191-1774139119.png" alt=""></p>
<blockquote>
<p>（文本分析中）</p>
<p>三个矩阵有非常清楚的物理含义：</p>
<ul>
<li>第一个矩阵X中的每一行表示意思相关的一类词，其中的每个非零元素表示这类词中每个词的重要性（或者说相关性），数值越大越相关。</li>
<li>第三个矩阵Y中的每一列表示同一主题一类文章，其中每个元素表示这类文章中每篇文章的相关性。</li>
<li>第二个矩阵B则表示类词和文章之间的相关性。因此，我们只要对关联矩阵A进行一次奇异值分解，我们就可以同时完成了近义词分类和文章的分类。（同时得到每类文章和每类词的相关性）。</li>
</ul>
</blockquote>
<p>SVD的性质</p>
<p>降维</p>
<p>对于奇异值,它跟我们特征分解中的特征值类似，在奇异值矩阵中也是按照从大到小排列，而且奇异值的减少特别的快，在很多情况下，前10%甚至1%的奇异值的和就占了全部的奇异值之和的99%以上的比例。也就是说，我们也可以用最大的k个的奇异值和对应的左右奇异向量来近似描述矩阵。也就是说：</p>
<script type="math/tex; mode=display">
A_{m \times n} = U_{m \times m}\Sigma_{m \times n} V^T_{n \times n} \approx U_{m \times k}\Sigma_{k \times k} V^T_{k \times n}</script>
          
        
      
    </div>

    

    
    
    

    

    
      
    
    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
  </section>

  
  <nav class="pagination">
    <a class="extend prev" rel="prev" href="/page/23/"><i class="fa fa-angle-left" aria-label="上一页"></i></a><a class="page-number" href="/">1</a><span class="space">&hellip;</span><a class="page-number" href="/page/23/">23</a><span class="page-number current">24</span><a class="page-number" href="/page/25/">25</a><span class="space">&hellip;</span><a class="page-number" href="/page/31/">31</a><a class="extend next" rel="next" href="/page/25/"><i class="fa fa-angle-right" aria-label="下一页"></i></a>
  </nav>



          </div>
          

        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    <div class="sidebar-inner">

      

      

      <div class="site-overview-wrap sidebar-panel sidebar-panel-active">
        <div class="site-overview">
          <div class="site-author motion-element" itemprop="author" itemscope="" itemtype="http://schema.org/Person">
            
              <p class="site-author-name" itemprop="name">Schwimmer</p>
              <div class="site-description motion-element" itemprop="description">Record and Think!</div>
          </div>

          
            <nav class="site-state motion-element">
              
                <div class="site-state-item site-state-posts">
                
                  <a href="/archives/">
                
                    <span class="site-state-item-count">308</span>
                    <span class="site-state-item-name">日志</span>
                  </a>
                </div>
              

              
                
                
                <div class="site-state-item site-state-categories">
                  
                    
                      <a href="/categories/">
                    
                  
                    
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                    <span class="site-state-item-count">25</span>
                    <span class="site-state-item-name">分类</span>
                  </a>
                </div>
              

              
                
                
                <div class="site-state-item site-state-tags">
                  
                    
                      <a href="/tags/">
                    
                  
                    
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                    <span class="site-state-item-count">61</span>
                    <span class="site-state-item-name">标签</span>
                  </a>
                </div>
              
            </nav>
          

          

          

          

          

          
          

          
            
          
          

        </div>
      </div>

      

      

    </div>
  </aside>
  


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <div class="copyright">&copy; <span itemprop="copyrightYear">2019</span>
  <span class="with-love" id="animate">
    <i class="fa fa-user"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">Schwimmer</span>

  

  
</div>


  <div class="powered-by">由 <a href="https://hexo.io" class="theme-link" rel="noopener" target="_blank">Hexo</a> 强力驱动 v3.9.0</div>



  <span class="post-meta-divider">|</span>



  <div class="theme-info">主题 – <a href="https://theme-next.org" class="theme-link" rel="noopener" target="_blank">NexT.Mist</a> v7.2.0</div>




        
<div class="busuanzi-count">
  <script async src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>

  
    <span class="post-meta-item-icon">
      <i class="fa fa-user"></i>
    </span>
    <span class="site-uv" title="总访客量">
      <span class="busuanzi-value" id="busuanzi_value_site_uv"></span>
    </span>
  

  
    <span class="post-meta-divider">|</span>
  

  
    <span class="post-meta-item-icon">
      <i class="fa fa-eye"></i>
    </span>
    <span class="site-pv" title="总访问量">
      <span class="busuanzi-value" id="busuanzi_value_site_pv"></span>
    </span>
  
</div>









        
      </div>
    </footer>

    
      <div class="back-to-top">
        <i class="fa fa-arrow-up"></i>
        
      </div>
    

    

    
      <div>
        
  <script>
    window._bd_share_config = {
      "common": {
        "bdText": "",
        "bdMini": "1",
        "bdMiniList": false,
        "bdPic": ""
      },
      "image": {
        "viewList": ["tsina", "douban", "sqq", "qzone", "weixin", "twi", "fbook"],
        "viewText": "分享到：",
        "viewSize": "16"
      },
      "slide": {
        "bdImg": "5",
        "bdPos": "left",
        "bdTop": "100"
      }
    }
  </script>

<script>
  with(document)0[(getElementsByTagName('head')[0]||body).appendChild(createElement('script')).src='//bdimg.share.baidu.com/static/api/js/share.js?cdnversion='+~(-new Date()/36e5)];
</script>

      </div>
    

    
  </div>

  

<script>
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>


























  
  <script src="/lib/jquery/index.js?v=3.4.1"></script>

  
  <script src="/lib/velocity/velocity.min.js?v=1.2.1"></script>

  
  <script src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>


  


  <script src="/js/utils.js?v=7.2.0"></script>

  <script src="/js/motion.js?v=7.2.0"></script>



  
  


  <script src="/js/schemes/muse.js?v=7.2.0"></script>




  

  


  <script src="/js/next-boot.js?v=7.2.0"></script>


  

  

  

  
  
<script>
  function loadCount() {
    var d = document, s = d.createElement('script');
    s.src = 'https://https-schwimmer-github-io.disqus.com/count.js';
    s.id = 'dsq-count-scr';
    (d.head || d.body).appendChild(s);
  }
  // defer loading until the whole page loading is completed
  window.addEventListener('load', loadCount, false);
</script>







  
  <script>
    // Popup Window;
    var isfetched = false;
    var isXml = true;
    // Search DB path;
    var search_path = "search.xml";
    if (search_path.length === 0) {
      search_path = "search.xml";
    } else if (/json$/i.test(search_path)) {
      isXml = false;
    }
    var path = "/" + search_path;
    // monitor main search box;

    var onPopupClose = function (e) {
      $('.popup').hide();
      $('#local-search-input').val('');
      $('.search-result-list').remove();
      $('#no-result').remove();
      $(".local-search-pop-overlay").remove();
      $('body').css('overflow', '');
    }

    function proceedsearch() {
      $("body")
        .append('<div class="search-popup-overlay local-search-pop-overlay"></div>')
        .css('overflow', 'hidden');
      $('.search-popup-overlay').click(onPopupClose);
      $('.popup').toggle();
      var $localSearchInput = $('#local-search-input');
      $localSearchInput.attr("autocapitalize", "none");
      $localSearchInput.attr("autocorrect", "off");
      $localSearchInput.focus();
    }

    // search function;
    var searchFunc = function(path, search_id, content_id) {
      'use strict';

      // start loading animation
      $("body")
        .append('<div class="search-popup-overlay local-search-pop-overlay">' +
          '<div id="search-loading-icon">' +
          '<i class="fa fa-spinner fa-pulse fa-5x fa-fw"></i>' +
          '</div>' +
          '</div>')
        .css('overflow', 'hidden');
      $("#search-loading-icon").css('margin', '20% auto 0 auto').css('text-align', 'center');

      

      $.ajax({
        url: path,
        dataType: isXml ? "xml" : "json",
        async: true,
        success: function(res) {
          // get the contents from search data
          isfetched = true;
          $('.popup').detach().appendTo('.header-inner');
          var datas = isXml ? $("entry", res).map(function() {
            return {
              title: $("title", this).text(),
              content: $("content",this).text(),
              url: $("url" , this).text()
            };
          }).get() : res;
          var input = document.getElementById(search_id);
          var resultContent = document.getElementById(content_id);
          var inputEventFunction = function() {
            var searchText = input.value.trim().toLowerCase();
            var keywords = searchText.split(/[\s\-]+/);
            if (keywords.length > 1) {
              keywords.push(searchText);
            }
            var resultItems = [];
            if (searchText.length > 0) {
              // perform local searching
              datas.forEach(function(data) {
                var isMatch = false;
                var hitCount = 0;
                var searchTextCount = 0;
                var title = data.title.trim();
                var titleInLowerCase = title.toLowerCase();
                var content = data.content.trim().replace(/<[^>]+>/g,"");
                
                var contentInLowerCase = content.toLowerCase();
                var articleUrl = decodeURIComponent(data.url).replace(/\/{2,}/g, '/');
                var indexOfTitle = [];
                var indexOfContent = [];
                // only match articles with not empty titles
                if(title != '') {
                  keywords.forEach(function(keyword) {
                    function getIndexByWord(word, text, caseSensitive) {
                      var wordLen = word.length;
                      if (wordLen === 0) {
                        return [];
                      }
                      var startPosition = 0, position = [], index = [];
                      if (!caseSensitive) {
                        text = text.toLowerCase();
                        word = word.toLowerCase();
                      }
                      while ((position = text.indexOf(word, startPosition)) > -1) {
                        index.push({position: position, word: word});
                        startPosition = position + wordLen;
                      }
                      return index;
                    }

                    indexOfTitle = indexOfTitle.concat(getIndexByWord(keyword, titleInLowerCase, false));
                    indexOfContent = indexOfContent.concat(getIndexByWord(keyword, contentInLowerCase, false));
                  });
                  if (indexOfTitle.length > 0 || indexOfContent.length > 0) {
                    isMatch = true;
                    hitCount = indexOfTitle.length + indexOfContent.length;
                  }
                }

                // show search results

                if (isMatch) {
                  // sort index by position of keyword

                  [indexOfTitle, indexOfContent].forEach(function (index) {
                    index.sort(function (itemLeft, itemRight) {
                      if (itemRight.position !== itemLeft.position) {
                        return itemRight.position - itemLeft.position;
                      } else {
                        return itemLeft.word.length - itemRight.word.length;
                      }
                    });
                  });

                  // merge hits into slices

                  function mergeIntoSlice(text, start, end, index) {
                    var item = index[index.length - 1];
                    var position = item.position;
                    var word = item.word;
                    var hits = [];
                    var searchTextCountInSlice = 0;
                    while (position + word.length <= end && index.length != 0) {
                      if (word === searchText) {
                        searchTextCountInSlice++;
                      }
                      hits.push({position: position, length: word.length});
                      var wordEnd = position + word.length;

                      // move to next position of hit

                      index.pop();
                      while (index.length != 0) {
                        item = index[index.length - 1];
                        position = item.position;
                        word = item.word;
                        if (wordEnd > position) {
                          index.pop();
                        } else {
                          break;
                        }
                      }
                    }
                    searchTextCount += searchTextCountInSlice;
                    return {
                      hits: hits,
                      start: start,
                      end: end,
                      searchTextCount: searchTextCountInSlice
                    };
                  }

                  var slicesOfTitle = [];
                  if (indexOfTitle.length != 0) {
                    slicesOfTitle.push(mergeIntoSlice(title, 0, title.length, indexOfTitle));
                  }

                  var slicesOfContent = [];
                  while (indexOfContent.length != 0) {
                    var item = indexOfContent[indexOfContent.length - 1];
                    var position = item.position;
                    var word = item.word;
                    // cut out 100 characters
                    var start = position - 20;
                    var end = position + 80;
                    if(start < 0){
                      start = 0;
                    }
                    if (end < position + word.length) {
                      end = position + word.length;
                    }
                    if(end > content.length){
                      end = content.length;
                    }
                    slicesOfContent.push(mergeIntoSlice(content, start, end, indexOfContent));
                  }

                  // sort slices in content by search text's count and hits' count

                  slicesOfContent.sort(function (sliceLeft, sliceRight) {
                    if (sliceLeft.searchTextCount !== sliceRight.searchTextCount) {
                      return sliceRight.searchTextCount - sliceLeft.searchTextCount;
                    } else if (sliceLeft.hits.length !== sliceRight.hits.length) {
                      return sliceRight.hits.length - sliceLeft.hits.length;
                    } else {
                      return sliceLeft.start - sliceRight.start;
                    }
                  });

                  // select top N slices in content

                  var upperBound = parseInt('1');
                  if (upperBound >= 0) {
                    slicesOfContent = slicesOfContent.slice(0, upperBound);
                  }

                  // highlight title and content

                  function highlightKeyword(text, slice) {
                    var result = '';
                    var prevEnd = slice.start;
                    slice.hits.forEach(function (hit) {
                      result += text.substring(prevEnd, hit.position);
                      var end = hit.position + hit.length;
                      result += '<b class="search-keyword">' + text.substring(hit.position, end) + '</b>';
                      prevEnd = end;
                    });
                    result += text.substring(prevEnd, slice.end);
                    return result;
                  }

                  var resultItem = '';

                  if (slicesOfTitle.length != 0) {
                    resultItem += "<li><a href='" + articleUrl + "' class='search-result-title'>" + highlightKeyword(title, slicesOfTitle[0]) + "</a>";
                  } else {
                    resultItem += "<li><a href='" + articleUrl + "' class='search-result-title'>" + title + "</a>";
                  }

                  slicesOfContent.forEach(function (slice) {
                    resultItem += "<a href='" + articleUrl + "'>" +
                      "<p class=\"search-result\">" + highlightKeyword(content, slice) +
                      "...</p>" + "</a>";
                  });

                  resultItem += "</li>";
                  resultItems.push({
                    item: resultItem,
                    searchTextCount: searchTextCount,
                    hitCount: hitCount,
                    id: resultItems.length
                  });
                }
              })
            };
            if (keywords.length === 1 && keywords[0] === "") {
              resultContent.innerHTML = '<div id="no-result"><i class="fa fa-search fa-5x"></i></div>'
            } else if (resultItems.length === 0) {
              resultContent.innerHTML = '<div id="no-result"><i class="fa fa-frown-o fa-5x"></i></div>'
            } else {
              resultItems.sort(function (resultLeft, resultRight) {
                if (resultLeft.searchTextCount !== resultRight.searchTextCount) {
                  return resultRight.searchTextCount - resultLeft.searchTextCount;
                } else if (resultLeft.hitCount !== resultRight.hitCount) {
                  return resultRight.hitCount - resultLeft.hitCount;
                } else {
                  return resultRight.id - resultLeft.id;
                }
              });
              var searchResultList = '<ul class=\"search-result-list\">';
              resultItems.forEach(function (result) {
                searchResultList += result.item;
              })
              searchResultList += "</ul>";
              resultContent.innerHTML = searchResultList;
            }
          }

          if ('auto' === 'auto') {
            input.addEventListener('input', inputEventFunction);
          } else {
            $('.search-icon').click(inputEventFunction);
            input.addEventListener('keypress', function (event) {
              if (event.keyCode === 13) {
                inputEventFunction();
              }
            });
          }

          // remove loading animation
          $(".local-search-pop-overlay").remove();
          $('body').css('overflow', '');

          proceedsearch();
        }
      });
    }

    // handle and trigger popup window;
    $('.popup-trigger').click(function(e) {
      e.stopPropagation();
      if (isfetched === false) {
        searchFunc(path, 'local-search-input', 'local-search-result');
      } else {
        proceedsearch();
      };
    });

    $('.popup-btn-close').click(onPopupClose);
    $('.popup').click(function(e){
      e.stopPropagation();
    });
    $(document).on('keyup', function (event) {
      var shouldDismissSearchPopup = event.which === 27 &&
        $('.search-popup').is(':visible');
      if (shouldDismissSearchPopup) {
        onPopupClose();
      }
    });
  </script>





  

  

  
  

  
  
    
      
    
      
    
      
    
      
    
      
    
      
    
      
    
      
    
      
    
      
    
  

  
    
      <script type="text/x-mathjax-config">
  

  MathJax.Hub.Config({
    tex2jax: {
      inlineMath: [ ['$', '$'], ['\\(', '\\)'] ],
      processEscapes: true,
      skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
    },
    TeX: {
      
      equationNumbers: {
        autoNumber: 'AMS'
      }
    }
  });
  MathJax.Hub.Register.StartupHook('TeX Jax Ready', function() {
    MathJax.InputJax.TeX.prefilterHooks.Add(function(data) {
      if (data.display) {
        var next = data.script.nextSibling;
        while (next && next.nodeName.toLowerCase() === '#text') { next = next.nextSibling }
        if (next && next.nodeName.toLowerCase() === 'br') { next.parentNode.removeChild(next) }
      }
    });
  });
</script>

<script type="text/x-mathjax-config">
  MathJax.Hub.Queue(function() {
    var all = MathJax.Hub.getAllJax(), i;
    for (i = 0; i < all.length; i += 1) {
      document.getElementById(all[i].inputID + '-Frame').parentNode.className += ' has-jax';
    }
  });
</script>
<script src="//cdn.jsdelivr.net/npm/mathjax@2/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script><!-- hexo-inject:begin --><!-- Begin: Injected MathJax -->
<script type="text/x-mathjax-config">
  MathJax.Hub.Config({"tex2jax":{"inlineMath":[["$","$"],["\\(","\\)"]],"skipTags":["script","noscript","style","textarea","pre","code"],"processEscapes":true},"TeX":{"equationNumbers":{"autoNumber":"AMS"}}});
</script>

<script type="text/x-mathjax-config">
  MathJax.Hub.Queue(function() {
    var all = MathJax.Hub.getAllJax(), i;
    for(i=0; i < all.length; i += 1) {
      all[i].SourceElement().parentNode.className += ' has-jax';
    }
  });
</script>

<script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js">
</script>
<!-- End: Injected MathJax -->
<!-- hexo-inject:end -->

    
  


  

  

  

  

  

  

  

  

  

  

  

</body>
</html>
