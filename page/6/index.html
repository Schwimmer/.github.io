<!DOCTYPE html>












  


<html class="theme-next mist use-motion" lang="zh-CN">
<head><meta name="generator" content="Hexo 3.9.0">
  <!-- hexo-inject:begin --><!-- hexo-inject:end --><meta charset="UTF-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">






















<link rel="stylesheet" href="/lib/font-awesome/css/font-awesome.min.css?v=4.7.0">

<link rel="stylesheet" href="/css/main.css?v=7.2.0">


  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png?v=7.2.0">


  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png?v=7.2.0">


  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png?v=7.2.0">


  <link rel="mask-icon" href="/images/logo.svg?v=7.2.0" color="#222">







<script id="hexo.configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '/',
    scheme: 'Mist',
    version: '7.2.0',
    sidebar: {"position":"left","display":"post","offset":12,"onmobile":false,"dimmer":false},
    back2top: true,
    back2top_sidebar: false,
    fancybox: false,
    fastclick: false,
    lazyload: false,
    tabs: true,
    motion: {"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},
    algolia: {
      applicationID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    }
  };
</script>


  




  <meta name="description" content="Record and Think!">
<meta property="og:type" content="website">
<meta property="og:title" content="Schwimmer&#39;s Blog">
<meta property="og:url" content="https://schwimmer.github.io/page/6/index.html">
<meta property="og:site_name" content="Schwimmer&#39;s Blog">
<meta property="og:description" content="Record and Think!">
<meta property="og:locale" content="zh-CN">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Schwimmer&#39;s Blog">
<meta name="twitter:description" content="Record and Think!">





  
  
  <link rel="canonical" href="https://schwimmer.github.io/page/6/">



<script id="page.configurations">
  CONFIG.page = {
    sidebar: "",
  };
</script>

  <title>Schwimmer's Blog</title>
  




  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-143240576-1"></script>
  <script>
    var host = window.location.hostname;
    if (host !== "localhost" || !true) {
      window.dataLayer = window.dataLayer || [];
      function gtag(){dataLayer.push(arguments);}
      gtag('js', new Date());
      gtag('config', 'UA-143240576-1');
    }
  </script>









  <noscript>
  <style>
  .use-motion .motion-element,
  .use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-title { opacity: initial; }

  .use-motion .logo,
  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript><!-- hexo-inject:begin --><!-- hexo-inject:end -->

</head>

<body itemscope="" itemtype="http://schema.org/WebPage" lang="zh-CN">

  
  
    
  

  <!-- hexo-inject:begin --><!-- hexo-inject:end --><div class="container sidebar-position-left 
  page-home">
    <div class="headband"></div>

    <header id="header" class="header" itemscope="" itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-wrapper">
  <div class="site-meta">
    

    <div class="custom-logo-site-title">
      <a href="/" class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">Schwimmer's Blog</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
    
    
  </div>

  <div class="site-nav-toggle">
    <button aria-label="切换导航栏">
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
    </button>
  </div>
</div>



<nav class="site-nav">
  
    <ul id="menu" class="menu">
      
        
        
        
          
          <li class="menu-item menu-item-home">

    
    
      
    

    

    <a href="/" rel="section"><i class="menu-item-icon fa fa-fw fa-home"></i> <br>首页</a>

  </li>
        
        
        
          
          <li class="menu-item menu-item-tags">

    
    
      
    

    

    <a href="/tags/" rel="section"><i class="menu-item-icon fa fa-fw fa-tags"></i> <br>标签</a>

  </li>
        
        
        
          
          <li class="menu-item menu-item-categories">

    
    
      
    

    

    <a href="/categories/" rel="section"><i class="menu-item-icon fa fa-fw fa-th"></i> <br>分类</a>

  </li>
        
        
        
          
          <li class="menu-item menu-item-archives">

    
    
      
    

    

    <a href="/archives/" rel="section"><i class="menu-item-icon fa fa-fw fa-archive"></i> <br>归档</a>

  </li>

      
      
        <li class="menu-item menu-item-search">
          
            <a href="javascript:;" class="popup-trigger">
          
            
              <i class="menu-item-icon fa fa-search fa-fw"></i> <br>搜索</a>
        </li>
      
    </ul>
  

  
    

  

  
    <div class="site-search">
      
  <div class="popup search-popup local-search-popup">
  <div class="local-search-header clearfix">
    <span class="search-icon">
      <i class="fa fa-search"></i>
    </span>
    <span class="popup-btn-close">
      <i class="fa fa-times-circle"></i>
    </span>
    <div class="local-search-input-wrapper">
      <input autocomplete="off" placeholder="搜索..." spellcheck="false" type="text" id="local-search-input">
    </div>
  </div>
  <div id="local-search-result"></div>
</div>



    </div>
  
</nav>



  



</div>
    </header>

    


    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          
          <div id="content" class="content">
            
  <section id="posts" class="posts-expand">
    
      

  

  
  
  

  

  <article class="post post-type-normal" itemscope="" itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="https://schwimmer.github.io/2019/06/02/机器学习/机器学习问题答疑/Adaboost/">

    <span hidden itemprop="author" itemscope="" itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Schwimmer">
      <meta itemprop="description" content="Record and Think!">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope="" itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Schwimmer's Blog">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                
                <a href="/2019/06/02/机器学习/机器学习问题答疑/Adaboost/" class="post-title-link" itemprop="url">未命名</a>
              
            
          </h1>
        

        <div class="post-meta">

          
          
          

          
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              

              
                
              

              <time title="创建时间：2019-06-02 15:54:20 / 修改时间：16:07:06" itemprop="dateCreated datePublished" datetime="2019-06-02T15:54:20+08:00">2019-06-02</time>
            </span>
          

          
            

            
          

          

          
            
            
              
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="fa fa-comment-o"></i>
                </span>
            
                <span class="post-meta-item-text">评论数：</span>
                <a href="/2019/06/02/机器学习/机器学习问题答疑/Adaboost/#comments" itemprop="discussionUrl">
                  <span class="post-comments-count disqus-comment-count" data-disqus-identifier="2019/06/02/机器学习/机器学习问题答疑/Adaboost/" itemprop="commentCount"></span>
                </a>
              </span>
            
          

          
          

          

          <br>
          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1 id="Adaboost"><a href="#Adaboost" class="headerlink" title="Adaboost"></a>Adaboost</h1><ol>
<li>想问下机器学习实战这里是不是写错了，应该是大于1的是吗？</li>
</ol>
<p><img src="/.io//pic/75&amp;e=1874736000&amp;token=kIxbL07-8jAj8w1n4s9zv64FuZZNEATmlU_Vm6zD:dIJQW2rLt2pya92qYnGwGO7619M=.jpeg" alt="img"></p>
<ul>
<li>你看那个参数threshIneq，它取值lt或gt。lt表示小于阈值的为-1，gt表示大于阈值的为-1</li>
</ul>
<ol>
<li>绘制roc曲线的代码逻辑都能看的懂，该函数接收的是训练样本被分类的概率值，将这些概率值按由小到大的顺序依次输出，如果是正例，则曲线向下移动，反之向左移动。老师能透彻的解释下，为什么这样绘制就是roc曲线吗？roc不是在不同的阈值下真阳率和假阳率的对应关系吗？</li>
</ol>
<ul>
<li>先要了解正阳率和假阳率的定义。正阳率是预测的正类中确实是正类占所有真实正类的概率，假阳率是预测的正类中确实是负类占所有真实负类的概率。曲线横坐标是假阳率，纵坐标是真阳率。注意，书中的代码跟一般的的做法不一样，一般的做法是将概率从大到小排列，曲线从左下角开始画，原理是一样的。</li>
</ul>
<ol>
<li>老师您好，请问在做回归预测的时候，多项式构造选取多少个属性合适?随机森林选取的属性  重要性小于多少的可以摒弃，一般取前几?</li>
</ol>
<ul>
<li>这没有固定的答案，看具体问题能有几个较好的特征，剔除不必要特征。可以看看特征选择算法。随机森林每棵树可以随机选择一部分特征进行训练。</li>
</ul>
<h1 id="kMeans"><a href="#kMeans" class="headerlink" title="kMeans"></a>kMeans</h1><ol>
<li>如何理解kmeans++算法在解决标准kmeans算法执行时初始质心选择的的作用？该算法的第3步该如何理解，1.先从数据库随机挑个随机点当“种子点”2.对于每个点，都计算其和最近的一个“种子点”的距离D(x)并保存在一个数组里，然后把这些距离加起来得到Sum(D(x))。3.然后，再取一个随机值，用权重的方式来取计算下一个“种子点”。这个算法的实现是，先取一个能落在Sum(D(x))中的随机值Random，然后用Random -= D(x)，直到其&lt;=0，此时的点就是下一个“种子点”。4.重复2和3直到k个聚类中心被选出来5.利用这k个初始的聚类中心运行标准的k-means算法</li>
</ol>
<ul>
<li>kmeans选择初始化质心有不同的方法，可以选择批次距离尽可能远的K个点，也可以选用层次聚类算法BIRCH和ROCK或者Canopy。具体的还要看具体文献或出处。</li>
</ul>
<h1 id="SVM"><a href="#SVM" class="headerlink" title="SVM"></a>SVM</h1><ol>
<li>请问SVM中的惩罚因子C的作用是什么，如何调节误分类点的个数和距离二者的关系，为什么当C无穷大时，软间隔就等价于硬间隔</li>
</ol>
<ul>
<li>SVM中允许有分类错误的点时引入了参数C，C表示尽可能选择宽边界和尽可能不要犯错两者之间的权衡。C越大表示希望得到更少的分类错误，即不惜选择窄边界也要尽可能把更多点正确分类；C越小表示希望得到更宽的边界，即不惜增加错误点个数也要选择更宽的分类边界。这种处理问题的思路有点类似于正则化。</li>
</ul>
<p>当C无穷大时候，可以想象选择极窄的边界让所有的点都分类正确，也就等价于硬间隔了。也可以从另一方面来看，硬间隔满足 0≤αn，软间隔满足 0≤αn≤C，当C无穷大时，0≤αn≤C等价于0≤αn。</p>
<ol>
<li>想问一下关于alpha的选择问题，首先，条件a两个alpha必须要在间隔边界之外，b这两个alpha还没有进行过区间化处理或者不在边界上。我的问题是，1)区间话处理是什么意思？2)程序中alpha(i)的选择是在边界之外，但alpha(j)的选择确实非i的任意一个，这能保证alpha(j)满足两个条件吗？其次，随着程序的运行alpha(i)也会选到已经更新的alpha(j),这是不是和未区间化的条件向矛盾</li>
</ol>
<p><img src="/.io//pic/75&amp;e=1874736000&amp;token=kIxbL07-8jAj8w1n4s9zv64FuZZNEATmlU_Vm6zD:qSLlCh12DkeIqFnKbUf0J0AQo20=.jpeg" alt="img"></p>
<ul>
<li>书中的做法是先找到违背条件的alpha1，然后alpha2取其误差与alpha1相差较大的那个，这样减少迭代次数。使用最优化解出alpha2后，根据其与alpha1的关系求得其值。</li>
</ul>
<ol>
<li>针对逻辑回归的这个推导看不明白，您能给讲下吗？数学哪方面知识是讲导数参与运算的，您能大体说下或有相关资料吗</li>
</ol>
<p><img src="/.io//pic/75&amp;e=1874736000&amp;token=kIxbL07-8jAj8w1n4s9zv64FuZZNEATmlU_Vm6zD:onJ5Fj7cX0QhiHRNaqzJiL0e0VI=.jpeg" alt="img"></p>
<ul>
<li>逻辑回归的偏导数计算是比较简单的，用到了指数偏导计算。高数书里有基本的偏导数计算方法。</li>
</ul>
<ol>
<li>这边有个项目需要用GBDT去做训练，如果训练样本数大概是60万左右，正负样本比例是1:5左右 很不均衡，如果只是通过下采样使之达到均衡的话，觉得训练样本量20万，有点少，这种情况，一般按照什么方式去处理比较好？</li>
</ol>
<ul>
<li>可以试试上采样构造正样本，或者即使正负样本比例不同，采用不同的类别权重，在损失函数中使用。</li>
</ul>
<ol>
<li>SVM中参数C的调教:C和松弛向量的乘积加入到了目标函数中，如果要使目标函数有最小值，就是要C和松弛向量的乘积越小，那是不是可以看成:C越大，松弛向量越小，那1-ξ就越大，间距就越大，容错就越大。为啥不能看成这样啊？我看答案是C小点儿越好。。。。</li>
</ol>
<ul>
<li>C是权衡犯错率和宽间隔的，C越大表示宁愿间隔小也要分类正确，对错误的容忍度小。小的C值争取获得更宽的边界。</li>
</ul>
<ol>
<li>请问有没有用svm做多分类的代码可以分享给我的</li>
</ol>
<ul>
<li>可以使用OVO方式，没有手写代码，可以使用libSVM库</li>
</ul>
<ol>
<li>请问这个最小值应该在边界上达到是为什么？</li>
</ol>
<p><img src="/.io//pic/Fni_QvWIJuY6ZYJNF2p6ySkNc_ne.jpg!thumbnail" alt="img"></p>
<ul>
<li>举个简单的例子，y=(x-1)^2，x在1处取得最小值。但是如果x的取值范围是[2,3]，那么只能在x的取值边界上得到最小值。</li>
</ul>
<ol>
<li>svm里 1 优化目标  maxmin  为什么要换成minmax  是为了引入基变换？方便计算？2  xi的位置是即可以是原始的特征 也可以是转换后由基函数表示吗 ？将不可分映射到高维可分？3  合约页损失函数是岭回归的思想吗</li>
</ol>
<ul>
<li><p>1.我们习惯解决最小化的优化问题，便于使用优化方法求解；</p>
</li>
<li><p>\2. 不太明白意思，xi可以是原始特征，但引入kernel后，可以认为是映射到高维，得到非线性分类面；</p>
</li>
<li><p>\3. 你说的应该是合页损失函数，它与岭回归不同，岭回归是平方误差函数加上了L2正则化项目，用于回归问题而不是分类问题。网上搜一下二者的区别很容易查到。</p>
</li>
</ul>
<ol>
<li>老师，这一步是你的博客上LinearSVM的代码，没看懂，感觉代码的逻辑说不通，并没有提取出每一个测试样本正例的分数</li>
</ol>
<p><img src="/.io//pic/75&amp;e=1874736000&amp;token=kIxbL07-8jAj8w1n4s9zv64FuZZNEATmlU_Vm6zD:n0uDmZaMQkQv_Xa-BLLIUvZbu7s=.jpeg" alt="img"></p>
<ul>
<li>这篇文章来源于之前看cs231n写的笔记。它的LinearSVM使用的Hinge Loss，使用梯度下降算法计算的，比较简单。这里还是以理解传统的SVM为主。</li>
</ul>
<ol>
<li>统计学习超平面是什么？</li>
</ol>
<p><img src="/.io//pic/75&amp;e=1874736000&amp;token=kIxbL07-8jAj8w1n4s9zv64FuZZNEATmlU_Vm6zD:mzqBn8A3XLrH5YVb_BEwHum7Hhg=.jpeg" alt="img"></p>
<ul>
<li>这里的超平面可以通俗理解为分类问题中的分类面，例如二维平面中的分类线，三维空间的分类面，对应到n维，就叫超平面。</li>
</ul>
<ol>
<li>老师，SVM中找到不满足KKT条件公式如图所示。但在实际代码中实现如下。这是为什么。 if ((self.y_train[i] <em> Ei &lt; -self.toler) and (self.alpha[i] &lt; self.C) or   (self.y_train[i] </em> Ei &gt; self.toler) and (self.alpha[i] &gt; 0)):</li>
</ol>
<p><img src="/.io//pic/75&amp;e=1874736000&amp;token=kIxbL07-8jAj8w1n4s9zv64FuZZNEATmlU_Vm6zD:gh_zjTg6Tfb60fYRgKbHYWNrasE=.jpeg" alt="img"></p>
<ul>
<li>你把代码中Ei=y-y_train代入，移位一下就会发现与理论是一样的了。我在之前SVM直播答疑的视频里讲过，你可以去看看。<a href="https://study.163.com/course/courseLearn.htm?courseId=1006284002&amp;share=2&amp;shareId=400000000445063#/learn/video?lessonId=1053809730&amp;courseId=1006284002" target="_blank" rel="noopener">《机器学习实战》书训练营直播间 - 网易云课堂</a></li>
</ul>
<ol>
<li>老师，为什么李航的统计学128页在SVM中提出SMO算法在每个子问题中选择两个变量优化，其中至少一个变量是违反KKT条件的。</li>
</ol>
<ul>
<li><p>选择两个变量的原因是所有的alpha满足下面图片所示的这个条件，为了保证等式成立，必须同时优化两个alpha。违反KKT条件是因为先找到违背KKT条件的点，让其满足条件。若所有的点都满足KKT条件，则优化结束了。</p>
</li>
<li><p><img src="/.io//pic/75&amp;e=1874736000&amp;token=kIxbL07-8jAj8w1n4s9zv64FuZZNEATmlU_Vm6zD:vKm1Y1htAp00LjzwNeWZMsEA6K4=.jpeg" alt="img"></p>
</li>
<li><p>老师，为什么因为先找到违背KKT条件的点，让其满足条件。这一步不理解</p>
</li>
<li><p>优化的目的是让所有点都满足KKT条件，因为满足KKT条件了，就得到最优化了。使用SMO是把整个优化问题切分成一个个小的优化问题，每次对两个alpha进行优化，让其满足KKT条件。</p>
</li>
<li><p>那找到违背KKT条件的点是不是要把这个点排除掉吗</p>
</li>
<li><p>更新alpha的值，让它满足KKT</p>
</li>
</ul>
<ol>
<li>老师，我想问一下机器学习实战第八章的内容，图中高斯核函数中的距离，指的是x轴的距离吗? 同时书中给的代码，感觉是x轴距离的平方，不知道我理解的对不对。</li>
</ol>
<p><img src="/.io//pic/75&amp;e=1874736000&amp;token=kIxbL07-8jAj8w1n4s9zv64FuZZNEATmlU_Vm6zD:OhBF3MR_p8y4H2_aIvOk09lNHto=.jpeg" alt="img"></p>
<ul>
<li>这里就是高斯核，x表示所有坐标轴，不是单指x轴。以书中代码为准，平方。</li>
</ul>
<ol>
<li>老师您好，机器学习实战svm这章KernelTrans这个函数里A表示什么?kTup[1]又表示的是什么，不是很明白，望解答一下</li>
</ol>
<p><img src="/.io//pic/75&amp;e=1874736000&amp;token=kIxbL07-8jAj8w1n4s9zv64FuZZNEATmlU_Vm6zD:P0qO5dt6CxKVEEwYDogVH_b826E=.jpeg" alt="img"></p>
<ul>
<li>这里的A就是每个训练样本，kTup是一个元组，kTup[0]表示核函数类型，kTup[1]表示高斯函数方差，sigma。</li>
</ul>
<ol>
<li>老师，请问使用svm做回归时，怎样评价模型的好坏</li>
</ol>
<ul>
<li>一般的回归模型评价指标可以是均方误差（MSE）、均方根误差（RMSE）、平均绝对误差（MAE）、校正决定系数（Ajusted R-Squre）等。</li>
</ul>
<ol>
<li>老师你好，我想问一下关于b阈值的理解，有效相等的话b1=b2，除此之外无效取值有什么意义嘛</li>
</ol>
<ul>
<li><p><img src="/.io//pic/75&amp;e=1874736000&amp;token=kIxbL07-8jAj8w1n4s9zv64FuZZNEATmlU_Vm6zD:7eRb59d61gqR88E-6-r0JTinA4I=.jpeg" alt="img"></p>
</li>
<li><p>第一种情况是该样本点是支持向量时，可以直接计算得到 b，若不是支持向量，b取两个b1和b2的均值。</p>
</li>
</ul>
<h1 id="决策树"><a href="#决策树" class="headerlink" title="决策树"></a>决策树</h1><ol>
<li>决策树有两个优点是对中间值缺失不敏感，可以处理不相关的特征数据，如何理解</li>
</ol>
<ul>
<li>第一个优点是对缺失值不敏感，因为决策树不是基于距离度量，大部分时候可以在数据有缺失的时候使用。如果涉及到距离度量，缺失数据就变得比较重要。第二个优点是可以处理不相关特征，树形结构并不要求特征之间具有较高相关性。</li>
</ul>
<ol>
<li>请问在决策树中找出最好的数据集划分方式，可不可以理解为以每一列为特征值计算熵，然后找出最小的呢？</li>
</ol>
<ul>
<li>对每个特征计算条件熵，可以理解为条件熵越小，信息增益越大，就以该特征进行划分。</li>
</ul>
<ol>
<li>能把这个注解函数的各个参数详细的说下嘛</li>
</ol>
<p><img src="/.io//pic/75&amp;e=1874736000&amp;token=kIxbL07-8jAj8w1n4s9zv64FuZZNEATmlU_Vm6zD:wbx9TK4z2PsH5un3ikfmwFolV0U=.jpeg" alt="img"></p>
<ul>
<li>这里使用的是python里的annotate，网上资料很多，可以自己搜一下<a href="https://blog.csdn.net/leaf_zizi/article/details/82886755" target="_blank" rel="noopener">https://blog.csdn.net/leaf_zizi/article/details/82886755</a></li>
</ul>
<ol>
<li>一般决策树用于连续值划分的用例多不多，西瓜书上决策树对连续值处理的理论我没太看明白</li>
</ol>
<ul>
<li>你说的应该是CART算法，应用蛮多的，Random Forest、GBDT都会用到决策树。CART部分建议好好看看，西瓜书理论对初学者不太友好，网上搜一搜简洁教程。</li>
</ul>
<ol>
<li>老师、请问这里为什么要分两段（featVec[：axis]和featVec[axis+1:]）添加featVec的信息？</li>
</ol>
<p><img src="/.io//pic/75&amp;e=1874736000&amp;token=kIxbL07-8jAj8w1n4s9zv64FuZZNEATmlU_Vm6zD:QCMkh3xchDHdelnx09vKhcSOgK4=.jpeg" alt="img"></p>
<ul>
<li>因为要把featVec[axis]这个特征删去。第三章决策树里面，它是使用一个特征之后就把该特征删去的，就像我们根据条件判断一样，这个条件使用过了就不会再用了。</li>
</ul>
<h1 id="k-近邻算法"><a href="#k-近邻算法" class="headerlink" title="k-近邻算法"></a>k-近邻算法</h1><ol>
<li>k近临算法的思路，是不是待观测值与训练数据之间求距离，然后寻找距离最短的点，认为与最短距离的点位一类。 那我想不明白的，图片中第一个矩形框的内容为什么这样写？第2框是对距离排序，而labels并没有排序，那怎么确定第三个框中labels是最短距离所对应的label？#k邻近</li>
</ol>
<p><img src="/.io//pic/75&amp;e=1874736000&amp;token=kIxbL07-8jAj8w1n4s9zv64FuZZNEATmlU_Vm6zD:6lmcCaNV0DDQhPhuaYyZAQchvQ0=.jpeg" alt="img"></p>
<ul>
<li><p>sortedDistIndicies存储的就是距离最小对应的label中类的下标。建议每个变量用print函数打印出来看看，加深理解。</p>
</li>
<li><p>首先，第一个框目的是求一个点和所有点的距离差值，这里的写法是把维度匹配上，做一个向量减法。换句话说就是把待测点的坐标复制出很多份（数量由训练数据大小决定），然后做向量减法。第二个框sort的是index不是里面的值，就是根据值sort了label。</p>
</li>
</ul>
<ol>
<li>ax.scatter(returnMat[:,0],returnMat[:,1],15.0<em>np.array(classLabelVector), 15.0</em>np.array(classLabelVector))  请问下，scatter这个函数第三第四个参数为啥都乘以15，而且为啥需要两个相同的参数？</li>
</ol>
<ul>
<li>第三个参数是s表示大小，第四个参数c表示颜色。之所以用label是让每个类别呈现不同的大小和颜色。15.0是变量，你可以调整为其他值看看效果。</li>
</ul>
<ol>
<li>knn算法为什要对数据进行normalization预处理，normalization方法有哪几种？</li>
</ol>
<ul>
<li>一般的机器学习算法都会对输入进行归一化，其主要目的是将各个特征归一化到相似尺度，提高训练精度。如果是梯度下降算法的话还会提高训练速度。常用的归一化有线性归一化，标准差标准化，非线性归一化等。</li>
</ul>
<ol>
<li>kdtree可以实现k邻近的搜索吗？看李航老师的书在讲knn的时候叙述了kdtree，只实现了最邻近。</li>
</ol>
<ul>
<li>当然可以！kdtree只是使用了特殊的存储结构，可以实现最近邻，也可以实现k近邻。而且李航的书中也说了。附图：</li>
</ul>
<p><img src="/.io//pic/75&amp;e=1874736000&amp;token=kIxbL07-8jAj8w1n4s9zv64FuZZNEATmlU_Vm6zD:Hfhii1JA8e0qsLgWDiYVqG6AmhM=.jpeg" alt="img"></p>
<ul>
<li><p>能请教一下kdtree实现k邻近的思路吗，是需要遍历所有的节点吗，想编程实现来着，但是对于在另一半子树中存在比当前子树中多个点更近的点时，想不出来怎么解决，网上也没看到资料</p>
</li>
<li><p>既然能找到最邻近点，一定能找到k邻近点。例如k=3，设置一个包含3个元素的数组，在往上寻找的时候总是把最邻近的3个点保存下来。最后统计最多所占的类别就好。</p>
</li>
<li><p>但是搜索完根节点的左子树，假设找到了三个点，怎么确定右子树中没有比这三个点更近的点，是需要在走一遍右子树吗，就是这没想通。在李航老师树的42页那个特征空间划分的图中，如果我想查找(6,1)并且k=3，走完左子树后查到三个最近的点，然后右子树还有一个(8，1)，比左子树中部分点更近，这种应该怎么办？</p>
</li>
<li><p>这还是需要在继续便利，直到右子树也遍历完，像你说的这种情况，会让右子树中的小值替换当前3个元素的数组中的大值，直到找出整个树中最小的前3个值。</p>
</li>
</ul>
<ol>
<li>KNN算法中的K是怎样取值的？越大越好？k它有什么意义吗?</li>
</ol>
<ul>
<li>K一般没有固定的取值，根据具体问题具体分析。一般可以使用交叉验证选择最佳的K值。</li>
</ul>
<ol>
<li>实战书的k近邻算法第二章第四小节说，”k近邻算法的另一个缺陷是它无法给出任何数据的基础信息结构，因此我们也无法知晓平均实例样本和典型实例样本具有什么特征。下一章我们将使用概率测量方法处理分类问题，该算法可以解决这个问题”。疑问1:没理解这个缺陷是什么缺陷，样本数据每个纬度值都有了，为什么说无法知晓具有什么特征和基础信息结构？疑问二:为什么说概率测量方法可以解决？</li>
</ol>
<ul>
<li>1、knn是基于实例的学习，训练的时候使用的是样本所有的输入值进行距离计算，例如图片识别中一张图片所有的像素点。整个过程并没有提取样本本身的固有特征。训练过程保持了所有的训练样本。2、决策树使用信息增益寻找最佳划分特征，信息增益是通过训练样本中的概率测量方法得到的。</li>
</ul>
<ol>
<li>knn运行加载学会数据出错，是什么原因呢</li>
</ol>
<p><img src="/.io//pic/75&amp;e=1874736000&amp;token=kIxbL07-8jAj8w1n4s9zv64FuZZNEATmlU_Vm6zD:AGwHVXhYwVL-ybKCq0-_DgRsQ3U=.jpeg" alt="img"></p>
<ul>
<li>看下你的“datingTestSet.txt”数据集，类别标签不是int型，你可以是使用“datingTestSet2.txt”数据集，label是int型的，或者修改file2matrix函数。这些都在训练营的github上：<a href="https://github.com/RedstoneWill/MachineLearningInAction-Camp" target="_blank" rel="noopener">https://github.com/RedstoneWill/MachineLearningInAction-Camp</a></li>
</ul>
<ol>
<li>老师，K近邻算法中如何理解？voteIlabel = labels[sortedDistIndicies[i]] ？为什么不能写成voteIlabel = labels[sortedDistIndicies==i] ？（当i 为0时 取sortedDistIndicies为0的那项）</li>
</ol>
<p><img src="/.io//pic/75&amp;e=1874736000&amp;token=kIxbL07-8jAj8w1n4s9zv64FuZZNEATmlU_Vm6zD:S5fagacN3D9dtMA9iIlXtMsESX4=.jpeg" alt="img"></p>
<ul>
<li>sortedDistIndicies存储的是从大到小排列，距离最近的label下标，即位置。然后找到前k个点，计这k个点属于哪一个类别，统计最多的那一个类别就是预测类别。建议把每行语句打印出来看看，这样理解得比较透彻。</li>
</ul>
<h1 id="朴素贝叶斯"><a href="#朴素贝叶斯" class="headerlink" title="朴素贝叶斯"></a>朴素贝叶斯</h1><ol>
<li>如何用极大似然估计法推出概率估计公式（4.8）和（4.9）。也是统计学习方法朴素贝叶斯法中的课后习题。</li>
</ol>
<p><img src="/.io//pic/75&amp;e=1874736000&amp;token=kIxbL07-8jAj8w1n4s9zv64FuZZNEATmlU_Vm6zD:6cGdixxIXfnKD1o-ESQzA2WOllM=.jpeg" alt="img"></p>
<ul>
<li><a href="https://blog.csdn.net/xiaoxiao_wen/article/details/54097917" target="_blank" rel="noopener">https://blog.csdn.net/xiaoxiao_wen/article/details/54097917</a></li>
</ul>
<ol>
<li>最近我在做文本分类的题目，按理说使用word2vec进行模型建立后，效果应该比用countvectorizer好的，但是我使用word2vec反而效果差了一些，不太懂为什么会这样？</li>
</ol>
<ul>
<li>可能跟样本集、算法、模型都有关系，没有说某个模型一定好。</li>
</ul>
<ol>
<li>想问一下图片上是怎么由1式得到的2式啊（记号处）</li>
</ol>
<p><img src="/.io//pic/75&amp;e=1874736000&amp;token=kIxbL07-8jAj8w1n4s9zv64FuZZNEATmlU_Vm6zD:iCXlUW9aTFzVJdZoHTAdKlMKutU=.jpeg" alt="img"></p>
<ul>
<li>这是条件期望的表达式，可以看成是取每个类别的概率乘以当前类别的期望风险，最后所有类别的总和。</li>
</ul>
<ol>
<li>这个的解答，能直接算p(y=1!2,s)和p(y=-1|2,s)的概率，哪个大就代表是哪个类别吗</li>
</ol>
<p><img src="/.io//pic/75&amp;e=1874736000&amp;token=kIxbL07-8jAj8w1n4s9zv64FuZZNEATmlU_Vm6zD:Zk5IB0G4ePgZi7JHn1wMMmhAHOo=.jpeg" alt="img"></p>
<ul>
<li>是的，朴素贝叶斯公式中，由于分母是全概率都是一样的，所以一般比较分子就行了。</li>
</ul>
<ol>
<li>针对4.5.2的公式和例子有两个问题1.例子中的文档和词条，谁是w谁是c?我理解c是词条，w是文档分类2.在4.5.3的classifyNB的计算中并没有除p(w)</li>
</ol>
<ul>
<li><p><img src="/.io//pic/75&amp;e=1874736000&amp;token=kIxbL07-8jAj8w1n4s9zv64FuZZNEATmlU_Vm6zD:sJrrYT3AYbEp9lZdN63KNELmEWQ=.jpeg" alt="img"></p>
</li>
<li><p>\1. c 意为 class，c 是类别，w 是特征词条。</p>
</li>
<li><p>\2. 之所以不除以 p(w) 是因为计算所有c别可能性的时候，p(w) 都是相同的，比较大小的时候只看分子就行了。</p>
</li>
</ul>
<ol>
<li>请问老师，在书上朴素贝叶斯分类器过滤垃圾邮件中，图中这几行代码该怎么理解？trainMatrix不是文本向量吗？+＝操作是咋回事？</li>
</ol>
<p><img src="/.io//pic/75&amp;e=1874736000&amp;token=kIxbL07-8jAj8w1n4s9zv64FuZZNEATmlU_Vm6zD:bHzNDf79I9crdbq9M4amyQu6-qk=.jpeg" alt="img"></p>
<ul>
<li>p1Num 和 p0Num 中的 += 操作是向量相加，统计的是训练样本两个类别每个单词出现的次数，p1Denom 和 p0Denom 中的 += 操作是数字相加，统计的是训练样本两个类别各自总的单词数。</li>
</ul>
<ol>
<li>老师，我想问下《机器学习实战》71页程序清单4-7这里，为什么要条件概率大于-6.0的单词加入到列表里，-6.0意味着什么</li>
</ol>
<p><img src="/.io//pic/75&amp;e=1874736000&amp;token=kIxbL07-8jAj8w1n4s9zv64FuZZNEATmlU_Vm6zD:t-YVYN4a776AC1xr6-1uHDSBSIs=.jpeg" alt="img"></p>
<ul>
<li>条件概率加了log，可能会出现负值。这里为什么是-6.0可能是个阈值把。这4.7节不是我们需要完成的任务。原始网站数据因为是外网，所以爬不到，就不用看了。</li>
</ul>
<h1 id="其他疑问"><a href="#其他疑问" class="headerlink" title="其他疑问"></a>其他疑问</h1><ol>
<li>想问一下逻辑回归求参数为什么不是直接求导 而是要梯度下降呢 像SVM这种不都是直接求导结合拉格朗日就可以求参数吗</li>
</ol>
<ul>
<li>首先并不是所有函数都可以直接令导数为零求得极值的，有时可以求出导数在每个点的值, 但是直接解方程解不出来。对计算机而言，更加适合用循环迭代的方法来求极值，即梯度下降。SVM的解是二次规划问题，对于二次规划问题，有经典的最速下降法，牛顿法等，并不是简单的直接求导。</li>
</ul>
<ol>
<li>训练数据集经常出现训练数据集里面没有的属性，这种属性训练的有什么用吗？这么利用，比如下图，希望老师解答的详细一点，之前没有接触过这种数据训练</li>
</ol>
<p><img src="/.io//pic/75&amp;e=1874736000&amp;token=kIxbL07-8jAj8w1n4s9zv64FuZZNEATmlU_Vm6zD:lpET1N0KWYLkGEAgF-sqe6LMKSo=.jpeg" alt="img"></p>
<ul>
<li>我看的是训练集里有一些特征，但是在测试集中却并未出现。尝试使用特征工程找出不同特征之间的相互关系。或者简单的方法忽略这些特征，训练的模型在测试集上测试看看效果如何。</li>
</ul>
<ol>
<li>请问训练营的10.1的阅读材料是台大机器学习基石的PLA,  训练营大纲是从knn开始的，1. 请问国庆节后训练营从哪个算法开始呢？2. 我们平时自己学习的时候按照实战的顺序学习吗？3. 那您博客的基石与技法的笔记要不要看呢？毕竟他们的内容不一样 4. 是否老师根据自己的需要安排算法的讲解顺序，并不是完全参考书本，然后讲解的算法内容与台大的笔记相结合学习？ 我自己比较纠结学习顺序，谢谢老师解答\</li>
</ol>
<ul>
<li>你好，1. 训练营的课程大纲是按照《机器学习实战》这本书为基础的，国庆假期的任务是我给大家安排的选修作业，并不在我们的任务要求之内，有兴趣的同学可以做一做。国庆后从决策树开始，具体见知识圈。2. 按照《机器学习实战》顺序。3. 我的个人博客、微信公众号有不错的资源和文章，大家可以作为参考资料看看。4. 目前这一期的训练营我们还是按照《机器学习实战》这本书的章节顺序来学习的，跟着我们大纲的顺序学习就好了。后期如果有调整会告知大家。</li>
</ul>
<ol>
<li>关于PLA算法的实现，我想问一下这里的x1和x2是随便设的嘛，为什么y1和y2要这样算呢</li>
</ol>
<p><img src="/.io//pic/75&amp;e=1874736000&amp;token=kIxbL07-8jAj8w1n4s9zv64FuZZNEATmlU_Vm6zD:RRyQpBB2tqQ1nkkpjh4-QG6D604=.jpeg" alt="img"></p>
<ul>
<li><p>这里是画出当前w对应的分类线，x1和x2选取合适的值就好。y1和y2是根据分类线表达式推导的，见下图：</p>
</li>
<li><p><img src="/.io//pic/75&amp;e=1874736000&amp;token=kIxbL07-8jAj8w1n4s9zv64FuZZNEATmlU_Vm6zD:5SEqeHWYeZIPyYa2mlKWwJYRfEA=.jpeg" alt="img"></p>
</li>
</ul>
<ol>
<li>有没有什么好的，理论教材，比如最优化，凸优化这些？</li>
</ol>
<ul>
<li>Bubeck的《Convex Optimization: Algorithms and Complexity》。最好根据自己实际情况找到最适合自己的就行。</li>
</ul>
<ol>
<li>能推荐对极大似然估计和softmax解释得通俗易懂的博客？</li>
</ol>
<ul>
<li>没有专门的推荐，网上资料很多，CSDN和博客园的文章都不错。Softmax的有一篇可以看看：<a href="https://mp.weixin.qq.com/s/XBK7T1P7z3rm3o-3BDNeOA" target="_blank" rel="noopener">https://mp.weixin.qq.com/s/XBK7T1P7z3rm3o-3BDNeOA</a></li>
</ul>
<ol>
<li>例如lstm的变体GRU，每个参数在编程中如何体现的，以及W如何设置呢？能写个样例吗？要是能debug到细节更好了！</li>
</ol>
<p><img src="/.io//pic/FnXmqd1ACovsuiQ_uMayt8Mt8P3i.jpg!thumbnail" alt="img"></p>
<ul>
<li>原理上与一般神经网络类似，使用梯度下降更新参数。现在多是直接调用深度学习框架来做，自己手写LSTM没啥必要。学有余力可以直接看看深度学习框架中LSTM的实现源码。</li>
</ul>
<ol>
<li>我安装scikit-learn的时候出现这个问题怎么解决呢</li>
</ol>
<p><img src="/.io//pic/75&amp;e=1874736000&amp;token=kIxbL07-8jAj8w1n4s9zv64FuZZNEATmlU_Vm6zD:najgnP2JhLK4Haeyh_MgbPdUNSw=.jpeg" alt="img"></p>
<ul>
<li>换个镜像源试试。建议使用Anaconda自带的conda，直接输入：conda install scikit-learn即可。</li>
</ul>
<ol>
<li>能详细介绍一下lstm的代码实现，以及每个参数的含义吗？最好是能跑起来的程序！现在网上搜的程序规模太大！不适合从浅入深的学习！</li>
</ol>
<ul>
<li>这个问题太大了，现在基本都是使用tensorflow或pytorch等库来实现LSTM。如果是入门的话，建议看看莫烦的教学视频，这里面讲到了LSTM：<a href="https://morvanzhou.github.io/tutorials/machine-learning/torch/" target="_blank" rel="noopener">https://morvanzhou.github.io/tutorials/machine-learning/torch/</a></li>
</ul>
<ol>
<li>机器学习工具包sklearn，有没有比较好的教程，以及还有其他的比较好的工具包吗</li>
</ol>
<ul>
<li><p>最好的教程就是官方文档。ApachenCN翻译了中文版，可以参考：<a href="http://sklearn.apachecn.org/" target="_blank" rel="noopener">http://sklearn.apachecn.org/</a></p>
</li>
<li><p>机器学习最好的就是sklearn了，其它的深度学习如TensorFlow，PyTorch，Keras等</p>
</li>
</ul>
<ol>
<li>老师，请问跟着你学完这门课程，还需要学习哪些东西，才能找到一分机器学习的工作呢？</li>
</ol>
<ul>
<li>这是一个很大又很实际的问题。首先学习这门课只是基础，帮助大家在理解一定机器学习理论的基础上使用python手写各个基本机器学习算法的实现过程。但掌握这些还远远不够。建议从三个方面入手：1. 补充机器学习理论基础知识，这点在找工作笔试、面试的时候是很重要的，例如SVM、AdaBoost、GBDT等等要吃得透一点。2. 提高代码编程能力，掌握对机器学习库的使用，例如scikit-learn、深度学习的tensorflow等。3. 有机会的话做一些项目积累经验，或者了解构建一个完整的机器学习项目的整个流程。</li>
</ul>
<ol>
<li>我这边在训练一个卷积网络的模型，但是我的数据中正样本很多，负样本很少，我觉得这样的数据训练出来的模型可能会有问题，我想请问一下数据集中正负样本的比例多大时训练出来的模型比较好？</li>
</ol>
<ul>
<li>一般是正负样本近似相等的时候比较好。但实际中出现正负样本不均匀的情况，可以使用重采样和欠采样来尽量让其数量接近。</li>
</ul>
<ol>
<li>我把一个训练好的模型用C++进行调用的时候，我发现单次调用的时候用时100ms左右，但是做100次循环求平均用时5ms左右！请问您知道是什么原因导致的吗？</li>
</ol>
<ul>
<li>第一次参数传到模型时耗时比较多。</li>
</ul>
<ol>
<li>老师您好，我今年27了，在一家国企的设计单位做轨道交通线路走向设计工作。我打算现在转行机器学习，是否来得及？因为年龄比较大了。</li>
</ol>
<ul>
<li>你好，任何时候想要转行机器学习都不晚。况且你也才27岁，还算年轻。建议原先的工作先干着，平时多学点机器学习，为找份机器学习工作做准备。我不知道你的基础如何，一般半年时间可以入门了。</li>
</ul>
<ol>
<li>关于PLA算法，我做机器学习基石作业1的第15题的时候，迭代次数一直都是21，网上的答案是45，不知道自己究竟是哪里出错了</li>
</ol>
<p><img src="/.io//pic/75&amp;e=1874736000&amp;token=kIxbL07-8jAj8w1n4s9zv64FuZZNEATmlU_Vm6zD:Ht9wz0Sn519trUPoelmrve2I-Bw=.jpeg" alt="img"></p>
<ul>
<li>PLA得到的分类超平面不是固定的，每次都可能产出新的结果，迭代次数也与初始选择的参数有关。你把最终的分类线在数据集上画出来看一下，正确的话就没有问题。</li>
</ul>
<ol>
<li>老师您好。本来想提一些关于实战书籍里的问题，结果发现琢磨着也很快看懂了。想来我的目的是来学习，并希望找一份相应的工作，请老师指点一下。我是一个走机器学习的转行人员，具备一年的python自学基础，目前毕业3年，软件测试干了2年，也算是IT行业吧。1,在这个深入一点的IT行业，机器学习里面，实际上机器学习会有怎样的使用。(应该不仅仅是kaggle或者天池020刷题一样吧？)2,机器学习涉及到大量数据的处理，我想问一下这些数据也是我自己来获取吗？3,对于面试，我应该准备到多少？(不会面多年经验的，所以就从初等看吧。)4,对于这种面试的情况下，我们应该面试的工资在什么范围？</li>
</ol>
<ul>
<li>你好。1.实际工程项目与打比赛区别还是很大的。比较仅仅考虑的是模型的准确率而不惜使用非常复杂、臃肿的模型。但是再工程应用上，除了考虑性能之外，还要注重速度、资源消耗、成本等各个方面。实际上机器学习有很大应用，比如推荐系统、图像识别等。2.数据不用自己获取，网络上有大量可供下载的数据集。公司里的话，也会有专门的人做数据收集、清洗等工作的。但是机器学习工程师也多少做过数据收集这些事情。3.面试的话多多准备一些机器学习典型问题的知识点，比如SVM、集成学习AdaBoost等，还有你的项目经验。4.这个得根据工作地点、公司、具体什么工作等来确定。可以根据当地IT均资来设个心理价位。</li>
</ul>
<ol>
<li>LSTM中的cell state表示什么意思？</li>
</ol>
<ul>
<li><p>cell state一般是保存模型当前及历史状态。有点像是传输带，它直直地流过整个链，受到轻微的非线性相互作用影响。因此信息可以轻松地沿它流动而不发生改变。可以看下这篇文章：<a href="http://colah.github.io/posts/2015-08-Understanding-LSTMs/" target="_blank" rel="noopener">Understanding LSTM Networks — colah’s blog</a></p>
</li>
<li><p><img src="/.io//pic/75&amp;e=1874736000&amp;token=kIxbL07-8jAj8w1n4s9zv64FuZZNEATmlU_Vm6zD:TxTw6IhA74ue0H40Y8kGSV61lMU=.jpeg" alt="img"></p>
</li>
</ul>
<ol>
<li>老师你好，学习算法需不需要每一步自己去证明它呢?</li>
</ol>
<ul>
<li>其实，对大部分人来说，机器学习算法的每一步详细的数学证明是不需要的。但是我们要感性地理解它的意思和推导方式。就像SVM中涉及的理论推导很多，拉格朗日那块内容每一步推导要大致知道思路和方法，但详细的数学证明可能就不需要了。</li>
</ul>

          
        
      
    </div>

    

    
    
    

    

    
      
    
    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  

  <article class="post post-type-normal" itemscope="" itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="https://schwimmer.github.io/2019/06/02/深度学习笔记/Pytorch莫烦/pytorch基础/">

    <span hidden itemprop="author" itemscope="" itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Schwimmer">
      <meta itemprop="description" content="Record and Think!">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope="" itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Schwimmer's Blog">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                
                <a href="/2019/06/02/深度学习笔记/Pytorch莫烦/pytorch基础/" class="post-title-link" itemprop="url">未命名</a>
              
            
          </h1>
        

        <div class="post-meta">

          
          
          

          
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              

              
                
              

              <time title="创建时间：2019-06-02 15:07:08 / 修改时间：16:09:19" itemprop="dateCreated datePublished" datetime="2019-06-02T15:07:08+08:00">2019-06-02</time>
            </span>
          

          
            

            
          

          

          
            
            
              
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="fa fa-comment-o"></i>
                </span>
            
                <span class="post-meta-item-text">评论数：</span>
                <a href="/2019/06/02/深度学习笔记/Pytorch莫烦/pytorch基础/#comments" itemprop="discussionUrl">
                  <span class="post-comments-count disqus-comment-count" data-disqus-identifier="2019/06/02/深度学习笔记/Pytorch莫烦/pytorch基础/" itemprop="commentCount"></span>
                </a>
              </span>
            
          

          
          

          

          <br>
          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p><a href="https://morvanzhou.github.io/tutorials/machine-learning/torch/2-01-torch-numpy/" target="_blank" rel="noopener">https://morvanzhou.github.io/tutorials/machine-learning/torch/2-01-torch-numpy/</a></p>
<p>基于0.1.11的版本</p>
<h2 id="用-Numpy-还是-Torch"><a href="#用-Numpy-还是-Torch" class="headerlink" title="用 Numpy 还是 Torch"></a>用 Numpy 还是 Torch</h2><p>我们对 Numpy 还是爱不释手的, 因为我们太习惯 numpy 的形式了. 不过 torch 看出来我们的喜爱, 他把 torch 做的和 numpy 能很好的兼容. 比如这样就能自由地转换 numpy array 和 torch tensor 了:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line">np_data = np.arange(<span class="number">6</span>).reshape((<span class="number">2</span>, <span class="number">3</span>))</span><br><span class="line">torch_data = torch.from_numpy(np_data)</span><br><span class="line">tensor2array = torch_data.numpy()</span><br><span class="line">print(</span><br><span class="line">    <span class="string">'\nnumpy array:'</span>, np_data,          <span class="comment"># [[0 1 2], [3 4 5]]</span></span><br><span class="line">    <span class="string">'\ntorch tensor:'</span>, torch_data,      <span class="comment">#  0  1  2 \n 3  4  5    [torch.LongTensor of size 2x3]</span></span><br><span class="line">    <span class="string">'\ntensor to array:'</span>, tensor2array, <span class="comment"># [[0 1 2], [3 4 5]]</span></span><br><span class="line">)</span><br></pre></td></tr></table></figure>
<h2 id="Torch-中的数学运算"><a href="#Torch-中的数学运算" class="headerlink" title="Torch 中的数学运算"></a>Torch 中的数学运算</h2><p>其实 torch 中 tensor 的运算和 numpy array 的如出一辙, 我们就以对比的形式来看. 如果想了解 torch 中其它更多有用的运算符, <a href="http://pytorch.org/docs/torch.html#math-operations" target="_blank" rel="noopener">API就是你要去的地方</a>.</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"># abs 绝对值计算</span><br><span class="line">data = [-1, -2, 1, 2]</span><br><span class="line">tensor = torch.FloatTensor(data)  # 转换成32位浮点 tensor</span><br><span class="line">print(</span><br><span class="line">    &apos;\nabs&apos;,</span><br><span class="line">    &apos;\nnumpy: &apos;, np.abs(data),          # [1 2 1 2]</span><br><span class="line">    &apos;\ntorch: &apos;, torch.abs(tensor)      # [1 2 1 2]</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"># sin   三角函数 sin</span><br><span class="line">print(</span><br><span class="line">    &apos;\nsin&apos;,</span><br><span class="line">    &apos;\nnumpy: &apos;, np.sin(data),      # [-0.84147098 -0.90929743  0.84147098  0.90929743]</span><br><span class="line">    &apos;\ntorch: &apos;, torch.sin(tensor)  # [-0.8415 -0.9093  0.8415  0.9093]</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"># mean  均值</span><br><span class="line">print(</span><br><span class="line">    &apos;\nmean&apos;,</span><br><span class="line">    &apos;\nnumpy: &apos;, np.mean(data),         # 0.0</span><br><span class="line">    &apos;\ntorch: &apos;, torch.mean(tensor)     # 0.0</span><br><span class="line">)</span><br></pre></td></tr></table></figure>
<p>除了简单的计算, 矩阵运算才是神经网络中最重要的部分. 所以我们展示下矩阵的乘法. 注意一下包含了一个 numpy 中可行, 但是 torch 中不可行的方式.</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"># matrix multiplication 矩阵点乘</span><br><span class="line">data = [[1,2], [3,4]]</span><br><span class="line">tensor = torch.FloatTensor(data)  # 转换成32位浮点 tensor</span><br><span class="line"># correct method</span><br><span class="line">print(</span><br><span class="line">    &apos;\nmatrix multiplication (matmul)&apos;,</span><br><span class="line">    &apos;\nnumpy: &apos;, np.matmul(data, data),     # [[7, 10], [15, 22]]</span><br><span class="line">    &apos;\ntorch: &apos;, torch.mm(tensor, tensor)   # [[7, 10], [15, 22]]</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"># !!!!  下面是错误的方法 !!!!</span><br><span class="line">data = np.array(data)</span><br><span class="line">print(</span><br><span class="line">    &apos;\nmatrix multiplication (dot)&apos;,</span><br><span class="line">    &apos;\nnumpy: &apos;, data.dot(data),        # [[7, 10], [15, 22]] 在numpy 中可行</span><br><span class="line">    &apos;\ntorch: &apos;, tensor.dot(tensor)     # torch 会转换成 [1,2,3,4].dot([1,2,3,4) = 30.0</span><br><span class="line">)</span><br></pre></td></tr></table></figure>
<p>新版本中(&gt;=0.3.0), 关于 <code>tensor.dot()</code> 有了新的改变, 它<a href="http://pytorch.org/docs/master/torch.html" target="_blank" rel="noopener">只能</a>针对于一维的数组. 所以上面的有所改变.</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">tensor.dot(tensor)     # torch 会转换成 [1,2,3,4].dot([1,2,3,4) = 30.0</span><br><span class="line"></span><br><span class="line"># 变为</span><br><span class="line">torch.dot(tensor.dot(tensor)</span><br></pre></td></tr></table></figure>
<h1 id="变量-Variable"><a href="#变量-Variable" class="headerlink" title="变量 (Variable)"></a>变量 (Variable)</h1><h2 id="什么是-Variable"><a href="#什么是-Variable" class="headerlink" title="什么是 Variable"></a>什么是 Variable</h2><p>在 Torch 中的 Variable 就是一个存放会变化的值的地理位置. 里面的值会不停的变化. 就像一个裝鸡蛋的篮子, 鸡蛋数会不停变动. 那谁是里面的鸡蛋呢, 自然就是 Torch 的 Tensor 咯. 如果用一个 Variable 进行计算, 那返回的也是一个同类型的 Variable.</p>
<p>我们定义一个 Variable:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">from</span> torch.autograd <span class="keyword">import</span> Variable <span class="comment"># torch 中 Variable 模块</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 先生鸡蛋</span></span><br><span class="line">tensor = torch.FloatTensor([[<span class="number">1</span>,<span class="number">2</span>],[<span class="number">3</span>,<span class="number">4</span>]])</span><br><span class="line"><span class="comment"># 把鸡蛋放到篮子里, requires_grad是参不参与误差反向传播, 要不要计算梯度</span></span><br><span class="line">variable = Variable(tensor, requires_grad=<span class="keyword">True</span>)</span><br><span class="line"></span><br><span class="line">print(tensor)</span><br><span class="line"><span class="string">"""</span></span><br><span class="line"><span class="string"> 1  2</span></span><br><span class="line"><span class="string"> 3  4</span></span><br><span class="line"><span class="string">[torch.FloatTensor of size 2x2]</span></span><br><span class="line"><span class="string">"""</span></span><br><span class="line"></span><br><span class="line">print(variable)</span><br><span class="line"><span class="string">"""</span></span><br><span class="line"><span class="string">Variable containing:</span></span><br><span class="line"><span class="string"> 1  2</span></span><br><span class="line"><span class="string"> 3  4</span></span><br><span class="line"><span class="string">[torch.FloatTensor of size 2x2]</span></span><br><span class="line"><span class="string">"""</span></span><br></pre></td></tr></table></figure>
<h2 id="Variable-计算-梯度"><a href="#Variable-计算-梯度" class="headerlink" title="Variable 计算, 梯度"></a>Variable 计算, 梯度</h2><p>我们再对比一下 tensor 的计算和 variable 的计算.</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">t_out = torch.mean(tensor*tensor)       # x^2</span><br><span class="line">v_out = torch.mean(variable*variable)   # x^2</span><br><span class="line">print(t_out)</span><br><span class="line">print(v_out)    # 7.5</span><br></pre></td></tr></table></figure>
<p>到目前为止, 我们看不出什么不同, <strong>但是时刻记住, Variable 计算时, 它在背景幕布后面一步步默默地搭建着一个庞大的系统, 叫做计算图, computational graph. 这个图是用来干嘛的? 原来是将所有的计算步骤 (节点) 都连接起来, 最后进行误差反向传递的时候, 一次性将所有 variable 里面的修改幅度 (梯度) 都计算出来, 而 tensor 就没有这个能力啦.</strong></p>
<p><code>v_out = torch.mean(variable*variable)</code> 就是在计算图中添加的一个计算步骤, 计算误差反向传递的时候有他一份功劳, 我们就来举个例子:</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">v_out.backward()    # 模拟 v_out 的误差反向传递</span><br><span class="line"></span><br><span class="line"># 下面两步看不懂没关系, 只要知道 Variable 是计算图的一部分, 可以用来传递误差就好.</span><br><span class="line"># v_out = 1/4 * sum(variable*variable) 这是计算图中的 v_out 计算步骤</span><br><span class="line"># 针对于 v_out 的梯度就是, d(v_out)/d(variable) = 1/4*2*variable = variable/2</span><br><span class="line"></span><br><span class="line">print(variable.grad)    # 初始 Variable 的梯度</span><br><span class="line">&apos;&apos;&apos;</span><br><span class="line"> 0.5000  1.0000</span><br><span class="line"> 1.5000  2.0000</span><br><span class="line">&apos;&apos;&apos;</span><br></pre></td></tr></table></figure>
<h2 id="获取-Variable-里面的数据"><a href="#获取-Variable-里面的数据" class="headerlink" title="获取 Variable 里面的数据"></a>获取 Variable 里面的数据</h2><p>直接<code>print(variable)</code>只会输出 Variable 形式的数据, 在很多时候是用不了的(比如想要用 plt 画图), 所以我们要转换一下, 将它变成 tensor 形式.</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">print(variable)     #  Variable 形式</span><br><span class="line">&quot;&quot;&quot;</span><br><span class="line">Variable containing:</span><br><span class="line"> 1  2</span><br><span class="line"> 3  4</span><br><span class="line">[torch.FloatTensor of size 2x2]</span><br><span class="line">&quot;&quot;&quot;</span><br><span class="line"></span><br><span class="line">print(variable.data)    # tensor 形式</span><br><span class="line">&quot;&quot;&quot;</span><br><span class="line"> 1  2</span><br><span class="line"> 3  4</span><br><span class="line">[torch.FloatTensor of size 2x2]</span><br><span class="line">&quot;&quot;&quot;</span><br><span class="line"></span><br><span class="line">print(variable.data.numpy())    # numpy 形式</span><br><span class="line">&quot;&quot;&quot;</span><br><span class="line">[[ 1.  2.]</span><br><span class="line"> [ 3.  4.]]</span><br><span class="line">&quot;&quot;&quot;</span><br></pre></td></tr></table></figure>

          
        
      
    </div>

    

    
    
    

    

    
      
    
    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  

  <article class="post post-type-normal" itemscope="" itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="https://schwimmer.github.io/2019/06/01/深度学习笔记/Pytorch训练营/D1 pytorch入门/">

    <span hidden itemprop="author" itemscope="" itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Schwimmer">
      <meta itemprop="description" content="Record and Think!">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope="" itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Schwimmer's Blog">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                
                <a href="/2019/06/01/深度学习笔记/Pytorch训练营/D1 pytorch入门/" class="post-title-link" itemprop="url">未命名</a>
              
            
          </h1>
        

        <div class="post-meta">

          
          
          

          
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              

              
                
              

              <time title="创建时间：2019-06-01 22:59:25" itemprop="dateCreated datePublished" datetime="2019-06-01T22:59:25+08:00">2019-06-01</time>
            </span>
          

          
            

            
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="fa fa-calendar-check-o"></i>
                </span>
                
                  <span class="post-meta-item-text">更新于</span>
                
                <time title="修改时间：2019-06-19 10:23:49" itemprop="dateModified" datetime="2019-06-19T10:23:49+08:00">2019-06-19</time>
              </span>
            
          

          

          
            
            
              
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="fa fa-comment-o"></i>
                </span>
            
                <span class="post-meta-item-text">评论数：</span>
                <a href="/2019/06/01/深度学习笔记/Pytorch训练营/D1 pytorch入门/#comments" itemprop="discussionUrl">
                  <span class="post-comments-count disqus-comment-count" data-disqus-identifier="2019/06/01/深度学习笔记/Pytorch训练营/D1 pytorch入门/" itemprop="commentCount"></span>
                </a>
              </span>
            
          

          
          

          

          <br>
          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>笔记见 幕布</p>
<p>pytorch和其他框架的区别</p>
<ul>
<li>pytorch：接口简洁，面向对象设计中最优雅的一个。底层c</li>
<li>tensorflow：接口复杂，且为静态图机制。底层c</li>
<li>Mxnet：小众框架</li>
<li>Keras：高度封装，最容易上手，但不能自定义函数。底层是python，速度慢</li>
<li>Caffe：缺少灵活性。</li>
</ul>
<p>智慧课堂项目</p>
<ul>
<li><p>面向全国学生，识别学生的姿态，举手/睡觉/看书</p>
</li>
<li><p>困难</p>
<ul>
<li>图片背景复杂，衣着、动作、体态都不一样</li>
<li>数据采集不均衡，比如举手的人很少，而看书/听课的人很多</li>
<li>有些动作差异不大，难以量化。比如举手和托腮</li>
</ul>
</li>
<li><p>方案</p>
<ul>
<li><p>骨架提取OpenPose。把背景复杂度降到最低</p>
<p><img src="/.io//pic/7b1a3454-982c-449c-8303-82ecd2394b4d-2148887.jpg" alt="img"></p>
</li>
<li><p>备选方案有目标检测、视频行为检测。很多具体项目使用单一方案很难达到预期效果，必须使用某些算法的组合，比如人体行为识别的项目，使用openpose提取骨架图+图像分类</p>
</li>
</ul>
</li>
</ul>
<h1 id="打卡要求"><a href="#打卡要求" class="headerlink" title="打卡要求"></a>打卡要求</h1><p><strong>打卡要求：</strong>在训练和测试时自动求导的区别？如何调用CUDA？程序中如何使用多进程？</p>
<p><strong>打卡内容：</strong>文字或图片拍照提交，文字要求最少50字，图片要求最少3张</p>
<p><strong>打卡截止时间：</strong>6/3</p>
<h1 id="1、在训练和测试时自动求导的区别？"><a href="#1、在训练和测试时自动求导的区别？" class="headerlink" title="1、在训练和测试时自动求导的区别？"></a>1、在训练和测试时自动求导的区别？</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">from</span> torch.autograd <span class="keyword">import</span> Variable </span><br><span class="line"></span><br><span class="line">x = Variable(torch.randn(<span class="number">5</span>,<span class="number">5</span>))</span><br><span class="line">z = Variable(torch.randn(<span class="number">5</span>,<span class="number">5</span>), requires_grad=<span class="keyword">True</span>)</span><br><span class="line">b = x + z</span><br><span class="line">b.requires_grad</span><br><span class="line"><span class="string">"""</span></span><br><span class="line"><span class="string">True</span></span><br><span class="line"><span class="string">"""</span></span><br></pre></td></tr></table></figure>
<p>训练时，需要开启自动求导，这样backward就可以自动计算所有的导数，更新权重。</p>
<p>而测试时，因为不需要更新权重，所以不用保存梯度，而pytorch默认是保存的，这就会导致测试时消耗无谓的资源。这个时候需要通过显式的设置<code>requires_grad=False</code>，这样测试和验证阶段就不会保存梯度了。</p>
<h2 id="2、如何调用CUDA？"><a href="#2、如何调用CUDA？" class="headerlink" title="2、如何调用CUDA？"></a>2、如何调用CUDA？</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 一种方法是定义时就在CUDA</span></span><br><span class="line">x = torch.cuda.FloatTensor(<span class="number">1</span>)</span><br><span class="line"><span class="string">"""</span></span><br><span class="line"><span class="string">x.get_device() == 0</span></span><br><span class="line"><span class="string">此时会默认使用GPU 0也就是第一张显卡来进行操作</span></span><br><span class="line"><span class="string">"""</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 也可以指定用哪一个显卡</span></span><br><span class="line"><span class="keyword">with</span> torch.cuda.device(<span class="number">1</span>):</span><br><span class="line">  a = torch.cuda.FloatTensor(<span class="number">1</span>)</span><br><span class="line"><span class="string">"""</span></span><br><span class="line"><span class="string">a.get_device() == 1</span></span><br><span class="line"><span class="string">"""</span></span><br><span class="line">  </span><br><span class="line"><span class="comment"># 另一种方法是从CPU复制到GPU，直接通过.cuda()</span></span><br><span class="line">ten1 = torch.FloatTensor(<span class="number">2</span>)</span><br><span class="line"><span class="keyword">if</span> torch.cuda.is_available():</span><br><span class="line">  ten1 = ten1.cuda()</span><br><span class="line"><span class="string">"""</span></span><br><span class="line"><span class="string">6.1101e+24</span></span><br><span class="line"><span class="string">4.5659e-41</span></span><br><span class="line"><span class="string">[torch.cuda.FloatTensor of size 2 (GPU 0)]</span></span><br><span class="line"><span class="string">"""</span></span><br></pre></td></tr></table></figure>
<h1 id="3、程序中如何使用多进程？"><a href="#3、程序中如何使用多进程？" class="headerlink" title="3、程序中如何使用多进程？"></a>3、程序中如何使用多进程？</h1><p>通过<code>torch.multiprocessing</code>使用多进程，扩展了python的<code>multiprocessing</code>，可以通过<code>multiprocessing.Queue</code>移动所有tensor的数据到共享内存中。</p>
<p>这种方式可以异步训练模型，参数可以一直共享，也可以定期同步。</p>
<h1 id="pytorch安装"><a href="#pytorch安装" class="headerlink" title="pytorch安装"></a>pytorch安装</h1><p>官网选择版本</p>
<p><a href="https://pytorch.org/get-started/locally/" target="_blank" rel="noopener">https://pytorch.org/get-started/locally/</a></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pip3 install torch torchvision</span><br></pre></td></tr></table></figure>
<p>目前稳定版是1.1版</p>
<p>安装后，<code>import torch</code>报错</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">&gt;&gt;&gt; import torch</span><br><span class="line">Traceback (most recent call last):</span><br><span class="line">  File &quot;&lt;stdin&gt;&quot;, line 1, in &lt;module&gt;</span><br><span class="line">  File &quot;/Users/david/anaconda3/lib/python3.6/site-packages/torch/__init__.py&quot;, line 79, in &lt;module&gt;</span><br><span class="line">    from torch._C import *</span><br><span class="line">ImportError: dlopen(/Users/david/anaconda3/lib/python3.6/site-packages/torch/_C.cpython-36m-darwin.so, 9): Library not loaded: /usr/local/opt/libomp/lib/libomp.dylib</span><br><span class="line">  Referenced from: /Users/david/anaconda3/lib/python3.6/site-packages/torch/lib/libshm.dylib</span><br><span class="line">  Reason: image not found</span><br></pre></td></tr></table></figure>
<p>解决：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">brew install libomp</span><br></pre></td></tr></table></figure>

          
        
      
    </div>

    

    
    
    

    

    
      
    
    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  

  <article class="post post-type-normal" itemscope="" itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="https://schwimmer.github.io/2019/05/21/深度学习笔记/tensorflow/基础-莫烦教程/5-2 CNN/">

    <span hidden itemprop="author" itemscope="" itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Schwimmer">
      <meta itemprop="description" content="Record and Think!">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope="" itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Schwimmer's Blog">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                
                <a href="/2019/05/21/深度学习笔记/tensorflow/基础-莫烦教程/5-2 CNN/" class="post-title-link" itemprop="url">未命名</a>
              
            
          </h1>
        

        <div class="post-meta">

          
          
          

          
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              

              
                
              

              <time title="创建时间：2019-05-21 23:17:28" itemprop="dateCreated datePublished" datetime="2019-05-21T23:17:28+08:00">2019-05-21</time>
            </span>
          

          
            

            
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="fa fa-calendar-check-o"></i>
                </span>
                
                  <span class="post-meta-item-text">更新于</span>
                
                <time title="修改时间：2019-05-22 09:30:32" itemprop="dateModified" datetime="2019-05-22T09:30:32+08:00">2019-05-22</time>
              </span>
            
          

          

          
            
            
              
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="fa fa-comment-o"></i>
                </span>
            
                <span class="post-meta-item-text">评论数：</span>
                <a href="/2019/05/21/深度学习笔记/tensorflow/基础-莫烦教程/5-2 CNN/#comments" itemprop="discussionUrl">
                  <span class="post-comments-count disqus-comment-count" data-disqus-identifier="2019/05/21/深度学习笔记/tensorflow/基础-莫烦教程/5-2 CNN/" itemprop="commentCount"></span>
                </a>
              </span>
            
          

          
          

          

          <br>
          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p><a href="https://morvanzhou.github.io/tutorials/machine-learning/tensorflow/5-03-A-CNN/" target="_blank" rel="noopener">https://morvanzhou.github.io/tutorials/machine-learning/tensorflow/5-03-A-CNN/</a></p>
<h2 id="流行的-CNN-结构"><a href="#流行的-CNN-结构" class="headerlink" title="流行的 CNN 结构"></a>流行的 CNN 结构</h2><p>比较流行的一种搭建结构是这样, 从下到上的顺序, 首先是输入的图片(image), 经过一层卷积层 (convolution), 然后在用池化(pooling)方式处理卷积的信息, 这里使用的是 max pooling 的方式. 然后在经过一次同样的处理, 把得到的第二次处理的信息传入两层全连接的神经层 (fully connected),这也是一般的两层神经网络层,最后在接上一个分类器(classifier)进行分类预测</p>
<p>我们在代码中实现一个基于MNIST数据集的例子</p>
<h2 id="定义卷积层的-weight-bias"><a href="#定义卷积层的-weight-bias" class="headerlink" title="定义卷积层的 weight bias"></a>定义卷积层的 weight bias</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">import tensorflow as tf</span><br><span class="line">python from tensorflow.examples.tutorials.mnist import input_data</span><br><span class="line"></span><br><span class="line">mnist=input_data.read_data_sets(&apos;MNIST_data&apos;,one_hot=true)</span><br></pre></td></tr></table></figure>
<p>定义<code>Weight</code>变量，输入<code>shape</code>，返回变量的参数。其中我们使用<code>tf.truncted_normal</code>产生随机变量来进行初始化:</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">def weight_variable(shape): </span><br><span class="line">	inital=tf.truncted_normal(shape,stddev=0.1)</span><br><span class="line">	return tf.Variable(initial)</span><br></pre></td></tr></table></figure>
<p>同样的定义<code>biase</code>变量，输入<code>shape</code> ,返回变量的一些参数。其中我们使用<code>tf.constant</code>常量函数来进行初始化:</p>

          
        
      
    </div>

    

    
    
    

    

    
      
    
    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  

  <article class="post post-type-normal" itemscope="" itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="https://schwimmer.github.io/2019/05/19/算法与数据结构/树/B树/">

    <span hidden itemprop="author" itemscope="" itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Schwimmer">
      <meta itemprop="description" content="Record and Think!">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope="" itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Schwimmer's Blog">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                
                <a href="/2019/05/19/算法与数据结构/树/B树/" class="post-title-link" itemprop="url">未命名</a>
              
            
          </h1>
        

        <div class="post-meta">

          
          
          

          
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              

              
                
              

              <time title="创建时间：2019-05-19 10:44:08" itemprop="dateCreated datePublished" datetime="2019-05-19T10:44:08+08:00">2019-05-19</time>
            </span>
          

          
            

            
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="fa fa-calendar-check-o"></i>
                </span>
                
                  <span class="post-meta-item-text">更新于</span>
                
                <time title="修改时间：2019-05-27 09:51:29" itemprop="dateModified" datetime="2019-05-27T09:51:29+08:00">2019-05-27</time>
              </span>
            
          

          

          
            
            
              
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="fa fa-comment-o"></i>
                </span>
            
                <span class="post-meta-item-text">评论数：</span>
                <a href="/2019/05/19/算法与数据结构/树/B树/#comments" itemprop="discussionUrl">
                  <span class="post-comments-count disqus-comment-count" data-disqus-identifier="2019/05/19/算法与数据结构/树/B树/" itemprop="commentCount"></span>
                </a>
              </span>
            
          

          
          

          

          <br>
          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1 id="B-树"><a href="#B-树" class="headerlink" title="B-树"></a><strong>B-树</strong></h1><h1 id="1、为什么需要B-树"><a href="#1、为什么需要B-树" class="headerlink" title="1、为什么需要B-树"></a>1、为什么需要B-树</h1><p>之前讲的都是二叉树结构，其查找的时间复杂度$O(log_2 N)$ 与树的深度有关，那么降低深度就能提高查找效率。</p>
<p>在大规模的数据存储中，树节点存储的元素数量是有限的，这样导致二叉查找树结构由于树的深度过大而造成磁盘I/O读写过于频繁，进而导致查询效率低下。</p>
<blockquote>
<p> 假设树的高度是4，查找的值是10，流程如下：</p>
</blockquote>
<p><strong>二叉查找树的结构：</strong></p>
<p><img src="/.io//pic/auto-orient.jpeg" alt="img"></p>
<p><strong>第1次磁盘IO：</strong></p>
<p><img src="/.io//pic/auto-orient-20190519224309411.jpeg" alt="img"></p>
<p>第2次磁盘IO：</p>
<p><img src="/.io//pic/auto-orient-20190519224321696.jpeg" alt="img"></p>
<p>第3次磁盘IO：</p>
<p><img src="/.io//pic/auto-orient-20190519224339846.jpeg" alt="img"></p>
<p><strong>第4次磁盘IO：</strong></p>
<p><img src="/.io//pic/auto-orient-20190519225013891.jpeg" alt="img"></p>
<p>所以最坏情况下，磁盘的IO次数等于索引树的高度。为了减少IO次数，要把”瘦高”的树变得”矮胖”，这就是B-树的特征之一。</p>
<h1 id="2、概念"><a href="#2、概念" class="headerlink" title="2、概念"></a>2、概念</h1><p><strong>一个m阶的B树具有如下几个特征：</strong></p>
<ol>
<li><p>根结点至少有两个子女。</p>
</li>
<li><p>每个中间节点都包含k-1个元素和k个孩子，其中 m/2 &lt;= k &lt;= m</p>
</li>
<li><p>每一个叶子节点都包含k-1个元素，其中 m/2 &lt;= k &lt;= m</p>
</li>
<li><p>所有的叶子结点都位于同一层。</p>
</li>
<li><p>每个节点中的元素从小到大排列，节点当中k-1个元素正好是k个孩子包含的元素的值域分划。</p>
</li>
</ol>
<blockquote>
<p>以一个3阶B-树为例，看看具体结构</p>
</blockquote>
<p><img src="/.io//pic/auto-orient-20190519230440624.jpeg" alt="img"></p>
<p>重点看(2, 6)节点，该节点有两个元素2，6，又有三个孩子。其中1<2，(3, 5)在(2,="" 6)中间，8="">6，符合规则。</2，(3,></p>
<p><img src="/.io//pic/auto-orient-20190519230652836.jpeg" alt="img"></p>
<h1 id="3、插入和删除节点"><a href="#3、插入和删除节点" class="headerlink" title="3、插入和删除节点"></a>3、插入和删除节点</h1><h2 id="3-1-插入"><a href="#3-1-插入" class="headerlink" title="3.1 插入"></a>3.1 插入</h2><p>B-树插入新节点的过程比较复杂，而且分成很多情况。举一个最典型的例子，假如我们要插入的值是4。</p>
<p>1）自顶向下查找4的节点位置，发现4应当插入到节点元素3，5之间。</p>
<p><img src="/.io//pic/auto-orient-20190520094205274.jpeg" alt="img"></p>
<p>2）节点3，5已经是两元素节点，无法再增加。父亲节点 2， 6 也是两元素节点，也无法再增加。根节点9是单元素节点，可以升级为两元素节点。于是<strong>拆分</strong>节点3，5与节点2，6，让根节点9升级为两元素节点4，9。节点6独立为根节点的第二个孩子。</p>
<p><img src="/.io//pic/auto-orient-20190520094214384.jpeg" alt="img"></p>
<p>可以看出，为了插入一个元素，B-树的很多节点都发生了连锁改变。但正因为如此，B-树能够始终保持平衡。</p>
<h2 id="3-2-删除"><a href="#3-2-删除" class="headerlink" title="3.2 删除"></a>3.2 删除</h2><p>假如删除节点11</p>
<p>1）自顶向下查找元素11的节点位置。</p>
<p><img src="/.io//pic/auto-orient-20190520094932331.jpeg" alt="img"></p>
<p>2）删除11后，节点12只有一个孩子，不符合B树规范。因此找出12,13,15三个节点的中位数13，取代节点12，而节点12自身下移成为第一个孩子。（这个过程称为<strong>左旋</strong>）</p>
<p><img src="/.io//pic/auto-orient-20190520094950535.jpeg" alt="img"></p>
<h1 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h1><p><a href="https://www.jianshu.com/p/8b653423c586" target="_blank" rel="noopener">漫画算法：什么是B树</a></p>
<p><a href="https://blog.csdn.net/qq_35644234/article/details/66969238" target="_blank" rel="noopener">https://blog.csdn.net/qq_35644234/article/details/66969238</a></p>
<p><a href="https://blog.csdn.net/dog250/article/details/81151687" target="_blank" rel="noopener">https://blog.csdn.net/dog250/article/details/81151687</a></p>
<p><a href="https://www.cnblogs.com/zhenbianshu/p/8185345.html?utm_source=debugrun&amp;utm_medium=referral" target="_blank" rel="noopener">https://www.cnblogs.com/zhenbianshu/p/8185345.html?utm_source=debugrun&amp;utm_medium=referral</a></p>

          
        
      
    </div>

    

    
    
    

    

    
      
    
    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  

  <article class="post post-type-normal" itemscope="" itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="https://schwimmer.github.io/2019/05/18/算法与数据结构/树/B+树/">

    <span hidden itemprop="author" itemscope="" itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Schwimmer">
      <meta itemprop="description" content="Record and Think!">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope="" itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Schwimmer's Blog">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                
                <a href="/2019/05/18/算法与数据结构/树/B+树/" class="post-title-link" itemprop="url">未命名</a>
              
            
          </h1>
        

        <div class="post-meta">

          
          
          

          
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              

              
                
              

              <time title="创建时间：2019-05-18 22:59:16" itemprop="dateCreated datePublished" datetime="2019-05-18T22:59:16+08:00">2019-05-18</time>
            </span>
          

          
            

            
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="fa fa-calendar-check-o"></i>
                </span>
                
                  <span class="post-meta-item-text">更新于</span>
                
                <time title="修改时间：2019-05-27 09:53:22" itemprop="dateModified" datetime="2019-05-27T09:53:22+08:00">2019-05-27</time>
              </span>
            
          

          

          
            
            
              
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="fa fa-comment-o"></i>
                </span>
            
                <span class="post-meta-item-text">评论数：</span>
                <a href="/2019/05/18/算法与数据结构/树/B+树/#comments" itemprop="discussionUrl">
                  <span class="post-comments-count disqus-comment-count" data-disqus-identifier="2019/05/18/算法与数据结构/树/B+树/" itemprop="commentCount"></span>
                </a>
              </span>
            
          

          
          

          

          <br>
          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1 id="B-树"><a href="#B-树" class="headerlink" title="B+树"></a><strong>B+树</strong></h1><h1 id="1、概念"><a href="#1、概念" class="headerlink" title="1、概念"></a>1、概念</h1><p><img src="/.io//pic/358025867be14bb99bf8806b98e774d9_th.png" alt="img"></p>
<p>一个m阶的B+树具有如下几个特征：</p>
<ol>
<li>有k个子树的中间节点包含有k个元素（B树中是k-1个元素），<strong>每个元素不保存数据，只用来索引，所有数据都保存在叶子节点</strong>。</li>
</ol>
<p>即[<strong>卫星数据</strong>]。卫星数据指的是索引元素所指向的数据记录，比如数据库中的某一行。在Ｂ-树中，无论中间节点还是叶子节点都带有卫星数据。</p>
<p><img src="/.io//pic/36efa69561dc4043a17d550133e13a6c_th.png" alt="img"></p>
<p>而在B+树中，只有叶子节点带有卫星数据，其余中间节点仅仅是索引，没有任何数据关联。</p>
<p><img src="/.io//pic/d8ae1b14e9bf4b1890146eb803ee9795_th.png" alt="img"></p>
<ol>
<li>所有的叶子结点中包含了全部元素的信息，及指向含这些元素记录的指针，且叶子结点本身<strong>依关键字的大小自小而大顺序链接</strong>。</li>
</ol>
<p><img src="/.io//pic/3bd2b4220a0f4d1887e2943a729c40a1_th.png" alt="img"></p>
<ol>
<li>所有的中间节点元素都同时存在于子节点，在子节点元素中是最大（或最小）元素。</li>
</ol>
<p><img src="/.io//pic/0611ff5a5103461e843ab627f8821419_th.png" alt="img"></p>
<p>能够推导出，根节点的最大元素，也就等同于整个B+树的最大元素。以后无论插入删除多少元素，始终要保持最大元素在根节点中。</p>
<h1 id="2、B-树的特点"><a href="#2、B-树的特点" class="headerlink" title="2、B+树的特点"></a>2、B+树的特点</h1><h2 id="2-1-为什么MySQL的索引用B-树"><a href="#2-1-为什么MySQL的索引用B-树" class="headerlink" title="2.1 为什么MySQL的索引用B+树"></a>2.1 为什么MySQL的索引用B+树</h2><ol>
<li><p>B-树每个节点都有data，如果data很大会增大节点大小，可能会增加磁盘IO次数。B+树的所有data都在叶子节点，磁盘IO次数就少。</p>
</li>
<li><p>B+树所有的Data域在叶子节点，一般来说都会进行一个优化，就是将所有的叶子节点用指针串起来。这样遍历叶子节点就能获得全部数据，这样就能进行区间访问了。</p>
</li>
</ol>
<p>(数据库索引采用B+树的主要原因是 <strong>B树在提高了磁盘IO性能的同时并没有解决元素遍历的效率低下的问题</strong>。正是为了解决这个问题，B+树应运而生。B+树只要遍历叶子节点就可以实现整棵树的遍历。而且在数据库中基于范围的查询是非常频繁的，而B树不支持这样的操作（或者说效率太低）)</p>
<blockquote>
<p>比如要查询范围3-11的元素</p>
</blockquote>
<p>B-树的范围查找过程</p>
<p>1）自顶向下，查找到范围的下限（3）：</p>
<p><img src="/.io//pic/bb40b700247c425f9b9d358c726d5e65_th.png" alt="img"></p>
<p>2）中序遍历到元素6：</p>
<p><img src="/.io//pic/244ea6eaee4a4e1d87a33967ff6ef5ff_th.png" alt="img"></p>
<p>3）中序遍历到元素8：</p>
<p><img src="/.io//pic/61f472a56f7840e78de23901cb5e85b2_th.png" alt="img"></p>
<p>4）中序遍历到元素9：</p>
<p><img src="/.io//pic/a7881e1683a8486fa3956d585a97bd6d_th.png" alt="img"></p>
<p>5）中序遍历到元素11，遍历结束：</p>
<p><img src="/.io//pic/c3fc3c097cf94d439c5d6962d2fb8d4e_th.png" alt="img"></p>
<p>B+树的范围查找过程</p>
<p>1）自顶向下，查找到范围的下限（3）：</p>
<p><img src="/.io//pic/c0ef4d22cedf43cc8d21732d27f9be3e_th.png" alt="img"></p>
<p>2）通过链表指针，遍历到元素6, 8：</p>
<p><img src="/.io//pic/005777d81ab247c281f8a1b4bc6b3461_th.png" alt="img"></p>
<p>3）通过链表指针，遍历到元素9, 11，遍历结束：</p>
<p><img src="/.io//pic/e972e47b2c554f789e02e90b26a8b543_th.png" alt="img"></p>
<h2 id="2-2-为什么MongoDB的索引用B-树"><a href="#2-2-为什么MongoDB的索引用B-树" class="headerlink" title="2.2 为什么MongoDB的索引用B-树"></a>2.2 为什么MongoDB的索引用B-树</h2><p>它并不是传统的关系性数据库，而是以Json格式作为存储的nosql，目的就是高性能，高可用，易扩展。而由于</p>
<p><strong>B+树内节点不存储数据，所有 data 存储在叶节点导致查询时间复杂度固定为 log n。而B-树查询时间复杂度不固定，与 key 在树中的位置有关，最好为O(1)。</strong></p>
<p>尽可能少的磁盘 IO 是提高性能的有效手段。MongoDB 是聚合型数据库，而 B-树恰好 key 和 data 域聚合在一起。找到key就可以直接访问data。</p>
<blockquote>
<p>HBase的索引——LSM树</p>
</blockquote>
<p><a href="https://blog.csdn.net/baigoohao/article/details/50816144" target="_blank" rel="noopener">LSM树 VS B+树</a></p>
<h2 id="2-3-B-树的优点"><a href="#2-3-B-树的优点" class="headerlink" title="2.3 B+树的优点"></a>2.3 B+树的优点</h2><ol>
<li><p><strong>单一节点存储更多的元素</strong>（这样该节点下分支变多了，树变矮胖了），使得查询的IO次数更少。</p>
</li>
<li><p><strong>所有查询都要查找到叶子节点</strong>，查询性能稳定。</p>
</li>
<li><p>所有<strong>叶子节点</strong>形成<strong>有序链表</strong>，便于<strong>范围查询</strong>。</p>
</li>
</ol>
<h1 id="3、从B-树看MySQL索引设计"><a href="#3、从B-树看MySQL索引设计" class="headerlink" title="3、从B+树看MySQL索引设计"></a>3、从B+树看MySQL索引设计</h1><blockquote>
<p>比如想要找出位于北京的所有90后用户列表，怎么设计索引。</p>
</blockquote>
<p>先看一下sql会是怎么写的（比如地域，北京对应的是1） </p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">select</span> * <span class="keyword">from</span> xxx <span class="keyword">where</span> localId=<span class="number">1</span> <span class="keyword">and</span> age&lt;=<span class="number">28</span></span><br></pre></td></tr></table></figure>
<p>如果给地域加个索引，再给年龄加个索引。如果单独对两个字段做索引，那么针对这个sql语句，其实只能用到地域这一个索引，年龄是不会走索引的。看了上面B+树的原理，应该很好理解这里的原因。</p>
<p>正确的索引设计应该是做联合索引： <strong>KEY(localId,age)</strong> 。这样如果只需要对地域做查询，可以用到这个索引，两个同时使用也可以用这个索引。<strong>但是如果只想对年龄做索引，这个索引是没有办法使用的</strong>（因为年龄在不同地域不是连续的）。</p>
<p>联合索引B+树是怎么存储的呢，其实也会做排序，<strong>先根据localId进行排序，再根据age进行排序存储</strong>。所以我们想直接用age进行索引的话就没法用这个联合索引了。但是想要找到北京的90后，就很容易可以找到。为什么呢，首先可以定位到localId为1的索引部分，接下来找到1岁开始，一直到28岁都拿出来。<strong>因为是个链表结构，所以这块的内容可以顺序索引出来而不需要再去重新走索引了</strong>。</p>
<p>如果想找出北京和天津的90后呢？显然有点麻烦，根据B+树的结构，找到北京，然后再去列出年龄范围数据；再去找到天津，再去列出年龄范围数据。所以还是需要找两遍，而没有办法一次就找出来两组数据不是连续的。</p>
<p>举下例子，比如数据叶子节点链表是这样的：</p>
<p><strong>（北京，1岁）、（北京，2岁）、（北京，3岁）、（上海，1岁），（上海，3岁）、（天津，2岁），（天津，3岁）</strong>。</p>
<p>索引找到北京，找对应年龄范围，而没有办法再通过链表找天津的年龄范围数据了。当地域城市的过滤条件多的话，其实效率就并不高了。</p>
<h1 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h1><p><a href="https://blog.csdn.net/qq_35571554/article/details/82759668" target="_blank" rel="noopener">漫画算法：什么是B+树</a></p>
<p><a href="https://blog.csdn.net/wl044090432/article/details/54409240" target="_blank" rel="noopener">从 MongoDB 及 Mysql 谈B-/B+树</a></p>
<p><a href="https://blog.csdn.net/qq_21993785/article/details/80580679" target="_blank" rel="noopener">B+Tree在数据库索引上拥有独特优势的原因</a></p>
<p><a href="[http://mysql.taobao.org/monthly/2018/09/01/#](http://mysql.taobao.org/monthly/2018/09/01/#">MySQL · 引擎特性 · B+树并发控制机制的前世今生</a>)</p>
<p><a href="[http://ju.outofmemory.cn/entry/350144](http://ju.outofmemory.cn/entry/350144">透过B树、B+树来聊聊Mysql索引</a>)</p>
<p><a href="https://read.douban.com/ebook/15233230/" target="_blank" rel="noopener">《MySQL技术内幕：InnoDB存储引擎》</a></p>
<p><a href="https://www.jianshu.com/p/2313a9ce8b2b" target="_blank" rel="noopener">浅析MySQL InnoDB中的B+树索引</a></p>

          
        
      
    </div>

    

    
    
    

    

    
      
    
    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  

  <article class="post post-type-normal" itemscope="" itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="https://schwimmer.github.io/2019/05/18/算法与数据结构/树/红黑树/">

    <span hidden itemprop="author" itemscope="" itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Schwimmer">
      <meta itemprop="description" content="Record and Think!">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope="" itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Schwimmer's Blog">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                
                <a href="/2019/05/18/算法与数据结构/树/红黑树/" class="post-title-link" itemprop="url">未命名</a>
              
            
          </h1>
        

        <div class="post-meta">

          
          
          

          
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              

              
                
              

              <time title="创建时间：2019-05-18 16:45:24" itemprop="dateCreated datePublished" datetime="2019-05-18T16:45:24+08:00">2019-05-18</time>
            </span>
          

          
            

            
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="fa fa-calendar-check-o"></i>
                </span>
                
                  <span class="post-meta-item-text">更新于</span>
                
                <time title="修改时间：2019-05-27 09:48:40" itemprop="dateModified" datetime="2019-05-27T09:48:40+08:00">2019-05-27</time>
              </span>
            
          

          

          
            
            
              
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="fa fa-comment-o"></i>
                </span>
            
                <span class="post-meta-item-text">评论数：</span>
                <a href="/2019/05/18/算法与数据结构/树/红黑树/#comments" itemprop="discussionUrl">
                  <span class="post-comments-count disqus-comment-count" data-disqus-identifier="2019/05/18/算法与数据结构/树/红黑树/" itemprop="commentCount"></span>
                </a>
              </span>
            
          

          
          

          

          <br>
          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1 id="红黑树"><a href="#红黑树" class="headerlink" title="红黑树"></a><strong>红黑树</strong></h1><h1 id="1、为什么需要红黑树"><a href="#1、为什么需要红黑树" class="headerlink" title="1、为什么需要红黑树"></a>1、为什么需要红黑树</h1><h2 id="1-1-BST的缺点"><a href="#1-1-BST的缺点" class="headerlink" title="1.1 BST的缺点"></a>1.1 BST的缺点</h2><p>BST有个比较大的缺陷，会影响查询性能。</p>
<p><img src="/.io//pic/143252963_6_201809040759064.jpeg" alt="äºåéææä»ä¹æ¯çº¢é»æ ï¼å¨ç¨å¾è§£ï¼"></p>
<p>依次插入5个节点，<code>{7,6,5,4,3}</code></p>
<p><img src="/.io//pic/143252963_7_2018090407590667.jpeg" alt="äºåéææä»ä¹æ¯çº¢é»æ ï¼å¨ç¨å¾è§£ï¼"></p>
<blockquote>
<p>缺陷：多次插入新节点导致的不平衡。</p>
</blockquote>
<h2 id="1-2-AVL的缺点"><a href="#1-2-AVL的缺点" class="headerlink" title="1.2 AVL的缺点"></a>1.2 AVL的缺点</h2><p>是一种严格按照定义来实现的平衡二叉查找树，所以它查找的效率非常稳定，为O(log n),由于其严格按照左右子树高度差不大于1的规则，插入和删除操作中需要大量的旋转操作来保持AVL树的平衡，因此ALV树<strong>适用于大量查询，少量插入和删除的场景中</strong>。</p>
<p>假设有这样一种场景：大量查询，大量插入和删除，现在使用AVL树就不太合适了，因为ALV树大量的插入和删除会非常耗时间。红黑树只要求部分地达到平衡要求，降低了对旋转的要求，从而提高了性能。</p>
<h1 id="2、概念"><a href="#2、概念" class="headerlink" title="2、概念"></a>2、概念</h1><p><strong>红黑树是一种近似平衡的二叉查找树，它能够确保任何一个节点的左右子树的高度差较低的两倍</strong>。具体来说，红黑树是满足如下条件的二叉查找树（binary search tree）：</p>
<ol>
<li>每个节点要么是红色，要么是黑色。</li>
<li>根节点必须是黑色</li>
<li>每个叶子节点都是黑色的空节点(null)</li>
<li>红色节点不能连续（也即是，红色节点的孩子和父亲都不能是红色）。</li>
<li>对于每个节点，从该点至叶子节点的任何路径，都含有相同个数的黑色节点。</li>
</ol>
<p>下图就是一个典型的红黑树</p>
<p><img src="/.io//pic/143252963_8_20180904075906145.jpeg" alt="äºåéææä»ä¹æ¯çº¢é»æ ï¼å¨ç¨å¾è§£ï¼"></p>
<h1 id="3、红黑树的调整"><a href="#3、红黑树的调整" class="headerlink" title="3、红黑树的调整"></a>3、红黑树的调整</h1><p>在树的结构发生改变时（插入或者删除操作），往往会破坏上述条件4或条件5，在什么情况下会破坏平衡？</p>
<ul>
<li>插入值为14的节点，由于父节点15是黑节点，没有破坏结构</li>
</ul>
<p><img src="/.io//pic/143252963_9_20180904075906208.jpeg" alt="äºåéææä»ä¹æ¯çº¢é»æ ï¼å¨ç¨å¾è§£ï¼"></p>
<ul>
<li>插入值为21的节点</li>
</ul>
<p><img src="/.io//pic/143252963_10_20180904075906317.jpeg" alt="äºåéææä»ä¹æ¯çº¢é»æ ï¼å¨ç¨å¾è§£ï¼"></p>
<p>违背了规则4，需要通过调整使得查找树重新满足红黑树的条件。</p>
<h2 id="3-1-变色"><a href="#3-1-变色" class="headerlink" title="3.1 变色"></a>3.1 变色</h2><p>为了符合红黑树的规则，可以改变节点颜色</p>
<ul>
<li>22红变黑，但不符合规则5</li>
</ul>
<p><img src="/.io//pic/143252963_11_20180904075906426.jpeg" alt="äºåéææä»ä¹æ¯çº¢é»æ ï¼å¨ç¨å¾è§£ï¼"></p>
<ul>
<li>25黑变红，但又不符合规则4</li>
</ul>
<p><img src="/.io//pic/143252963_12_20180904075906583.jpeg" alt="äºåéææä»ä¹æ¯çº¢é»æ ï¼å¨ç¨å¾è§£ï¼"></p>
<ul>
<li>27红变黑</li>
</ul>
<p><img src="/.io//pic/143252963_13_20180904075906661.jpeg" alt="äºåéææä»ä¹æ¯çº¢é»æ ï¼å¨ç¨å¾è§£ï¼"></p>
<h2 id="3-2-旋转"><a href="#3-2-旋转" class="headerlink" title="3.2 旋转"></a>3.2 旋转</h2><h3 id="3-2-1-左旋（Rotate-Left）"><a href="#3-2-1-左旋（Rotate-Left）" class="headerlink" title="3.2.1 左旋（Rotate Left）"></a>3.2.1 左旋（Rotate Left）</h3><p>逆时针旋转两个节点，使父节点被自己的右孩子取代，而自己成为自己的左孩子。</p>
<p><img src="/.io//pic/143252963_14_20180904075906754.jpeg" alt="äºåéææä»ä¹æ¯çº¢é»æ ï¼å¨ç¨å¾è§£ï¼"></p>
<h3 id="3-2-2-右旋（RotateRight）"><a href="#3-2-2-右旋（RotateRight）" class="headerlink" title="3.2.2 右旋（RotateRight）"></a>3.2.2 右旋（RotateRight）</h3><p>顺时针旋转两个节点。</p>
<p><img src="/.io//pic/143252963_15_20180904075906926.jpeg" alt="äºåéææä»ä¹æ¯çº¢é»æ ï¼å¨ç¨å¾è§£ï¼"></p>
<h1 id="4、TreeMap的实现"><a href="#4、TreeMap的实现" class="headerlink" title="4、TreeMap的实现"></a>4、TreeMap的实现</h1><p><a href="http://www.ibm.com/developerworks/cn/java/j-lo-tree/index.html?ca=drs-" target="_blank" rel="noopener">IBM DevelopWorks </a>上一篇文章讲解非常好，供参考。</p>
<p>TreeMap 和 TreeSet 是 Java Collection Framework 的两个重要成员，其中 TreeMap 是 Map 接口的常用实现类，而 TreeSet 是 Set 接口的常用实现类。虽然 HashMap 和 HashSet 实现的接口规范不同，但 <strong>TreeSet 底层是通过 TreeMap 来实现的，因此二者的实现方式完全一样。而 TreeMap 的实现就是红黑树算法</strong>。</p>
<p>对于 TreeMap 而言，由于它底层采用一棵“红黑树”来保存集合中的 Entry，这意味这 <strong>TreeMap 添加元素、取出元素的性能都比 HashMap 低</strong>：当 TreeMap 添加元素时，需要通过循环找到新增 Entry 的插入位置，因此比较耗性能；当从 TreeMap 中取出元素时，需要通过循环才能找到合适的 Entry，也比较耗性能。</p>
<p>但 TreeMap、TreeSet 比 HashMap、HashSet 的优势在于：TreeMap 中的所有 Entry 总是按 key <strong>根据指定排序规则保持有序状态</strong>，TreeSet 中所有元素总是根据指定排序规则保持有序状态。</p>
<h1 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h1><p><a href="https://blog.csdn.net/p5deyt322jacs/article/details/78433942" target="_blank" rel="noopener">漫画算法：什么是红黑树</a></p>
<p><a href="https://blog.csdn.net/u014688145/article/details/68489582" target="_blank" rel="noopener">算法原理系列：红黑树</a>：分析红黑树的诞生过程</p>

          
        
      
    </div>

    

    
    
    

    

    
      
    
    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  

  <article class="post post-type-normal" itemscope="" itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="https://schwimmer.github.io/2019/05/12/编程语言学习/SCALA/scala笔记/">

    <span hidden itemprop="author" itemscope="" itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Schwimmer">
      <meta itemprop="description" content="Record and Think!">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope="" itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Schwimmer's Blog">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                
                <a href="/2019/05/12/编程语言学习/SCALA/scala笔记/" class="post-title-link" itemprop="url">scala笔记</a>
              
            
          </h1>
        

        <div class="post-meta">

          
          
          

          
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              

              
                
              

              <time title="创建时间：2019-05-12 11:49:53" itemprop="dateCreated datePublished" datetime="2019-05-12T11:49:53+08:00">2019-05-12</time>
            </span>
          

          
            

            
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="fa fa-calendar-check-o"></i>
                </span>
                
                  <span class="post-meta-item-text">更新于</span>
                
                <time title="修改时间：2019-07-04 10:14:58" itemprop="dateModified" datetime="2019-07-04T10:14:58+08:00">2019-07-04</time>
              </span>
            
          

          
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope="" itemtype="http://schema.org/Thing"><a href="/categories/SCALA/" itemprop="url" rel="index"><span itemprop="name">SCALA</span></a></span>

                
                
              
            </span>
          

          
            
            
              
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="fa fa-comment-o"></i>
                </span>
            
                <span class="post-meta-item-text">评论数：</span>
                <a href="/2019/05/12/编程语言学习/SCALA/scala笔记/#comments" itemprop="discussionUrl">
                  <span class="post-comments-count disqus-comment-count" data-disqus-identifier="2019/05/12/编程语言学习/SCALA/scala笔记/" itemprop="commentCount"></span>
                </a>
              </span>
            
          

          
          

          

          <br>
          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1 id="option"><a href="#option" class="headerlink" title="option"></a>option</h1><p><code>Option[A]</code> 是一个类型为 <code>A</code> 的可选值的容器： 如果值存在， <code>Option[A]</code> 就是一个 <code>Some[A]</code> ，如果不存在， <code>Option[A]</code> 就是对象 <code>None</code> 。</p>
<p>Option类型的值通常作为Scala集合类型（List,Map等）操作的返回类型。比如Map的get方法：</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">scala&gt; <span class="keyword">val</span> capitals = <span class="type">Map</span>(<span class="string">"France"</span>-&gt;<span class="string">"Paris"</span>, <span class="string">"Japan"</span>-&gt;<span class="string">"Tokyo"</span>, <span class="string">"China"</span>-&gt;<span class="string">"Beijing"</span>)</span><br><span class="line">capitals: scala.collection.immutable.<span class="type">Map</span>[<span class="type">String</span>,<span class="type">String</span>] = <span class="type">Map</span>(<span class="type">France</span> -&gt; <span class="type">Paris</span>, <span class="type">Japan</span> -&gt; <span class="type">Tokyo</span>, <span class="type">China</span> -&gt; <span class="type">Beijing</span>)</span><br><span class="line"></span><br><span class="line">scala&gt; capitals get <span class="string">"France"</span></span><br><span class="line">res0: <span class="type">Option</span>[<span class="type">String</span>] = <span class="type">Some</span>(<span class="type">Paris</span>)</span><br><span class="line"></span><br><span class="line">scala&gt; capitals get <span class="string">"North Pole"</span></span><br><span class="line">res1: <span class="type">Option</span>[<span class="type">String</span>] = <span class="type">None</span></span><br></pre></td></tr></table></figure>
<p>Option有两个子类别，Some和None。当程序回传Some的时候，代表这个函式成功地给了你一个String，而你可以透过get()函数拿到那个String，如果程序返回的是None，则代表没有字符串可以给你。</p>
<p>在返回None，也就是没有String给你的时候，如果你还硬要调用get()来取得 String 的话，Scala一样是会抛出一个<strong>NoSuchElementException异常</strong>给你的。</p>
<p>我们也可以选用另外一个方法，<strong>getOrElse</strong>。这个方法在这个Option是Some的实例时返回对应的值，而在是None的实例时返回传入的参数。换句话说，传入getOrElse的参数实际上是默认返回值。</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">scala&gt; capitals get <span class="string">"North Pole"</span> get</span><br><span class="line">warning: there was one feature warning; re-run <span class="keyword">with</span> -feature <span class="keyword">for</span> details</span><br><span class="line">java.util.<span class="type">NoSuchElementException</span>: <span class="type">None</span>.get</span><br><span class="line">  at scala.<span class="type">None</span>$.get(<span class="type">Option</span>.scala:<span class="number">347</span>)</span><br><span class="line">  at scala.<span class="type">None</span>$.get(<span class="type">Option</span>.scala:<span class="number">345</span>)</span><br><span class="line">  ... <span class="number">33</span> elided</span><br><span class="line"></span><br><span class="line">scala&gt; capitals get <span class="string">"France"</span> get</span><br><span class="line">warning: there was one feature warning; re-run <span class="keyword">with</span> -feature <span class="keyword">for</span> details</span><br><span class="line">res3: <span class="type">String</span> = <span class="type">Paris</span></span><br><span class="line"></span><br><span class="line">scala&gt; (capitals get <span class="string">"North Pole"</span>) getOrElse <span class="string">"Oops"</span></span><br><span class="line">res7: <span class="type">String</span> = <span class="type">Oops</span></span><br><span class="line"></span><br><span class="line">scala&gt; capitals get <span class="string">"France"</span> getOrElse <span class="string">"Oops"</span></span><br><span class="line">res8: <span class="type">String</span> = <span class="type">Paris</span></span><br></pre></td></tr></table></figure>
<blockquote>
<p>提示：Scala程序使用Option非常频繁，在Java中使用null来表示空值，代码中很多地方都要添加null关键字检测，不然很容易出现NullPointException。因此Java程序需要关心那些变量可能是null,而这些变量出现null的可能性很低，但一但出现，很难查出为什么出现NullPointerException。Scala的Option类型可以避免这种情况，因此Scala应用推荐使用Option类型来代表一些可选值。使用Option类型，读者一眼就可以看出这种类型的值可能为None。文／JasonDing（简书作者）<br>原文链接：<a href="http://www.jianshu.com/p/95896d06a94d" target="_blank" rel="noopener">http://www.jianshu.com/p/95896d06a94d</a></p>
</blockquote>
<h2 id="详解Option-T"><a href="#详解Option-T" class="headerlink" title="详解Option[T]"></a>详解Option[T]</h2><p>在Scala里Option[T]实际上是一个容器，就像数组或是List一样，你可以把他看成是一个可能有零到一个元素的List。<br>当你的Option里面有东西的时候，这个List的长度是1（也就是 Some），而当你的Option里没有东西的时候，它的长度是0（也就是 None）。</p>
<h1 id="case-class"><a href="#case-class" class="headerlink" title="case class"></a>case class</h1><p>例如：</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">abstract</span> <span class="class"><span class="keyword">class</span> <span class="title">Expr</span></span></span><br><span class="line"><span class="class"><span class="title">case</span> <span class="title">class</span> <span class="title">Var</span>(<span class="params">name:<span class="type">String</span></span>) <span class="keyword">extends</span> <span class="title">Expr</span></span></span><br><span class="line"><span class="class"><span class="title">case</span> <span class="title">class</span> <span class="title">Number</span>(<span class="params">num:<span class="type">Double</span></span>) <span class="keyword">extends</span> <span class="title">Expr</span></span></span><br><span class="line"><span class="class"><span class="title">case</span> <span class="title">class</span> <span class="title">UnOp</span>(<span class="params">operator:<span class="type">String</span>, arg:<span class="type">Expr</span></span>) <span class="keyword">extends</span> <span class="title">Expr</span></span></span><br><span class="line"><span class="class"><span class="title">case</span> <span class="title">class</span> <span class="title">BinOp</span>(<span class="params">operator:<span class="type">String</span>,left:<span class="type">Expr</span>,right:<span class="type">Expr</span></span>) <span class="keyword">extends</span> <span class="title">Expr</span></span></span><br></pre></td></tr></table></figure>
<p>首先，编译器为case class生成一个同名的对象构造器（Factory Method），也就是你可以使用 Var(“x”) 来创建一个类的实例，而无需使用new Var(“x”).</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">scala&gt; val x = Var(&quot;x&quot;)</span><br><span class="line">x: Var = Var(x)</span><br></pre></td></tr></table></figure>
<p>其次，Scala编译器为case class的构造函数的参数创建以参数名为名称的属性，比如Val的类的参数name:String 可以直接通过 .name访问，比如：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">scala&gt; x.name</span><br><span class="line">res1: String = x</span><br></pre></td></tr></table></figure>
<p>第三，编译器为case class 构造了更自然的toString，hashCode和equals实现，它们会递归打印，比较case class的参数属性。比如：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">scala&gt; val op=BinOp(&quot;+&quot;,Number(1),x)</span><br><span class="line">op: BinOp = BinOp(+,Number(1.0),Var(x))</span><br><span class="line"></span><br><span class="line">scala&gt; println(op)</span><br><span class="line">BinOp(+,Number(1.0),Var(x))</span><br><span class="line"></span><br><span class="line">scala&gt; op.right == Var(&quot;x&quot;)</span><br><span class="line">res3: Boolean = true</span><br></pre></td></tr></table></figure>
<h1 id="数据类型"><a href="#数据类型" class="headerlink" title="数据类型"></a>数据类型</h1><p>double转int</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">val a=1.0</span><br><span class="line">a.toInt</span><br></pre></td></tr></table></figure>
<p>类型强转，用<strong>asInstanceOf</strong></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">//java中</span><br><span class="line">StructObjectInspector inspector = (StructObjectInspector)reader.getObjectInspector();</span><br><span class="line"></span><br><span class="line">//scala中</span><br><span class="line">val inspector = reader.getObjectInspector().asInstanceOf[StructObjectInspector]</span><br></pre></td></tr></table></figure>
<h1 id="文件读写"><a href="#文件读写" class="headerlink" title="文件读写"></a>文件读写</h1><p>读文件</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">import scala.io.Source</span><br><span class="line"></span><br><span class="line">object Test &#123;</span><br><span class="line">   def main(args: Array[String]) &#123;</span><br><span class="line">      println(&quot;Following is the content read:&quot; )</span><br><span class="line"></span><br><span class="line">      Source.fromFile(&quot;test.txt&quot; ).foreach&#123; </span><br><span class="line">         print </span><br><span class="line">      &#125;</span><br><span class="line">   &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h2 id="写文件"><a href="#写文件" class="headerlink" title="写文件"></a>写文件</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">val writer = new PrintWriter(new File(&quot;ctrout.dat&quot;))</span><br><span class="line">writer.println(p.toString() + &quot;,&quot; + log.get.predictionCtr.toString() + &quot;,&quot; + log.get.isClick)</span><br><span class="line">writer.close()</span><br></pre></td></tr></table></figure>
<h1 id="初始化空对象"><a href="#初始化空对象" class="headerlink" title="初始化空对象"></a>初始化空对象</h1><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">var qc_hk : QueueCollection = null</span><br><span class="line">  try &#123;</span><br><span class="line">    qc_hk = new QueueCollection(config.getProperty(&quot;data.dir&quot;, &quot;/var/lib/queues_hk&quot;))</span><br><span class="line">  &#125; catch &#123;</span><br><span class="line">    case t: Throwable =&gt; t.printStackTrace()</span><br><span class="line">  &#125;</span><br></pre></td></tr></table></figure>
<h1 id="集合"><a href="#集合" class="headerlink" title="集合"></a>集合</h1><h2 id="数组"><a href="#数组" class="headerlink" title="数组"></a>数组</h2><p>定义数组</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">val greetStrings = new Array[String](3)   </span><br><span class="line"></span><br><span class="line">greetStrings(0) = &quot;Hello&quot; </span><br><span class="line"></span><br><span class="line">greetStrings(1) = &quot;, &quot; </span><br><span class="line"></span><br><span class="line">greetStrings(2) = &quot;world!\n&quot; </span><br><span class="line"></span><br><span class="line">for (i &lt;- 0 to 2)  print(greetStrings(i))</span><br></pre></td></tr></table></figure>
<p>取数组下标<br>greetStrings(0) = ‘Hello’</p>
<p>定义2<br>val numNames = Array(‘1’, ‘2’ , ‘3’)<br>实际是创造并返回新数组的apply工厂方法。apply有个不定个数的参数。完整写法是<br>val numNames = Array.apply (‘1’, ‘2’ , ‘3’)</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">//新建一个固定长度的数组</span><br><span class="line">val data = Array.ofDim[T](max)</span><br></pre></td></tr></table></figure>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">//取数组中不为空的并转为list</span><br><span class="line">def list(): List[T] = &#123;</span><br><span class="line">    data.filter(x =&gt; x != null).toList</span><br><span class="line">  &#125;</span><br></pre></td></tr></table></figure>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">// 重复多次计算的结果生成一个数组</span><br><span class="line">Array.fill(3)&#123; math.random &#125;</span><br><span class="line">res3: Array[Double] = Array(0.365461167592537, 1.550395944913685E-4, 0.7907242137333306)</span><br><span class="line"></span><br><span class="line">val queues = Array.fill(4)(new java.util.LinkedList[QueueInfo])</span><br></pre></td></tr></table></figure>
<h2 id="列表"><a href="#列表" class="headerlink" title="列表"></a>列表</h2><p>List创建了不能改变。<br>val list1 = List(1,2,3)</p>
<p>列表的叠加</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">  val oneTwo = List(1,2)</span><br><span class="line">  val threeFour = List(3,4)</span><br><span class="line">  val oneFour = oneTwo:::threeFour</span><br></pre></td></tr></table></figure>
<p>将新元素组合到现有列表的前端</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">  val oneTwo = List(1,2)</span><br><span class="line">  val zeroTwo = 1 :: oneTwo</span><br></pre></td></tr></table></figure>
<p>在   1 :: oneTwo中，::是右操作数oneTwo的方法，1是方法的传入参数，因此也可写成<br>oneTwo.::(1)</p>
<h2 id="list的一些方法"><a href="#list的一些方法" class="headerlink" title="list的一些方法"></a>list的一些方法</h2><p>计算长度为4的元素个数<br>list.count(s =&gt; s.length == 4)</p>
<p>判断元素是否在list<br>list.exists(s =&gt; s == ‘until’)</p>
<p>返回长度为4的元素组成的新列表<br>list.filter(s =&gt; s.length == 4)</p>
<p>判断是否列表所有元素都以1结尾<br>list.forall(s =&gt; s.endsWith(‘1’))</p>
<p>打印数组<br>list.foreach(print)</p>
<p>列表每个元素加上字符的新列表<br>list.map(s =&gt; s + ‘y’)</p>
<p>用列表元素组成字符串<br>list.mkStirng(“, “)</p>
<p>按照第一个元素的小写字母排序<br>list.sort((s,t) =&gt; s.charAt(0).toLowerCase &lt; t.charAr(0).toLowerCase)</p>
<h3 id="list整体转数据类型"><a href="#list整体转数据类型" class="headerlink" title="list整体转数据类型"></a>list整体转数据类型</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">name2NumMap: Map[String, String]</span><br><span class="line"></span><br><span class="line">val sum = name2NumMap.map(_._2.toDouble).sum</span><br></pre></td></tr></table></figure>
<h2 id="元组"><a href="#元组" class="headerlink" title="元组"></a>元组</h2><p>元组不可变，但可以包含不同类型的元素</p>
<p>定义<br>val pair = (99, ‘tuple’)<br>用下划线访问元素<br>pair._1<br>pair._2</p>
<blockquote>
<p> 列表可以用list(0)，因为列表的apply方法始终返回同样类型。<br>另外，元组_N的索引从1开始。因为对拥有静态类型元素的其他语言，入Haskell和ML，从1开始是传统设定。</p>
</blockquote>
<h2 id="集（set）和映射（map）"><a href="#集（set）和映射（map）" class="headerlink" title="集（set）和映射（map）"></a>集（set）和映射（map）</h2><p>scala的API包含set的基本特质（trait），特质相当于接口。Scala还提供了两个子特质，可变set和不可变set。</p>
<p>比如图中的HashSet，各有一个可变或不可变的类型。</p>
<p><strong>定义</strong></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">var jetset = Set(&quot;1&quot;, &quot;2&quot;)     //不可变set</span><br><span class="line">jetset += &quot;3&quot;     //成为可变set</span><br></pre></td></tr></table></figure>
<p>不可变set用+=，会产生一个新的可变set，+=在这里的完整写法是<br>jetset = jetset + “3”</p>
<blockquote>
<p> 这里jetset默认是不可变set，因此+=操作会需要对jetset重新赋值，要用var</p>
</blockquote>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">import scala.collection.mutable.Set</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">val movieSet = Set(&quot;Hi&quot;, &quot;df&quot;)</span><br><span class="line">movieSet += &quot;Shet&quot;</span><br></pre></td></tr></table></figure>
<blockquote>
<p> 这里显式指定了是可变set，所以新增元素就不需要重新赋值，用val就可以</p>
</blockquote>
<p>定义</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">import scala.collection.mutable.Map</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">val treaMap = Map[Int, String]()</span><br><span class="line">treaMap += (1-&gt; &quot;Go&quot;)</span><br><span class="line">println(treaMap(1))  //这里的1是key</span><br></pre></td></tr></table></figure>
<h3 id="map的遍历"><a href="#map的遍历" class="headerlink" title="map的遍历"></a>map的遍历</h3><p>注意这个case</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">var</span> a:<span class="type">Map</span>[<span class="type">String</span>,<span class="type">Int</span>]=<span class="type">Map</span>(<span class="string">"k1"</span>-&gt;<span class="number">1</span>,<span class="string">"k2"</span>-&gt;<span class="number">2</span>)</span><br><span class="line">a.foreach&#123;<span class="keyword">case</span> (e,i) =&gt; println(e,i)&#125;</span><br></pre></td></tr></table></figure>
<h2 id="List转Map"><a href="#List转Map" class="headerlink" title="List转Map"></a>List转Map</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">list的toMap方法，但list需要是类似(String, String)的结构，这样会自动转为map</span><br></pre></td></tr></table></figure>
<h2 id="元组创建map"><a href="#元组创建map" class="headerlink" title="元组创建map"></a>元组创建map</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">val allDistinctFeatures: Map[Int, mutable.HashSet[Double]] =</span><br><span class="line">          Map((startCol until endCol).map(col =&gt; (col, mutable.HashSet.empty[Double])): _*)</span><br></pre></td></tr></table></figure>
<h2 id="map插入元素"><a href="#map插入元素" class="headerlink" title="map插入元素"></a>map插入元素</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">allDistinctFeatures(col) += feature</span><br></pre></td></tr></table></figure>
<h2 id="创建一个map的list"><a href="#创建一个map的list" class="headerlink" title="创建一个map的list"></a>创建一个map的list</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">var testMapList = ListBuffer[Map[String, String]]()</span><br><span class="line">testMapList += Map(&quot;gpstime&quot;-&gt;&quot;2018-1-06 00:03:44&quot;, &quot;lon&quot;-&gt;&quot;118.22065000&quot;, &quot;lat&quot;-&gt;&quot;26.19307700&quot;, &quot;unittype&quot;-&gt;&quot;1&quot;)</span><br><span class="line">testMapList += Map(&quot;gpstime&quot;-&gt;&quot;2018-1-06 00:12:52&quot;, &quot;lon&quot;-&gt;&quot;118.22065000&quot;, &quot;lat&quot;-&gt;&quot;26.19307700&quot;, &quot;unittype&quot;-&gt;&quot;1&quot;)</span><br></pre></td></tr></table></figure>
<h2 id="零碎"><a href="#零碎" class="headerlink" title="零碎"></a>零碎</h2><p>Unit：在scala任何的函数、表达式、方法都有返回值（有些情况类似与java的void，所以scala创立了unit这个标识符来表示特殊的返回值）</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">val (codeMap, codeLength) = featureCodeMap.get(featureFlag).get</span><br><span class="line">featureCodeMap.get(featureFlag).get出来是一个tuple  (Map[String, Int], Int)</span><br></pre></td></tr></table></figure>
<p>定义空的scala对象</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">var buff: BufferedWriter = null</span><br><span class="line">buff = new BufferedWriter(new OutputStreamWriter(new FileOutputStream(existedSlotTagsPath)))</span><br><span class="line">buff = new BufferedWriter(new OutputStreamWriter(new FileOutputStream(featureCodeMapPath)))</span><br></pre></td></tr></table></figure>
<h2 id="Seq"><a href="#Seq" class="headerlink" title="Seq"></a>Seq</h2><p>Seq 是列表，适合存有序重复数据，进行快速插入/删除元素等场景<br>Set 是集合，适合存无序非重复数据，进行快速查找海量元素的等场景</p>
<h2 id="本地文件读取"><a href="#本地文件读取" class="headerlink" title="本地文件读取"></a>本地文件读取</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">import scala.io.Source</span><br><span class="line"></span><br><span class="line">val s = Source.fromFile(&quot;D:\\code\\Data\\rtb.BJ2.2016052513_7.log&quot;).getLines().foreach &#123; x =&gt; println(x.toString()) &#125;</span><br></pre></td></tr></table></figure>
<p>找出文本中最长的一行</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">val longestLine = lines.reduceLeft (</span><br><span class="line">   (a,b) =&gt; if (a.length &gt; b.length ) then a else b</span><br><span class="line">)</span><br></pre></td></tr></table></figure>
<h2 id="Array"><a href="#Array" class="headerlink" title="Array"></a>Array</h2><p>数组的初始化</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">//长度为10的整数数组，所有元素初始化为0  </span><br><span class="line"> val numArr = new Array[Int](10)  </span><br><span class="line">  </span><br><span class="line">//长度为10的字符串数组，所有元素初始化为null  </span><br><span class="line">val numArr = new Array[String](10)  </span><br><span class="line">  </span><br><span class="line">//长度为2的数组，数据类型自动推断出来，已经提供初始值就不需要new关键字  </span><br><span class="line">val s = Array(&quot;cai&quot;,&quot;yong&quot;)  </span><br><span class="line">  </span><br><span class="line">//通过ArrayName(index)访问数组元素和更改数组元素  </span><br><span class="line">val s = Array(&quot;cai&quot;,&quot;yong&quot;)  </span><br><span class="line"> println(s(0))  </span><br><span class="line">s(0) = &quot;haha&quot;  </span><br><span class="line">println(s(0))</span><br></pre></td></tr></table></figure>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">//n.length是0</span><br><span class="line">val n = Array[Double](100)</span><br><span class="line">//n.length是100</span><br><span class="line">val n = new Array[Double](100)</span><br></pre></td></tr></table></figure>
<h2 id="List"><a href="#List" class="headerlink" title="List"></a>List</h2><h2 id="list元素用字符拼接"><a href="#list元素用字符拼接" class="headerlink" title="list元素用字符拼接"></a>list元素用字符拼接</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">val keyList = new ListBuffer[String]</span><br><span class="line">keyList += &quot;a&quot;</span><br><span class="line">keyList += &quot;b&quot;</span><br><span class="line">println(keyList.addString(new mutable.StringBuilder, &quot;|&quot;).toString)</span><br></pre></td></tr></table></figure>
<h2 id="ListBuffer"><a href="#ListBuffer" class="headerlink" title="ListBuffer"></a>ListBuffer</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">val instance: ListBuffer[Int]=ListBuffer()</span><br><span class="line"></span><br><span class="line">ListBuffer.result = ListBuffer.toList</span><br></pre></td></tr></table></figure>
<h3 id="ListBuffer添加元素"><a href="#ListBuffer添加元素" class="headerlink" title="ListBuffer添加元素"></a>ListBuffer添加元素</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">val chiResult = new ListBuffer[(Int, Double)]</span><br><span class="line">chiResult += ((0, left)) // 两层括号</span><br></pre></td></tr></table></figure>
<h3 id="list转listBuffer"><a href="#list转listBuffer" class="headerlink" title="list转listBuffer"></a>list转listBuffer</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">scala&gt; val l = List(1,2,3)</span><br><span class="line">l: List[Int] = List(1, 2, 3)</span><br><span class="line">scala&gt; l.to[ListBuffer]</span><br><span class="line">res1: scala.collection.mutable.ListBuffer[Int] = ListBuffer(1, 2, 3)</span><br></pre></td></tr></table></figure>
<h2 id="转java-util-List"><a href="#转java-util-List" class="headerlink" title="转java.util.List"></a>转java.util.List</h2><p>首先需要<code>scala.collection.JavaConversions._</code></p>
<p>Java和Scala容器的转换</p>
<p><a href="https://blog.csdn.net/high2011/article/details/52204625" target="_blank" rel="noopener">https://blog.csdn.net/high2011/article/details/52204625</a></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">import scala.collection.JavaConverters._</span><br><span class="line"></span><br><span class="line">val list: java.util.List[Int] = Seq(1,2,3,4).asJava</span><br><span class="line">val buffer: scala.collection.mutable.Buffer[Int] = list.asScala</span><br></pre></td></tr></table></figure>
<h1 id="map"><a href="#map" class="headerlink" title="map"></a>map</h1><h2 id="新建一个map"><a href="#新建一个map" class="headerlink" title="新建一个map"></a>新建一个map</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">// 如果后面没有括号，会被认为是一个seq</span><br><span class="line">var map = mutable.Map[String, String]()</span><br></pre></td></tr></table></figure>
<h2 id="map根据key排序"><a href="#map根据key排序" class="headerlink" title="map根据key排序"></a>map根据key排序</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">val aMap = new scala.collection.mutable.HashMap[String, Double]</span><br><span class="line"></span><br><span class="line">    val a = Array(&quot;A&quot;, &quot;B&quot;, &quot;C&quot;, &quot;D&quot;)</span><br><span class="line">    val b = Array(4, 5, 8, 9)</span><br><span class="line"></span><br><span class="line">    for(i &lt;- a.indices)&#123;</span><br><span class="line">      aMap += (a(i) -&gt; b(i))</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    // 从小到大(默认)</span><br><span class="line">    val mapSortSmall = aMap.toList.sortBy(_._2)</span><br><span class="line">    mapSortSmall.foreach(line =&gt; println(line._1 +&quot;\t&quot;+ line._2))</span><br></pre></td></tr></table></figure>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">val arr = new ArrayBuffer[String]</span><br><span class="line">    arr += &quot;aaa&quot;</span><br><span class="line">    arr += &quot;bbb&quot;</span><br><span class="line">    arr += &quot;bbb&quot;</span><br><span class="line">    val aa = arr.map(f =&gt; &#123;</span><br><span class="line">      (f, 1)</span><br><span class="line">    &#125;).groupBy(_._1).mapValues(_.size).toList.sortBy(_._2)</span><br><span class="line">    println(aa.last._1)</span><br></pre></td></tr></table></figure>
<h2 id="取所有的key"><a href="#取所有的key" class="headerlink" title="取所有的key"></a>取所有的key</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">val  scores=Map(&quot;Alice&quot;-&gt;10,&quot;Bob&quot;-&gt;3,&quot;Cindy&quot;-&gt;8)</span><br><span class="line">//     获取所有的key</span><br><span class="line">     val nameList=scores.map(_._1)</span><br><span class="line">//     map 函数返回List</span><br><span class="line">     println(nameList.getClass)</span><br><span class="line">遍历list中的元素</span><br><span class="line">     nameList.foreach((x:String)=&gt;print(x+&quot; &quot;))</span><br></pre></td></tr></table></figure>
<h2 id="mutable和immutable互转"><a href="#mutable和immutable互转" class="headerlink" title="mutable和immutable互转"></a>mutable和immutable互转</h2><p>If you just want a mutable <code>HashMap</code>, you can just use <code>x.toMap</code> in 2.8 or <code>collection.immutable.Map(x.toList: _*)</code> in 2.7.</p>
<p>But if you want the whole structure to be immutable—including the underlying set!—then you have to do more: you need to convert the sets along the way. In 2.8:</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">x.map(kv =&gt; (kv._1,kv._2.toSet)).toMap</span><br></pre></td></tr></table></figure>
<p>In 2.7:</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">collection.immutable.Map(</span><br><span class="line">  x.map(kv =&gt; (kv._1,collection.immutable.Set(kv._2.toList: _*))).toList: _*</span><br><span class="line">)</span><br></pre></td></tr></table></figure>
<h1 id="可变容器"><a href="#可变容器" class="headerlink" title="可变容器"></a>可变容器</h1><h2 id="listbuffer"><a href="#listbuffer" class="headerlink" title="listbuffer"></a>listbuffer</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">import scala.collection.mutable.ListBuffer</span><br><span class="line"></span><br><span class="line">val fieldListBuffer = new ListBuffer[String]</span><br><span class="line">// or</span><br><span class="line">val list = ListBuffer.empty[String]</span><br><span class="line">    list += &quot;ds&quot;</span><br><span class="line">    list += &quot;sd&quot;</span><br><span class="line">    list.foreach(println)</span><br></pre></td></tr></table></figure>
<h2 id="HashSet定义"><a href="#HashSet定义" class="headerlink" title="HashSet定义"></a>HashSet定义</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">val distinctLabels = mutable.HashSet.empty[Double]</span><br></pre></td></tr></table></figure>
<h1 id="for循环"><a href="#for循环" class="headerlink" title="for循环"></a>for循环</h1><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">object Test &#123;</span><br><span class="line">   def main(args: Array[String]) &#123;</span><br><span class="line">      var a = 0;</span><br><span class="line">      var b = 0;</span><br><span class="line">      // for 循环</span><br><span class="line">      for( a &lt;- 1 to 3; b &lt;- 1 to 3)&#123;</span><br><span class="line">         println( &quot;Value of a: &quot; + a );</span><br><span class="line">         println( &quot;Value of b: &quot; + b );</span><br><span class="line">      &#125;</span><br><span class="line">   &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>以上语法中，<strong>Range</strong> 可以是一个数字区间表示 <strong>i to j</strong> ，或者 <strong>i until j</strong>。左箭头 &lt;- 用于为变量 x 赋值，循环范围是[i, j]。</p>
<p>有过滤器的循环</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">object Demo &#123;</span><br><span class="line">   def main(args: Array[String]) &#123;</span><br><span class="line">      var a = 0;</span><br><span class="line">      val numList = List(1,2,3,4,5,6,7,8,9,10);</span><br><span class="line"></span><br><span class="line">      // for loop execution with multiple filters</span><br><span class="line">      for( a &lt;- numList</span><br><span class="line">           if a != 3; if a &lt; 8 )&#123;</span><br><span class="line">         println( &quot;Value of a: &quot; + a );</span><br><span class="line">      &#125;</span><br><span class="line">   &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h3 id="跳出循环"><a href="#跳出循环" class="headerlink" title="跳出循环"></a>跳出循环</h3><p><a href="http://www.cnblogs.com/r0n9/p/6733909.html" target="_blank" rel="noopener">http://www.cnblogs.com/r0n9/p/6733909.html</a></p>
<p>我是定义一个flag来实现break</p>
<h1 id="match"><a href="#match" class="headerlink" title="match"></a>match</h1><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">main</span></span>(args: <span class="type">Array</span>[<span class="type">String</span>]) &#123;</span><br><span class="line">    <span class="comment">//通过模式匹配进行条件判断</span></span><br><span class="line">    <span class="keyword">val</span> test1: <span class="type">String</span> = <span class="string">"1"</span></span><br><span class="line">    <span class="keyword">val</span> result1 = test1 <span class="keyword">match</span> &#123;</span><br><span class="line">      <span class="keyword">case</span> <span class="string">"1"</span> =&gt; &#123;</span><br><span class="line">        <span class="string">"one"</span></span><br><span class="line">      &#125;</span><br><span class="line">      <span class="keyword">case</span> <span class="string">"2"</span> =&gt; <span class="string">"two"</span></span><br><span class="line">      <span class="keyword">case</span> _ =&gt; <span class="string">"other"</span></span><br><span class="line">    &#125;</span><br></pre></td></tr></table></figure>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">val</span> test2: <span class="type">Int</span> = <span class="number">1</span>;</span><br><span class="line">    <span class="keyword">val</span> result2 = test2 <span class="keyword">match</span> &#123;</span><br><span class="line">      <span class="keyword">case</span> i <span class="keyword">if</span> i + <span class="number">1</span> == <span class="number">2</span> =&gt; <span class="string">"one"</span></span><br><span class="line">      <span class="keyword">case</span> i <span class="keyword">if</span> i + <span class="number">1</span> == <span class="number">3</span> =&gt; <span class="string">"tow"</span></span><br><span class="line">      <span class="keyword">case</span> _ =&gt; <span class="string">"error"</span></span><br><span class="line">    &#125;</span><br><span class="line">    println(result2)</span><br></pre></td></tr></table></figure>
<h1 id="线上执行"><a href="#线上执行" class="headerlink" title="线上执行"></a>线上执行</h1><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash">!/bin/sh</span></span><br><span class="line"></span><br><span class="line">export JAVA_HOME=/opt/jdk1.7.0_67</span><br><span class="line">export  PATH=$PATH:$JAVA_HOME/bin</span><br><span class="line"></span><br><span class="line">P_HOME="/home/xmo/buzzads-bidding-model-test"</span><br><span class="line">CLASSPATH=$&#123;P_HOME&#125;/conf:$&#123;P_HOME&#125;/buzzads-bidding-model-local.jar</span><br><span class="line">for f in $&#123;P_HOME&#125;/lib/*.jar; do</span><br><span class="line">  CLASSPATH=$&#123;CLASSPATH&#125;:$f</span><br><span class="line">done</span><br><span class="line">java -server -Dfile.encoding=UTF-8 -Xms1G -Xmx1G -XX:+UseConcMarkSweepGC -XX:+CMSIncrementalMode -XX:+CMSIncrementalPacing -XX:CMSIncrementalDutyCycleMin=0 -XX:CMSIncrementalDutyCycle=10 -XX:MaxNewSize=1024M -XX:MaxPermSize=256M -XX:+DisableExplicitGC -cp $CLASSPATH com.buzzinate.bidding.main.Main &gt; $&#123;P_HOME&#125;/train.log</span><br></pre></td></tr></table></figure>
<h1 id="随机数"><a href="#随机数" class="headerlink" title="随机数"></a>随机数</h1><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">import java.util.Random</span><br><span class="line"></span><br><span class="line">val random = new Random(System.currentTimeMillis)</span><br><span class="line"></span><br><span class="line">if (random.nextDouble() &lt; 0.00001) &#123;</span><br></pre></td></tr></table></figure>
<h1 id="trait"><a href="#trait" class="headerlink" title="trait"></a>trait</h1><p>类似于接口。使用的时候</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">//with后面的就是trait</span><br><span class="line">val titleCnt = new HashMap[String, Int] with HashMapUtil.IntHashMap[String]</span><br></pre></td></tr></table></figure>
<h1 id="HashTable"><a href="#HashTable" class="headerlink" title="HashTable"></a>HashTable</h1><p>一个应用是定义一个可以插入或累加的方法</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//定义是/home/david/gitlab/user-gene/nlp/src/main/scala/com/buzzinate/keywords/util/HashMapUtil.scala</span></span><br><span class="line"><span class="class"><span class="keyword">object</span> <span class="title">HashMapUtil</span> </span>&#123;</span><br><span class="line">  <span class="class"><span class="keyword">trait</span> <span class="title">IntHashMap</span>[<span class="type">A</span>] <span class="keyword">extends</span> <span class="title">HashTable</span>[<span class="type">A</span>, <span class="type">DefaultEntry</span>[<span class="type">A</span>, <span class="type">Int</span>]] </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">adjustOrPut</span></span>(key: <span class="type">A</span>, incr: <span class="type">Int</span>, value: <span class="type">Int</span>): <span class="type">Int</span> = &#123;</span><br><span class="line">      <span class="keyword">val</span> e = findEntry(key)</span><br><span class="line">      <span class="keyword">if</span> (e == <span class="literal">null</span>) &#123;</span><br><span class="line">        addEntry(<span class="keyword">new</span> <span class="type">DefaultEntry</span>[<span class="type">A</span>, <span class="type">Int</span>](key, value))</span><br><span class="line">        <span class="number">0</span></span><br><span class="line">      &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">        <span class="keyword">val</span> old = e.value</span><br><span class="line">        e.value += incr</span><br><span class="line">        old</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">putMax</span></span>(key: <span class="type">A</span>, value: <span class="type">Int</span>): <span class="type">Int</span> = &#123;</span><br><span class="line">      <span class="keyword">val</span> e = findEntry(key)</span><br><span class="line">      <span class="keyword">if</span> (e == <span class="literal">null</span>) &#123;</span><br><span class="line">        addEntry(<span class="keyword">new</span> <span class="type">DefaultEntry</span>[<span class="type">A</span>, <span class="type">Int</span>](key, value))</span><br><span class="line">        <span class="number">0</span></span><br><span class="line">      &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">        <span class="keyword">val</span> old = e.value</span><br><span class="line">        <span class="keyword">if</span> (value &gt; e.value) e.value = value</span><br><span class="line">        old</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">//使用时</span></span><br><span class="line"><span class="keyword">val</span> titleCnt = <span class="keyword">new</span> <span class="type">HashMap</span>[<span class="type">String</span>, <span class="type">Int</span>] <span class="keyword">with</span> <span class="type">HashMapUtil</span>.<span class="type">IntHashMap</span>[<span class="type">String</span>]</span><br><span class="line">titleCnt.adjustOrPut(te.extract(rawTitle).trim, <span class="number">1</span>, <span class="number">1</span>)</span><br></pre></td></tr></table></figure>
<h1 id="case-class-1"><a href="#case-class-1" class="headerlink" title="case class"></a>case class</h1><p>让编译器可以自动生成一些方法，如apply、copy、equals等，当希望设计一个类只是用来作为数据载体时，case class是一个ERR Client sent AUTH, but no password is set很好的选择。</p>
<h1 id="RDD操作"><a href="#RDD操作" class="headerlink" title="RDD操作"></a>RDD操作</h1><h2 id="配置"><a href="#配置" class="headerlink" title="配置"></a>配置</h2><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">val</span> conf = <span class="keyword">new</span> <span class="type">SparkConf</span>().setAppName(<span class="string">"wordSegname"</span>).setMaster(<span class="string">"local[4]"</span>).</span><br><span class="line">    set(<span class="string">"spark.sql.shuffle.partitions"</span>,<span class="string">"10"</span>).set(<span class="string">"spark.network.timeout"</span>,<span class="string">"30s"</span>) </span><br><span class="line"><span class="keyword">val</span> sc = <span class="keyword">new</span> <span class="type">SparkContext</span>(conf)</span><br></pre></td></tr></table></figure>
<ul>
<li>local[4]是指在本地运行，用4核CPU。</li>
<li>spark.sql.shuffle.partitions是指partition的数量。SparkSQL在运行时，将一个查询任务分解成多个task，一个task就是一个partition。默认是200个partition，而如果实际集群只能并行3个task，则跑完200个partition要200/3=67次。</li>
<li>spark.network.timeout是指所有网络通信的超时时间，默认是120s</li>
</ul>
<h2 id="读文件"><a href="#读文件" class="headerlink" title="读文件"></a>读文件</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">//读取本地文件</span><br><span class="line">val path = &quot;file:///home/david/get_keyword_hash.txt&quot;</span><br><span class="line">val word1 = sc.textFile(path).map &#123; x =&gt;</span><br><span class="line">      val x_filter = x.replaceAll(&quot;\\p&#123;Punct&#125;&quot;, &quot; &quot;).replaceAll(&quot;\\pP&quot;, &quot; &quot;).replaceAll(&quot;[&quot; + AtomsUitl.stopwords + &quot;]&quot;, &quot; &quot;)</span><br><span class="line">        .replaceAll(&quot;　&quot;, &quot; &quot;).replaceAll(&quot;\\p&#123;Blank&#125;&quot;, &quot; &quot;).replaceAll(&quot;\\p&#123;Space&#125;&quot;, &quot; &quot;).replaceAll(&quot;\\p&#123;Cntrl&#125;&quot;, &quot; &quot;)</span><br><span class="line"></span><br><span class="line">      x_filter</span><br><span class="line">    &#125;</span><br></pre></td></tr></table></figure>
<p>上文中，是将所有的特殊字符都用空格代替</p>
<p>AtomsUitl.stopwords停用词是”的很了么呢是嘛个都也比还这于不与才上用就好在和对挺去后没说”</p>
<p>sc.textFile读取文件后，生成一个RDD，以行为单位，所以后面的map是对每行的操作</p>
<p>打印出所有的元素，用</p>
<p>word1.foreach { x =&gt; println(x) }  </p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">val word_document = word1.zipWithIndex.filter &#123; x =&gt; !StringUtils.isBlank(x._1) &#125;.flatMap &#123; x =&gt;</span><br><span class="line">      val arr = ArrayBuffer[(String, Int)]()</span><br><span class="line">      val line = x._1.split(&quot; &quot;)</span><br><span class="line">      for (i &lt;- line) &#123;</span><br><span class="line">        arr += ((i, x._2.toInt))</span><br><span class="line">      &#125;</span><br><span class="line">      arr</span><br><span class="line">    &#125;.map &#123; x =&gt; (x._1.trim, x._2) &#125;.filter(x =&gt; !StringUtils.isBlank(x._1))</span><br></pre></td></tr></table></figure>
<h3 id="zipWithIndex"><a href="#zipWithIndex" class="headerlink" title="zipWithIndex"></a>zipWithIndex</h3><p>该函数将RDD中的元素和这个元素在RDD中的ID（索引号）组合成键/值对。</p>
<blockquote>
<p>例如：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">&gt; scala&gt; var rdd2 = sc.makeRDD(Seq(&quot;A&quot;,&quot;B&quot;,&quot;R&quot;,&quot;D&quot;,&quot;F&quot;),2)</span><br><span class="line">&gt; rdd2: org.apache.spark.rdd.RDD[String] = ParallelCollectionRDD[34] at makeRDD at :21</span><br><span class="line">&gt;  </span><br><span class="line">&gt; scala&gt; rdd2.zipWithIndex().collect</span><br><span class="line">&gt; res27: Array[(String, Long)] = Array((A,0), (B,1), (R,2), (D,3), (F,4))</span><br><span class="line">&gt;</span><br><span class="line">&gt;</span><br></pre></td></tr></table></figure>
</blockquote>
<p>filter 过滤的结果还是RDD</p>
<h3 id="zipWithIndex反过来"><a href="#zipWithIndex反过来" class="headerlink" title="zipWithIndex反过来"></a>zipWithIndex反过来</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>
<h3 id="flatMap和Map"><a href="#flatMap和Map" class="headerlink" title="flatMap和Map"></a>flatMap和Map</h3><ul>
<li>Spark 中 map函数会对每一条输入进行指定的操作，然后为每一条输入返回一个对象；</li>
<li><p>而flatMap函数则是两个操作的集合——正是“先映射后扁平化”：</p>
<p> 操作1：同map函数一样：对每一条输入进行指定的操作，然后为每一条输入返回一个对象</p>
<p> 操作2：最后将所有对象合并为一个对象</p>
</li>
</ul>
<h1 id="获取目录下所有文件路径"><a href="#获取目录下所有文件路径" class="headerlink" title="获取目录下所有文件路径"></a>获取目录下所有文件路径</h1><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">import java.io.PrintWriter</span><br><span class="line">import java.io.File</span><br><span class="line">import scala.reflect.io.Directory</span><br><span class="line"></span><br><span class="line">object Test &#123;</span><br><span class="line">  def main(args: Array[String]): Unit = &#123;</span><br><span class="line">    val dir = new File(&quot;F:\\joke\\DCIM\\299MEDIA&quot;)</span><br><span class="line">    val children = dir.listFiles()</span><br><span class="line">    for ( d &lt;- children)</span><br><span class="line">      println(d)</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>结果为<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">F:\joke\DCIM\299MEDIA\YDXJ0580.THM</span><br><span class="line">F:\joke\DCIM\299MEDIA\YDXJ0580_thm.mp4</span><br><span class="line">F:\joke\DCIM\299MEDIA\YDXJ0581.THM</span><br><span class="line">F:\joke\DCIM\299MEDIA\YDXJ0581_thm.mp4</span><br><span class="line">F:\joke\DCIM\299MEDIA\YDXJ0582.THM</span><br><span class="line">F:\joke\DCIM\299MEDIA\YDXJ0582_thm.mp4</span><br></pre></td></tr></table></figure></p>
<h1 id="位运算"><a href="#位运算" class="headerlink" title="位运算"></a>位运算</h1><h2 id="除以2"><a href="#除以2" class="headerlink" title="除以2"></a>除以2</h2><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 二进制向右移动一位</span></span><br><span class="line"><span class="number">10</span> &gt;&gt;&gt; <span class="number">1</span></span><br></pre></td></tr></table></figure>
<p>得到5</p>
<h2 id="翻倍"><a href="#翻倍" class="headerlink" title="翻倍"></a>翻倍</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">// 二进制向左移动一位</span><br><span class="line">10 &lt;&lt; 1</span><br></pre></td></tr></table></figure>
<p>得到20</p>
<h1 id="scala实现wordcount几种方法"><a href="#scala实现wordcount几种方法" class="headerlink" title="scala实现wordcount几种方法"></a>scala实现wordcount几种方法</h1><p><a href="https://blog.csdn.net/qq_31780525/article/details/79036728" target="_blank" rel="noopener">https://blog.csdn.net/qq_31780525/article/details/79036728</a></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">  val lines=List(&quot;hello tom hello jerry&quot;,&quot;hello tom hello kitty hello china&quot;)</span><br><span class="line">方法一:</span><br><span class="line">  val wc=lines.flatMap(_.split(&quot; &quot;)).map((_,1)).groupBy(_._1).map(t=&gt;(t._1,t._2.size)).toList.sortBy(_._2).reverse</span><br><span class="line">方法二：</span><br><span class="line">  val wc2=lines.flatMap(_.split(&quot; &quot;)).map((_,1)).groupBy(_._1).mapValues(_.size)</span><br><span class="line">方法三：</span><br><span class="line">  val wc3=lines.flatMap(_.split(&quot; &quot;)).map((_,1)).groupBy(_._1).mapValues(_.foldLeft(0)(_+_._2))</span><br><span class="line">如果是在spark上：</span><br><span class="line">  val wc4=lines.flatMap(_.split(&quot; &quot;)).map((_,1)).reduceByKey(_+_).sortBy(_._2,false).collect</span><br></pre></td></tr></table></figure>
<p>对于以下情况</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">(1.0,2)</span><br><span class="line">(2.0,1)</span><br><span class="line">(3.0,3)</span><br></pre></td></tr></table></figure>
<p>用<code>groupBy(_._1).mapValues(_.foldLeft(0)(_+_._2))</code>是可以的，</p>
<p>mapValues的用途是直接将Array的内容进行按照key相同的进行统计计算。<br><code>.foldLeft(0)(+._2)</code> 第一个下划线表示的是的是数组中的key，意思是分别取出其中的Array集合，<code>.foldLeft(0)(+_.2)</code>表示将Array进行求和，后边括号中的第一个下划线表示的是处事值0，第二个下划线是表示的是元组，<code>.2</code>表示的是元组中的第二个值，即单词出现的次数。</p>
<h1 id="immutable-Map转mutable-Map"><a href="#immutable-Map转mutable-Map" class="headerlink" title="immutable.Map转mutable.Map"></a>immutable.Map转mutable.Map</h1><p><a href="https://stackoverflow.com/questions/5042878/how-can-i-convert-immutable-map-to-mutable-map-in-scala" target="_blank" rel="noopener">https://stackoverflow.com/questions/5042878/how-can-i-convert-immutable-map-to-mutable-map-in-scala</a></p>
<p>The cleanest way would be to use the <code>mutable.Map</code> varargs factory. Unlike the <code>++</code> approach, this uses the <code>CanBuildFrom</code> mechanism, and so has the potential to be more efficient if library code was written to take advantage of this:</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">val m = collection.immutable.Map(1-&gt;&quot;one&quot;,2-&gt;&quot;Two&quot;)</span><br><span class="line">val n = collection.mutable.Map(m.toSeq: _*)</span><br></pre></td></tr></table></figure>
<p>This works because a <code>Map</code> can also be viewed as a sequence of Pairs.</p>
<h1 id="import的类改名"><a href="#import的类改名" class="headerlink" title="import的类改名"></a>import的类改名</h1><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">import breeze.linalg.&#123;DenseMatrix =&gt; BDM&#125;</span><br></pre></td></tr></table></figure>
<h1 id="数组抽样"><a href="#数组抽样" class="headerlink" title="数组抽样"></a>数组抽样</h1><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">import scala.util.Random</span><br><span class="line"></span><br><span class="line">Random.shuffle(list).take(n)</span><br><span class="line">Random.shuffle(array.toList).take(n)</span><br><span class="line"></span><br><span class="line">// Seeded version</span><br><span class="line">val r = new Random(seed)</span><br><span class="line">r.shuffle(...)</span><br></pre></td></tr></table></figure>
<h1 id="保留小数"><a href="#保留小数" class="headerlink" title="保留小数"></a>保留小数</h1><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">val df = new DecimalFormat(&quot;0.0000&quot;)</span><br><span class="line">println(df.format(-1.0))</span><br></pre></td></tr></table></figure>
<h1 id="解析python导出的json"><a href="#解析python导出的json" class="headerlink" title="解析python导出的json"></a>解析python导出的json</h1><p>python导出的一个dict，形如</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">&#123;&quot;product_code&quot;:&#123;&quot;0.3661996&quot;:&quot;45&quot;&#125;,&quot;now_term_rate&quot;:&#123;&quot;0.0811413&quot;:&quot;90&quot;&#125;&#125;</span><br></pre></td></tr></table></figure>
<p>scala解析报错</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">Exception in thread &quot;main&quot; org.json4s.package$MappingException: No usable value for colDiscretizedPoints</span><br><span class="line">Expected object but got JNothing</span><br></pre></td></tr></table></figure>
<p>如果用json4s来解析，需要解析成一个case class，并且JSON中要包含case class中的一个对象名，如<code>colWoe2ID</code></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">case class OneHotModel(colWoe2ID: Map[String, Map[String, Int]])</span><br></pre></td></tr></table></figure>
<p>所以在python导出的JSON中手动增加一个对象</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">&#123;&quot;colWoe2ID&quot;: &#123;&quot;product_code&quot;: &#123;&quot;-0.3235455&quot;: 45&#125;, &quot;now_term_rate&quot;: &#123;&quot;0.1132489&quot;: 90, &quot;-0.0115938&quot;: 91, &quot;0.0294193&quot;: 92, &quot;-0.6089315&quot;: 93, &quot;0.0811413&quot;: 94, &quot;1.3411297&quot;: 95, &quot;-0.0237762&quot;: 96, &quot;0.0890516&quot;: 97, &quot;0.1255305&quot;: 98&#125;&#125;&#125;</span><br></pre></td></tr></table></figure>
<p>这样就不会报错了</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">val dict = Source.fromFile(&quot;/Users/david/david/code/00project/carthage/dictjson.txt&quot;).getLines().toList(0)</span><br><span class="line">    val dict2 = parse(dict).extract[OneHotModel].colWoe2ID</span><br><span class="line">    println(dict2.toList.toString())</span><br></pre></td></tr></table></figure>
<h1 id="正则判断"><a href="#正则判断" class="headerlink" title="正则判断"></a>正则判断</h1><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">val regex=&quot;&quot;&quot;^\d+$&quot;&quot;&quot;.r</span><br><span class="line">    println(regex.pattern.matcher(&quot;321239&quot;).matches())</span><br></pre></td></tr></table></figure>
<h1 id="方法返回多个参数"><a href="#方法返回多个参数" class="headerlink" title="方法返回多个参数"></a>方法返回多个参数</h1><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">// 返回的变量可以是之前定义过的</span><br><span class="line">val (is_more_than_3_cars_meet_in_100m, more_than_3_cars_meet_in_100m_app_code) = GPSWXMetricInfoHandler.isCarsMeetInDistance(wxLon, wxLat, app_code, 3, 0.1, geoHash2appCodeLonlatMap)</span><br></pre></td></tr></table></figure>
<h1 id="泛型"><a href="#泛型" class="headerlink" title="泛型"></a>泛型</h1><h2 id="classOf如何用于类型参数"><a href="#classOf如何用于类型参数" class="headerlink" title="classOf如何用于类型参数"></a>classOf如何用于类型参数</h2><p>参考<a href="https://cloud.tencent.com/developer/ask/117470" target="_blank" rel="noopener">https://cloud.tencent.com/developer/ask/117470</a></p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">val</span> clazz = classOf[<span class="type">T</span>]</span><br><span class="line">gdav.app_code = clazz.getDeclaredMethod(<span class="string">"getAppCode"</span>).invoke(x).asInstanceOf[<span class="type">String</span>]</span><br><span class="line"></span><br><span class="line"><span class="comment">// 或者一个java方法体是</span></span><br><span class="line"><span class="comment">// public static &lt;T&gt; ArrayList&lt;T&gt; getAnomalyData(String sql, Class&lt;T&gt; obj)</span></span><br><span class="line"><span class="comment">// scala调用时</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">commonFunc</span></span>[<span class="type">T</span>](sc: <span class="type">SparkContext</span>, sqlName: <span class="type">String</span>): <span class="type">RDD</span>[<span class="type">Row</span>] = &#123;</span><br><span class="line">    <span class="keyword">val</span> anomalyList = <span class="type">DefaultAnomalyDataJdbc</span>.getAnomalyData(</span><br><span class="line">      <span class="type">HiveHandler</span>.getExecuteSql(sqlName, <span class="type">List</span>(currentDateStr)),</span><br><span class="line">      classOf[<span class="type">T</span>]</span><br><span class="line">    ).asScala</span><br></pre></td></tr></table></figure>
<p>就会报错class type required but T found，显示<code>classOf[T]</code>这里报错</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">class type required but T found</span><br></pre></td></tr></table></figure>
<p>解决方案是</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">commonFunc</span></span>[<span class="type">T</span>](sc: <span class="type">SparkContext</span>, sqlName: <span class="type">String</span>)(<span class="keyword">implicit</span> tag: <span class="type">ClassTag</span>[<span class="type">T</span>]): <span class="type">RDD</span>[<span class="type">Row</span>] = &#123;</span><br><span class="line">    <span class="keyword">val</span> anomalyList = <span class="type">DefaultAnomalyDataJdbc</span>.getAnomalyData(</span><br><span class="line">      <span class="type">HiveHandler</span>.getExecuteSql(sqlName, <span class="type">List</span>(currentDateStr)),</span><br><span class="line">      <span class="comment">// 这里</span></span><br><span class="line">      tag.runtimeClass</span><br><span class="line">    ).asScala</span><br></pre></td></tr></table></figure>
<h2 id="泛型调用方法"><a href="#泛型调用方法" class="headerlink" title="泛型调用方法"></a>泛型调用方法</h2><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">sc.parallelize(anomalyList, <span class="number">5</span>).map(&#123;</span><br><span class="line">      x =&gt;</span><br><span class="line">        <span class="keyword">val</span> gdav = <span class="keyword">new</span> <span class="type">GpsDefaultAnomalyVals</span></span><br><span class="line">        <span class="keyword">val</span> clazz = tag.runtimeClass</span><br><span class="line">        gdav.app_code = clazz.getDeclaredMethod(<span class="string">"getAppCode"</span>).invoke(x).asInstanceOf[<span class="type">String</span>]</span><br></pre></td></tr></table></figure>
<h1 id="最小堆"><a href="#最小堆" class="headerlink" title="最小堆"></a>最小堆</h1><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">object</span> <span class="title">TopK</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">  <span class="keyword">val</span> <span class="type">K</span> = <span class="number">3</span></span><br><span class="line"></span><br><span class="line">  <span class="keyword">val</span> ord = <span class="type">Ordering</span>.by[(<span class="type">String</span>, <span class="type">Int</span>), <span class="type">Int</span>](_._2).reverse</span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">main</span></span>(args: <span class="type">Array</span>[<span class="type">String</span>]) &#123;</span><br><span class="line">    <span class="comment">// 执行 wordcount</span></span><br><span class="line">    <span class="keyword">val</span> conf = <span class="keyword">new</span> <span class="type">SparkConf</span>().setAppName(<span class="string">"TopK"</span>)</span><br><span class="line">    <span class="keyword">val</span> spark = <span class="keyword">new</span> <span class="type">SparkContext</span>(conf)</span><br><span class="line">    <span class="keyword">val</span> textRDD = spark.textFile(<span class="string">"hdfs://10.0.8.162:9000/home/yuzx/input/wordcount.txt"</span>)</span><br><span class="line">    <span class="keyword">val</span> countRes = textRDD.flatMap(line =&gt; line.split(<span class="string">" "</span>)).map(word =&gt; (word, <span class="number">1</span>)).reduceByKey(_ + _)</span><br><span class="line"></span><br><span class="line">    <span class="comment">// debug mapreduce 的结果</span></span><br><span class="line">    countRes.foreach(println)</span><br><span class="line"></span><br><span class="line">    <span class="comment">/*</span></span><br><span class="line"><span class="comment">     每个 RDD 分区内进行 TOP K 计算</span></span><br><span class="line"><span class="comment">     需要每个分区内有自己的桶，如果整个程序使用一个 heap（将 heap 设定为成员变量） 会不正确</span></span><br><span class="line"><span class="comment">     为什么呢？</span></span><br><span class="line"><span class="comment">      */</span></span><br><span class="line">    <span class="keyword">val</span> topk = countRes.mapPartitions(iter =&gt; &#123;</span><br><span class="line">      <span class="keyword">val</span> heap = <span class="keyword">new</span> mutable.<span class="type">PriorityQueue</span>[(<span class="type">String</span>, <span class="type">Int</span>)]()(ord)</span><br><span class="line">      <span class="keyword">while</span> (iter.hasNext) &#123;</span><br><span class="line">        <span class="keyword">val</span> n = iter.next</span><br><span class="line">        println(<span class="string">"分区计算："</span> + n)</span><br><span class="line">        putToHeap(heap, n)</span><br><span class="line">      &#125;</span><br><span class="line"></span><br><span class="line">      heap.iterator</span><br><span class="line">    &#125;).collect()</span><br><span class="line"></span><br><span class="line">    println(<span class="string">"分区结果："</span>)</span><br><span class="line">    topk.foreach(println)</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 每个分区的 TOP K 合并，计算总的 TopK</span></span><br><span class="line">    <span class="keyword">val</span> heap = <span class="keyword">new</span> mutable.<span class="type">PriorityQueue</span>[(<span class="type">String</span>, <span class="type">Int</span>)]()(ord)</span><br><span class="line">    <span class="keyword">val</span> iter = topk.iterator</span><br><span class="line">    <span class="keyword">while</span> (iter.hasNext) &#123;</span><br><span class="line">      putToHeap(heap, iter.next)</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    println(<span class="string">"最终结果："</span>)</span><br><span class="line">    <span class="keyword">while</span> (heap.nonEmpty) &#123;</span><br><span class="line">      println(heap.dequeue())</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    spark.stop()</span><br><span class="line"></span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">putToHeap</span></span>(heap: mutable.<span class="type">PriorityQueue</span>[(<span class="type">String</span>, <span class="type">Int</span>)], iter: (<span class="type">String</span>, <span class="type">Int</span>)): <span class="type">Unit</span> = &#123;</span><br><span class="line">    <span class="keyword">if</span> (heap.nonEmpty &amp;&amp; heap.size &gt;= <span class="type">K</span>) &#123;</span><br><span class="line">      <span class="keyword">if</span> (heap.head._2 &lt; iter._2) &#123;</span><br><span class="line">        heap += iter</span><br><span class="line">        heap.dequeue()</span><br><span class="line">      &#125;</span><br><span class="line">    &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">      heap += iter</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h1 id="PriorityQueue的使用"><a href="#PriorityQueue的使用" class="headerlink" title="PriorityQueue的使用"></a>PriorityQueue的使用</h1><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 定义</span></span><br><span class="line"><span class="comment">// 表示队列中是(String,Double),按Double排序，从小到大排序</span></span><br><span class="line"><span class="keyword">val</span> ord = <span class="type">Ordering</span>.by[(<span class="type">String</span>, <span class="type">Double</span>), <span class="type">Double</span>](_._2).reverse</span><br><span class="line"><span class="keyword">val</span> heap = <span class="keyword">new</span> mutable.<span class="type">PriorityQueue</span>[(<span class="type">String</span>, <span class="type">Double</span>)]()(ord)</span><br><span class="line"></span><br><span class="line"><span class="comment">// 插入</span></span><br><span class="line"> <span class="keyword">if</span> (heap.nonEmpty &amp;&amp; heap.size &gt;= topK) &#123;</span><br><span class="line">   <span class="keyword">if</span> (heap.head._2 &lt; similarity) &#123;</span><br><span class="line">     heap += ((x._1, similarity))</span><br><span class="line">     heap.dequeue()</span><br><span class="line">   &#125;</span><br><span class="line"> &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">   heap += ((x._1, similarity))</span><br><span class="line"> &#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 取元素</span></span><br><span class="line"><span class="keyword">if</span> (heap.nonEmpty) &#123;</span><br><span class="line">  <span class="keyword">val</span> res = heap.dequeue()</span><br><span class="line">  msv.app_code_top_1 = res._1</span><br><span class="line">  msv.similariry_top_1 = res._2</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 取元素另一种方法</span></span><br><span class="line"><span class="keyword">val</span> iter = heap.iterator</span><br><span class="line"><span class="keyword">if</span> (iter.hasNext) &#123;</span><br><span class="line">  <span class="keyword">val</span> res = iter.next()</span><br><span class="line">  msv.app_code_top_1 = res._1</span><br><span class="line">  msv.similariry_top_1 = res._2</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h1 id="mapValues的用法"><a href="#mapValues的用法" class="headerlink" title="mapValues的用法"></a>mapValues的用法</h1><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">val cluster2Cnt = dbscan.points.asScala.groupBy(_.getCluster).mapValues(_.size)</span><br></pre></td></tr></table></figure>
<p>这里的points是一个<code>List&lt;Object&gt;</code>，对Object中的某个属性做group，然后再mapValues，就返回每个属性的count的一个Map对象</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">cluster2Cnt: Map[Int, Int]</span><br></pre></td></tr></table></figure>

          
        
      
    </div>

    

    
    
    

    

    
      
    
    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  

  <article class="post post-type-normal" itemscope="" itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="https://schwimmer.github.io/2019/05/08/编程语言学习/MySQL/mysql笔记/">

    <span hidden itemprop="author" itemscope="" itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Schwimmer">
      <meta itemprop="description" content="Record and Think!">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope="" itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Schwimmer's Blog">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                
                <a href="/2019/05/08/编程语言学习/MySQL/mysql笔记/" class="post-title-link" itemprop="url">MySQL技巧总结（不断更新中）</a>
              
            
          </h1>
        

        <div class="post-meta">

          
          
          

          
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              

              
                
              

              <time title="创建时间：2019-05-08 16:30:55" itemprop="dateCreated datePublished" datetime="2019-05-08T16:30:55+08:00">2019-05-08</time>
            </span>
          

          
            

            
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="fa fa-calendar-check-o"></i>
                </span>
                
                  <span class="post-meta-item-text">更新于</span>
                
                <time title="修改时间：2019-07-03 22:55:50" itemprop="dateModified" datetime="2019-07-03T22:55:50+08:00">2019-07-03</time>
              </span>
            
          

          
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope="" itemtype="http://schema.org/Thing"><a href="/categories/MySQL/" itemprop="url" rel="index"><span itemprop="name">MySQL</span></a></span>

                
                
              
            </span>
          

          
            
            
              
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="fa fa-comment-o"></i>
                </span>
            
                <span class="post-meta-item-text">评论数：</span>
                <a href="/2019/05/08/编程语言学习/MySQL/mysql笔记/#comments" itemprop="discussionUrl">
                  <span class="post-comments-count disqus-comment-count" data-disqus-identifier="2019/05/08/编程语言学习/MySQL/mysql笔记/" itemprop="commentCount"></span>
                </a>
              </span>
            
          

          
          

          

          <br>
          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h2 id="ON-DUPLICATE-KEY-UPDATE"><a href="#ON-DUPLICATE-KEY-UPDATE" class="headerlink" title="ON DUPLICATE KEY UPDATE"></a>ON DUPLICATE KEY UPDATE</h2><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">val merge_sql = "<span class="keyword">INSERT</span> <span class="keyword">INTO</span> GPS_WARN_INFO(GPS_ID,CREATE_TIME,UPDATE_TIME,IS_TIME_INITIALIZED,HAS_TRACK,HAS_SPEED,HAS_BEEN_TO_BLACK_LIST_AREA)<span class="string">" +</span></span><br><span class="line"><span class="string">		"</span> <span class="keyword">values</span>(?,?,?,?,?,?,?) <span class="string">" +</span></span><br><span class="line"><span class="string">		"</span><span class="keyword">ON</span> <span class="keyword">DUPLICATE</span> <span class="keyword">KEY</span> <span class="keyword">UPDATE</span> <span class="string">" +</span></span><br><span class="line"><span class="string">		"</span>UPDATE_TIME=<span class="keyword">values</span>(UPDATE_TIME), <span class="string">" +</span></span><br><span class="line"><span class="string">		"</span>IS_TIME_INITIALIZED=<span class="keyword">case</span> <span class="keyword">WHEN</span> GPS_WARN_INFO.IS_TIME_INITIALIZED=<span class="number">1</span> || <span class="keyword">values</span>(IS_TIME_INITIALIZED) = <span class="number">1</span> <span class="keyword">then</span> <span class="number">1</span> <span class="keyword">else</span> <span class="number">0</span> <span class="keyword">end</span>, <span class="string">" +</span></span><br><span class="line"><span class="string">		"</span>HAS_TRACK=<span class="keyword">case</span> <span class="keyword">WHEN</span> GPS_WARN_INFO.HAS_TRACK=<span class="number">1</span> || <span class="keyword">values</span>(HAS_TRACK)=<span class="number">1</span> <span class="keyword">then</span> <span class="number">1</span> <span class="keyword">else</span> <span class="number">0</span> <span class="keyword">end</span>, <span class="string">" +</span></span><br><span class="line"><span class="string">		"</span>HAS_SPEED=<span class="keyword">case</span> <span class="keyword">WHEN</span> GPS_WARN_INFO.HAS_SPEED=<span class="number">1</span> || <span class="keyword">values</span>(HAS_SPEED)=<span class="number">1</span> <span class="keyword">then</span> <span class="number">1</span> <span class="keyword">else</span> <span class="number">0</span> <span class="keyword">end</span>, <span class="string">" +</span></span><br><span class="line"><span class="string">		"</span>HAS_BEEN_TO_BLACK_LIST_AREA=<span class="keyword">case</span> <span class="keyword">when</span> GPS_WARN_INFO.HAS_BEEN_TO_BLACK_LIST_AREA=<span class="string">''</span>||GPS_WARN_INFO.HAS_BEEN_TO_BLACK_LIST_AREA <span class="keyword">is</span> <span class="literal">null</span> <span class="keyword">then</span>  <span class="keyword">values</span>(HAS_BEEN_TO_BLACK_LIST_AREA)<span class="string">" +</span></span><br><span class="line"><span class="string">		"</span>    <span class="keyword">else</span> <span class="keyword">case</span> <span class="keyword">when</span> <span class="keyword">values</span>(HAS_BEEN_TO_BLACK_LIST_AREA) =<span class="string">''</span>|| <span class="keyword">values</span>(HAS_BEEN_TO_BLACK_LIST_AREA) <span class="keyword">is</span> <span class="literal">null</span> <span class="keyword">THEN</span>  GPS_WARN_INFO.HAS_BEEN_TO_BLACK_LIST_AREA  <span class="keyword">else</span> <span class="keyword">case</span> <span class="keyword">when</span> <span class="keyword">instr</span>(HAS_BEEN_TO_BLACK_LIST_AREA,<span class="keyword">values</span>(HAS_BEEN_TO_BLACK_LIST_AREA)) &gt;<span class="number">0</span> <span class="keyword">then</span> GPS_WARN_INFO.HAS_BEEN_TO_BLACK_LIST_AREA <span class="keyword">else</span>  <span class="keyword">CONCAT_WS</span>(<span class="string">'|'</span>,GPS_WARN_INFO.HAS_BEEN_TO_BLACK_LIST_AREA,<span class="keyword">values</span>(HAS_BEEN_TO_BLACK_LIST_AREA)) <span class="keyword">end</span> <span class="keyword">end</span> <span class="keyword">end</span><span class="string">"</span></span><br></pre></td></tr></table></figure>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">val merge_sql = "<span class="keyword">INSERT</span> <span class="keyword">INTO</span> GPS_WARN_INFO(GPS_ID,CREATE_TIME,UPDATE_TIME,IS_TIME_INITIALIZED,HAS_TRACK,HAS_SPEED,HAS_BEEN_TO_BLACK_LIST_AREA)<span class="string">" +</span></span><br><span class="line"><span class="string">		"</span> <span class="keyword">values</span>(?,?,?,?,?,?,?) <span class="string">" +</span></span><br><span class="line"><span class="string">		"</span><span class="keyword">ON</span> <span class="keyword">DUPLICATE</span> <span class="keyword">KEY</span> <span class="keyword">UPDATE</span> <span class="string">" +</span></span><br><span class="line"><span class="string">		"</span>UPDATE_TIME=<span class="keyword">values</span>(UPDATE_TIME), <span class="string">" +   </span></span><br><span class="line"><span class="string">		"</span>IS_TIME_INITIALIZED=GPS_WARN_INFO.IS_TIME_INITIALIZED<span class="string">";</span></span><br></pre></td></tr></table></figure>
<h1 id="删除主键"><a href="#删除主键" class="headerlink" title="删除主键"></a>删除主键</h1><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">alter table gps_analysis_wx_cluster drop primary key ;</span><br></pre></td></tr></table></figure>
<h1 id="增加主键、自增并放到第一个字段"><a href="#增加主键、自增并放到第一个字段" class="headerlink" title="增加主键、自增并放到第一个字段"></a>增加主键、自增并放到第一个字段</h1><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ALTER TABLE gps_analysis_wx_cluster ADD `id` BIGINT(20) NOT NULL PRIMARY KEY AUTO_INCREMENT FIRST;</span><br></pre></td></tr></table></figure>
<h1 id="增加字段"><a href="#增加字段" class="headerlink" title="增加字段"></a>增加字段</h1><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">alter table gps_analysis_wx_cluster add column `id` bigint(20) NOT NULL AUTO_INCREMENT COMMENT &apos;主键&apos;;</span><br></pre></td></tr></table></figure>
<h1 id="删除索引"><a href="#删除索引" class="headerlink" title="删除索引"></a>删除索引</h1><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">ALTER TABLE gps_analysis_wx_cluster </span><br><span class="line">DROP INDEX data_date_index</span><br></pre></td></tr></table></figure>

          
        
      
    </div>

    

    
    
    

    

    
      
    
    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  

  <article class="post post-type-normal" itemscope="" itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="https://schwimmer.github.io/2019/05/04/深度学习笔记/tensorflow/基础-莫烦教程/5-1 分类学习/">

    <span hidden itemprop="author" itemscope="" itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Schwimmer">
      <meta itemprop="description" content="Record and Think!">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope="" itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Schwimmer's Blog">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                
                <a href="/2019/05/04/深度学习笔记/tensorflow/基础-莫烦教程/5-1 分类学习/" class="post-title-link" itemprop="url">未命名</a>
              
            
          </h1>
        

        <div class="post-meta">

          
          
          

          
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              

              
                
              

              <time title="创建时间：2019-05-04 10:46:30" itemprop="dateCreated datePublished" datetime="2019-05-04T10:46:30+08:00">2019-05-04</time>
            </span>
          

          
            

            
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="fa fa-calendar-check-o"></i>
                </span>
                
                  <span class="post-meta-item-text">更新于</span>
                
                <time title="修改时间：2019-05-21 23:17:21" itemprop="dateModified" datetime="2019-05-21T23:17:21+08:00">2019-05-21</time>
              </span>
            
          

          

          
            
            
              
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="fa fa-comment-o"></i>
                </span>
            
                <span class="post-meta-item-text">评论数：</span>
                <a href="/2019/05/04/深度学习笔记/tensorflow/基础-莫烦教程/5-1 分类学习/#comments" itemprop="discussionUrl">
                  <span class="post-comments-count disqus-comment-count" data-disqus-identifier="2019/05/04/深度学习笔记/tensorflow/基础-莫烦教程/5-1 分类学习/" itemprop="commentCount"></span>
                </a>
              </span>
            
          

          
          

          

          <br>
          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p><a href="https://morvanzhou.github.io/tutorials/machine-learning/tensorflow/5-01-classifier/" target="_blank" rel="noopener">https://morvanzhou.github.io/tutorials/machine-learning/tensorflow/5-01-classifier/</a></p>
<h2 id="MNIST-数据"><a href="#MNIST-数据" class="headerlink" title="MNIST 数据"></a>MNIST 数据</h2><p>首先准备数据（MNIST库）</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">from tensorflow.examples.tutorials.mnist import input_data</span><br><span class="line">mnist = input_data.read_data_sets(&apos;MNIST_data&apos;, one_hot=True)</span><br></pre></td></tr></table></figure>
<h2 id="搭建网络"><a href="#搭建网络" class="headerlink" title="搭建网络"></a>搭建网络</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">xs = tf.placeholder(tf.float32, [None, 784]) # 28x28</span><br></pre></td></tr></table></figure>
<p>每张图片都表示一个数字，所以我们的输出是数字0到9，共10类。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ys = tf.placeholder(tf.float32, [None, 10])</span><br></pre></td></tr></table></figure>
<p>调用add_layer函数搭建一个最简单的训练网络结构，只有输入层和输出层。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">prediction = add_layer(xs, 784, 10, activation_function=tf.nn.softmax)</span><br></pre></td></tr></table></figure>
<p>其中输入数据是784个特征，输出数据是10个特征，激励采用softmax函数，网络结构图是这样子的</p>
<p><img src="/.io//pic/5_01_2.png" alt="img"></p>
<h2 id="Cross-entropy-loss"><a href="#Cross-entropy-loss" class="headerlink" title="Cross entropy loss"></a>Cross entropy loss</h2><p>loss函数（即最优化目标函数）选用交叉熵函数。交叉熵用来衡量预测值和真实值的相似程度，如果完全相同，它们的交叉熵等于零。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">cross_entropy = tf.reduce_mean(-tf.reduce_sum(ys * tf.log(prediction),</span><br><span class="line">reduction_indices=[1])) # loss</span><br></pre></td></tr></table></figure>
<p>train方法（最优化算法）采用梯度下降法。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">train_step = tf.train.GradientDescentOptimizer(0.5).minimize(cross_entropy)</span><br><span class="line">sess = tf.Session()</span><br><span class="line"># tf.initialize_all_variables() 这种写法马上就要被废弃</span><br><span class="line"># 替换成下面的写法:</span><br><span class="line">sess.run(tf.global_variables_initializer())</span><br></pre></td></tr></table></figure>
<h2 id="训练"><a href="#训练" class="headerlink" title="训练"></a>训练</h2><p>现在开始train，每次只取100张图片，免得数据太多训练太慢。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">batch_xs, batch_ys = mnist.train.next_batch(100)</span><br><span class="line">sess.run(train_step, feed_dict=&#123;xs: batch_xs, ys: batch_ys&#125;)</span><br></pre></td></tr></table></figure>
<p>每训练50次输出一下预测精度</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">if i % 50 == 0:</span><br><span class="line">        print(compute_accuracy(</span><br><span class="line">            mnist.test.images, mnist.test.labels))</span><br></pre></td></tr></table></figure>
<p>输出结果如下：</p>
<p><img src="/.io//pic/5_01_3.png" alt="Classification åç±»å­¦ä¹ "></p>
<h1 id="Dropout解决过拟合"><a href="#Dropout解决过拟合" class="headerlink" title="Dropout解决过拟合"></a>Dropout解决过拟合</h1><h2 id="建立-dropout-层"><a href="#建立-dropout-层" class="headerlink" title="建立 dropout 层"></a>建立 dropout 层</h2><p>本次内容需要使用一下 sklearn 数据库当中的数据,  没有安装 sklearn 的同学可以参考一下<a href="https://morvanzhou.github.io/tutorials/machine-learning/sklearn/1-2-install/" target="_blank" rel="noopener">这个教程</a> 安装一下. 然后 <code>import</code> 以下模块.</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">import tensorflow as tf</span><br><span class="line">from sklearn.datasets import load_digits</span><br><span class="line">from sklearn.cross_validation import train_test_split</span><br><span class="line">from sklearn.preprocessing import LabelBinarizer</span><br><span class="line"></span><br><span class="line">keep_prob = tf.placeholder(tf.float32)</span><br><span class="line">...</span><br><span class="line">...</span><br><span class="line">Wx_plus_b = tf.nn.dropout(Wx_plus_b, keep_prob)</span><br></pre></td></tr></table></figure>
<p>这里的<code>keep_prob</code>是保留概率，即我们要保留的结果所占比例，它作为一个<code>placeholder</code>，在<code>run</code>时传入， 当<code>keep_prob=1</code>的时候，相当于100%保留，也就是dropout没有起作用。 下面我们分析一下程序结构，首先准备数据，</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">digits = load_digits()</span><br><span class="line">X = digits.data</span><br><span class="line">y = digits.target</span><br><span class="line">y = LabelBinarizer().fit_transform(y)</span><br><span class="line">X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.3)</span><br></pre></td></tr></table></figure>
<p>其中<code>X_train</code>是训练数据, <code>X_test</code>是测试数据。 然后添加隐含层和输出层</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"># add output layer</span><br><span class="line">l1 = add_layer(xs, 64, 50, &apos;l1&apos;, activation_function=tf.nn.tanh)</span><br><span class="line">prediction = add_layer(l1, 50, 10, &apos;l2&apos;, activation_function=tf.nn.softmax)</span><br></pre></td></tr></table></figure>
<p>loss函数（即最优化目标函数）选用交叉熵函数。交叉熵用来衡量预测值和真实值的相似程度，如果完全相同，交叉熵就等于零。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">cross_entropy = tf.reduce_mean(-tf.reduce_sum(ys * tf.log(prediction),</span><br><span class="line">                                              reduction_indices=[1]))  # loss</span><br></pre></td></tr></table></figure>
<p>train方法（最优化算法）采用梯度下降法。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">train_step = tf.train.GradientDescentOptimizer(0.5).minimize(cross_entropy)</span><br></pre></td></tr></table></figure>
<h2 id="训练-1"><a href="#训练-1" class="headerlink" title="训练"></a>训练</h2><p>最后开始train，总共训练500次。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">sess.run(train_step, feed_dict=&#123;xs: X_train, ys: y_train, keep_prob: 0.5&#125;)</span><br><span class="line">#sess.run(train_step, feed_dict=&#123;xs: X_train, ys: y_train, keep_prob: 1&#125;)</span><br></pre></td></tr></table></figure>
<h2 id="可视化结果"><a href="#可视化结果" class="headerlink" title="可视化结果"></a>可视化结果</h2><p>训练中<code>keep_prob=1</code>时，就可以暴露出overfitting问题。<code>keep_prob=0.5</code>时，<code>dropout</code>就发挥了作用。 我们可以两种参数分别运行程序，对比一下结果。</p>
<p>当<code>keep_prob=1</code>时，模型对训练数据的适应性优于测试数据，存在overfitting，输出如下： 红线是 <code>train</code> 的误差, 蓝线是 <code>test</code> 的误差.</p>
<p><a href="https://github.com/MorvanZhou/Tensorflow-Tutorial" target="_blank" rel="noopener">https://github.com/MorvanZhou/Tensorflow-Tutorial</a></p>
<p>这里有简化版代码</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">"""</span></span><br><span class="line"><span class="string">Know more, visit my Python tutorial page: https://morvanzhou.github.io/tutorials/</span></span><br><span class="line"><span class="string">My Youtube Channel: https://www.youtube.com/user/MorvanZhou</span></span><br><span class="line"><span class="string">Dependencies:</span></span><br><span class="line"><span class="string">tensorflow: 1.1.0</span></span><br><span class="line"><span class="string">matplotlib</span></span><br><span class="line"><span class="string">numpy</span></span><br><span class="line"><span class="string">"""</span></span><br><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"></span><br><span class="line">tf.set_random_seed(<span class="number">1</span>)</span><br><span class="line">np.random.seed(<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Hyper parameters</span></span><br><span class="line">N_SAMPLES = <span class="number">20</span></span><br><span class="line">N_HIDDEN = <span class="number">300</span></span><br><span class="line">LR = <span class="number">0.01</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># training data</span></span><br><span class="line">x = np.linspace(<span class="number">-1</span>, <span class="number">1</span>, N_SAMPLES)[:, np.newaxis]</span><br><span class="line">y = x + <span class="number">0.3</span>*np.random.randn(N_SAMPLES)[:, np.newaxis]</span><br><span class="line"></span><br><span class="line"><span class="comment"># test data</span></span><br><span class="line">test_x = x.copy()</span><br><span class="line">test_y = test_x + <span class="number">0.3</span>*np.random.randn(N_SAMPLES)[:, np.newaxis]</span><br><span class="line"></span><br><span class="line"><span class="comment"># show data</span></span><br><span class="line">plt.scatter(x, y, c=<span class="string">'magenta'</span>, s=<span class="number">50</span>, alpha=<span class="number">0.5</span>, label=<span class="string">'train'</span>)</span><br><span class="line">plt.scatter(test_x, test_y, c=<span class="string">'cyan'</span>, s=<span class="number">50</span>, alpha=<span class="number">0.5</span>, label=<span class="string">'test'</span>)</span><br><span class="line">plt.legend(loc=<span class="string">'upper left'</span>)</span><br><span class="line">plt.ylim((<span class="number">-2.5</span>, <span class="number">2.5</span>))</span><br><span class="line">plt.show()</span><br><span class="line"></span><br><span class="line"><span class="comment"># tf placeholders</span></span><br><span class="line">tf_x = tf.placeholder(tf.float32, [<span class="keyword">None</span>, <span class="number">1</span>])</span><br><span class="line">tf_y = tf.placeholder(tf.float32, [<span class="keyword">None</span>, <span class="number">1</span>])</span><br><span class="line">tf_is_training = tf.placeholder(tf.bool, <span class="keyword">None</span>)  <span class="comment"># to control dropout when training and testing</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># overfitting net</span></span><br><span class="line">o1 = tf.layers.dense(tf_x, N_HIDDEN, tf.nn.relu)</span><br><span class="line">o2 = tf.layers.dense(o1, N_HIDDEN, tf.nn.relu)</span><br><span class="line">o_out = tf.layers.dense(o2, <span class="number">1</span>)</span><br><span class="line">o_loss = tf.losses.mean_squared_error(tf_y, o_out)</span><br><span class="line">o_train = tf.train.AdamOptimizer(LR).minimize(o_loss)</span><br><span class="line"></span><br><span class="line"><span class="comment"># dropout net</span></span><br><span class="line">d1 = tf.layers.dense(tf_x, N_HIDDEN, tf.nn.relu)</span><br><span class="line">d1 = tf.layers.dropout(d1, rate=<span class="number">0.5</span>, training=tf_is_training)   <span class="comment"># drop out 50% of inputs</span></span><br><span class="line">d2 = tf.layers.dense(d1, N_HIDDEN, tf.nn.relu)</span><br><span class="line">d2 = tf.layers.dropout(d2, rate=<span class="number">0.5</span>, training=tf_is_training)   <span class="comment"># drop out 50% of inputs</span></span><br><span class="line">d_out = tf.layers.dense(d2, <span class="number">1</span>)</span><br><span class="line">d_loss = tf.losses.mean_squared_error(tf_y, d_out)</span><br><span class="line">d_train = tf.train.AdamOptimizer(LR).minimize(d_loss)</span><br><span class="line"></span><br><span class="line">sess = tf.Session()</span><br><span class="line">sess.run(tf.global_variables_initializer())</span><br><span class="line"></span><br><span class="line">plt.ion()   <span class="comment"># something about plotting</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> t <span class="keyword">in</span> range(<span class="number">500</span>):</span><br><span class="line">    sess.run([o_train, d_train], &#123;tf_x: x, tf_y: y, tf_is_training: <span class="keyword">True</span>&#125;)  <span class="comment"># train, set is_training=True</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> t % <span class="number">10</span> == <span class="number">0</span>:</span><br><span class="line">        <span class="comment"># plotting</span></span><br><span class="line">        plt.cla()</span><br><span class="line">        o_loss_, d_loss_, o_out_, d_out_ = sess.run(</span><br><span class="line">            [o_loss, d_loss, o_out, d_out], &#123;tf_x: test_x, tf_y: test_y, tf_is_training: <span class="keyword">False</span>&#125; <span class="comment"># test, set is_training=False</span></span><br><span class="line">        )</span><br><span class="line">        plt.scatter(x, y, c=<span class="string">'magenta'</span>, s=<span class="number">50</span>, alpha=<span class="number">0.3</span>, label=<span class="string">'train'</span>); plt.scatter(test_x, test_y, c=<span class="string">'cyan'</span>, s=<span class="number">50</span>, alpha=<span class="number">0.3</span>, label=<span class="string">'test'</span>)</span><br><span class="line">        plt.plot(test_x, o_out_, <span class="string">'r-'</span>, lw=<span class="number">3</span>, label=<span class="string">'overfitting'</span>); plt.plot(test_x, d_out_, <span class="string">'b--'</span>, lw=<span class="number">3</span>, label=<span class="string">'dropout(50%)'</span>)</span><br><span class="line">        plt.text(<span class="number">0</span>, <span class="number">-1.2</span>, <span class="string">'overfitting loss=%.4f'</span> % o_loss_, fontdict=&#123;<span class="string">'size'</span>: <span class="number">20</span>, <span class="string">'color'</span>:  <span class="string">'red'</span>&#125;); plt.text(<span class="number">0</span>, <span class="number">-1.5</span>, <span class="string">'dropout loss=%.4f'</span> % d_loss_, fontdict=&#123;<span class="string">'size'</span>: <span class="number">20</span>, <span class="string">'color'</span>: <span class="string">'blue'</span>&#125;)</span><br><span class="line">        plt.legend(loc=<span class="string">'upper left'</span>); plt.ylim((<span class="number">-2.5</span>, <span class="number">2.5</span>)); plt.pause(<span class="number">0.1</span>)</span><br><span class="line"></span><br><span class="line">plt.ioff()</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>

          
        
      
    </div>

    

    
    
    

    

    
      
    
    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
  </section>

  
  <nav class="pagination">
    <a class="extend prev" rel="prev" href="/page/5/"><i class="fa fa-angle-left" aria-label="上一页"></i></a><a class="page-number" href="/">1</a><span class="space">&hellip;</span><a class="page-number" href="/page/5/">5</a><span class="page-number current">6</span><a class="page-number" href="/page/7/">7</a><span class="space">&hellip;</span><a class="page-number" href="/page/32/">32</a><a class="extend next" rel="next" href="/page/7/"><i class="fa fa-angle-right" aria-label="下一页"></i></a>
  </nav>



          </div>
          

        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    <div class="sidebar-inner">

      

      

      <div class="site-overview-wrap sidebar-panel sidebar-panel-active">
        <div class="site-overview">
          <div class="site-author motion-element" itemprop="author" itemscope="" itemtype="http://schema.org/Person">
            
              <p class="site-author-name" itemprop="name">Schwimmer</p>
              <div class="site-description motion-element" itemprop="description">Record and Think!</div>
          </div>

          
            <nav class="site-state motion-element">
              
                <div class="site-state-item site-state-posts">
                
                  <a href="/archives/">
                
                    <span class="site-state-item-count">314</span>
                    <span class="site-state-item-name">日志</span>
                  </a>
                </div>
              

              
                
                
                <div class="site-state-item site-state-categories">
                  
                    
                      <a href="/categories/">
                    
                  
                    
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                    <span class="site-state-item-count">22</span>
                    <span class="site-state-item-name">分类</span>
                  </a>
                </div>
              

              
                
                
                <div class="site-state-item site-state-tags">
                  
                    
                      <a href="/tags/">
                    
                  
                    
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                    <span class="site-state-item-count">59</span>
                    <span class="site-state-item-name">标签</span>
                  </a>
                </div>
              
            </nav>
          

          

          

          

          

          
          

          
            
          
          

        </div>
      </div>

      

      

    </div>
  </aside>
  


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <div class="copyright">&copy; <span itemprop="copyrightYear">2019</span>
  <span class="with-love" id="animate">
    <i class="fa fa-user"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">Schwimmer</span>

  

  
</div>


  <div class="powered-by">由 <a href="https://hexo.io" class="theme-link" rel="noopener" target="_blank">Hexo</a> 强力驱动 v3.9.0</div>



  <span class="post-meta-divider">|</span>



  <div class="theme-info">主题 – <a href="https://theme-next.org" class="theme-link" rel="noopener" target="_blank">NexT.Mist</a> v7.2.0</div>




        
<div class="busuanzi-count">
  <script async src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>

  
    <span class="post-meta-item-icon">
      <i class="fa fa-user"></i>
    </span>
    <span class="site-uv" title="总访客量">
      <span class="busuanzi-value" id="busuanzi_value_site_uv"></span>
    </span>
  

  
    <span class="post-meta-divider">|</span>
  

  
    <span class="post-meta-item-icon">
      <i class="fa fa-eye"></i>
    </span>
    <span class="site-pv" title="总访问量">
      <span class="busuanzi-value" id="busuanzi_value_site_pv"></span>
    </span>
  
</div>









        
      </div>
    </footer>

    
      <div class="back-to-top">
        <i class="fa fa-arrow-up"></i>
        
      </div>
    

    

    
      <div>
        
  <script>
    window._bd_share_config = {
      "common": {
        "bdText": "",
        "bdMini": "1",
        "bdMiniList": false,
        "bdPic": ""
      },
      "image": {
        "viewList": ["tsina", "douban", "sqq", "qzone", "weixin", "twi", "fbook"],
        "viewText": "分享到：",
        "viewSize": "16"
      },
      "slide": {
        "bdImg": "5",
        "bdPos": "left",
        "bdTop": "100"
      }
    }
  </script>

<script>
  with(document)0[(getElementsByTagName('head')[0]||body).appendChild(createElement('script')).src='//bdimg.share.baidu.com/static/api/js/share.js?cdnversion='+~(-new Date()/36e5)];
</script>

      </div>
    

    
  </div>

  

<script>
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>


























  
  <script src="/lib/jquery/index.js?v=3.4.1"></script>

  
  <script src="/lib/velocity/velocity.min.js?v=1.2.1"></script>

  
  <script src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>


  


  <script src="/js/utils.js?v=7.2.0"></script>

  <script src="/js/motion.js?v=7.2.0"></script>



  
  


  <script src="/js/schemes/muse.js?v=7.2.0"></script>




  

  


  <script src="/js/next-boot.js?v=7.2.0"></script>


  

  

  

  
  
<script>
  function loadCount() {
    var d = document, s = d.createElement('script');
    s.src = 'https://https-schwimmer-github-io.disqus.com/count.js';
    s.id = 'dsq-count-scr';
    (d.head || d.body).appendChild(s);
  }
  // defer loading until the whole page loading is completed
  window.addEventListener('load', loadCount, false);
</script>







  
  <script>
    // Popup Window;
    var isfetched = false;
    var isXml = true;
    // Search DB path;
    var search_path = "search.xml";
    if (search_path.length === 0) {
      search_path = "search.xml";
    } else if (/json$/i.test(search_path)) {
      isXml = false;
    }
    var path = "/" + search_path;
    // monitor main search box;

    var onPopupClose = function (e) {
      $('.popup').hide();
      $('#local-search-input').val('');
      $('.search-result-list').remove();
      $('#no-result').remove();
      $(".local-search-pop-overlay").remove();
      $('body').css('overflow', '');
    }

    function proceedsearch() {
      $("body")
        .append('<div class="search-popup-overlay local-search-pop-overlay"></div>')
        .css('overflow', 'hidden');
      $('.search-popup-overlay').click(onPopupClose);
      $('.popup').toggle();
      var $localSearchInput = $('#local-search-input');
      $localSearchInput.attr("autocapitalize", "none");
      $localSearchInput.attr("autocorrect", "off");
      $localSearchInput.focus();
    }

    // search function;
    var searchFunc = function(path, search_id, content_id) {
      'use strict';

      // start loading animation
      $("body")
        .append('<div class="search-popup-overlay local-search-pop-overlay">' +
          '<div id="search-loading-icon">' +
          '<i class="fa fa-spinner fa-pulse fa-5x fa-fw"></i>' +
          '</div>' +
          '</div>')
        .css('overflow', 'hidden');
      $("#search-loading-icon").css('margin', '20% auto 0 auto').css('text-align', 'center');

      

      $.ajax({
        url: path,
        dataType: isXml ? "xml" : "json",
        async: true,
        success: function(res) {
          // get the contents from search data
          isfetched = true;
          $('.popup').detach().appendTo('.header-inner');
          var datas = isXml ? $("entry", res).map(function() {
            return {
              title: $("title", this).text(),
              content: $("content",this).text(),
              url: $("url" , this).text()
            };
          }).get() : res;
          var input = document.getElementById(search_id);
          var resultContent = document.getElementById(content_id);
          var inputEventFunction = function() {
            var searchText = input.value.trim().toLowerCase();
            var keywords = searchText.split(/[\s\-]+/);
            if (keywords.length > 1) {
              keywords.push(searchText);
            }
            var resultItems = [];
            if (searchText.length > 0) {
              // perform local searching
              datas.forEach(function(data) {
                var isMatch = false;
                var hitCount = 0;
                var searchTextCount = 0;
                var title = data.title.trim();
                var titleInLowerCase = title.toLowerCase();
                var content = data.content.trim().replace(/<[^>]+>/g,"");
                
                var contentInLowerCase = content.toLowerCase();
                var articleUrl = decodeURIComponent(data.url).replace(/\/{2,}/g, '/');
                var indexOfTitle = [];
                var indexOfContent = [];
                // only match articles with not empty titles
                if(title != '') {
                  keywords.forEach(function(keyword) {
                    function getIndexByWord(word, text, caseSensitive) {
                      var wordLen = word.length;
                      if (wordLen === 0) {
                        return [];
                      }
                      var startPosition = 0, position = [], index = [];
                      if (!caseSensitive) {
                        text = text.toLowerCase();
                        word = word.toLowerCase();
                      }
                      while ((position = text.indexOf(word, startPosition)) > -1) {
                        index.push({position: position, word: word});
                        startPosition = position + wordLen;
                      }
                      return index;
                    }

                    indexOfTitle = indexOfTitle.concat(getIndexByWord(keyword, titleInLowerCase, false));
                    indexOfContent = indexOfContent.concat(getIndexByWord(keyword, contentInLowerCase, false));
                  });
                  if (indexOfTitle.length > 0 || indexOfContent.length > 0) {
                    isMatch = true;
                    hitCount = indexOfTitle.length + indexOfContent.length;
                  }
                }

                // show search results

                if (isMatch) {
                  // sort index by position of keyword

                  [indexOfTitle, indexOfContent].forEach(function (index) {
                    index.sort(function (itemLeft, itemRight) {
                      if (itemRight.position !== itemLeft.position) {
                        return itemRight.position - itemLeft.position;
                      } else {
                        return itemLeft.word.length - itemRight.word.length;
                      }
                    });
                  });

                  // merge hits into slices

                  function mergeIntoSlice(text, start, end, index) {
                    var item = index[index.length - 1];
                    var position = item.position;
                    var word = item.word;
                    var hits = [];
                    var searchTextCountInSlice = 0;
                    while (position + word.length <= end && index.length != 0) {
                      if (word === searchText) {
                        searchTextCountInSlice++;
                      }
                      hits.push({position: position, length: word.length});
                      var wordEnd = position + word.length;

                      // move to next position of hit

                      index.pop();
                      while (index.length != 0) {
                        item = index[index.length - 1];
                        position = item.position;
                        word = item.word;
                        if (wordEnd > position) {
                          index.pop();
                        } else {
                          break;
                        }
                      }
                    }
                    searchTextCount += searchTextCountInSlice;
                    return {
                      hits: hits,
                      start: start,
                      end: end,
                      searchTextCount: searchTextCountInSlice
                    };
                  }

                  var slicesOfTitle = [];
                  if (indexOfTitle.length != 0) {
                    slicesOfTitle.push(mergeIntoSlice(title, 0, title.length, indexOfTitle));
                  }

                  var slicesOfContent = [];
                  while (indexOfContent.length != 0) {
                    var item = indexOfContent[indexOfContent.length - 1];
                    var position = item.position;
                    var word = item.word;
                    // cut out 100 characters
                    var start = position - 20;
                    var end = position + 80;
                    if(start < 0){
                      start = 0;
                    }
                    if (end < position + word.length) {
                      end = position + word.length;
                    }
                    if(end > content.length){
                      end = content.length;
                    }
                    slicesOfContent.push(mergeIntoSlice(content, start, end, indexOfContent));
                  }

                  // sort slices in content by search text's count and hits' count

                  slicesOfContent.sort(function (sliceLeft, sliceRight) {
                    if (sliceLeft.searchTextCount !== sliceRight.searchTextCount) {
                      return sliceRight.searchTextCount - sliceLeft.searchTextCount;
                    } else if (sliceLeft.hits.length !== sliceRight.hits.length) {
                      return sliceRight.hits.length - sliceLeft.hits.length;
                    } else {
                      return sliceLeft.start - sliceRight.start;
                    }
                  });

                  // select top N slices in content

                  var upperBound = parseInt('1');
                  if (upperBound >= 0) {
                    slicesOfContent = slicesOfContent.slice(0, upperBound);
                  }

                  // highlight title and content

                  function highlightKeyword(text, slice) {
                    var result = '';
                    var prevEnd = slice.start;
                    slice.hits.forEach(function (hit) {
                      result += text.substring(prevEnd, hit.position);
                      var end = hit.position + hit.length;
                      result += '<b class="search-keyword">' + text.substring(hit.position, end) + '</b>';
                      prevEnd = end;
                    });
                    result += text.substring(prevEnd, slice.end);
                    return result;
                  }

                  var resultItem = '';

                  if (slicesOfTitle.length != 0) {
                    resultItem += "<li><a href='" + articleUrl + "' class='search-result-title'>" + highlightKeyword(title, slicesOfTitle[0]) + "</a>";
                  } else {
                    resultItem += "<li><a href='" + articleUrl + "' class='search-result-title'>" + title + "</a>";
                  }

                  slicesOfContent.forEach(function (slice) {
                    resultItem += "<a href='" + articleUrl + "'>" +
                      "<p class=\"search-result\">" + highlightKeyword(content, slice) +
                      "...</p>" + "</a>";
                  });

                  resultItem += "</li>";
                  resultItems.push({
                    item: resultItem,
                    searchTextCount: searchTextCount,
                    hitCount: hitCount,
                    id: resultItems.length
                  });
                }
              })
            };
            if (keywords.length === 1 && keywords[0] === "") {
              resultContent.innerHTML = '<div id="no-result"><i class="fa fa-search fa-5x"></i></div>'
            } else if (resultItems.length === 0) {
              resultContent.innerHTML = '<div id="no-result"><i class="fa fa-frown-o fa-5x"></i></div>'
            } else {
              resultItems.sort(function (resultLeft, resultRight) {
                if (resultLeft.searchTextCount !== resultRight.searchTextCount) {
                  return resultRight.searchTextCount - resultLeft.searchTextCount;
                } else if (resultLeft.hitCount !== resultRight.hitCount) {
                  return resultRight.hitCount - resultLeft.hitCount;
                } else {
                  return resultRight.id - resultLeft.id;
                }
              });
              var searchResultList = '<ul class=\"search-result-list\">';
              resultItems.forEach(function (result) {
                searchResultList += result.item;
              })
              searchResultList += "</ul>";
              resultContent.innerHTML = searchResultList;
            }
          }

          if ('auto' === 'auto') {
            input.addEventListener('input', inputEventFunction);
          } else {
            $('.search-icon').click(inputEventFunction);
            input.addEventListener('keypress', function (event) {
              if (event.keyCode === 13) {
                inputEventFunction();
              }
            });
          }

          // remove loading animation
          $(".local-search-pop-overlay").remove();
          $('body').css('overflow', '');

          proceedsearch();
        }
      });
    }

    // handle and trigger popup window;
    $('.popup-trigger').click(function(e) {
      e.stopPropagation();
      if (isfetched === false) {
        searchFunc(path, 'local-search-input', 'local-search-result');
      } else {
        proceedsearch();
      };
    });

    $('.popup-btn-close').click(onPopupClose);
    $('.popup').click(function(e){
      e.stopPropagation();
    });
    $(document).on('keyup', function (event) {
      var shouldDismissSearchPopup = event.which === 27 &&
        $('.search-popup').is(':visible');
      if (shouldDismissSearchPopup) {
        onPopupClose();
      }
    });
  </script>





  

  

  
  

  
  
    
      
    
      
    
      
    
      
    
      
    
      
    
      
    
      
    
      
    
      
    
  

  
    
      <script type="text/x-mathjax-config">
  

  MathJax.Hub.Config({
    tex2jax: {
      inlineMath: [ ['$', '$'], ['\\(', '\\)'] ],
      processEscapes: true,
      skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
    },
    TeX: {
      
      equationNumbers: {
        autoNumber: 'AMS'
      }
    }
  });
  MathJax.Hub.Register.StartupHook('TeX Jax Ready', function() {
    MathJax.InputJax.TeX.prefilterHooks.Add(function(data) {
      if (data.display) {
        var next = data.script.nextSibling;
        while (next && next.nodeName.toLowerCase() === '#text') { next = next.nextSibling }
        if (next && next.nodeName.toLowerCase() === 'br') { next.parentNode.removeChild(next) }
      }
    });
  });
</script>

<script type="text/x-mathjax-config">
  MathJax.Hub.Queue(function() {
    var all = MathJax.Hub.getAllJax(), i;
    for (i = 0; i < all.length; i += 1) {
      document.getElementById(all[i].inputID + '-Frame').parentNode.className += ' has-jax';
    }
  });
</script>
<script src="//cdn.jsdelivr.net/npm/mathjax@2/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script><!-- hexo-inject:begin --><!-- Begin: Injected MathJax -->
<script type="text/x-mathjax-config">
  MathJax.Hub.Config({"tex2jax":{"inlineMath":[["$","$"],["\\(","\\)"]],"skipTags":["script","noscript","style","textarea","pre","code"],"processEscapes":true},"TeX":{"equationNumbers":{"autoNumber":"AMS"}}});
</script>

<script type="text/x-mathjax-config">
  MathJax.Hub.Queue(function() {
    var all = MathJax.Hub.getAllJax(), i;
    for(i=0; i < all.length; i += 1) {
      all[i].SourceElement().parentNode.className += ' has-jax';
    }
  });
</script>

<script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js">
</script>
<!-- End: Injected MathJax -->
<!-- hexo-inject:end -->

    
  


  

  

  

  

  

  

  

  

  

  

  

</body>
</html>
