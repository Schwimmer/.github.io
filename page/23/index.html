<!DOCTYPE html>












  


<html class="theme-next mist use-motion" lang="zh-CN">
<head><meta name="generator" content="Hexo 3.9.0">
  <!-- hexo-inject:begin --><!-- hexo-inject:end --><meta charset="UTF-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">






















<link rel="stylesheet" href="/lib/font-awesome/css/font-awesome.min.css?v=4.7.0">

<link rel="stylesheet" href="/css/main.css?v=7.2.0">


  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png?v=7.2.0">


  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png?v=7.2.0">


  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png?v=7.2.0">


  <link rel="mask-icon" href="/images/logo.svg?v=7.2.0" color="#222">







<script id="hexo.configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '/',
    scheme: 'Mist',
    version: '7.2.0',
    sidebar: {"position":"left","display":"post","offset":12,"onmobile":false,"dimmer":false},
    back2top: true,
    back2top_sidebar: false,
    fancybox: false,
    fastclick: false,
    lazyload: false,
    tabs: true,
    motion: {"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},
    algolia: {
      applicationID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    }
  };
</script>


  




  <meta name="description" content="Record and Think!">
<meta property="og:type" content="website">
<meta property="og:title" content="Schwimmer&#39;s Blog">
<meta property="og:url" content="https://schwimmer.github.io/page/23/index.html">
<meta property="og:site_name" content="Schwimmer&#39;s Blog">
<meta property="og:description" content="Record and Think!">
<meta property="og:locale" content="zh-CN">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Schwimmer&#39;s Blog">
<meta name="twitter:description" content="Record and Think!">





  
  
  <link rel="canonical" href="https://schwimmer.github.io/page/23/">



<script id="page.configurations">
  CONFIG.page = {
    sidebar: "",
  };
</script>

  <title>Schwimmer's Blog</title>
  




  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-143240576-1"></script>
  <script>
    var host = window.location.hostname;
    if (host !== "localhost" || !true) {
      window.dataLayer = window.dataLayer || [];
      function gtag(){dataLayer.push(arguments);}
      gtag('js', new Date());
      gtag('config', 'UA-143240576-1');
    }
  </script>









  <noscript>
  <style>
  .use-motion .motion-element,
  .use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-title { opacity: initial; }

  .use-motion .logo,
  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript><!-- hexo-inject:begin --><!-- hexo-inject:end -->

</head>

<body itemscope="" itemtype="http://schema.org/WebPage" lang="zh-CN">

  
  
    
  

  <!-- hexo-inject:begin --><!-- hexo-inject:end --><div class="container sidebar-position-left 
  page-home">
    <div class="headband"></div>

    <header id="header" class="header" itemscope="" itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-wrapper">
  <div class="site-meta">
    

    <div class="custom-logo-site-title">
      <a href="/" class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">Schwimmer's Blog</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
    
    
  </div>

  <div class="site-nav-toggle">
    <button aria-label="切换导航栏">
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
    </button>
  </div>
</div>



<nav class="site-nav">
  
    <ul id="menu" class="menu">
      
        
        
        
          
          <li class="menu-item menu-item-home">

    
    
      
    

    

    <a href="/" rel="section"><i class="menu-item-icon fa fa-fw fa-home"></i> <br>首页</a>

  </li>
        
        
        
          
          <li class="menu-item menu-item-tags">

    
    
      
    

    

    <a href="/tags/" rel="section"><i class="menu-item-icon fa fa-fw fa-tags"></i> <br>标签</a>

  </li>
        
        
        
          
          <li class="menu-item menu-item-categories">

    
    
      
    

    

    <a href="/categories/" rel="section"><i class="menu-item-icon fa fa-fw fa-th"></i> <br>分类</a>

  </li>
        
        
        
          
          <li class="menu-item menu-item-archives">

    
    
      
    

    

    <a href="/archives/" rel="section"><i class="menu-item-icon fa fa-fw fa-archive"></i> <br>归档</a>

  </li>

      
      
        <li class="menu-item menu-item-search">
          
            <a href="javascript:;" class="popup-trigger">
          
            
              <i class="menu-item-icon fa fa-search fa-fw"></i> <br>搜索</a>
        </li>
      
    </ul>
  

  
    

  

  
    <div class="site-search">
      
  <div class="popup search-popup local-search-popup">
  <div class="local-search-header clearfix">
    <span class="search-icon">
      <i class="fa fa-search"></i>
    </span>
    <span class="popup-btn-close">
      <i class="fa fa-times-circle"></i>
    </span>
    <div class="local-search-input-wrapper">
      <input autocomplete="off" placeholder="搜索..." spellcheck="false" type="text" id="local-search-input">
    </div>
  </div>
  <div id="local-search-result"></div>
</div>



    </div>
  
</nav>



  



</div>
    </header>

    


    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          
          <div id="content" class="content">
            
  <section id="posts" class="posts-expand">
    
      

  

  
  
  

  

  <article class="post post-type-normal" itemscope="" itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="https://schwimmer.github.io/2018/03/23/hadoop-spark/kafka的log存储/">

    <span hidden itemprop="author" itemscope="" itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Schwimmer">
      <meta itemprop="description" content="Record and Think!">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope="" itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Schwimmer's Blog">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                
                <a href="/2018/03/23/hadoop-spark/kafka的log存储/" class="post-title-link" itemprop="url">kafka的log存储</a>
              
            
          </h1>
        

        <div class="post-meta">

          
          
          

          
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              

              
                
              

              <time title="创建时间：2018-03-23 21:02:13" itemprop="dateCreated datePublished" datetime="2018-03-23T21:02:13+08:00">2018-03-23</time>
            </span>
          

          

          
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope="" itemtype="http://schema.org/Thing"><a href="/categories/机器学习/" itemprop="url" rel="index"><span itemprop="name">机器学习</span></a></span>

                
                
              
            </span>
          

          
            
            
              
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="fa fa-comment-o"></i>
                </span>
            
                <span class="post-meta-item-text">评论数：</span>
                <a href="/2018/03/23/hadoop-spark/kafka的log存储/#comments" itemprop="discussionUrl">
                  <span class="post-comments-count disqus-comment-count" data-disqus-identifier="2018/03/23/hadoop-spark/kafka的log存储/" itemprop="commentCount"></span>
                </a>
              </span>
            
          

          
          

          

          <br>
          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>转自<a href="https://www.cnblogs.com/dorothychai/p/6181058.html" target="_blank" rel="noopener">https://www.cnblogs.com/dorothychai/p/6181058.html</a></p>

          
        
      
    </div>

    

    
    
    

    

    
      
    
    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  

  <article class="post post-type-normal" itemscope="" itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="https://schwimmer.github.io/2018/03/17/机器学习/GBDT/">

    <span hidden itemprop="author" itemscope="" itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Schwimmer">
      <meta itemprop="description" content="Record and Think!">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope="" itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Schwimmer's Blog">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                
                <a href="/2018/03/17/机器学习/GBDT/" class="post-title-link" itemprop="url">GBDT</a>
              
            
          </h1>
        

        <div class="post-meta">

          
          
          

          
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              

              
                
              

              <time title="创建时间：2018-03-17 20:50:55" itemprop="dateCreated datePublished" datetime="2018-03-17T20:50:55+08:00">2018-03-17</time>
            </span>
          

          
            

            
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="fa fa-calendar-check-o"></i>
                </span>
                
                  <span class="post-meta-item-text">更新于</span>
                
                <time title="修改时间：2018-09-14 12:58:36" itemprop="dateModified" datetime="2018-09-14T12:58:36+08:00">2018-09-14</time>
              </span>
            
          

          
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope="" itemtype="http://schema.org/Thing"><a href="/categories/机器学习/" itemprop="url" rel="index"><span itemprop="name">机器学习</span></a></span>

                
                
              
            </span>
          

          
            
            
              
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="fa fa-comment-o"></i>
                </span>
            
                <span class="post-meta-item-text">评论数：</span>
                <a href="/2018/03/17/机器学习/GBDT/#comments" itemprop="discussionUrl">
                  <span class="post-comments-count disqus-comment-count" data-disqus-identifier="2018/03/17/机器学习/GBDT/" itemprop="commentCount"></span>
                </a>
              </span>
            
          

          
          

          

          <br>
          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>tips</p>
<p>论文中GBDT的参数，树的数量最多500颗（500以上就没有提升了），每棵树的节点不多于12。</p>
<p> <a href="https://blog.csdn.net/shine19930820/article/details/71713680" target="_blank" rel="noopener">https://blog.csdn.net/shine19930820/article/details/71713680</a></p>
<h1 id="原理"><a href="#原理" class="headerlink" title="原理"></a>原理</h1><p><a href="https://blog.csdn.net/davidie/article/details/50897278" target="_blank" rel="noopener">算法原理整理</a></p>
<p><a href="http://blog.csdn.net/google19890102/article/details/51746402" target="_blank" rel="noopener">简单易学的GBDT原理</a></p>
<p><a href="">GBDT公式推导</a></p>
<p><a href="https://blog.csdn.net/yangxudong/article/details/53872141" target="_blank" rel="noopener">GBDT算法原理深入解析</a></p>
<p><a href="https://www.cnblogs.com/peizhe123/p/5086128.html" target="_blank" rel="noopener">GBDT详解</a></p>
<h2 id="梯度提升算法"><a href="#梯度提升算法" class="headerlink" title="梯度提升算法"></a>梯度提升算法</h2><p>Freidman提出了梯度提升算法，该方法是利用最速下降法的近似方法，其关键是利用损失函数的负梯度在当前模型的值  </p>
<script type="math/tex; mode=display">-[{\partial L(y,f(x_i)) \over \partial f(x_i)}]_{f(x) = f_{m-1}(x)}</script><blockquote>
<p>这个公式中，每个参数什么意思</p>
</blockquote>
<p>作为回归问题算法中的残差的近似值，拟合一个回归模型。</p>
<p>其算法流程如下：</p>
<ol>
<li>$F<em>0(x) = argmin</em>\rho \sum _{i=1}^N L(y_i, \rho)$</li>
<li>For $m = 1$ to $M$ do:  </li>
<li>$\qquad \tilde y<em>i = -[{\partial L(y,F(x_i)) \over \partial F(x_i)}]</em>{F(x) = F_{m-1}(x)}, i = 1, N$  </li>
<li>$\qquad a<em>m = argmin</em>{a,\beta}\sum_{i=1}^N[\tilde y_i - \beta h(x_i; a)]^2$ </li>
<li>$\qquad \rho<em>m = argmin</em>\rho \sum<em>{i=1}^N L(y_i, F</em>{m-1}(x_i) + \rho h(x_i; a_m))$ </li>
<li>$\qquad F<em>m(x) = F</em>{m-1}(x) + \rho_m h(x;a_m)$</li>
<li>endFor<br>endAlgorighm</li>
</ol>
<p>其中$h(x_i;a_m)$表示基本分类器（weak learner or base learner），4中$a_m$表示拟合负梯度能力最好的分类器参数<br>负梯度只是表示下降的方向，但是下降多少没有确定，5中$\rho_m$可以认为是下降最快的步长，可以让Loss最小，可以用线性搜索的方式来估计$\rho_m$的值</p>
<p>为何这里不直接利用负梯度来调节，而是需要用一个分类器来拟合呢？因为这里的负梯度是在训练集上求出的，不能被泛化测试集中。我们的参数是在一个函数空间里面，不能使用例如SGD这样的求解方式。使用一个分类器来拟合，是一个泛化的方式。</p>
<h4 id="回归树"><a href="#回归树" class="headerlink" title="回归树"></a>回归树</h4><p>当我们的基本分类器是一个包含J个节点的回归树时，回归树模型可以表示为  </p>
<script type="math/tex; mode=display">h(x;\{b_j, R_j\}_1^J) = \sum_{b=j}^Jb_jI(x\in R_j) \qquad (8)</script><p>其中${ R_j }_1^J$不相交的区域，它们的集合覆盖了预测值的空间，${ b_j }_1^J$是叶子节点的值，可以认为是模型$h$的系数</p>
<p>利用回归树模型，算法流程6中的公式可以被替换为：<script type="math/tex">F_m(x) = F_{m-1}(x) + \rho_m \sum_{j=1}^J b_{jm}I(x \in R_{jm})\qquad (9)</script> </p>
<p>其中${ R_{jm} }_1^J$是第m次迭代生成的树所产生的区域。第m次迭代的树用来预测流程3中由流程4中平方误差产生的${\tilde y_i}_i^N$  </p>
<p>${ b<em>{jm}}$可以被表示为 $$b</em>{jm} = ave<em>{x_i \in R</em>{jm}} \tilde y_i$$ 即用平均值表示该叶子节点拟合的值</p>
<p>有了下降的方向，我们还需要最好的步长，缩放因子$\rho_m$是流程5中线性搜索方式的一种解决方案</p>
<p>从上面可以看出，我们是先求的$b<em>{jm}$，然后在求解$\rho_m$，我们能否同时求解呢？<br>另$\gamma</em>{jm} = \rho<em>{m}b</em>{jm}$，公式9可以被表示为：<script type="math/tex">F_m(x) = F_{m-1}(x) + \sum_{j=1}^J \gamma_{jm}I(x \in R_{jm})\qquad (10)</script> </p>
<p>通过优化如下公式来获取最优的系数$\gamma_{jm}$：</p>
<script type="math/tex; mode=display">\{\gamma_{jm}\}_1^J = argmin_{\ \gamma_j {\ _1^J}}\sum_{i=1}^N L\left(y_i, F_{m-1}(x_i) + \sum_{j=1}^J\gamma_jI(x \in R_{jm})\right)\qquad 1)</script><p>由于回归树产生的叶子节点各个区域之间是不相交的，且所有的样本最终都会属于某个叶子节点，所以公式11可以表示为：</p>
<script type="math/tex; mode=display">\gamma_{jm} = argmin_\gamma \sum_{x_i\in R_{jm}} L(y_i, F_{m-1}(x_i) + \gamma)</script><p>给定当前$F<em>{m-1}(i)$，$\gamma</em>{jm}$可以作为叶子节点的值，该值可以看做是基于损失函数L的每个叶子节点的最理想的常数更新值，也可以认为$\gamma_{jm}$是即有下降方向又有下降步长的值。</p>
<p>综上，用回归树作为基本分类器的梯度提升算法流程可以如下表示：</p>
<ol>
<li>$F<em>0(x) = argmin</em>\rho \sum _{i=1}^N L(y_i, \rho)$</li>
<li>For $m = 1$ to $M$ do:  </li>
<li>$\qquad \tilde y<em>i = -[{\partial L(y,F(x_i)) \over \partial F(x_i)}]</em>{F(x) = F_{m-1}(x)}, i = 1, N$  </li>
<li>$\qquad {R_{jm}}_1^J = J-terminal\, node\, tree({ \tilde y_i, x_i }_i^N)$ </li>
<li>$\qquad \gamma<em>{jm} = argmin</em>\gamma \sum<em>{x_i\in R</em>{jm}} L(y<em>i, F</em>{m-1}(x_i) + \gamma)$</li>
<li>$\qquad F<em>m(x) = F</em>{m-1}(x) + \sum<em>{j=1}^J \gamma</em>{jm}I(x \in R_{jm})$</li>
<li>endFor<br>endAlgorighm</li>
</ol>
<p>其中3是计算残差（利用损失函数的负梯度在当前模型的值作为残差的近似值），4是拟合一颗含有J个叶子节点的回归树，5是估计回归树叶子节点的值</p>
<p>下面我们看一下二元分类、多元分类、回归中残差的计算、叶子节点值的估计。</p>
<h4 id="Two-class-logistic-regression-and-classification"><a href="#Two-class-logistic-regression-and-classification" class="headerlink" title="Two-class logistic regression and classification"></a>Two-class logistic regression and classification</h4><p>我们用negative binomial log-likehood作为我们的损失函数：</p>
<script type="math/tex; mode=display">L(y, F) = log(1 + exp(-2yF)), y \in {-1, 1}\qquad (12)</script><p>其中<script type="math/tex">F(x) = {1\over2}log\left[{Pr(y=1|x) \over Pr(y=-1|x)}\right]\qquad (13)</script><br>公式13是logit函数，log odds</p>
<p>如上公式是Freidman的论文中使用的公式，我认为使用在逻辑回归中常见的$L(y, F) = ylogF + (1-y)log(1-F)$，其中$F(z) ={ 1\over{1+exp(-z)}}$也可以</p>
<p>计算残差：<script type="math/tex">\tilde y_i = -[{\partial L(y,F(x_i)) \over \partial F(x_i)}]_{F(x) = F_{m-1}(x)} = {2y_i\over 1+exp(2y_iF_{m-1}(x_i))}\qquad(14)</script></p>
<p>叶子节点值的估计：</p>
<script type="math/tex; mode=display">\gamma_jm = argmin_\gamma \sum_{x_i \in R_{jm}} log(1+exp(-2y_i(F_{m-1}(x_i) + \gamma)))\qquad (15)</script><p>可以通过一步Newton-Raphson来近似公式15，估计结果为：</p>
<script type="math/tex; mode=display">\gamma_{jm} = {\sum_{x_i \in R_{jm}}\tilde y_i \over {\sum_{x_i \in R_{jm}}}|\tilde y_i|(2-|\tilde y_i|)}</script><p>最终得到的$F_M(x)$与对数几率 log-odds相关，我们可以用来进行概率估计</p>
<script type="math/tex; mode=display">F(x) = {1\over2}log\left({p \over 1-p}\right)</script><script type="math/tex; mode=display">e^{2F(x)} = {p\over(1-p)}</script><script type="math/tex; mode=display">P_+(x) = p = {e^{2F(x)}\over 1+e^{2F(x)}} = {1\over1+e^{-2F(x)}}</script><script type="math/tex; mode=display">P_-(x) = 1-p = {1\over1+e^{2F(x)}}</script><p>有了概率之后，我们接下来就可以利用概率进行分类</p>
<h4 id="Multi-class-logistic-regression-and-classification"><a href="#Multi-class-logistic-regression-and-classification" class="headerlink" title="Multi-class logistic regression and classification"></a>Multi-class logistic regression and classification</h4><p>我们使用multi-class log-loss作为损失函数：</p>
<script type="math/tex; mode=display">L(\{y_k, F_k(x)\}_1^K) = -\sum_{k=1}^K y_klogp_k(x)\qquad(16)</script><p>其中使用softmax来计算概率：<script type="math/tex">p_k(x) = exp(F_k(x)) / \sum_{l=1}^Kexp(F_l(x))\qquad(17)</script></p>
<p>从公式17可以得出，对于多分类问题，我们需要为每个类别创建一颗回归树$F_l(x)\, l=1,2,…,k$</p>
<p>计算残差：</p>
<script type="math/tex; mode=display">\tilde y_{ik} = -[{\partial L(\{y_{il},F_l(x_i)\}_{l=1}^K) \over \partial F_k(x_i)}]_{\{F_l(x) = F_{l, m-1(x)}\}_1^K} = y_{ik} - p_{k,m-1(i)}\qquad (18)</script><p>我们假定共分为3类，那么logloss为：</p>
<script type="math/tex; mode=display">L = -y_1log{exp(F_1(x))\over exp(F_1(x)) + exp(F_1(x)) + exp(F_1(x))} -y_2log{exp(F_2(x))\over exp(F_1(x)) + exp(F_1(x)) + exp(F_1(x))} _3log{exp(F_3(x))\over exp(F_1(x)) + exp(F_1(x)) + exp(F_1(x))}</script><script type="math/tex; mode=display">{\partial L \over \partial F_1(x)} = -y_1 + y_1p_1 + y_2p_2 + y_3p_3</script><script type="math/tex; mode=display">{\partial L \over \partial F_2(x)} = y_1p_1 - y_2 + y_2p_2 + y_3p_3</script><script type="math/tex; mode=display">{\partial L \over \partial F_3(x)} = y_1p_1 + y_2p_2 - y_3 + y_3p_3</script><p>如果当期样本的类别为(1,0,0)，那么</p>
<script type="math/tex; mode=display">{\partial L \over \partial F_1(x)} = -1 + p1</script><script type="math/tex; mode=display">{\partial L \over \partial F_2(x)} = p_2</script><script type="math/tex; mode=display">{\partial L \over \partial F_3(x)} = p_3</script><p>取负梯度，则</p>
<script type="math/tex; mode=display">-{\partial L \over \partial F_1(x)} = 1 - p_1</script><script type="math/tex; mode=display">-{\partial L \over \partial F_2(x)} = -p_2 = 0 - p_2</script><script type="math/tex; mode=display">-{\partial L \over \partial F_3(x)} = -p_3 = 0 - p_3</script><p>符合公式18中的$\tilde y<em>{ik} = y</em>{ik} - p_{k,m-1(x_i)}$</p>
<p>叶子节点值的估计：</p>
<script type="math/tex; mode=display">\{r_{jkm}\} = argmin_{\gamma_{jk}}\sum_{i=1}^N \sum_{k=1}^K \phi \left( y_{ik}, F_{k,m-1}(x_i) + \sum_{j=1}^J\gamma_{jk}I(x_i \in {jm})\}\right)\qquad(19)</script><p>可以通过一步Newton-Raphson来近似公式19，估计结果为：</p>
<script type="math/tex; mode=display">\gamma_{jkm} = {K-1\over K}{\sum_{x_i \in R_{jkm}}\tilde y_{ik} \over {\sum_{x_i \in R_{jkm}}}|\tilde y_{ik}|(1-|\tilde y_{ik}|)}</script><h4 id="Regression"><a href="#Regression" class="headerlink" title="Regression"></a>Regression</h4><p>我们使用Least-squares作为损失函数：<script type="math/tex">L(y, F) = {(y-F)^2\over 2}</script></p>
<p>计算残差：<script type="math/tex">\tilde y_i = -[{\partial L(y,F(x_i)) \over \partial F(x_i)}]_{F(x) = F_{m-1}(x)} = {y_i - F_{m-1}(x_i)}\qquad(20)</script></p>
<p>叶子节点值的估计：</p>
<script type="math/tex; mode=display">\gamma_{jm} = argmin_\gamma \sum_{x_i \in R_{jm}} {1\over 2}(y_i - (F_{m-1}(x_i) + \gamma))^2\qquad (21)</script><script type="math/tex; mode=display">\gamma_{jm} = argmin_\gamma \sum_{x_i \in R_{jm}} {1\over 2}(y_i - F_{m-1}(x_i) - \gamma)^2</script><script type="math/tex; mode=display">\gamma_{jm} = argmin_\gamma \sum_{x_i \in R_{jm}} {1\over 2}(\tilde y_i -  \gamma)^2</script><p>容易得出以下结果：<script type="math/tex">\gamma_{jm} = ave_{x_i \in R_{jm}} \tilde y_i</script></p>
<h4 id="回归树的创建"><a href="#回归树的创建" class="headerlink" title="回归树的创建"></a>回归树的创建</h4><p>拟合残数是一个回归问题，所以在分割样本时，我们不会采用基尼指数（Gini）、信息增益（IG）等用于分类的标准。<br>我们可以选用MSE(mean square error impurity criterion)作为分割样本的标准。<br>也可是采用Friedman在论文中的the least-squares improvement criterion，公式如下：</p>
<script type="math/tex; mode=display">i_2(R_l, R_r) = {w_lw_r\over w_l + w_r}(\bar y_l - \bar y_r)^2</script><p>其中$\bar y_l \, \bar y_r$分别是左右孩子的平均值，$w_l \, w_r$分别是左右孩子对应的权重和</p>
<p>本文是针对具体的损失函数进行的相关推导，泛化能力差，大家可以参考xgboost作者的这篇<a href="http://www.52cs.org/?p=429" target="_blank" rel="noopener">文章</a>，作者进行了更加一般的推导，这一个抽象的形式对于实现机器学习工具也是非常有帮助的。</p>
<p>引用：<br>Greedy Function Approximation: A Gradient Boosting Machine</p>
<h2 id="与RF的区别"><a href="#与RF的区别" class="headerlink" title="与RF的区别"></a>与RF的区别</h2><h2 id="实现"><a href="#实现" class="headerlink" title="实现"></a>实现</h2><p><a href="https://github.com/liudragonfly/GBDT" target="_blank" rel="noopener">GBDT的python实现</a></p>
<h1 id="python配置XGB"><a href="#python配置XGB" class="headerlink" title="python配置XGB"></a>python配置XGB</h1><p>参考</p>
<p>gbdt</p>
<p><a href="http://www.itopmarketing.com/index.php/News/show/id/7951/lmid/197/utm_source/tuicool/utm_medium/referral/" target="_blank" rel="noopener">http://www.itopmarketing.com/index.php/News/show/id/7951/lmid/197/utm_source/tuicool/utm_medium/referral/</a> 【关于点击率模型，你知道这三点就够了】</p>
<p><a href="http://www.cnblogs.com/zhouxiaohui888/p/6008368.html" target="_blank" rel="noopener">http://www.cnblogs.com/zhouxiaohui888/p/6008368.html</a> 【xgboost原理及应用】</p>
<p>官网介绍的原理：<a href="https://xgboost.readthedocs.io/en/latest/model.html" target="_blank" rel="noopener">https://xgboost.readthedocs.io/en/latest/model.html</a></p>
<p>原理的中文解释<a href="http://dataunion.org/15787.html" target="_blank" rel="noopener">http://dataunion.org/15787.html</a></p>
<p><a href="https://github.com/dmlc/xgboost" target="_blank" rel="noopener">https://github.com/dmlc/xgboost</a></p>
<p><a href="https://github.com/Schwimmer/xgboost/tree/master/jvm-packages/xgboost4j-example/src/main/scala/ml/dmlc/xgboost4j/scala/example/spark" target="_blank" rel="noopener">https://github.com/Schwimmer/xgboost/tree/master/jvm-packages/xgboost4j-example/src/main/scala/ml/dmlc/xgboost4j/scala/example/spark</a></p>
<p>GBDT</p>
<p>（Gradient Boost Decision Tree）是一种常用的非线性模型[6][7][8][9]，它基于集成学习中的boosting思想[10]，每次迭代都在减少残差的梯度方向新建立一颗决策树，迭代多少次就会生成多少颗决策树。</p>
<p>GBDT</p>
<p>的思想使其具有天然优势可以发现多种有区分性的特征以及特征组合，决策树的路径可以直接作为LR输入特征使用，省去了人工寻找特征、特征组合的步骤。这种通过</p>
<p>GBDT</p>
<p>生成LR特征的方式（</p>
<p>GBDT</p>
<p>+LR），业界已有实践（Facebook，Kaggle-2014），且效果不错</p>
<p>来源： <a href="http://blog.csdn.net/lilyth_lilyth/article/details/48032119" target="_blank" rel="noopener">http://blog.csdn.net/lilyth_lilyth/article/details/48032119</a></p>
<p>XGBoost</p>
<p><a href="http://blog.csdn.net/dusj1993/article/details/51925387【" target="_blank" rel="noopener">http://blog.csdn.net/dusj1993/article/details/51925387【</a> 在集群上部署xgboost踩过的坑】</p>
<p><a href="http://blog.csdn.net/u010306433/article/details/51403894" target="_blank" rel="noopener">http://blog.csdn.net/u010306433/article/details/51403894</a> 【xgboost 分布式部署教程】</p>
<p>mvn install:install-file -Dfile=D:\code\jar_package\xgboost4j-spark-0.5-jar-with-dependencies.jar -DgroupId=ml.dmlc -DartifactId=xgboost4j -Dversion=0.5 -Dpackaging=jar</p>
<dependency>

  <groupid>ml.dmlc</groupid>

  <artifactid>xgboost4j</artifactid>

  <version>0.7</version>

</dependency>

<p>\<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">http://blog.csdn.net/zhangweijiqn/article/details/53214186</span><br><span class="line"></span><br><span class="line">XGBoost4J:</span><br><span class="line"></span><br><span class="line">Distributed XGBoost for Scala/Java (XFBoost 4 JVM environment)，目前看来还比较小众，文档不够多，网上xgboost4j的资料也很少，社区不够活跃。</span><br><span class="line"></span><br><span class="line">Portable Distributed XGBoost in Spark, Flink and Dataflow: </span><br><span class="line"></span><br><span class="line">http://dmlc.ml/2016/03/14/xgboost4j-portable-distributed-xgboost-in-spark-flink-and-dataflow.html</span><br><span class="line"></span><br><span class="line">Scala和Spark等分布式的包在jvm-packages下。</span><br><span class="line"></span><br><span class="line">安装：http://xgboost.readthedocs.io/en/latest/jvm/</span><br><span class="line"></span><br><span class="line">目前安装仅支持从源码安装:</span><br><span class="line"></span><br><span class="line">$ git clone --recursive </span><br><span class="line"></span><br><span class="line">https://github.com/dmlc/xgboost</span><br><span class="line"></span><br><span class="line">$ cd xgboost/jvm-packages</span><br><span class="line"></span><br><span class="line">$ mvn package</span><br><span class="line"></span><br><span class="line">安装scala/java的jvm版xgboost:</span><br><span class="line"></span><br><span class="line">$ cd jvm-packages/xgboost4j</span><br><span class="line"></span><br><span class="line">$ mvn install:install-file -Dfile=target/xgboost4j-0.7.jar -DgroupId=ml.dmlc -DartifactId=xgboost4j -Dversion=0.7 -Dpackaging=jar</span><br><span class="line"></span><br><span class="line">安装spark版的xgboost:</span><br><span class="line"></span><br><span class="line">$ cd jvm-packages/xgboost4j-spark</span><br><span class="line"></span><br><span class="line">$ mvn install:install-file -Dfile=target/xgboost4j-spark-0.7.jar -DgroupId=ml.dmlc -DartifactId=xgboost4j-spark -Dversion=0.7 -Dpackaging=jar</span><br><span class="line"></span><br><span class="line">Maven pom.xml file:</span><br><span class="line"></span><br><span class="line">&lt;dependency&gt;</span><br><span class="line"></span><br><span class="line">&lt;groupId&gt;ml.dmlc&lt;/groupId&gt;</span><br><span class="line"></span><br><span class="line">&lt;artifactId&gt;xgboost4j-spark&lt;/artifactId&gt;</span><br><span class="line"></span><br><span class="line">&lt;version&gt;0.7&lt;/version&gt;</span><br><span class="line"></span><br><span class="line">&lt;/dependency&gt;</span><br><span class="line"></span><br><span class="line">Spark code，参考https://github.com/dmlc/xgboost/tree/master/jvm-packages，分别有RDD版本和DataFrame版本:</span><br><span class="line"></span><br><span class="line">import</span><br><span class="line"></span><br><span class="line">ml.dmlc.xgboost4j.scala.spark.XGBoost</span><br><span class="line"></span><br><span class="line">\</span><br></pre></td></tr></table></figure></p>
<p>用maven安装xgboost4j时候的坑</p>
<p>执行</p>
<p>mvn clean -DskipTests=true package</p>
<p>1、checkstyle报错</p>
<p>xgboost4j的pom中增加了checkstyple插件，在win7下package会报错</p>
<p>\<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">method name must match pattern</span><br><span class="line"></span><br><span class="line">no-trailing-spaces</span><br><span class="line"></span><br><span class="line">等</span><br><span class="line"></span><br><span class="line">\</span><br></pre></td></tr></table></figure></p>
<p>解决：在pom.xml中去掉checkstyle插件</p>
<p>\<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">            &lt;plugin&gt;</span><br><span class="line"></span><br><span class="line">                &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt;</span><br><span class="line"></span><br><span class="line">                &lt;artifactId&gt;maven-checkstyle-plugin&lt;/artifactId&gt;</span><br><span class="line"></span><br><span class="line">                &lt;version&gt;2.17&lt;/version&gt;</span><br><span class="line"></span><br><span class="line">                &lt;configuration&gt;</span><br><span class="line"></span><br><span class="line">                    &lt;configLocation&gt;checkstyle.xml&lt;/configLocation&gt;</span><br><span class="line"></span><br><span class="line">                    &lt;failOnViolation&gt;true&lt;/failOnViolation&gt;</span><br><span class="line"></span><br><span class="line">                &lt;/configuration&gt;</span><br><span class="line"></span><br><span class="line">                &lt;executions&gt;</span><br><span class="line"></span><br><span class="line">                    &lt;execution&gt;</span><br><span class="line"></span><br><span class="line">                        &lt;id&gt;checkstyle&lt;/id&gt;</span><br><span class="line"></span><br><span class="line">                        &lt;phase&gt;validate&lt;/phase&gt;</span><br><span class="line"></span><br><span class="line">                        &lt;goals&gt;</span><br><span class="line"></span><br><span class="line">                            &lt;goal&gt;check&lt;/goal&gt;</span><br><span class="line"></span><br><span class="line">                        &lt;/goals&gt;</span><br><span class="line"></span><br><span class="line">                    &lt;/execution&gt;</span><br><span class="line"></span><br><span class="line">                &lt;/executions&gt;</span><br><span class="line"></span><br><span class="line">            &lt;/plugin&gt;</span><br><span class="line"></span><br><span class="line">                &lt;executions&gt;</span><br><span class="line"></span><br><span class="line">                    &lt;execution&gt;</span><br><span class="line"></span><br><span class="line">                        &lt;id&gt;checkstyle&lt;/id&gt;</span><br><span class="line"></span><br><span class="line">                        &lt;phase&gt;validate&lt;/phase&gt;</span><br><span class="line"></span><br><span class="line">                        &lt;goals&gt;</span><br><span class="line"></span><br><span class="line">                            &lt;goal&gt;check&lt;/goal&gt;</span><br><span class="line"></span><br><span class="line">                        &lt;/goals&gt;</span><br><span class="line"></span><br><span class="line">                    &lt;/execution&gt;</span><br><span class="line"></span><br><span class="line">                &lt;/executions&gt;</span><br><span class="line"></span><br><span class="line">\</span><br></pre></td></tr></table></figure></p>
<p>2、用scala的例子<strong>BasicWalkThrough.scala</strong>报错</p>
<p>\<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">ERROR [main] (DMatrix.java:41) - java.io.FileNotFoundException: File /lib/xgboost4j.dll was not found inside JAR.</span><br><span class="line"></span><br><span class="line">\</span><br></pre></td></tr></table></figure></p>
<p>参考：<a href="https://github.com/dmlc/xgboost/issues/1148" target="_blank" rel="noopener">https://github.com/dmlc/xgboost/issues/1148</a></p>
<p><a href="https://www.ibm.com/developerworks/community/blogs/jfp/entry/Installing_XGBoost_For_Anaconda_on_Windows?lang=en" target="_blank" rel="noopener">https://www.ibm.com/developerworks/community/blogs/jfp/entry/Installing_XGBoost_For_Anaconda_on_Windows?lang=en</a></p>
<p>需要装MINGW，然后make jvm，但是会报错</p>
<p>\<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">mingw32-make: *** No rule to make target &apos;jvm&apos;.  Stop.</span><br><span class="line"></span><br><span class="line">\</span><br></pre></td></tr></table></figure></p>
<p>应该在有MakeFile的目录下执行，也就是根目录D:\gitlab\xgboost。并且，要从git上手动下载项目中的dmlc-core和rabit，再执行，继续报错</p>
<p>\<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">process_begin: CreateProcess(NULL, uname, ...) failed.</span><br><span class="line"></span><br><span class="line">mingw32-make: Makefile:44: pipe: No error</span><br><span class="line"></span><br><span class="line">g++ -std=c++0x -Wall -Wno-unknown-pragmas -Iinclude   -Idmlc-core/include -Irabi</span><br><span class="line"></span><br><span class="line">t/include -O3 -funroll-loops -msse2 -fopenmp -MM -MT build/learner.o src/learner</span><br><span class="line"></span><br><span class="line">.cc &gt;build/learner.d</span><br><span class="line"></span><br><span class="line">g++ -c -std=c++0x -Wall -Wno-unknown-pragmas -Iinclude   -Idmlc-core/include -Ir</span><br><span class="line"></span><br><span class="line">abit/include -O3 -funroll-loops -msse2 -fopenmp src/learner.cc -o build/learner.</span><br><span class="line"></span><br><span class="line">o</span><br><span class="line"></span><br><span class="line">子目录或文件 -p 已经存在。</span><br><span class="line"></span><br><span class="line">处理: -p 时出错。</span><br><span class="line"></span><br><span class="line">子目录或文件 build 已经存在。</span><br><span class="line"></span><br><span class="line">处理: build 时出错。</span><br><span class="line"></span><br><span class="line">Makefile:113: recipe for target &apos;build/logging.o&apos; failed</span><br><span class="line"></span><br><span class="line">mingw32-make: *** [build/logging.o] Error 1</span><br><span class="line"></span><br><span class="line">\</span><br></pre></td></tr></table></figure></p>
<p>应该用git-bash来执行，然后接着报错</p>
<p>\<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">\</span><br></pre></td></tr></table></figure></p>
<p><a href="https://github.com/dmlc/xgboost/issues/1267" target="_blank" rel="noopener">https://github.com/dmlc/xgboost/issues/1267</a></p>
<p>跟着一步步执行，再报错</p>
<p>\<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">cc1plus.exe: sorry, unimplemented: 64-bit mode not compiled in</span><br><span class="line"></span><br><span class="line">\</span><br></pre></td></tr></table></figure></p>
<p>windows安装失败，在ubuntu环境下安装</p>
<h1 id="CART"><a href="#CART" class="headerlink" title="CART"></a>CART</h1><p><a href="https://www.cnblogs.com/qwj-sysu/p/5974421.html" target="_blank" rel="noopener">https://www.cnblogs.com/qwj-sysu/p/5974421.html</a> 离散值处理</p>
<p><a href="https://www.cnblogs.com/qwj-sysu/p/5981231.html" target="_blank" rel="noopener">https://www.cnblogs.com/qwj-sysu/p/5981231.html</a> 连续值处理</p>
<p>经典算法详解—CART分类决策树、回归树和模型树</p>
<p><a href="https://blog.csdn.net/jiede1/article/details/76034328" target="_blank" rel="noopener">https://blog.csdn.net/jiede1/article/details/76034328</a></p>

          
        
      
    </div>

    

    
    
    

    

    
      
    
    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  

  <article class="post post-type-normal" itemscope="" itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="https://schwimmer.github.io/2018/03/17/编程语言学习/PYTHON/Numpy/">

    <span hidden itemprop="author" itemscope="" itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Schwimmer">
      <meta itemprop="description" content="Record and Think!">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope="" itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Schwimmer's Blog">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                
                <a href="/2018/03/17/编程语言学习/PYTHON/Numpy/" class="post-title-link" itemprop="url">Numpy技巧总结</a>
              
            
          </h1>
        

        <div class="post-meta">

          
          
          

          
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              

              
                
              

              <time title="创建时间：2018-03-17 20:50:31" itemprop="dateCreated datePublished" datetime="2018-03-17T20:50:31+08:00">2018-03-17</time>
            </span>
          

          
            

            
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="fa fa-calendar-check-o"></i>
                </span>
                
                  <span class="post-meta-item-text">更新于</span>
                
                <time title="修改时间：2019-07-03 23:17:56" itemprop="dateModified" datetime="2019-07-03T23:17:56+08:00">2019-07-03</time>
              </span>
            
          

          
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope="" itemtype="http://schema.org/Thing"><a href="/categories/Python/" itemprop="url" rel="index"><span itemprop="name">Python</span></a></span>

                
                
              
            </span>
          

          
            
            
              
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="fa fa-comment-o"></i>
                </span>
            
                <span class="post-meta-item-text">评论数：</span>
                <a href="/2018/03/17/编程语言学习/PYTHON/Numpy/#comments" itemprop="discussionUrl">
                  <span class="post-comments-count disqus-comment-count" data-disqus-identifier="2018/03/17/编程语言学习/PYTHON/Numpy/" itemprop="commentCount"></span>
                </a>
              </span>
            
          

          
          

          

          <br>
          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1 id="创建数据"><a href="#创建数据" class="headerlink" title="创建数据"></a>创建数据</h1><h2 id="创建ndarray"><a href="#创建ndarray" class="headerlink" title="创建ndarray"></a>创建ndarray</h2><p>NumPy的数组类被称作ndarray。通常被称作数组。</p>
<p>Numpy库中的矩阵模块为ndarray对象，有很多属性：T，data, dtype,flags,flat,imag,real,size,</p>
<p>itemsize,nbytes,ndim,shape,strides,ctypes,base等等。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">import numpy as np</span><br><span class="line">vector = np.array([10,20,30])</span><br><span class="line">matrix=np.array([[1,2,3],[4,5,6],[7,8,9]])</span><br><span class="line"></span><br><span class="line"># 创建10个float32的一维数组</span><br><span class="line">np.random.rand(10).astype(np.float32)</span><br><span class="line"># 这样就是10*2的二维数组</span><br><span class="line">np.random.rand(10,2).astype(np.float32)</span><br></pre></td></tr></table></figure>
<h3 id="随机array"><a href="#随机array" class="headerlink" title="随机array"></a>随机array</h3><p><code>np.random.randn</code>可以返回一个随机数组</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">np.random.randn(1,2)</span><br><span class="line">Out[11]: array([[-2.67809797,  1.49728361]])</span><br><span class="line"></span><br><span class="line"># 在0-5之间生成随机数</span><br><span class="line">np.random.rand(2,3)*5</span><br><span class="line"># 或者</span><br><span class="line">np.dot(5,np.random.rand(2,3))</span><br><span class="line"># 指定生成随机数的范围</span><br><span class="line">np.random.randint(0, 20, size=[2,3])</span><br></pre></td></tr></table></figure>
<ul>
<li>np.random.rand  随机样本位于[0,1)中</li>
<li>np.random.randn 从标准正态分布$N=(\mu , \sigma ^2)$中返回样本，默认的范围是$N(0,1)$，等价于np.random.standard_normal</li>
</ul>
<blockquote>
<p>如果要返回2*4的$N(3,6.25)$的随机分布，可知均值是3，标准差是2.5，则</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">&gt; 3+2.5*np.random.randn(2,4)</span><br><span class="line">&gt;</span><br></pre></td></tr></table></figure>
</blockquote>
<h3 id="指定随机数类型"><a href="#指定随机数类型" class="headerlink" title="指定随机数类型"></a>指定随机数类型</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">x_data = np.random.rand(100).astype(np.float32)</span><br></pre></td></tr></table></figure>
<h3 id="创建空的array"><a href="#创建空的array" class="headerlink" title="创建空的array"></a>创建空的array</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">np.zeros((5,1))</span><br></pre></td></tr></table></figure>
<p>注意有两层括号，因为参数是一个shape</p>
<h3 id="随机数的seed"><a href="#随机数的seed" class="headerlink" title="随机数的seed"></a>随机数的seed</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">numpy.random.seed()</span><br></pre></td></tr></table></figure>
<p>seed( ) 用于指定随机数生成时所用算法开始的整数值，如果使用相同的seed( )值，则每次生成的随即数都相同，如果不设置这个值，则系统根据时间来自己选择这个值，此时每次生成的随机数因时间差异而不同。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">from numpy import *</span><br><span class="line">num=0</span><br><span class="line">while(num&lt;5):</span><br><span class="line">    random.seed(5)</span><br><span class="line">    print(random.random())</span><br><span class="line">    num+=1</span><br></pre></td></tr></table></figure>
<p>每次都一样</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">from numpy import *</span><br><span class="line">num=0</span><br><span class="line">random.seed(5)</span><br><span class="line">while(num&lt;5):</span><br><span class="line">    print(random.random())</span><br><span class="line">    num+=1</span><br></pre></td></tr></table></figure>
<p>每次不一样</p>
<p>也就是一次有效。</p>
<h3 id="创建等差数列"><a href="#创建等差数列" class="headerlink" title="创建等差数列"></a>创建等差数列</h3><p>创建等差数列，默认是创建50个，一般写成</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">x2 = np.linspace(1,10,10)</span><br></pre></td></tr></table></figure>
<h3 id="由函数创建"><a href="#由函数创建" class="headerlink" title="由函数创建"></a>由函数创建</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">&gt;&gt;&gt; def func (i):</span><br><span class="line"></span><br><span class="line">...        return  i%4+1</span><br><span class="line"></span><br><span class="line">&gt;&gt;&gt;  np. fromfunction(func, (10 ,))</span><br><span class="line"></span><br><span class="line">array([ 1., 2., 3., 4., 1., 2., 3., 4., 1., 2.])</span><br></pre></td></tr></table></figure>
<p>首先，定义一个func函数，模4加1。<br>然后，调用np对象的fromfunction内建函数，第一个参数是我们自定义的func,第二个参数（m,n），他处理的逻辑是这个样的：第一行第一列取（0，0）带入func函数，第一行第二列取（0，1）带入func函数，第一行第三列取（0，2）带入func函数……循环往复，直到取到值（0,n-1）带入函数以后，开始取第二行。。因为我们定义的函数只有一个参数，所以m从0取到9即可。最后返回数列：array([ 1., 2., 3., 4., 1., 2., 3., 4., 1., 2.]) 。</p>
<h3 id="读取csv转为numpy"><a href="#读取csv转为numpy" class="headerlink" title="读取csv转为numpy"></a>读取csv转为numpy</h3><p>假设第一行是描述，第二行起是数据；第一列是标签，后面是特征项</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">import numpy as np</span><br><span class="line"></span><br><span class="line">data = np.loadtxt(open(&apos;sample.csv&apos;,&apos;rb&apos;), delimiter=&apos;,&apos;, skiprows=1)</span><br><span class="line">y_train = data[:,0]</span><br><span class="line">x_train = data[:,1:-1]</span><br></pre></td></tr></table></figure>
<p><code>np.random.randn</code>可以返回一个随机数组</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">np.random.randn(1,2)</span><br><span class="line"></span><br><span class="line">Out[11]: array([[-2.67809797,  1.49728361]])</span><br></pre></td></tr></table></figure>
<ul>
<li>np.random.rand  随机样本位于[0,1)中</li>
<li>np.random.randn 从标准正态分布$N=(\mu , \sigma ^2)$中返回样本，默认的范围是$N(0,1)$，等价于np.random.standard_normal</li>
</ul>
<blockquote>
<p>如果要返回2*4的$N(3,6.25)$的随机分布，可知均值是3，标准差是2.5，则</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">&gt; 3+2.5*np.random.randn(2,4)</span><br><span class="line">&gt;</span><br></pre></td></tr></table></figure>
</blockquote>
<p>如果在matlib模块中使用，则返回的是matrix而不是array</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy.matlib</span><br><span class="line">np.matlib.randn(<span class="number">1</span>,<span class="number">2</span>)</span><br><span class="line"></span><br><span class="line">Out[<span class="number">13</span>]: matrix([[ <span class="number">0.13107513</span>, <span class="number">-0.87977247</span>]])</span><br></pre></td></tr></table></figure>
<h1 id="矩阵变换"><a href="#矩阵变换" class="headerlink" title="矩阵变换"></a>矩阵变换</h1><h2 id="shape"><a href="#shape" class="headerlink" title="shape"></a>shape</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">vector_shape = vector.shape</span><br><span class="line">matrix_shape = matrix.shape</span><br></pre></td></tr></table></figure>
<p>(3,)</p>
<p>(3, 3)</p>
<h2 id="reshape"><a href="#reshape" class="headerlink" title="reshape"></a>reshape</h2><p>生成新矩阵</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>xdata</span><br><span class="line">array([<span class="number">2</span>, <span class="number">4</span>, <span class="number">0</span>, <span class="number">3</span>, <span class="number">5</span>, <span class="number">2</span>, <span class="number">6</span>, <span class="number">0</span>, <span class="number">1</span>, <span class="number">8</span>])</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>len(xdata)</span><br><span class="line"><span class="number">10</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>xdata.reshape(<span class="number">5</span>,<span class="number">-1</span>)</span><br><span class="line">array([[<span class="number">2</span>, <span class="number">4</span>],</span><br><span class="line">       [<span class="number">0</span>, <span class="number">3</span>],</span><br><span class="line">       [<span class="number">5</span>, <span class="number">2</span>],</span><br><span class="line">       [<span class="number">6</span>, <span class="number">0</span>],</span><br><span class="line">       [<span class="number">1</span>, <span class="number">8</span>]])</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>xdata.reshape(<span class="number">5</span>,<span class="number">2</span>)</span><br><span class="line">array([[<span class="number">2</span>, <span class="number">4</span>],</span><br><span class="line">       [<span class="number">0</span>, <span class="number">3</span>],</span><br><span class="line">       [<span class="number">5</span>, <span class="number">2</span>],</span><br><span class="line">       [<span class="number">6</span>, <span class="number">0</span>],</span><br><span class="line">       [<span class="number">1</span>, <span class="number">8</span>]])</span><br></pre></td></tr></table></figure>
<p>指定了第一维后，第二维可以不指定，写为-1</p>
<h3 id="flatten"><a href="#flatten" class="headerlink" title="flatten"></a>flatten</h3><p>把(a,b,c,d)的X reshape为<code>(b*c*d, a)</code></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">X_flatten = X.reshape(-1, X.shape[0])</span><br></pre></td></tr></table></figure>
<h3 id="获得x的转置"><a href="#获得x的转置" class="headerlink" title="获得x的转置"></a>获得x的转置</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">print(x.T)</span><br></pre></td></tr></table></figure>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">[[1 4 7]</span><br><span class="line"> [2 5 8]</span><br><span class="line"> [3 6 9]]</span><br></pre></td></tr></table></figure>
<p>返回数组内部的信息</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">print(x.flags)</span><br></pre></td></tr></table></figure>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">C_CONTIGUOUS : True</span><br><span class="line">F_CONTIGUOUS : False</span><br><span class="line">OWNDATA : True</span><br><span class="line">WRITEABLE : True</span><br><span class="line">ALIGNED : True</span><br><span class="line">UPDATEIFCOPY : False</span><br></pre></td></tr></table></figure>
<p>将数组变为1维数组，并获取其中的一部分数据</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">print(x.flat[2:6])</span><br></pre></td></tr></table></figure>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[3 4 5 6]</span><br></pre></td></tr></table></figure>
<p>将值赋给1维数组，再转化成有原有数组的大小形式</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">x.flat=4;x</span><br><span class="line">print(x)</span><br></pre></td></tr></table></figure>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">[[4 4 4]</span><br><span class="line"> [4 4 4]</span><br><span class="line"> [4 4 4]]</span><br></pre></td></tr></table></figure>
<p>轴的个数（秩）</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">print(x.ndim)</span><br></pre></td></tr></table></figure>
<p>2</p>
<p>数组的维度，翻坠一个整数构成的元组。元组的长度就是秩</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">print(x.shape)</span><br></pre></td></tr></table></figure>
<p>(3,3)</p>
<p>可以取任意维的shape</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"># 取到第二维</span><br><span class="line">print(x.shape[:2])</span><br></pre></td></tr></table></figure>
<p>数组元素的总数</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">print(x.size)</span><br></pre></td></tr></table></figure>
<p>9</p>
<h1 id="axis理解"><a href="#axis理解" class="headerlink" title="axis理解"></a>axis理解</h1><p>NumPy数组的维数称为轴（axes），轴的个数叫秩（rank），一维数组的秩为1，二维数组的秩为2。</p>
<p><a href="https://www.jianshu.com/p/9aa448ea397c" target="_blank" rel="noopener">Stackoverflow系列(1) -Python Pandas与Numpy中axis参数的二义性</a></p>
<h1 id="取数组元素"><a href="#取数组元素" class="headerlink" title="取数组元素"></a>取数组元素</h1><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">x = np.array([2,  4,  0,  3,  5])</span><br><span class="line"># 不包括倒数第一个</span><br><span class="line">x[:-1]</span><br></pre></td></tr></table></figure>
<p>[2,4,0,3]</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">x=np.array([[1,2,3],[4,5,6],[7,8,9]])</span><br><span class="line"># 二维数组，逗号前后表示要取的行和列，:就是全部取，0:2就是取第0列和第1列，不包括第2列</span><br><span class="line">print(x[:,0:2])</span><br></pre></td></tr></table></figure>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">[[1 2]</span><br><span class="line"> [4 5]</span><br><span class="line"> [7 8]]</span><br></pre></td></tr></table></figure>
<p>如果只取一列，下面这种形式就会变成一个一位数组，要加上一个[]，才可以维持原有的二维数组的形式。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">print(x[:,-1])</span><br></pre></td></tr></table></figure>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[3 6 9]</span><br></pre></td></tr></table></figure>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">print(x[:,[-1]])</span><br></pre></td></tr></table></figure>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">[[3]</span><br><span class="line"> [6]</span><br><span class="line"> [9]]</span><br></pre></td></tr></table></figure>
<h1 id="排序"><a href="#排序" class="headerlink" title="排序"></a>排序</h1><p><a href="http://blog.csdn.net/pipisorry/article/details/51822775" target="_blank" rel="noopener">numpy教程：排序、搜索和计数</a></p>
<p>默认是升序排序。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">list1 = [[<span class="number">1</span>,<span class="number">3</span>,<span class="number">2</span>], [<span class="number">3</span>,<span class="number">5</span>,<span class="number">4</span>]]</span><br><span class="line">array = numpy.array(list1)</span><br><span class="line">array = sort(array, axis=<span class="number">1</span>)   <span class="comment">#对第1维升序排序</span></span><br><span class="line"><span class="comment">#array = sort(array, axis=0)   #对第0维</span></span><br><span class="line">print(array)</span><br><span class="line">[[<span class="number">1</span> <span class="number">2</span> <span class="number">3</span>]</span><br><span class="line"> [<span class="number">3</span> <span class="number">4</span> <span class="number">5</span>]]</span><br></pre></td></tr></table></figure>
<p>降序排序的实现:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">array = -sort(-array, axis=<span class="number">1</span>)   <span class="comment">#降序</span></span><br><span class="line">[[<span class="number">3</span> <span class="number">2</span> <span class="number">1</span>]</span><br><span class="line"> [<span class="number">5</span> <span class="number">4</span> <span class="number">3</span>]]</span><br></pre></td></tr></table></figure>
<p>参考</p>
<p>【1】<a href="http://blog.csdn.net/qq403977698/article/details/47254597" target="_blank" rel="noopener">numpy中的ndarray方法和属性</a></p>
<h1 id="运算、索引、切片"><a href="#运算、索引、切片" class="headerlink" title="运算、索引、切片"></a>运算、索引、切片</h1><p><a href="http://blog.csdn.net/liangzuojiayi/article/details/51534164" target="_blank" rel="noopener">http://blog.csdn.net/liangzuojiayi/article/details/51534164</a></p>
<h1 id="矩阵的各类乘法"><a href="#矩阵的各类乘法" class="headerlink" title="矩阵的各类乘法"></a>矩阵的各类乘法</h1><h2 id="dot-product点积"><a href="#dot-product点积" class="headerlink" title="dot product点积"></a>dot product点积</h2><script type="math/tex; mode=display">
a \cdot b = a_1b_1+a_2b_2...a_nb_n</script><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">x1 = [<span class="number">9</span>, <span class="number">2</span>, <span class="number">5</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">7</span>, <span class="number">5</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">9</span>, <span class="number">2</span>, <span class="number">5</span>, <span class="number">0</span>, <span class="number">0</span>]</span><br><span class="line">x2 = [<span class="number">9</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">9</span>, <span class="number">0</span>, <span class="number">9</span>, <span class="number">2</span>, <span class="number">5</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">9</span>, <span class="number">2</span>, <span class="number">5</span>, <span class="number">0</span>, <span class="number">0</span>]</span><br><span class="line"><span class="comment">### VECTORIZED DOT PRODUCT OF VECTORS ###</span></span><br><span class="line">tic = time.process_time()</span><br><span class="line">dot = np.dot(x1,x2)</span><br><span class="line">toc = time.process_time()</span><br><span class="line"><span class="keyword">print</span> (<span class="string">"dot = "</span> + str(dot) + <span class="string">"\n ----- Computation time = "</span> + str(<span class="number">1000</span>*(toc - tic)) + <span class="string">"ms"</span>)</span><br></pre></td></tr></table></figure>
<p>只有两个值是普通数组的时候才可以是点积，如果是np.array，则dot会变成矩阵乘法。也就是</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">x1 = np.array([[1,2,3]])</span><br><span class="line">x2 = np.array([[1,2,3]])</span><br><span class="line">np.dot(x1,x2)</span><br></pre></td></tr></table></figure>
<p>会报错</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ValueError: shapes (1,3) and (1,3) not aligned: 3 (dim 1) != 1 (dim 0)</span><br></pre></td></tr></table></figure>
<h2 id="outer-product外积"><a href="#outer-product外积" class="headerlink" title="outer product外积"></a>outer product外积</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">x1 = [<span class="number">9</span>, <span class="number">2</span>, <span class="number">5</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">7</span>, <span class="number">5</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">9</span>, <span class="number">2</span>, <span class="number">5</span>, <span class="number">0</span>, <span class="number">0</span>]</span><br><span class="line">x2 = [<span class="number">9</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">9</span>, <span class="number">0</span>, <span class="number">9</span>, <span class="number">2</span>, <span class="number">5</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">9</span>, <span class="number">2</span>, <span class="number">5</span>, <span class="number">0</span>, <span class="number">0</span>]</span><br><span class="line"><span class="comment">### VECTORIZED OUTER PRODUCT ###</span></span><br><span class="line">outer = np.outer(x1,x2)</span><br></pre></td></tr></table></figure>
<h2 id="element-wise-multipulation按位乘"><a href="#element-wise-multipulation按位乘" class="headerlink" title="element-wise multipulation按位乘"></a>element-wise multipulation按位乘</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">mul = np.multiply(x1,x2)</span><br></pre></td></tr></table></figure>
<h2 id="general-dot-product矩阵乘法"><a href="#general-dot-product矩阵乘法" class="headerlink" title="general dot product矩阵乘法"></a>general dot product矩阵乘法</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">W = np.random.rand(3,len(x1))</span><br><span class="line">dot = np.dot(W,x1)</span><br></pre></td></tr></table></figure>
<p>可以看出dot既可以用作点积，也可以执行矩阵乘法</p>
<h1 id="Broadcasting"><a href="#Broadcasting" class="headerlink" title="Broadcasting"></a>Broadcasting</h1><p>广播用以描述numpy中对两个形状不同的阵列进行数学计算的处理机制。较小的阵列“广播”到较大阵列相同的形状尺度上，使它们对等以可以进行数学计算。广播提供了一种向量化阵列的操作方式，因此Python不需要像C一样循环。广播操作不需要数据复制，通常执行效率非常高。然而，有时广播是个坏主意，可能会导致内存浪费以致计算减慢。</p>
<p>Numpy操作通常由成对的阵列完成，阵列间逐个元素对元素地执行。最简单的情形是两个阵列有一样的形状，例如：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">&gt;&gt;&gt; a = np.array([1.0, 2.0, 3.0])</span><br><span class="line">&gt;&gt;&gt; b = np.array([2.0, 2.0, 2.0])</span><br><span class="line">&gt;&gt;&gt; a * b</span><br><span class="line">array([ 2.,  4.,  6.])</span><br></pre></td></tr></table></figure>
<p>Numpy的广播机制放宽了对阵列形状的限制。最简单的情形是一个阵列和一个尺度值相乘：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">&gt;&gt;&gt; a = np.array([1.0, 2.0, 3.0])</span><br><span class="line">&gt;&gt;&gt; b = 2.0</span><br><span class="line">&gt;&gt;&gt; a * b</span><br><span class="line">array([ 2.,  4.,  6.])</span><br></pre></td></tr></table></figure>
<p>上面两种结果是一样的，我们可以认为尺度值b在计算时被延展得和a一样的形状。延展后的b的每一个元素都是原来尺度值的复制。延展的类比只是一种概念性的。实际上，Numpy并不需要真的复制这些尺度值，所以广播运算在内存和计算效率上尽量高效。</p>
<p>上面的第二个例子比第一个更高效，因为广播在乘法计算时动用更少的内存。</p>
<h2 id="exp"><a href="#exp" class="headerlink" title="exp"></a>exp</h2><p>broadcast运算</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">x = np.array([<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>])</span><br><span class="line">np.exp(x)</span><br></pre></td></tr></table></figure>
<h2 id="sum"><a href="#sum" class="headerlink" title="sum"></a>sum</h2><p>broadcast运算。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">softmax</span><span class="params">(x)</span>:</span></span><br><span class="line">	x_exp = np.exp(x)</span><br><span class="line">	x_sum = np.sum(x_exp, axis=<span class="number">1</span>, keepdims=<span class="keyword">True</span>)</span><br><span class="line">	s = x_exp/x_sum</span><br></pre></td></tr></table></figure>
<h1 id="matrix"><a href="#matrix" class="headerlink" title="matrix"></a>matrix</h1><h2 id="array转matrix"><a href="#array转matrix" class="headerlink" title="array转matrix"></a>array转matrix</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">s = np.array([5,5,0,0,0,5])</span><br><span class="line">np.matrix(s)</span><br></pre></td></tr></table></figure>
<h1 id="加载数据"><a href="#加载数据" class="headerlink" title="加载数据"></a>加载数据</h1><h2 id="loadtxt"><a href="#loadtxt" class="headerlink" title="loadtxt"></a>loadtxt</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">numpy.loadtxt(fname, dtype=&lt;type &apos;float&apos;&gt;, comments=&apos;#&apos;, delimiter=None, converters=None, skiprows=0, usecols=None, unpack=False, ndmin=0)[source]</span><br></pre></td></tr></table></figure>
<p>参数</p>
<p><strong>fname</strong> : file, str, or pathlib.Path</p>
<blockquote>
<p>File, filename, or generator to read. If the filename extension is <code>.gz</code> or <code>.bz2</code>, the file is first decompressed. Note that generators should return byte strings for Python 3k.</p>
</blockquote>
<p><strong>dtype</strong> : data-type, optional</p>
<blockquote>
<p>Data-type of the resulting array; default: float. If this is a structured data-type, the resulting array will be 1-dimensional, and each row will be interpreted as an element of the array. In this case, the number of columns used must match the number of fields in the data-type.</p>
</blockquote>
<p><strong>comments</strong> : str or sequence, optional</p>
<blockquote>
<p>The characters or list of characters used to indicate the start of a comment; default: ‘#’.</p>
</blockquote>
<p><strong>delimiter</strong> : str, optional</p>
<blockquote>
<p>The string used to separate values. By default, this is any whitespace.</p>
</blockquote>
<p><strong>converters</strong> : dict, optional</p>
<blockquote>
<p>A dictionary mapping column number to a function that will convert that column to a float. E.g., if column 0 is a date string: <code>converters = {0: datestr2num}</code>. Converters can also be used to provide a default value for missing data (but see also <a href="https://docs.scipy.org/doc/numpy/reference/generated/numpy.genfromtxt.html#numpy.genfromtxt" target="_blank" rel="noopener"><code>genfromtxt</code></a>):<code>converters = {3: lambda s: float(s.strip() or 0)}</code>. Default: None.</p>
</blockquote>
<p><strong>skiprows</strong> : int, optional</p>
<blockquote>
<p>Skip the first <em>skiprows</em> lines; default: 0.</p>
</blockquote>
<p><strong>usecols</strong> : int or sequence, optional</p>
<blockquote>
<p>Which columns to read, with 0 being the first. For example, usecols = (1,4,5) will extract the 2nd, 5th and 6th columns. The default, None, results in all columns being read.</p>
<p>New in version 1.11.0.</p>
<p>Also when a single column has to be read it is possible to use an integer instead of a tuple. E.g <code>usecols = 3</code> reads the fourth column the same way as <em>usecols = (3,)`</em> would.</p>
</blockquote>
<p><strong>unpack</strong> : bool, optional</p>
<blockquote>
<p>If True, the returned array is transposed, so that arguments may be unpacked using <code>x, y, z = loadtxt(...)</code>. When used with a structured data-type, arrays are returned for each field. Default is False.</p>
</blockquote>
<p><strong>ndmin</strong> : int, optional</p>
<blockquote>
<p>The returned array will have at least <em>ndmin</em> dimensions. Otherwise mono-dimensional axes will be squeezed. Legal values: 0 (default), 1 or 2.</p>
<p>New in version 1.6.0.</p>
</blockquote>
<p>返回</p>
<p><strong>out</strong> : ndarray</p>
<blockquote>
<p>Data read from the text file.</p>
</blockquote>
<h2 id="genfromtxt"><a href="#genfromtxt" class="headerlink" title="genfromtxt"></a>genfromtxt</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">import numpy</span><br><span class="line">nfl = numpy.genfromtxt(&quot;data.csv&quot;, delimiter=&quot;,&quot;)</span><br></pre></td></tr></table></figure>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"># U75就是将每个值作为一个75 byte的unicode来读取</span><br><span class="line">world_alcohol = np.genfromtxt(&apos;world_alcohol.csv&apos;, dtype=&apos;U75&apos;, skip_header=1, delimiter=&apos;,&apos;)</span><br></pre></td></tr></table></figure>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">data = np.genfromtxt(&apos;/Users/david/david/code/00project/carthage/scripts/adult.data&apos;, delimiter=&apos;, &apos;, dtype=str)</span><br><span class="line"># 取第14列</span><br><span class="line">labels = data[:,14]</span><br><span class="line"># 取除了倒数第二列之外的所有列</span><br><span class="line">data = data[:,:-1]</span><br></pre></td></tr></table></figure>
<h1 id="matrix转数组"><a href="#matrix转数组" class="headerlink" title="matrix转数组"></a>matrix转数组</h1><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">np.argsort(y_score, kind=&quot;mergesort&quot;)[::-1]</span><br></pre></td></tr></table></figure>
<h1 id="随机数字的矩阵"><a href="#随机数字的矩阵" class="headerlink" title="随机数字的矩阵"></a>随机数字的矩阵</h1><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">import numpy as np</span><br><span class="line">numpy_matrix = np.random.randint(10, size=[5,2])</span><br><span class="line"></span><br><span class="line">‘’‘</span><br><span class="line">array([[1, 0],</span><br><span class="line">       [8, 4],</span><br><span class="line">       [0, 5],</span><br><span class="line">       [2, 9],</span><br><span class="line">       [9, 9]])</span><br><span class="line">’‘’</span><br></pre></td></tr></table></figure>
<h1 id="获取排序后数据位置的下标"><a href="#获取排序后数据位置的下标" class="headerlink" title="获取排序后数据位置的下标"></a>获取排序后数据位置的下标</h1><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">import numpy as np</span><br><span class="line">dd=np.mat([4,5,1]) </span><br><span class="line">dd1 = dd.argsort()</span><br><span class="line">print dd</span><br><span class="line">print dd1		#matrix([[2, 0, 1]], dtype=int64)</span><br></pre></td></tr></table></figure>
<h1 id="squeeze"><a href="#squeeze" class="headerlink" title="squeeze"></a>squeeze</h1><p>从数组的形状中删除单维条目，即把shape中为1的维度去掉</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">x = np.array([[[0], [1], [2]]])  </span><br><span class="line">np.squeeze(x)</span><br></pre></td></tr></table></figure>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">array([0, 1, 2])</span><br></pre></td></tr></table></figure>
<p>如果本来就是(1,1)的矩阵，则变成常数</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">cost = np.array([[1]])</span><br><span class="line">cost = np.squeeze(cost)</span><br></pre></td></tr></table></figure>
<p>得到1，cost的shape变成<code>()</code></p>
<h1 id="获取符合条件的行列集合"><a href="#获取符合条件的行列集合" class="headerlink" title="获取符合条件的行列集合"></a>获取符合条件的行列集合</h1><p>数据如</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">1,1,1,0,0,0</span><br><span class="line">0,1,1,1,1,0</span><br><span class="line">1,0,0,1,1,0</span><br><span class="line">0,0,0,1,1,0</span><br></pre></td></tr></table></figure>
<p>第一列作为y_train，后面矩阵作为x_train，需要获取y_train中为1的x_train的行</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">pos_rows = (y_train == 1)</span><br><span class="line">x_train[pos_rows,:]</span><br></pre></td></tr></table></figure>
<p>还有个例子</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">vector = numpy.array([5, 10, 15, 20])</span><br><span class="line">vector == 10</span><br></pre></td></tr></table></figure>
<p>[False, True, False, False]</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">matrix = numpy.array([</span><br><span class="line">                    [5, 10, 15], </span><br><span class="line">                    [20, 25, 30],</span><br><span class="line">                    [35, 40, 45]</span><br><span class="line">                 ])</span><br><span class="line">    matrix == 25</span><br></pre></td></tr></table></figure>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">[</span><br><span class="line">    [False, False, False], </span><br><span class="line">    [False, True,  False],</span><br><span class="line">    [False, False, False]</span><br><span class="line">]</span><br></pre></td></tr></table></figure>
<p>比如要找第二列中是25的那一行</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">matrix = np.array([</span><br><span class="line">                [5, 10, 15], </span><br><span class="line">                [20, 25, 30],</span><br><span class="line">                [35, 40, 45]</span><br><span class="line">             ])</span><br><span class="line">    second_column_25 = (matrix[:,1] == 25)</span><br><span class="line">    # 等同于print(matrix[second_column_25])</span><br><span class="line">    print(matrix[second_column_25, :])</span><br></pre></td></tr></table></figure>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">[</span><br><span class="line">    [20, 25, 30]</span><br><span class="line">]</span><br></pre></td></tr></table></figure>
<p>多个条件的比较</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">vector = numpy.array([5, 10, 15, 20])</span><br><span class="line">equal_to_ten_and_five = (vector == 10) &amp; (vector == 5)</span><br></pre></td></tr></table></figure>
<p><code>[False, False, False, False]</code></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">vector = numpy.array([5, 10, 15, 20])</span><br><span class="line">equal_to_ten_or_five = (vector == 10) | (vector == 5)</span><br></pre></td></tr></table></figure>
<p><code>[True, True, False, False]</code></p>
<p>也可以根据比较的结果改变值</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">vector = numpy.array([5, 10, 15, 20])</span><br><span class="line">equal_to_ten_or_five = (vector == 10) | (vector == 5)</span><br><span class="line">vector[equal_to_ten_or_five] = 50</span><br><span class="line">print(vector)</span><br></pre></td></tr></table></figure>
<p>true的都变成了50</p>
<p><code>[50, 50, 15, 20]</code></p>
<h1 id="判断条件并转成0和1的输出"><a href="#判断条件并转成0和1的输出" class="headerlink" title="判断条件并转成0和1的输出"></a>判断条件并转成0和1的输出</h1><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"># x是numpy的数组，如</span><br><span class="line"># x = np.array([-1.0, 1.0, 2.0])</span><br><span class="line">def step_function(x):</span><br><span class="line">    return np.array(x &gt; 0, dtype=np.int)</span><br><span class="line">    </span><br><span class="line"># 或者</span><br><span class="line">def step_function(x):</span><br><span class="line">	y = x &gt; 0</span><br><span class="line">	# astype把bool转成int</span><br><span class="line">	return y.astype(np.int)</span><br></pre></td></tr></table></figure>

          
        
      
    </div>

    

    
    
    

    

    
      
    
    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  

  <article class="post post-type-normal" itemscope="" itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="https://schwimmer.github.io/2018/03/17/算法与数据结构/硬币问题/">

    <span hidden itemprop="author" itemscope="" itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Schwimmer">
      <meta itemprop="description" content="Record and Think!">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope="" itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Schwimmer's Blog">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                
                <a href="/2018/03/17/算法与数据结构/硬币问题/" class="post-title-link" itemprop="url">硬币问题</a>
              
            
          </h1>
        

        <div class="post-meta">

          
          
          

          
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              

              
                
              

              <time title="创建时间：2018-03-17 20:50:31" itemprop="dateCreated datePublished" datetime="2018-03-17T20:50:31+08:00">2018-03-17</time>
            </span>
          

          

          
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope="" itemtype="http://schema.org/Thing"><a href="/categories/算法与数据结构/" itemprop="url" rel="index"><span itemprop="name">算法与数据结构</span></a></span>

                
                
              
            </span>
          

          
            
            
              
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="fa fa-comment-o"></i>
                </span>
            
                <span class="post-meta-item-text">评论数：</span>
                <a href="/2018/03/17/算法与数据结构/硬币问题/#comments" itemprop="discussionUrl">
                  <span class="post-comments-count disqus-comment-count" data-disqus-identifier="2018/03/17/算法与数据结构/硬币问题/" itemprop="commentCount"></span>
                </a>
              </span>
            
          

          
          

          

          <br>
          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>转自 <a href="http://www.cnblogs.com/z941030/p/4908115.html" target="_blank" rel="noopener">动态规划之硬币组合问题</a></p>
<p>动态规划的本质是将原问题分解为同性质的若干相同子结构，在求解最优值的过程中将子结构的最优值记录到一个表中以避免有时会有大量的重复计算。</p>
<p>例如硬币组合问题，若求凑够11元的最少硬币数，可以先从凑够0元、1元、2元……的子结构开始分析。</p>
<p>假设d(i)为凑够i元所需最少硬币数，则</p>
<p>d(0) = 0 　　　　　　　　理所当然</p>
<p>d(1) = 1 　　　　　　　　要凑够1元，需要从面值小于等于1元的硬币中选择，目前只有面值为1元的硬币</p>
<p>　　　　　　　　　　　　此时d(1) = d(0) + 1</p>
<p>d(2) = d(2 - 1) + 1 = 2， 从面值小于等于2元的硬币中选择，符合要求的硬币面值为：1元。</p>
<p>　　　　　　　　　　　　此时d(2) = d(2-1) + 1</p>
<p>d(3) = d(3 - 3) + 1 = 1， 从面值小于等于3元的硬币中选择，符合要求的硬币面值为：1元，3元。</p>
<p>　　　　　　　　　　　　此时有有两种选择：是否选择含有面值3元的硬币</p>
<p>　　　　　　　　　　　　含有3元硬币：d(3) = d(3 - 3) + 1 = 1</p>
<p>　　　　　　　　　　　　不含3元硬币：d(3) = d(3 - 1) + 1 = d(2) + 1 = 3</p>
<p>　　　　　　　　　　　　自然是选择二者中较小值</p>
<p>依次类推…</p>
<p>就该问题总结一下，随着要凑够钱数的增加：</p>
<p>1、首先要知道所有不大于该钱数的面值;</p>
<p>2、对于每种面值的硬币，求出当选择一个该面值的硬币时所需的硬币数</p>
<p>当选择一个硬币后，所需硬币数+1，所要凑够的钱数=原所要凑的钱数-该硬币面值，所要凑够的钱数减少，求减少后要凑钱数最少所需硬币数，属于原问题的子结构，已求出解</p>
<p>3.在上述求出的结果集中，选择最小值，即为要凑够该钱数所需的最少硬币数</p>
<p>由此可以看出，每个问题的最优值都是借其子结构的最优值得到的。</p>
<p>而该算法的最小的子结构的最优解是已知的，即：当要凑钱数为0元时，最少需要0枚硬币。</p>
<p>利用这个最小的子结构，通过递推式便可求出所指定值凑够钱数的最优值</p>
<p>上面所提到的递推式，便是<strong>状态转移方程</strong>。利用已知状态，不断通过状态转移方程求解，便得到了最优值和最优解。</p>
<p>下面看一下硬币组合问题的数学描述：</p>
<p>d(i)=min{ d(i-vj)+1 }，其中i-vj &gt;=0，vj表示第j个硬币的面值，i表示要凑够i元，d(i)表示凑够i元最少需要的硬币数。即：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">                     　　　　0  　　　　 i == 0 时</span><br><span class="line">min_coin_num(i) = &#123;</span><br><span class="line">                  　　　　　min&#123; min_coin_num( i-coin_value(j) )+1 | i-coin_value(j)&gt;0&#125; coin_value(j)表示第j种硬币的面值 　　i &gt; 0 时</span><br></pre></td></tr></table></figure>
<p>当总值total_value为i时， 对于所有的 coin_value(j) &lt; i的硬币j ,取min{ min_coin_num(i-coin_value(j)) }</p>
<p>代码在 <code>dynamic_programming/coin.py</code></p>

          
        
      
    </div>

    

    
    
    

    

    
      
    
    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  

  <article class="post post-type-normal" itemscope="" itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="https://schwimmer.github.io/2018/03/17/算法与数据结构/数学问题综合/">

    <span hidden itemprop="author" itemscope="" itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Schwimmer">
      <meta itemprop="description" content="Record and Think!">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope="" itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Schwimmer's Blog">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                
                <a href="/2018/03/17/算法与数据结构/数学问题综合/" class="post-title-link" itemprop="url">数学问题综合</a>
              
            
          </h1>
        

        <div class="post-meta">

          
          
          

          
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              

              
                
              

              <time title="创建时间：2018-03-17 20:50:31" itemprop="dateCreated datePublished" datetime="2018-03-17T20:50:31+08:00">2018-03-17</time>
            </span>
          

          

          
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope="" itemtype="http://schema.org/Thing"><a href="/categories/算法与数据结构/" itemprop="url" rel="index"><span itemprop="name">算法与数据结构</span></a></span>

                
                
              
            </span>
          

          
            
            
              
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="fa fa-comment-o"></i>
                </span>
            
                <span class="post-meta-item-text">评论数：</span>
                <a href="/2018/03/17/算法与数据结构/数学问题综合/#comments" itemprop="discussionUrl">
                  <span class="post-comments-count disqus-comment-count" data-disqus-identifier="2018/03/17/算法与数据结构/数学问题综合/" itemprop="commentCount"></span>
                </a>
              </span>
            
          

          
          

          

          <br>
          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1 id="从1-200中任意选出101个自然数-其中一个数必是另一个数的整数倍"><a href="#从1-200中任意选出101个自然数-其中一个数必是另一个数的整数倍" class="headerlink" title="从1-200中任意选出101个自然数,其中一个数必是另一个数的整数倍"></a>从1-200中任意选出101个自然数,其中一个数必是另一个数的整数倍</h1><p>把这200个数分类如下：</p>
<p><img src="https://s10.sinaimg.cn/mw690/001qZCIpzy7d4N8k2xP79&amp;690" alt=""></p>
<p>以上共分为100类，即100个抽屉。显然在同一类中的数若不少于两个，那么这类中的任意两个数都有倍数关系。从中任取101个数，根据抽屉原理，一定至少有两个数取自同一类，因此其中一个数是另一个数的倍数。</p>

          
        
      
    </div>

    

    
    
    

    

    
      
    
    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  

  <article class="post post-type-normal" itemscope="" itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="https://schwimmer.github.io/2018/03/17/算法与数据结构/排序/">

    <span hidden itemprop="author" itemscope="" itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Schwimmer">
      <meta itemprop="description" content="Record and Think!">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope="" itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Schwimmer's Blog">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                
                <a href="/2018/03/17/算法与数据结构/排序/" class="post-title-link" itemprop="url">排序</a>
              
            
          </h1>
        

        <div class="post-meta">

          
          
          

          
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              

              
                
              

              <time title="创建时间：2018-03-17 20:50:31" itemprop="dateCreated datePublished" datetime="2018-03-17T20:50:31+08:00">2018-03-17</time>
            </span>
          

          

          
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope="" itemtype="http://schema.org/Thing"><a href="/categories/算法与数据结构/" itemprop="url" rel="index"><span itemprop="name">算法与数据结构</span></a></span>

                
                
              
            </span>
          

          
            
            
              
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="fa fa-comment-o"></i>
                </span>
            
                <span class="post-meta-item-text">评论数：</span>
                <a href="/2018/03/17/算法与数据结构/排序/#comments" itemprop="discussionUrl">
                  <span class="post-comments-count disqus-comment-count" data-disqus-identifier="2018/03/17/算法与数据结构/排序/" itemprop="commentCount"></span>
                </a>
              </span>
            
          

          
          

          

          <br>
          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>堆排序</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#!/usr/bin/env python2</span></span><br><span class="line"><span class="comment"># -*- coding: utf-8 -*-</span></span><br><span class="line"><span class="string">"""</span></span><br><span class="line"><span class="string">Created on Tue Mar 13 09:46:42 2018</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">@author: david</span></span><br><span class="line"><span class="string">"""</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">sift_down</span><span class="params">(array, start, end)</span>:</span></span><br><span class="line">    <span class="string">"""</span></span><br><span class="line"><span class="string">    调整成大顶堆，初始堆时，从下往上；交换堆顶与堆尾后，从上往下调整</span></span><br><span class="line"><span class="string">    :param array: 列表的引用</span></span><br><span class="line"><span class="string">    :param start: 父结点</span></span><br><span class="line"><span class="string">    :param end: 结束的下标</span></span><br><span class="line"><span class="string">    :return: 无</span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line">    <span class="keyword">while</span> <span class="keyword">True</span>:</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 当列表第一个是以下标0开始，结点下标为i,左孩子则为2*i+1,右孩子下标则为2*i+2;</span></span><br><span class="line">        <span class="comment"># 若下标以1开始，左孩子则为2*i,右孩子则为2*i+１</span></span><br><span class="line">        left_child = <span class="number">2</span>*start + <span class="number">1</span>  <span class="comment"># 左孩子的结点下标</span></span><br><span class="line">        <span class="comment"># 当结点的右孩子存在，且大于结点的左孩子时</span></span><br><span class="line">        <span class="keyword">if</span> left_child &gt; end:</span><br><span class="line">            <span class="keyword">break</span></span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> left_child+<span class="number">1</span> &lt;= end <span class="keyword">and</span> array[left_child+<span class="number">1</span>] &gt; array[left_child]:</span><br><span class="line">            left_child += <span class="number">1</span></span><br><span class="line">        <span class="keyword">if</span> array[left_child] &gt; array[start]:  <span class="comment"># 当左右孩子的最大值大于父结点时，则交换</span></span><br><span class="line">            array[left_child], array[start] = array[start], array[left_child]</span><br><span class="line"></span><br><span class="line">            start = left_child  <span class="comment"># 交换之后以交换子结点为根的堆可能不是大顶堆，需重新调整</span></span><br><span class="line">        <span class="keyword">else</span>:  <span class="comment"># 若父结点大于左右孩子，则退出循环</span></span><br><span class="line">            <span class="keyword">break</span></span><br><span class="line"></span><br><span class="line">        print(<span class="string">"&gt;&gt;"</span>, array)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">heap_sort</span><span class="params">(array)</span>:</span>  <span class="comment"># 堆排序</span></span><br><span class="line">    <span class="comment"># 先初始化大顶堆</span></span><br><span class="line">    first = len(array)//<span class="number">2</span> <span class="number">-1</span>  <span class="comment"># 最后一个有孩子的节点(//表示取整的意思)</span></span><br><span class="line">    <span class="comment"># 第一个结点的下标为０，很多博客&amp;课本教材是从下标1开始，无所谓吧，你随意</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(first, <span class="number">-1</span>, <span class="number">-1</span>):  <span class="comment"># 从最后一个有孩子的节点开始往上调整</span></span><br><span class="line">        print(array[i])</span><br><span class="line">        sift_down(array, i, len(array)<span class="number">-1</span>)  <span class="comment"># 初始化大顶堆</span></span><br><span class="line"></span><br><span class="line">    print(<span class="string">"初始化大顶堆结果:"</span>, array)</span><br><span class="line">    <span class="comment"># 交换堆顶与堆尾</span></span><br><span class="line">    <span class="keyword">for</span> head_end <span class="keyword">in</span> range(len(array)<span class="number">-1</span>, <span class="number">0</span>, <span class="number">-1</span>):  <span class="comment"># start stop step</span></span><br><span class="line">        array[head_end], array[<span class="number">0</span>] = array[<span class="number">0</span>], array[head_end] <span class="comment"># 交换堆顶与堆尾</span></span><br><span class="line">        sift_down(array, <span class="number">0</span>, head_end<span class="number">-1</span>)  <span class="comment"># 堆长度减一(head_end-1)，再从上往下调整成大顶堆</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">"__main__"</span>:</span><br><span class="line">    array = [<span class="number">16</span>, <span class="number">7</span>, <span class="number">3</span>, <span class="number">20</span>, <span class="number">17</span>, <span class="number">8</span>]</span><br><span class="line">    print(array)</span><br><span class="line">    heap_sort(array)</span><br><span class="line">    print(<span class="string">"堆排序最终结果:"</span>, array)</span><br></pre></td></tr></table></figure>

          
        
      
    </div>

    

    
    
    

    

    
      
    
    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  

  <article class="post post-type-normal" itemscope="" itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="https://schwimmer.github.io/2018/03/17/机器学习/逻辑回归/">

    <span hidden itemprop="author" itemscope="" itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Schwimmer">
      <meta itemprop="description" content="Record and Think!">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope="" itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Schwimmer's Blog">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                
                <a href="/2018/03/17/机器学习/逻辑回归/" class="post-title-link" itemprop="url">逻辑回归</a>
              
            
          </h1>
        

        <div class="post-meta">

          
          
          

          
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              

              
                
              

              <time title="创建时间：2018-03-17 20:50:31" itemprop="dateCreated datePublished" datetime="2018-03-17T20:50:31+08:00">2018-03-17</time>
            </span>
          

          
            

            
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="fa fa-calendar-check-o"></i>
                </span>
                
                  <span class="post-meta-item-text">更新于</span>
                
                <time title="修改时间：2019-07-06 14:33:39" itemprop="dateModified" datetime="2019-07-06T14:33:39+08:00">2019-07-06</time>
              </span>
            
          

          
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope="" itemtype="http://schema.org/Thing"><a href="/categories/机器学习/" itemprop="url" rel="index"><span itemprop="name">机器学习</span></a></span>

                
                
              
            </span>
          

          
            
            
              
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="fa fa-comment-o"></i>
                </span>
            
                <span class="post-meta-item-text">评论数：</span>
                <a href="/2018/03/17/机器学习/逻辑回归/#comments" itemprop="discussionUrl">
                  <span class="post-comments-count disqus-comment-count" data-disqus-identifier="2018/03/17/机器学习/逻辑回归/" itemprop="commentCount"></span>
                </a>
              </span>
            
          

          
          

          

          <br>
          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">'''</span></span><br><span class="line"><span class="string">Created on Oct 27, 2010</span></span><br><span class="line"><span class="string">Logistic Regression Working Module</span></span><br><span class="line"><span class="string">@author: Peter</span></span><br><span class="line"><span class="string">'''</span></span><br><span class="line"><span class="keyword">from</span> numpy <span class="keyword">import</span> *</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">loadDataSet</span><span class="params">()</span>:</span></span><br><span class="line">    dataMat = []; labelMat = []</span><br><span class="line">    fr = open(<span class="string">'testSet.txt'</span>)</span><br><span class="line">    <span class="keyword">for</span> line <span class="keyword">in</span> fr.readlines():</span><br><span class="line">        lineArr = line.strip().split()</span><br><span class="line">        dataMat.append([<span class="number">1.0</span>, float(lineArr[<span class="number">0</span>]), float(lineArr[<span class="number">1</span>])])</span><br><span class="line">        labelMat.append(int(lineArr[<span class="number">2</span>]))</span><br><span class="line">    <span class="keyword">return</span> dataMat,labelMat</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">sigmoid</span><span class="params">(inX)</span>:</span></span><br><span class="line">    <span class="keyword">return</span> <span class="number">1.0</span>/(<span class="number">1</span>+exp(-inX))</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">gradAscent</span><span class="params">(dataMatIn, classLabels)</span>:</span></span><br><span class="line">    dataMatrix = mat(dataMatIn)             <span class="comment">#convert to NumPy matrix</span></span><br><span class="line">    labelMat = mat(classLabels).transpose() <span class="comment">#convert to NumPy matrix</span></span><br><span class="line">    m,n = shape(dataMatrix)</span><br><span class="line">    alpha = <span class="number">0.001</span></span><br><span class="line">    maxCycles = <span class="number">500</span></span><br><span class="line">    weights = ones((n,<span class="number">1</span>))</span><br><span class="line">    <span class="keyword">for</span> k <span class="keyword">in</span> range(maxCycles):              <span class="comment">#heavy on matrix operations</span></span><br><span class="line">        h = sigmoid(dataMatrix*weights)     <span class="comment">#matrix mult</span></span><br><span class="line">        error = (labelMat - h)              <span class="comment">#vector subtraction</span></span><br><span class="line">        weights = weights + alpha * dataMatrix.transpose()* error <span class="comment">#matrix mult</span></span><br><span class="line">    <span class="keyword">return</span> weights</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">plotBestFit</span><span class="params">(weights)</span>:</span></span><br><span class="line">    <span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line">    dataMat,labelMat=loadDataSet()</span><br><span class="line">    dataArr = array(dataMat)</span><br><span class="line">    n = shape(dataArr)[<span class="number">0</span>] </span><br><span class="line">    xcord1 = []; ycord1 = []</span><br><span class="line">    xcord2 = []; ycord2 = []</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(n):</span><br><span class="line">        <span class="keyword">if</span> int(labelMat[i])== <span class="number">1</span>:</span><br><span class="line">            xcord1.append(dataArr[i,<span class="number">1</span>]); ycord1.append(dataArr[i,<span class="number">2</span>])</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            xcord2.append(dataArr[i,<span class="number">1</span>]); ycord2.append(dataArr[i,<span class="number">2</span>])</span><br><span class="line">    fig = plt.figure()</span><br><span class="line">    ax = fig.add_subplot(<span class="number">111</span>)</span><br><span class="line">    ax.scatter(xcord1, ycord1, s=<span class="number">30</span>, c=<span class="string">'red'</span>, marker=<span class="string">'s'</span>)</span><br><span class="line">    ax.scatter(xcord2, ycord2, s=<span class="number">30</span>, c=<span class="string">'green'</span>)</span><br><span class="line">    x = arange(<span class="number">-3.0</span>, <span class="number">3.0</span>, <span class="number">0.1</span>)</span><br><span class="line">    y = (-weights[<span class="number">0</span>]-weights[<span class="number">1</span>]*x)/weights[<span class="number">2</span>]</span><br><span class="line">    ax.plot(x, y)</span><br><span class="line">    plt.xlabel(<span class="string">'X1'</span>); plt.ylabel(<span class="string">'X2'</span>);</span><br><span class="line">    plt.show()</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">stocGradAscent0</span><span class="params">(dataMatrix, classLabels)</span>:</span></span><br><span class="line">    m,n = shape(dataMatrix)</span><br><span class="line">    alpha = <span class="number">0.01</span></span><br><span class="line">    weights = ones(n)   <span class="comment">#initialize to all ones</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(m):</span><br><span class="line">        h = sigmoid(sum(dataMatrix[i]*weights))</span><br><span class="line">        error = classLabels[i] - h</span><br><span class="line">        weights = weights + alpha * error * dataMatrix[i]</span><br><span class="line">    <span class="keyword">return</span> weights</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">stocGradAscent1</span><span class="params">(dataMatrix, classLabels, numIter=<span class="number">150</span>)</span>:</span></span><br><span class="line">    m,n = shape(dataMatrix)</span><br><span class="line">    weights = ones(n)   <span class="comment">#initialize to all ones</span></span><br><span class="line">    <span class="keyword">for</span> j <span class="keyword">in</span> range(numIter):</span><br><span class="line">        dataIndex = range(m)</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> range(m):</span><br><span class="line">            alpha = <span class="number">4</span>/(<span class="number">1.0</span>+j+i)+<span class="number">0.0001</span>    <span class="comment">#apha decreases with iteration, does not </span></span><br><span class="line">            randIndex = int(random.uniform(<span class="number">0</span>,len(dataIndex)))<span class="comment">#go to 0 because of the constant</span></span><br><span class="line">            h = sigmoid(sum(dataMatrix[randIndex]*weights))</span><br><span class="line">            error = classLabels[randIndex] - h</span><br><span class="line">            weights = weights + alpha * error * dataMatrix[randIndex]</span><br><span class="line">            <span class="keyword">del</span>(dataIndex[randIndex])</span><br><span class="line">    <span class="keyword">return</span> weights</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">classifyVector</span><span class="params">(inX, weights)</span>:</span></span><br><span class="line">    prob = sigmoid(sum(inX*weights))</span><br><span class="line">    <span class="keyword">if</span> prob &gt; <span class="number">0.5</span>: <span class="keyword">return</span> <span class="number">1.0</span></span><br><span class="line">    <span class="keyword">else</span>: <span class="keyword">return</span> <span class="number">0.0</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">colicTest</span><span class="params">()</span>:</span></span><br><span class="line">    frTrain = open(<span class="string">'horseColicTraining.txt'</span>); frTest = open(<span class="string">'horseColicTest.txt'</span>)</span><br><span class="line">    trainingSet = []; trainingLabels = []</span><br><span class="line">    <span class="keyword">for</span> line <span class="keyword">in</span> frTrain.readlines():</span><br><span class="line">        currLine = line.strip().split(<span class="string">'\t'</span>)</span><br><span class="line">        lineArr =[]</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">21</span>):</span><br><span class="line">            lineArr.append(float(currLine[i]))</span><br><span class="line">        trainingSet.append(lineArr)</span><br><span class="line">        trainingLabels.append(float(currLine[<span class="number">21</span>]))</span><br><span class="line">    trainWeights = stocGradAscent1(array(trainingSet), trainingLabels, <span class="number">1000</span>)</span><br><span class="line">    errorCount = <span class="number">0</span>; numTestVec = <span class="number">0.0</span></span><br><span class="line">    <span class="keyword">for</span> line <span class="keyword">in</span> frTest.readlines():</span><br><span class="line">        numTestVec += <span class="number">1.0</span></span><br><span class="line">        currLine = line.strip().split(<span class="string">'\t'</span>)</span><br><span class="line">        lineArr =[]</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">21</span>):</span><br><span class="line">            lineArr.append(float(currLine[i]))</span><br><span class="line">        <span class="keyword">if</span> int(classifyVector(array(lineArr), trainWeights))!= int(currLine[<span class="number">21</span>]):</span><br><span class="line">            errorCount += <span class="number">1</span></span><br><span class="line">    errorRate = (float(errorCount)/numTestVec)</span><br><span class="line">    <span class="keyword">print</span> <span class="string">"the error rate of this test is: %f"</span> % errorRate</span><br><span class="line">    <span class="keyword">return</span> errorRate</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">multiTest</span><span class="params">()</span>:</span></span><br><span class="line">    numTests = <span class="number">10</span>; errorSum=<span class="number">0.0</span></span><br><span class="line">    <span class="keyword">for</span> k <span class="keyword">in</span> range(numTests):</span><br><span class="line">        errorSum += colicTest()</span><br><span class="line">    <span class="keyword">print</span> <span class="string">"after %d iterations the average error rate is: %f"</span> % (numTests, errorSum/float(numTests))</span><br></pre></td></tr></table></figure>
<p><a href="http://blog.csdn.net/ljn113399/article/details/52725736" target="_blank" rel="noopener">逻辑回归详解</a></p>
<p>对随机梯度下降算法，我们做两处改进来避免上述的波动问题：</p>
<p>1）在每次迭代时，调整更新步长alpha的值。随着迭代的进行，alpha越来越小，这会缓解系数的高频波动（也就是每次迭代系数改变得太大，跳的跨度太大）。当然了，为了避免alpha随着迭代不断减小到接近于0（这时候，系数几乎没有调整，那么迭代也没有意义了），我们约束alpha一定大于一个稍微大点的常数项，具体见代码。</p>
<p>2）每次迭代，改变样本的优化顺序。也就是随机选择样本来更新回归系数。这样做可以减少周期性的波动，因为样本顺序的改变，使得每次迭代不再形成周期性。</p>
<h1 id="sklearn的LR"><a href="#sklearn的LR" class="headerlink" title="sklearn的LR"></a>sklearn的LR</h1><p><a href="http://www.cnblogs.com/pinard/p/6035872.html" target="_blank" rel="noopener">scikit-learn 逻辑回归类库使用小结</a></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># coding: utf-8</span></span><br><span class="line"><span class="comment"># pylint: disable = invalid-name, C0111</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">from</span> itertools <span class="keyword">import</span> cycle</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">from</span> sklearn <span class="keyword">import</span> svm, datasets</span><br><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> roc_curve, auc</span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> train_test_split</span><br><span class="line"><span class="keyword">from</span> sklearn.preprocessing <span class="keyword">import</span> label_binarize</span><br><span class="line"><span class="keyword">from</span> sklearn.multiclass <span class="keyword">import</span> OneVsRestClassifier</span><br><span class="line"><span class="keyword">from</span> scipy <span class="keyword">import</span> interp</span><br><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> confusion_matrix</span><br><span class="line"><span class="keyword">from</span> sklearn.preprocessing <span class="keyword">import</span> OneHotEncoder</span><br><span class="line"><span class="keyword">import</span> zipfile</span><br><span class="line"><span class="keyword">from</span> sklearn.linear_model <span class="keyword">import</span> LogisticRegression</span><br><span class="line"><span class="keyword">from</span> sklearn.externals <span class="keyword">import</span> joblib</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># with zipfile.ZipFile('df_allfeature_train1-7.csv.zip', 'r') as z:</span></span><br><span class="line"><span class="comment">#     f = z.open('df_allfeature_train1-7.csv')</span></span><br><span class="line"><span class="comment">#     df = pd.read_csv(f, header=0)</span></span><br><span class="line"></span><br><span class="line">df = pd.read_csv(<span class="string">'df_allfeature_train_lite.csv'</span>, header=<span class="number">0</span>)</span><br><span class="line"></span><br><span class="line">col_imp = [<span class="string">'product_code'</span>, <span class="string">'now_term_rate'</span>, <span class="string">'label'</span>]</span><br><span class="line">df = pd.DataFrame(df, columns=col_imp)</span><br><span class="line"></span><br><span class="line">y_train = df.label</span><br><span class="line">X_train = df.drop([<span class="string">'label'</span>], axis=<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">f</span><span class="params">(col)</span>:</span></span><br><span class="line">    y = abs(col) * <span class="number">100000</span></span><br><span class="line">    colDict = dict()</span><br><span class="line">    <span class="keyword">for</span> idx, val <span class="keyword">in</span> enumerate(set(y)):</span><br><span class="line">        colDict[int(val)] = int(idx)</span><br><span class="line">    print(colDict)</span><br><span class="line">    <span class="keyword">return</span> pd.Series([colDict[int(x)] <span class="keyword">for</span> x <span class="keyword">in</span> y])</span><br><span class="line"></span><br><span class="line"><span class="comment"># 每一列的WOE处理成int的编号</span></span><br><span class="line">X_train = X_train.apply(f, axis=<span class="number">0</span>)</span><br><span class="line">print(X_train)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 变成one-hot encoder</span></span><br><span class="line">enc = OneHotEncoder()</span><br><span class="line">enc.fit(X_train)</span><br><span class="line">print(enc.n_values_)</span><br><span class="line">print(enc.feature_indices_)</span><br><span class="line"></span><br><span class="line">X_train = pd.DataFrame(enc.fit_transform(X_train).todense())</span><br><span class="line">print(X_train.shape)</span><br><span class="line">print(X_train.head(<span class="number">2</span>))</span><br><span class="line"></span><br><span class="line">classifier = LogisticRegression()  <span class="comment"># 使用类，参数全是默认的</span></span><br><span class="line">classifier.fit(X_train, y_train)  <span class="comment"># 训练数据来学习，不需要返回值</span></span><br><span class="line">print(<span class="string">"Coefficients:%s, intercept %s"</span>%(classifier.coef_,classifier.intercept_))</span><br><span class="line"><span class="comment"># joblib.dump(classifier, 'lr.m')</span></span><br></pre></td></tr></table></figure>
<p><code>clf.coef_</code>就是权重矩阵，<code>classifier.intercept_</code>是偏置</p>
<h1 id="逻辑回归的结果解释"><a href="#逻辑回归的结果解释" class="headerlink" title="逻辑回归的结果解释"></a>逻辑回归的结果解释</h1><p><a href="https://www.jianshu.com/p/a72302fa03d7" target="_blank" rel="noopener">https://www.jianshu.com/p/a72302fa03d7</a></p>
<p><a href="https://blog.csdn.net/sjpljr/article/details/70169046" target="_blank" rel="noopener">https://blog.csdn.net/sjpljr/article/details/70169046</a></p>
<p><a href="https://wenku.baidu.com/view/953be54268eae009581b6bd97f1922791688be6c.html" target="_blank" rel="noopener">https://wenku.baidu.com/view/953be54268eae009581b6bd97f1922791688be6c.html</a></p>
<h1 id="原理讲解"><a href="#原理讲解" class="headerlink" title="原理讲解"></a>原理讲解</h1><p><a href="http://blog.sina.com.cn/s/blog_44befaf60102vznn.html" target="_blank" rel="noopener">http://blog.sina.com.cn/s/blog_44befaf60102vznn.html</a></p>
<p>Logistic回归虽然名字叫”回归” ，但却是一种分类学习方法。使用场景大概有两个：第一用来预测，第二寻找因变量的影响因素。 </p>
<p><strong>一 从线性回归到Logistic回归</strong></p>
<p>线性回归和Logistic回归都是广义线性模型的特例。</p>
<p>假设有一个因变量y和一组自变量x1, x2, x3, … , xn，其中y为连续变量，我们可以拟合一个线性方程：</p>
<p>y =β0 +β1<em>x1 +β2</em>x2 +β3<em>x3 +…+βn</em>xn</p>
<p>并通过最小二乘法估计各个β系数的值。</p>
<p>如果y为二分类变量，只能取值0或1，那么线性回归方程就会遇到困难: 方程右侧是一个连续的值，取值为负无穷到正无穷，而左侧只能取值[0,1]，无法对应。为了继续使用线性回归的思想，统计学家想到了一个变换方法，就是将方程右边的取值变换为[0,1]。最后选中了Logistic函数：</p>
<p>y = 1 / (1+e-x)</p>
<p>这是一个S型函数，值域为(0,1)，能将任何数值映射到(0,1)，且具有无限阶可导等优良数学性质。</p>
<h1 id="机器学习sklearn19-0——Logistic回归算法"><a href="#机器学习sklearn19-0——Logistic回归算法" class="headerlink" title="机器学习sklearn19.0——Logistic回归算法"></a>机器学习sklearn19.0——Logistic回归算法</h1><p><a href="https://blog.csdn.net/loveliuzz/article/details/78708359" target="_blank" rel="noopener">https://blog.csdn.net/loveliuzz/article/details/78708359</a></p>
<p>参数讲解全面</p>

          
        
      
    </div>

    

    
    
    

    

    
      
    
    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  

  <article class="post post-type-normal" itemscope="" itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="https://schwimmer.github.io/2018/03/17/机器学习/评价指标/">

    <span hidden itemprop="author" itemscope="" itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Schwimmer">
      <meta itemprop="description" content="Record and Think!">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope="" itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Schwimmer's Blog">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                
                <a href="/2018/03/17/机器学习/评价指标/" class="post-title-link" itemprop="url">评价指标</a>
              
            
          </h1>
        

        <div class="post-meta">

          
          
          

          
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              

              
                
              

              <time title="创建时间：2018-03-17 20:50:31" itemprop="dateCreated datePublished" datetime="2018-03-17T20:50:31+08:00">2018-03-17</time>
            </span>
          

          
            

            
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="fa fa-calendar-check-o"></i>
                </span>
                
                  <span class="post-meta-item-text">更新于</span>
                
                <time title="修改时间：2018-08-21 16:50:47" itemprop="dateModified" datetime="2018-08-21T16:50:47+08:00">2018-08-21</time>
              </span>
            
          

          
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope="" itemtype="http://schema.org/Thing"><a href="/categories/机器学习/" itemprop="url" rel="index"><span itemprop="name">机器学习</span></a></span>

                
                
              
            </span>
          

          
            
            
              
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="fa fa-comment-o"></i>
                </span>
            
                <span class="post-meta-item-text">评论数：</span>
                <a href="/2018/03/17/机器学习/评价指标/#comments" itemprop="discussionUrl">
                  <span class="post-comments-count disqus-comment-count" data-disqus-identifier="2018/03/17/机器学习/评价指标/" itemprop="commentCount"></span>
                </a>
              </span>
            
          

          
          

          

          <br>
          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1 id="准确率Accuracy"><a href="#准确率Accuracy" class="headerlink" title="准确率Accuracy"></a>准确率Accuracy</h1><p>分类器正确分类的样本数与总样本数之比。</p>
<h1 id="ROC-AUC"><a href="#ROC-AUC" class="headerlink" title="ROC AUC"></a>ROC AUC</h1><div class="table-container">
<table>
<thead>
<tr>
<th><strong> </strong></th>
<th><strong>相关(Relevant),正类</strong></th>
<th><strong>无关(NonRelevant),负类</strong></th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>被检索到(Retrieved)</strong></td>
<td>true positives(TP 正类判定为正类,例子中就是正确的判定”这位是女生”)</td>
<td>false positives(FP 负类判定为正类,”存伪”,例子中就是分明是男生却判断为女生,当下伪娘横行,这个错常有人犯)</td>
</tr>
<tr>
<td><strong>未被检索到(Not Retrieved)</strong></td>
<td>false negatives(FN 正类判定为负类,”去真”,例子中就是,分明是女生,这哥们却判断为男生—梁山伯同学犯的错就是这个)</td>
<td>true negatives(TN 负类判定为负类,也就是一个男生被判断为男生,像我这样的纯爷们一准儿就会在此处)</td>
</tr>
</tbody>
</table>
</div>
<blockquote>
<p>假如某个班级有男生<strong>80</strong>人,女生<strong>20</strong>人,共计<strong>100</strong>人.目标是找出所有女生.<br>现在某人挑选出<strong>50</strong>个人,其中<strong>20</strong>人是女生,另外还错误的把30个男生也当作女生挑选出来了.<br>作为评估者的你需要来评估(<strong>evaluation</strong>)下他的工作</p>
<p>TP=20<br>FP=30<br>FN=0<br>TN=50</p>
</blockquote>
<p><img src="http://alexkong.net/images/Roccurves.png" alt=""></p>
<p><img src="http://alexkong.net/images/fpr-and-tpr.png" alt=""></p>
<p>考虑ROC曲线图中的四个点和一条线。第一个点，(0,1)，即FPR=0, TPR=1，这意味着FN（false negative）=0，并且FP（false positive）=0。    </p>
<p><strong>ROC曲线越接近左上角，该分类器的性能越好。</strong></p>
<p>曲线就是一系列FPR和TPR的结果。就是将每次分类结果的（0,1）的点作为分类的阈值。</p>
<blockquote>
<p>但是，ROC的曲线——如上面几位已经说过——有数据均衡的问题。在数据极度不平衡的情况下，譬如说1万封邮件中只有1封垃圾邮件，那么如果我挑出10封，50封，100，。。封垃圾邮件（假设全部包含真正的那封垃圾邮件），Recall都是100%，但是FPR分别是9/9999, 49/9999, 99/9999（数据都比较好看：FPR越低越好），而Precision却只有1/10，1/50， 1/100 （数据很差：Precision越高越好）。所以在数据非常不均衡的情况下，看ROC的AUC可能是看不出太多好坏的，而PR curve就要敏感的多。（不过真实世界中，垃圾邮件也许与你的有用的邮件一样多——甚至比有用的还更多。。。）作者：竹间智能 Emotibot链接：<a href="https://www.zhihu.com/question/30643044/answer/161955532来源：知乎著作权归作者所有。商业转载请联系作者获得授权，非商业转载请注明出处。" target="_blank" rel="noopener">https://www.zhihu.com/question/30643044/answer/161955532来源：知乎著作权归作者所有。商业转载请联系作者获得授权，非商业转载请注明出处。</a></p>
</blockquote>
<h1 id="精确率Precision"><a href="#精确率Precision" class="headerlink" title="精确率Precision"></a>精确率Precision</h1><p>TP/(TP+FP) 检索到的结果中是正确的比例，比如检索出50个女生只有20个是正确的</p>
<h1 id="召回率Recall"><a href="#召回率Recall" class="headerlink" title="召回率Recall"></a>召回率Recall</h1><p>TP/(TP+FN) 检索到的结果占应该检索结果的比例。比如检索的结果里面有20个女生，全班一共有20个女生，所以是100%</p>
<h1 id="F1"><a href="#F1" class="headerlink" title="F1"></a>F1</h1><p>精确值和召回率的调和均值</p>
<script type="math/tex; mode=display">
F_1 = \frac{2PR}{P+R} = \frac{2TP}{2TP + FP + FN}</script><h1 id="多分类的精确率和召回率"><a href="#多分类的精确率和召回率" class="headerlink" title="多分类的精确率和召回率"></a>多分类的精确率和召回率</h1><p><a href="http://blog.csdn.net/lanchunhui/article/details/51221729" target="_blank" rel="noopener">http://blog.csdn.net/lanchunhui/article/details/51221729</a></p>
<p>把每个类别单独视为”正“，所有其它类型视为”负“</p>
<p>就是看每行对角线的P和R</p>
<p>代码见<code>multi_recall.py</code></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">M = [</span><br><span class="line">    [<span class="number">14371</span>, <span class="number">6500</span>, <span class="number">9</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">2</span>, <span class="number">316</span>],</span><br><span class="line">    [<span class="number">5700</span>, <span class="number">22205</span>, <span class="number">454</span>, <span class="number">20</span>, <span class="number">0</span>, <span class="number">11</span>, <span class="number">23</span>],</span><br><span class="line">    [<span class="number">0</span>, <span class="number">445</span>, <span class="number">3115</span>, <span class="number">71</span>, <span class="number">0</span>, <span class="number">11</span>, <span class="number">0</span>],</span><br><span class="line">    [<span class="number">0</span>, <span class="number">0</span>, <span class="number">160</span>, <span class="number">112</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>],</span><br><span class="line">    [<span class="number">0</span>, <span class="number">888</span>, <span class="number">39</span>, <span class="number">2</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>],</span><br><span class="line">    [<span class="number">0</span>, <span class="number">486</span>, <span class="number">1196</span>, <span class="number">30</span>, <span class="number">0</span>, <span class="number">74</span>, <span class="number">0</span>],</span><br><span class="line">    [<span class="number">1139</span>, <span class="number">35</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">865</span>]</span><br><span class="line">]</span><br><span class="line"></span><br><span class="line">n = len(M)</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> range(n):</span><br><span class="line">    rowsum, colsum = sum(M[i]), sum(M[r][i] <span class="keyword">for</span> r <span class="keyword">in</span> range(n))</span><br><span class="line">    <span class="keyword">try</span>:</span><br><span class="line">        <span class="keyword">print</span> <span class="string">'precision: %s'</span> % (M[i][i]/float(colsum)), <span class="string">'recall: %s'</span> % (M[i][i]/float(rowsum))</span><br><span class="line">    <span class="keyword">except</span> ZeroDivisionError:</span><br><span class="line">        <span class="keyword">print</span> <span class="string">'precision: %s'</span> % <span class="number">0</span>, <span class="string">'recall: %s'</span> %<span class="number">0</span></span><br></pre></td></tr></table></figure>
<h1 id="回归的混淆矩阵"><a href="#回归的混淆矩阵" class="headerlink" title="回归的混淆矩阵"></a>回归的混淆矩阵</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">y_test = df_base_pred.dpd</span><br><span class="line">y_pred = gbm.predict(X_test, num_iteration=gbm.best_iteration)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">cm1 = confusion_matrix(np.where(y_pred &gt; <span class="number">0.8</span>, <span class="number">0</span>, <span class="number">1</span>), np.where(y_test &gt; <span class="number">0.8</span>, <span class="number">0</span>, <span class="number">1</span>))</span><br><span class="line">cm2 = confusion_matrix(np.where(((y_test &gt; <span class="number">0.5</span>) &amp; (y_test &lt; <span class="number">0.8</span>)), <span class="number">0</span>, <span class="number">1</span>), np.where(((y_pred &gt; <span class="number">0.5</span>) &amp; (y_pred &lt; <span class="number">0.8</span>)), <span class="number">0</span>, <span class="number">1</span>))</span><br><span class="line">cm3 = confusion_matrix(np.where(((y_test &gt; <span class="number">0.1</span>) &amp; (y_test &lt; <span class="number">0.5</span>)), <span class="number">0</span>, <span class="number">1</span>), np.where(((y_pred &gt; <span class="number">0.1</span>) &amp; (y_pred &lt; <span class="number">0.5</span>)), <span class="number">0</span>, <span class="number">1</span>))</span><br></pre></td></tr></table></figure>
<h1 id="K-S"><a href="#K-S" class="headerlink" title="K-S"></a>K-S</h1><p><a href="http://www.sohu.com/a/211697143_793685" target="_blank" rel="noopener">http://www.sohu.com/a/211697143_793685</a></p>
<p><a href="https://blog.csdn.net/sinat_30316741/article/details/80018932" target="_blank" rel="noopener">https://blog.csdn.net/sinat_30316741/article/details/80018932</a></p>
<p><a href="https://www.cnblogs.com/nxld/p/6208613.html" target="_blank" rel="noopener">https://www.cnblogs.com/nxld/p/6208613.html</a></p>
<p><a href="https://blog.csdn.net/pzw_0612/article/details/45280411" target="_blank" rel="noopener">https://blog.csdn.net/pzw_0612/article/details/45280411</a></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line">def compute_ks(data):</span><br><span class="line">    sorted_list = data.sort_values([&apos;predict_proba&apos;], ascending=[True])#按照样本为正样本的概率值升序排序 ，也即坏样本的概率从高到低排序</span><br><span class="line">    total_good=sorted_list[&apos;label&apos;].sum()</span><br><span class="line">    total_bad = sorted_list.shape[0] - total_good  </span><br><span class="line">    max_ks = 0.0</span><br><span class="line">    good_count = 0.0</span><br><span class="line">    bad_count = 0.0</span><br><span class="line">    for index, row in sorted_list.iterrows(): #按照标签和每行拆开</span><br><span class="line">        if row[&apos;label&apos;] == 0:</span><br><span class="line">            bad_count +=1</span><br><span class="line">        else:</span><br><span class="line">            good_count +=1</span><br><span class="line">        val = abs(bad_count/total_bad - good_count/total_good)</span><br><span class="line">        max_ks = max(max_ks, val)</span><br><span class="line">    return max_ks </span><br><span class="line">test_pd=pd.DataFrame()</span><br><span class="line">y_predict_proba=est.predict_proba(X_test)[:,1]#取被分为正样本的概率那一列</span><br><span class="line">Y_test_1=np.array(Y_test)</span><br><span class="line">test_pd[&apos;label&apos;]=Y_test_1</span><br><span class="line">test_pd[&apos;predict_proba&apos;]=y_predict_proba</span><br><span class="line">print (&quot;测试集 KS:&quot;,compute_ks(test_pd))</span><br><span class="line"></span><br><span class="line">作者：暸望塔</span><br><span class="line">链接：https://www.jianshu.com/p/fec4105a60d7</span><br><span class="line">來源：简书</span><br><span class="line">简书著作权归作者所有，任何形式的转载都请联系作者获得授权并注明出处。</span><br></pre></td></tr></table></figure>
<h1 id="回归模型的评价"><a href="#回归模型的评价" class="headerlink" title="回归模型的评价"></a>回归模型的评价</h1><p><a href="https://blog.csdn.net/shy19890510/article/details/79375062" target="_blank" rel="noopener">https://blog.csdn.net/shy19890510/article/details/79375062</a></p>
<p>对于回归模型效果的判断指标经过了几个过程，从SSE到R-square再到Ajusted R-square, 是一个完善的过程：</p>
<p>SSE(误差平方和)：The sum of squares due to error</p>
<p>R-square(决定系数)：Coefficient of determination</p>
<p>Adjusted R-square：Degree-of-freedom adjusted coefficient of determination</p>
<p>下面我对以上几个名词进行详细的解释下，相信能给大家带来一定的帮助！！</p>
<p><strong>一、SSE(误差平方和)</strong></p>
<p>计算公式如下：</p>
<p>​     <img src="https://img-blog.csdn.net/20180226141307251" alt="img"></p>
<ul>
<li>同样的数据集的情况下，SSE越小，误差越小，模型效果越好</li>
<li>缺点：</li>
</ul>
<p>SSE数值大小本身没有意义，随着样本增加，SSE必然增加，也就是说，不同的数据集的情况下，SSE比较没有意义</p>
<p><strong>二、R-square(决定系数)</strong></p>
<p><img src="https://img-blog.csdn.net/20180226141109847" alt="img"></p>
<ul>
<li><strong>数学理解：</strong> 分母理解为原始数据的离散程度，分子为预测数据和原始数据的误差，二者相除可以消除原始数据离散程度的影响</li>
<li>其实“决定系数”是通过数据的变化来表征一个拟合的好坏。</li>
<li>理论上取值范围（-∞，1], 正常取值范围为[0 1] ———实际操作中通常会选择拟合较好的曲线计算R²，因此很少出现-∞</li>
</ul>
<p>越接近1，表明方程的变量对y的解释能力越强，这个模型对数据拟合的也较好</p>
<p>越接近0，表明模型拟合的越差</p>
<p>经验值：&gt;0.4， 拟合效果好</p>
<ul>
<li>缺点：</li>
</ul>
<p>数据集的样本越大，R²越大，因此，不同数据集的模型结果比较会有一定的误差</p>
<p><strong>三、Adjusted R-Square (校正决定系数）</strong></p>
<p>​      <img src="https://img-blog.csdn.net/20180226141125835" alt="img"></p>
<p>n为样本数量，p为特征数量</p>
<ul>
<li>消除了样本数量和特征数量的影响</li>
</ul>

          
        
      
    </div>

    

    
    
    

    

    
      
    
    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  

  <article class="post post-type-normal" itemscope="" itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="https://schwimmer.github.io/2018/03/17/机器学习/知识图谱入门/">

    <span hidden itemprop="author" itemscope="" itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Schwimmer">
      <meta itemprop="description" content="Record and Think!">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope="" itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Schwimmer's Blog">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                
                <a href="/2018/03/17/机器学习/知识图谱入门/" class="post-title-link" itemprop="url">知识图谱入门</a>
              
            
          </h1>
        

        <div class="post-meta">

          
          
          

          
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              

              
                
              

              <time title="创建时间：2018-03-17 20:50:31" itemprop="dateCreated datePublished" datetime="2018-03-17T20:50:31+08:00">2018-03-17</time>
            </span>
          

          

          
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope="" itemtype="http://schema.org/Thing"><a href="/categories/机器学习/" itemprop="url" rel="index"><span itemprop="name">机器学习</span></a></span>

                
                
              
            </span>
          

          
            
            
              
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="fa fa-comment-o"></i>
                </span>
            
                <span class="post-meta-item-text">评论数：</span>
                <a href="/2018/03/17/机器学习/知识图谱入门/#comments" itemprop="discussionUrl">
                  <span class="post-comments-count disqus-comment-count" data-disqus-identifier="2018/03/17/机器学习/知识图谱入门/" itemprop="commentCount"></span>
                </a>
              </span>
            
          

          
          

          

          <br>
          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p><a href="https://www.zhihu.com/question/52368821#answer-51023978" target="_blank" rel="noopener">知识图谱入门</a></p>
<p>知道RDF，OWL，SPARQL这些W3C技术堆栈，知道它们的长处和局限。会使用RDF数据库和推理机。</p>
<p>了解一点描述逻辑基础，知道描述逻辑和一阶逻辑的关系。知道模型论，不然完全没法理解RDF和OWL。</p>
<p>了解图灵机和基本的算法复杂性。知道什么是决策问题、可判定性、完备性和一致性、P、NP、NExpTime。</p>
<p>最好再知道一点逻辑程序（Logic Programming），涉猎一点答集程序（Answer Set Programming），知道LP和ASP的一些小工具。这些东西是规则引擎的核心。如果不满足于正则表达式和if-then-else，最好学一点这些。</p>
<p>从正则文法到自动机。不理解自动机很多高效的模式提取算法都理解不了。</p>
<p>熟悉常见的知识库，不必事事重新造轮子，如Freebase, Wikidata, Yago, DBPedia。</p>
<p>熟悉结构化数据建模的基本方法，如ER，面向对象，UML，脑图。</p>
<p>学会使用一些本体编辑器，如Protege。</p>
<p>熟悉任何一种关系数据库。会使用存储过程写递归查询。明白什么叫物化视图、传递闭包、推理闭包。</p>
<p>熟悉任何一种图数据库。明白图的局部索引和关系的全局索引的理论和实践性能差异。</p>
<p>熟悉词法分析的基本工具，如分词、词性标注</p>
<p>熟悉句法分析的基本工具，如成分分析、依存文法分析、深层文法分析</p>
<p>熟悉TFIDF、主题模型和分布式表示的基本概念和工具。知道怎么计算两个词的相似度、词和句子的关联度。</p>
<p>知道怎么做命名实体识别。知道一些常用的词表。知道怎么用规则做关系提取。</p>
<p>了解前人已经建好的各种Lexical数据库，如Wordnet, framenet,  BabelNet, PropBank。熟悉一些常用的Corpus。</p>
<p>知道信息检索的基本原理。知道各种结构的索引的代价。</p>
<p>掌握Lucene或者Solr/Elasticsearch的使用。</p>
<p><img src="https://pic4.zhimg.com/80/v2-c5b129d69119a5b5524bbfb63df9ee7b_hd.jpg" alt=""></p>
<h2 id="知识融合"><a href="#知识融合" class="headerlink" title="知识融合"></a>知识融合</h2><p>把结构化数据、半结构化数据、非结构化数据的知识表达形式都统一成RDF的形式，便于存储和查询。具体的知识融合主要包括如下两种类型：</p>
<ul>
<li>合并外部知识库： 数据层的融合、模式层的融合</li>
</ul>
<p>开放数据集成框架：LDIF</p>
<ul>
<li>合并关系型数据库：将关系型数据转换成RDF的格式，现有工具Triplify、 d2rServer 、OpenLink、 Virtuoso 、SparqlMap等</li>
</ul>
<p><img src="https://pic4.zhimg.com/80/v2-ea49d6925e7d1461b6c6f6d393861038_hd.jpg" alt=""></p>
<h2 id="知识推理"><a href="#知识推理" class="headerlink" title="知识推理"></a>知识推理</h2><ul>
<li>jena是一个java 的API，用来支持语义网的有关应用，学习jena需要了解XML 、RDF、 Ontology、OWL等方面的知识。</li>
<li>RDFox是一个高度可扩展的<strong>内存</strong>RDF三重存储，支持共享内存并行数据推理。它是一个用C ++编写的跨平台软件，带有一个Java包装器，可以与任何基于Java的解决方案轻松集成</li>
</ul>

          
        
      
    </div>

    

    
    
    

    

    
      
    
    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  

  <article class="post post-type-normal" itemscope="" itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="https://schwimmer.github.io/2018/03/17/机器学习/特征选择/">

    <span hidden itemprop="author" itemscope="" itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Schwimmer">
      <meta itemprop="description" content="Record and Think!">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope="" itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Schwimmer's Blog">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                
                <a href="/2018/03/17/机器学习/特征选择/" class="post-title-link" itemprop="url">特征选择</a>
              
            
          </h1>
        

        <div class="post-meta">

          
          
          

          
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              

              
                
              

              <time title="创建时间：2018-03-17 20:50:31" itemprop="dateCreated datePublished" datetime="2018-03-17T20:50:31+08:00">2018-03-17</time>
            </span>
          

          
            

            
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="fa fa-calendar-check-o"></i>
                </span>
                
                  <span class="post-meta-item-text">更新于</span>
                
                <time title="修改时间：2018-09-29 10:23:59" itemprop="dateModified" datetime="2018-09-29T10:23:59+08:00">2018-09-29</time>
              </span>
            
          

          
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope="" itemtype="http://schema.org/Thing"><a href="/categories/机器学习/" itemprop="url" rel="index"><span itemprop="name">机器学习</span></a></span>

                
                
              
            </span>
          

          
            
            
              
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="fa fa-comment-o"></i>
                </span>
            
                <span class="post-meta-item-text">评论数：</span>
                <a href="/2018/03/17/机器学习/特征选择/#comments" itemprop="discussionUrl">
                  <span class="post-comments-count disqus-comment-count" data-disqus-identifier="2018/03/17/机器学习/特征选择/" itemprop="commentCount"></span>
                </a>
              </span>
            
          

          
          

          

          <br>
          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1 id="选择哪些指标"><a href="#选择哪些指标" class="headerlink" title="选择哪些指标"></a>选择哪些指标</h1><p><a href="https://blog.csdn.net/fisherming/article/details/79925574" target="_blank" rel="noopener">https://blog.csdn.net/fisherming/article/details/79925574</a></p>
<p>历届的Kaggle/天池比赛，天猫/京东排序和推荐业务线里模型用到的特 </p>
<p>1.<strong>加减平均</strong>：这个用户所买商品<strong>高于</strong>所有用户购买商品平均价格的多少（<strong>权衡一个人的消费能力</strong>），用户连续登录天数超过平均多少（<strong>表明这个用户对该产品的黏性</strong>）  </p>
<p>2.<strong>分位线</strong>：商品属于售出商品价格的多少分位线处。（<strong>比如20%，说明20%的人买东西都不会低于这个价格</strong>）。  3.<strong>次序型</strong>：排在第几位。  </p>
<p>4.<strong>比例型</strong>：电商中，某商品在某电商平台<strong>好/中/差评</strong>的比例 </p>
<p>转自知乎：<a href="https://www.zhihu.com/question/29316149/answer/110159647" target="_blank" rel="noopener">特征工程到底是什么？</a></p>
<p><a href="https://www.cnblogs.com/jasonfreak/p/5448385.html" target="_blank" rel="noopener">https://www.cnblogs.com/jasonfreak/p/5448385.html</a></p>
<p>代码在<code>blogcodes/feature_selection.py</code></p>
<p>目录</p>
<p>1 特征工程是什么？<br>2 数据预处理<br>　　2.1 无量纲化<br>　　　　2.1.1 标准化<br>　　　　2.1.2 区间缩放法<br>　　　　2.1.3 标准化与归一化的区别<br>　　2.2 对定量特征二值化<br>　　2.3 对定性特征哑编码<br>　　2.4 缺失值计算<br>　　2.5 数据变换<br>3 特征选择<br>　　3.1 Filter<br>　　　　3.1.1 方差选择法<br>　　　　3.1.2 相关系数法<br>　　　　3.1.3 卡方检验<br>　　　　3.1.4 互信息法<br>　　3.2 Wrapper<br>　　　　3.2.1 递归特征消除法<br>　　3.3 Embedded<br>　　　　3.3.1 基于惩罚项的特征选择法<br>　　　　3.3.2 基于树模型的特征选择法<br>4 降维<br>　　4.1 主成分分析法（PCA）<br>　　4.2 线性判别分析法（LDA）<br>5 总结<br>6 参考资料</p>
<p><img src="https://pic1.zhimg.com/80/20e4522e6104ad71fc543cc21f402b36_hd.jpg" alt=""></p>
<p>本文中使用sklearn中的<a href="https://link.zhihu.com/?target=http%3A//scikit-learn.org/stable/modules/generated/sklearn.datasets.load_iris.html%23sklearn.datasets.load_iris" target="_blank" rel="noopener">IRIS（鸢尾花）数据集</a>来对特征处理功能进行说明。IRIS数据集由Fisher在1936年整理，包含4个特征（Sepal.Length（花萼长度）、Sepal.Width（花萼宽度）、Petal.Length（花瓣长度）、Petal.Width（花瓣宽度）），特征值都为正浮点数，单位为厘米。目标值为鸢尾花的分类（Iris Setosa（山鸢尾）、Iris Versicolour（杂色鸢尾），Iris Virginica（维吉尼亚鸢尾））。导入IRIS数据集的代码如下：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">from sklearn.datasets import load_iris</span><br><span class="line"># 返回的是一个Bunch，类似Dict，可以获取iris.data、iris.target等</span><br><span class="line">iris = load_iris()</span><br></pre></td></tr></table></figure>
<h1 id="数据预处理"><a href="#数据预处理" class="headerlink" title="数据预处理"></a>数据预处理</h1><p>未处理的特征有如下问题，我们使用sklearn中的preproccessing库来进行数据预处理。</p>
<h2 id="无量纲化"><a href="#无量纲化" class="headerlink" title="无量纲化"></a>无量纲化</h2><p>无量纲化使不同规格的数据转换到同一规格。常见的无量纲化方法有标准化和区间缩放法。</p>
<p>标准化的前提是特征值<strong>服从正态分布</strong>，标准化后，其转换成标准正态分布。</p>
<p>区间缩放法利用了边界值信息，将特征的取值区间缩放到某个特定的范围，例如[0, 1]等。</p>
<h3 id="标准化"><a href="#标准化" class="headerlink" title="标准化"></a>标准化</h3><p>z-score。将原始数据归一化到均值为0，方差为1的数据集。</p>
<p><img src="https://pic1.zhimg.com/80/c7e852db6bd05b7bb1017b5425ffeec1_hd.jpg" alt=""></p>
<p>优点：当X的最大值和最小值未知，或孤立点左右了最大－最小规范化时，　该方法有用</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">from sklearn.preprocessing import StandardScaler</span><br><span class="line"> </span><br><span class="line">#标准化，返回值为标准化后的数据</span><br><span class="line">StandardScaler().fit_transform(iris.data)</span><br></pre></td></tr></table></figure>
<h3 id="区间缩放归一化"><a href="#区间缩放归一化" class="headerlink" title="区间缩放归一化"></a>区间缩放归一化</h3><p>最大最小归一化。线性转换。</p>
<p><img src="https://pic1.zhimg.com/80/0f119a8e8f69509c5b95ef6a8a01a809_hd.jpg" alt=""></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">from sklearn.preprocessing import MinMaxScaler</span><br><span class="line"></span><br><span class="line">#区间缩放，返回值为缩放到[0, 1]区间的数据</span><br><span class="line">MinMaxScaler().fit_transform(iris.data)</span><br></pre></td></tr></table></figure>
<h3 id="L2范数归一化"><a href="#L2范数归一化" class="headerlink" title="L2范数归一化"></a>L2范数归一化</h3><p><img src="http://img.blog.csdn.net/20160508111702785?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQv/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/Center" alt=""></p>
<p>L2范数归一化就是向量中每个元素除以向量的L2范数</p>
<p><img src="https://pic4.zhimg.com/80/fbb2fd0a163f2fa211829b735194baac_hd.jpg" alt=""></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">from sklearn.preprocessing import Normalizer</span><br><span class="line"></span><br><span class="line">#归一化，返回值为归一化后的数据</span><br><span class="line">Normalizer().fit_transform(iris.data)</span><br></pre></td></tr></table></figure>
<h3 id="什么情况需要"><a href="#什么情况需要" class="headerlink" title="什么情况需要"></a>什么情况需要</h3><p>主要看模型是否具有<strong>伸缩不变性</strong>。</p>
<p>有些模型在各个维度进行不均匀伸缩后，最优解与原来不等价，例如SVM。对于这样的模型，除非本来各维数据的分布范围就比较接近，否则必须进行标准化，<strong>以免模型参数被分布范围较大或较小的数据</strong>dominate。</p>
<p>标准化是依照特征矩阵的<strong>列</strong>处理数据</p>
<p>归一化是依照特征矩阵的<strong>行</strong>处理数据</p>
<p>有些模型在各个维度进行不均匀伸缩后，最优解与原来等价，例如logistic regression。对于这样的模型，是否标准化理论上不会改变最优解。但是，由于实际求解往往使用迭代算法，如果目标函数的形状太“扁”，迭代算法可能收敛得很慢甚至不收敛。所以对于具有伸缩不变性的模型，最好也进行数据标准化。</p>
<p>缩放的最主要<strong>优点是能够避免大数值区间的属性过分支配了小数值区间的属性</strong>。</p>
<p>另一个优点能<strong>避免计算过程中数值复杂度</strong>。因为关键值通常依赖特征向量的内积（inner products），例如，线性核和多项式核，属性的大数值可能会导致数值问题。我们推荐将每个属性线性缩放到区间[-1,+1]或者[0, 1]。</p>
<h2 id="对定量特征二值化"><a href="#对定量特征二值化" class="headerlink" title="对定量特征二值化"></a>对定量特征二值化</h2><p>定量特征二值化的核心在于设定一个阈值，大于阈值的赋值为1，小于等于阈值的赋值为0，公式表达如下</p>
<p><img src="https://pic3.zhimg.com/80/11111244c5b69c1af6c034496a2591ad_hd.jpg" alt=""></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">from sklearn.preprocessing import Binarizer</span><br><span class="line"></span><br><span class="line">#二值化，阈值设置为3，返回值为二值化后的数据</span><br><span class="line">Binarizer(threshold=3).fit_transform(iris.data)</span><br></pre></td></tr></table></figure>
<h2 id="对定性特征哑编码"><a href="#对定性特征哑编码" class="headerlink" title="对定性特征哑编码"></a>对定性特征哑编码</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">from sklearn.preprocessing import OneHotEncoder</span><br><span class="line"></span><br><span class="line">#哑编码，对IRIS数据集的目标值，返回值为哑编码后的数据</span><br><span class="line">OneHotEncoder().fit_transform(iris.target.reshape((-1,1)))</span><br></pre></td></tr></table></figure>
<h2 id="缺失值计算"><a href="#缺失值计算" class="headerlink" title="缺失值计算"></a>缺失值计算</h2><p>默认用均值填充</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">from numpy import vstack, array, nan</span><br><span class="line">from sklearn.preprocessing import Imputer</span><br><span class="line"></span><br><span class="line">#缺失值计算，返回值为计算缺失值后的数据</span><br><span class="line">#参数missing_value为缺失值的表示形式，默认为NaN</span><br><span class="line">#参数strategy为缺失值填充方式，默认为mean（均值）</span><br><span class="line">Imputer().fit_transform(vstack((array([nan, nan, nan, nan]), iris.data)))</span><br></pre></td></tr></table></figure>
<h2 id="数据变换"><a href="#数据变换" class="headerlink" title="数据变换"></a>数据变换</h2><p>常见的数据变换有基于多项式的、基于指数函数的、基于对数函数的。4个特征，度为2的多项式转换公式如下：<br><img src="https://pic1.zhimg.com/80/d1c57a66fad39df90b87cea330efb3f3_hd.jpg" alt=""></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">from sklearn.preprocessing import PolynomialFeatures</span><br><span class="line"></span><br><span class="line">#多项式转换</span><br><span class="line">#参数degree为度，默认值为2</span><br><span class="line">PolynomialFeatures().fit_transform(iris.data)</span><br></pre></td></tr></table></figure>
<p>基于单变元函数的数据变换可以使用一个统一的方式完成，使用preproccessing库的FunctionTransformer对数据进行对数函数转换的代码如下：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">from numpy import log1p</span><br><span class="line">from sklearn.preprocessing import FunctionTransformer</span><br><span class="line"></span><br><span class="line">#自定义转换函数为对数函数的数据变换</span><br><span class="line">#第一个参数是单变元函数</span><br><span class="line">FunctionTransformer(log1p).fit_transform(iris.data)</span><br></pre></td></tr></table></figure>
<h1 id="特征选择"><a href="#特征选择" class="headerlink" title="特征选择"></a>特征选择</h1><p>选有效的特征，一般从两个方面看：</p>
<p>1）特征是否发散。一个方差接近于0，也就是说样本在这个特征上基本没有差异，对于样本的区分就没什么用。</p>
<p>2）特征与目标的相关性。</p>
<p>根据特征选择的形式又可以将特征选择方法分为3种：</p>
<ul>
<li>Filter：过滤法，按照发散性或者相关性对各个特征进行评分，设定阈值或者待选择阈值的个数，选择特征。</li>
<li>Wrapper：包装法，根据目标函数（通常是预测效果评分），每次选择若干特征，或者排除若干特征。</li>
<li>Embedded：嵌入法，先使用某些机器学习的算法和模型进行训练，得到各个特征的权值系数，根据系数从大到小选择特征。类似于Filter方法，但是是通过训练来确定特征的优劣。</li>
</ul>
<p>　　我们使用sklearn中的feature_selection库来进行特征选择。</p>
<h2 id="Filter"><a href="#Filter" class="headerlink" title="Filter"></a>Filter</h2><h3 id="方差选择法"><a href="#方差选择法" class="headerlink" title="方差选择法"></a>方差选择法</h3><p>选择方差大于阈值的特征。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">from sklearn.feature_selection import VarianceThreshold</span><br><span class="line"></span><br><span class="line">#方差选择法，返回值为特征选择后的数据</span><br><span class="line">#参数threshold为方差的阈值</span><br><span class="line">VarianceThreshold(threshold=3).fit_transform(iris.data)</span><br></pre></td></tr></table></figure>
<h3 id="相关系数法"><a href="#相关系数法" class="headerlink" title="相关系数法"></a>相关系数法</h3><p>缺点是<strong>对非线性关系不敏感</strong>。</p>
<p>计算各个特征对目标值的pearson相关系数</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">from sklearn.feature_selection import SelectKBest</span><br><span class="line">from scipy.stats import pearsonr</span><br><span class="line"></span><br><span class="line">#选择K个最好的特征，返回选择特征后的数据</span><br><span class="line">#第一个参数为计算评估特征是否好的函数，该函数输入特征矩阵和目标向量，输出二元组（评分，P值）的数组，数组第i项为第i个特征的评分和P值。在此定义为计算相关系数</span><br><span class="line">#参数k为选择的特征个数</span><br><span class="line">SelectKBest(lambda X, Y: array(map(lambda x:pearsonr(x, Y), X.T)).T, k=2).fit_transform(iris.data, iris.target)</span><br></pre></td></tr></table></figure>
<p>要理解Pearson相关系数，首先要理解<strong>协方差</strong>（Covariance），协方差是一个反映两个随机变量相关程度的指标，如果一个变量跟随着另一个变量同时变大或者变小，那么这两个变量的协方差就是正值，反之相反，公式如下：</p>
<p><img src="https://pic3.zhimg.com/80/0dfac74fd0cc7e4670fc04e15a5d79e2_hd.jpg" alt=""></p>
<p>Pearson相关系数公式如下：</p>
<p><img src="https://pic2.zhimg.com/80/95c7b4484dc46f28390c4de96c83b915_hd.jpg" alt=""></p>
<p>pearson是一个介于-1和1之间的值，当两个变量的线性关系增强时，相关系数趋于1或-1；当一个变量增大，另一个变量也增大时，表明它们之间是正相关的，相关系数大于0；如果一个变量增大，另一个变量却减小，表明它们之间是负相关的，相关系数小于0；如果相关系数等于0，表明它们之间不存在线性相关关系。</p>
<h3 id="卡方检验"><a href="#卡方检验" class="headerlink" title="卡方检验"></a>卡方检验</h3><p>方检验是检验定性自变量对定性因变量的相关性。</p>
<p><a href="https://blog.csdn.net/snowdroptulip/article/details/78770088" target="_blank" rel="noopener">https://blog.csdn.net/snowdroptulip/article/details/78770088</a></p>
<p><a href="https://segmentfault.com/a/1190000003719712" target="_blank" rel="noopener">卡方检验原理及应用</a></p>
<p>衡量实际值和理论值的差异程度。卡方值越大，相关程度越大。</p>
<p>比如某个特征有3个取值，构建矩阵，看这3个特征对应的点击和不点击的值分别是多少，然后计算总的点击率，求出每个特征的理论点击和不点击的数量。然后计算卡方值，再查表。</p>
<p>因此卡方就可以用来降维，比如找相关程度最大的特征。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">from sklearn.feature_selection import SelectKBest</span><br><span class="line">from sklearn.feature_selection import chi2</span><br><span class="line"></span><br><span class="line">#选择K个最好的特征，返回选择特征后的数据</span><br><span class="line">SelectKBest(chi2, k=2).fit_transform(iris.data, iris.target)</span><br></pre></td></tr></table></figure>
<p>另一种方法</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">import numpy as np</span><br><span class="line">from scipy.stats import chi2_contingency</span><br><span class="line"></span><br><span class="line">d = np.array([[37, 49, 23], [150, 100, 57]])</span><br><span class="line">chi2_contingency(d)</span><br></pre></td></tr></table></figure>
<p>数据如下：</p>
<div class="table-container">
<table>
<thead>
<tr>
<th>杀虫效果</th>
<th>甲</th>
<th>乙</th>
<th>丙</th>
</tr>
</thead>
<tbody>
<tr>
<td>死亡数</td>
<td>37</td>
<td>49</td>
<td>23</td>
</tr>
<tr>
<td>未死亡数</td>
<td>150</td>
<td>100</td>
<td>57</td>
</tr>
</tbody>
</table>
</div>
<p>输出为：<br> <strong>(7.6919413561281065,</strong><br> <strong>0.021365652322337315,</strong><br> <strong>2,</strong><br> <strong>array([[  48.99759615,   39.04086538,   20.96153846],</strong><br>​         <strong>[ 138.00240385,  109.95913462,   59.03846154]]))</strong></p>
<p>第一个值为<strong>卡方值</strong>，第二个值为<strong>P值</strong>，第三个值为<strong>自由度</strong>，第四个为与原数据数组同维度的对应<strong>理论值</strong></p>
<p>[<a href="https://blog.csdn.net/QimaoRyan/article/details/72824766?utm_source=copy" target="_blank" rel="noopener">https://blog.csdn.net/QimaoRyan/article/details/72824766?utm_source=copy</a> ]</p>
<h3 id="互信息法"><a href="#互信息法" class="headerlink" title="互信息法"></a>互信息法</h3><h1 id="图像标签hashtag的特征处理"><a href="#图像标签hashtag的特征处理" class="headerlink" title="图像标签hashtag的特征处理"></a>图像标签hashtag的特征处理</h1><p><a href="https://www.jiqizhixin.com/articles/050303" target="_blank" rel="noopener">https://www.jiqizhixin.com/articles/050303</a></p>
<p>由于人们通常使用 hashtag 描述照片，所以 Facebook 研究人员认为它们可以作为模型训练数据的完美来源。这允许研究人员使用 hashtag 来完成一直以来的目标：基于人们自己标注的 hashtag 获取更多图像。</p>
<p>但是 hashtag 通常指非视觉概念，如 #tbt 表示「throwback Thursday」。或者它们比较模糊，如 #party 可以描述活动、设置，或者 both。对于图像识别来说，tag 的作用是弱监督数据，而模糊和／或不相关的 hashtag 是标签噪声，可能会混淆深度学习模型。</p>
<p>这些噪声标签是大规模训练工作的重点，因此研究人员开发了一种新方法，专为使用 hashtag 监督执行图像识别实验而准备。该方法包括处理每个图像的多个标签（加 hashtag 的用户通常会添加多个 hashtag）、<strong>整理 hashtag 同义词、平衡经常出现的 hashtag 和出现频率较低的 hashtag 的影响力</strong>。</p>
<h1 id="特征选择和特征理解"><a href="#特征选择和特征理解" class="headerlink" title="特征选择和特征理解"></a>特征选择和特征理解</h1><p><a href="https://www.cnblogs.com/tonglin0325/p/6214978.html" target="_blank" rel="noopener">https://www.cnblogs.com/tonglin0325/p/6214978.html</a></p>

          
        
      
    </div>

    

    
    
    

    

    
      
    
    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
  </section>

  
  <nav class="pagination">
    <a class="extend prev" rel="prev" href="/page/22/"><i class="fa fa-angle-left" aria-label="上一页"></i></a><a class="page-number" href="/">1</a><span class="space">&hellip;</span><a class="page-number" href="/page/22/">22</a><span class="page-number current">23</span><a class="page-number" href="/page/24/">24</a><span class="space">&hellip;</span><a class="page-number" href="/page/31/">31</a><a class="extend next" rel="next" href="/page/24/"><i class="fa fa-angle-right" aria-label="下一页"></i></a>
  </nav>



          </div>
          

        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    <div class="sidebar-inner">

      

      

      <div class="site-overview-wrap sidebar-panel sidebar-panel-active">
        <div class="site-overview">
          <div class="site-author motion-element" itemprop="author" itemscope="" itemtype="http://schema.org/Person">
            
              <p class="site-author-name" itemprop="name">Schwimmer</p>
              <div class="site-description motion-element" itemprop="description">Record and Think!</div>
          </div>

          
            <nav class="site-state motion-element">
              
                <div class="site-state-item site-state-posts">
                
                  <a href="/archives/">
                
                    <span class="site-state-item-count">308</span>
                    <span class="site-state-item-name">日志</span>
                  </a>
                </div>
              

              
                
                
                <div class="site-state-item site-state-categories">
                  
                    
                      <a href="/categories/">
                    
                  
                    
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                    <span class="site-state-item-count">25</span>
                    <span class="site-state-item-name">分类</span>
                  </a>
                </div>
              

              
                
                
                <div class="site-state-item site-state-tags">
                  
                    
                      <a href="/tags/">
                    
                  
                    
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                    <span class="site-state-item-count">61</span>
                    <span class="site-state-item-name">标签</span>
                  </a>
                </div>
              
            </nav>
          

          

          

          

          

          
          

          
            
          
          

        </div>
      </div>

      

      

    </div>
  </aside>
  


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <div class="copyright">&copy; <span itemprop="copyrightYear">2019</span>
  <span class="with-love" id="animate">
    <i class="fa fa-user"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">Schwimmer</span>

  

  
</div>


  <div class="powered-by">由 <a href="https://hexo.io" class="theme-link" rel="noopener" target="_blank">Hexo</a> 强力驱动 v3.9.0</div>



  <span class="post-meta-divider">|</span>



  <div class="theme-info">主题 – <a href="https://theme-next.org" class="theme-link" rel="noopener" target="_blank">NexT.Mist</a> v7.2.0</div>




        
<div class="busuanzi-count">
  <script async src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>

  
    <span class="post-meta-item-icon">
      <i class="fa fa-user"></i>
    </span>
    <span class="site-uv" title="总访客量">
      <span class="busuanzi-value" id="busuanzi_value_site_uv"></span>
    </span>
  

  
    <span class="post-meta-divider">|</span>
  

  
    <span class="post-meta-item-icon">
      <i class="fa fa-eye"></i>
    </span>
    <span class="site-pv" title="总访问量">
      <span class="busuanzi-value" id="busuanzi_value_site_pv"></span>
    </span>
  
</div>









        
      </div>
    </footer>

    
      <div class="back-to-top">
        <i class="fa fa-arrow-up"></i>
        
      </div>
    

    

    
      <div>
        
  <script>
    window._bd_share_config = {
      "common": {
        "bdText": "",
        "bdMini": "1",
        "bdMiniList": false,
        "bdPic": ""
      },
      "image": {
        "viewList": ["tsina", "douban", "sqq", "qzone", "weixin", "twi", "fbook"],
        "viewText": "分享到：",
        "viewSize": "16"
      },
      "slide": {
        "bdImg": "5",
        "bdPos": "left",
        "bdTop": "100"
      }
    }
  </script>

<script>
  with(document)0[(getElementsByTagName('head')[0]||body).appendChild(createElement('script')).src='//bdimg.share.baidu.com/static/api/js/share.js?cdnversion='+~(-new Date()/36e5)];
</script>

      </div>
    

    
  </div>

  

<script>
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>


























  
  <script src="/lib/jquery/index.js?v=3.4.1"></script>

  
  <script src="/lib/velocity/velocity.min.js?v=1.2.1"></script>

  
  <script src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>


  


  <script src="/js/utils.js?v=7.2.0"></script>

  <script src="/js/motion.js?v=7.2.0"></script>



  
  


  <script src="/js/schemes/muse.js?v=7.2.0"></script>




  

  


  <script src="/js/next-boot.js?v=7.2.0"></script>


  

  

  

  
  
<script>
  function loadCount() {
    var d = document, s = d.createElement('script');
    s.src = 'https://https-schwimmer-github-io.disqus.com/count.js';
    s.id = 'dsq-count-scr';
    (d.head || d.body).appendChild(s);
  }
  // defer loading until the whole page loading is completed
  window.addEventListener('load', loadCount, false);
</script>







  
  <script>
    // Popup Window;
    var isfetched = false;
    var isXml = true;
    // Search DB path;
    var search_path = "search.xml";
    if (search_path.length === 0) {
      search_path = "search.xml";
    } else if (/json$/i.test(search_path)) {
      isXml = false;
    }
    var path = "/" + search_path;
    // monitor main search box;

    var onPopupClose = function (e) {
      $('.popup').hide();
      $('#local-search-input').val('');
      $('.search-result-list').remove();
      $('#no-result').remove();
      $(".local-search-pop-overlay").remove();
      $('body').css('overflow', '');
    }

    function proceedsearch() {
      $("body")
        .append('<div class="search-popup-overlay local-search-pop-overlay"></div>')
        .css('overflow', 'hidden');
      $('.search-popup-overlay').click(onPopupClose);
      $('.popup').toggle();
      var $localSearchInput = $('#local-search-input');
      $localSearchInput.attr("autocapitalize", "none");
      $localSearchInput.attr("autocorrect", "off");
      $localSearchInput.focus();
    }

    // search function;
    var searchFunc = function(path, search_id, content_id) {
      'use strict';

      // start loading animation
      $("body")
        .append('<div class="search-popup-overlay local-search-pop-overlay">' +
          '<div id="search-loading-icon">' +
          '<i class="fa fa-spinner fa-pulse fa-5x fa-fw"></i>' +
          '</div>' +
          '</div>')
        .css('overflow', 'hidden');
      $("#search-loading-icon").css('margin', '20% auto 0 auto').css('text-align', 'center');

      

      $.ajax({
        url: path,
        dataType: isXml ? "xml" : "json",
        async: true,
        success: function(res) {
          // get the contents from search data
          isfetched = true;
          $('.popup').detach().appendTo('.header-inner');
          var datas = isXml ? $("entry", res).map(function() {
            return {
              title: $("title", this).text(),
              content: $("content",this).text(),
              url: $("url" , this).text()
            };
          }).get() : res;
          var input = document.getElementById(search_id);
          var resultContent = document.getElementById(content_id);
          var inputEventFunction = function() {
            var searchText = input.value.trim().toLowerCase();
            var keywords = searchText.split(/[\s\-]+/);
            if (keywords.length > 1) {
              keywords.push(searchText);
            }
            var resultItems = [];
            if (searchText.length > 0) {
              // perform local searching
              datas.forEach(function(data) {
                var isMatch = false;
                var hitCount = 0;
                var searchTextCount = 0;
                var title = data.title.trim();
                var titleInLowerCase = title.toLowerCase();
                var content = data.content.trim().replace(/<[^>]+>/g,"");
                
                var contentInLowerCase = content.toLowerCase();
                var articleUrl = decodeURIComponent(data.url).replace(/\/{2,}/g, '/');
                var indexOfTitle = [];
                var indexOfContent = [];
                // only match articles with not empty titles
                if(title != '') {
                  keywords.forEach(function(keyword) {
                    function getIndexByWord(word, text, caseSensitive) {
                      var wordLen = word.length;
                      if (wordLen === 0) {
                        return [];
                      }
                      var startPosition = 0, position = [], index = [];
                      if (!caseSensitive) {
                        text = text.toLowerCase();
                        word = word.toLowerCase();
                      }
                      while ((position = text.indexOf(word, startPosition)) > -1) {
                        index.push({position: position, word: word});
                        startPosition = position + wordLen;
                      }
                      return index;
                    }

                    indexOfTitle = indexOfTitle.concat(getIndexByWord(keyword, titleInLowerCase, false));
                    indexOfContent = indexOfContent.concat(getIndexByWord(keyword, contentInLowerCase, false));
                  });
                  if (indexOfTitle.length > 0 || indexOfContent.length > 0) {
                    isMatch = true;
                    hitCount = indexOfTitle.length + indexOfContent.length;
                  }
                }

                // show search results

                if (isMatch) {
                  // sort index by position of keyword

                  [indexOfTitle, indexOfContent].forEach(function (index) {
                    index.sort(function (itemLeft, itemRight) {
                      if (itemRight.position !== itemLeft.position) {
                        return itemRight.position - itemLeft.position;
                      } else {
                        return itemLeft.word.length - itemRight.word.length;
                      }
                    });
                  });

                  // merge hits into slices

                  function mergeIntoSlice(text, start, end, index) {
                    var item = index[index.length - 1];
                    var position = item.position;
                    var word = item.word;
                    var hits = [];
                    var searchTextCountInSlice = 0;
                    while (position + word.length <= end && index.length != 0) {
                      if (word === searchText) {
                        searchTextCountInSlice++;
                      }
                      hits.push({position: position, length: word.length});
                      var wordEnd = position + word.length;

                      // move to next position of hit

                      index.pop();
                      while (index.length != 0) {
                        item = index[index.length - 1];
                        position = item.position;
                        word = item.word;
                        if (wordEnd > position) {
                          index.pop();
                        } else {
                          break;
                        }
                      }
                    }
                    searchTextCount += searchTextCountInSlice;
                    return {
                      hits: hits,
                      start: start,
                      end: end,
                      searchTextCount: searchTextCountInSlice
                    };
                  }

                  var slicesOfTitle = [];
                  if (indexOfTitle.length != 0) {
                    slicesOfTitle.push(mergeIntoSlice(title, 0, title.length, indexOfTitle));
                  }

                  var slicesOfContent = [];
                  while (indexOfContent.length != 0) {
                    var item = indexOfContent[indexOfContent.length - 1];
                    var position = item.position;
                    var word = item.word;
                    // cut out 100 characters
                    var start = position - 20;
                    var end = position + 80;
                    if(start < 0){
                      start = 0;
                    }
                    if (end < position + word.length) {
                      end = position + word.length;
                    }
                    if(end > content.length){
                      end = content.length;
                    }
                    slicesOfContent.push(mergeIntoSlice(content, start, end, indexOfContent));
                  }

                  // sort slices in content by search text's count and hits' count

                  slicesOfContent.sort(function (sliceLeft, sliceRight) {
                    if (sliceLeft.searchTextCount !== sliceRight.searchTextCount) {
                      return sliceRight.searchTextCount - sliceLeft.searchTextCount;
                    } else if (sliceLeft.hits.length !== sliceRight.hits.length) {
                      return sliceRight.hits.length - sliceLeft.hits.length;
                    } else {
                      return sliceLeft.start - sliceRight.start;
                    }
                  });

                  // select top N slices in content

                  var upperBound = parseInt('1');
                  if (upperBound >= 0) {
                    slicesOfContent = slicesOfContent.slice(0, upperBound);
                  }

                  // highlight title and content

                  function highlightKeyword(text, slice) {
                    var result = '';
                    var prevEnd = slice.start;
                    slice.hits.forEach(function (hit) {
                      result += text.substring(prevEnd, hit.position);
                      var end = hit.position + hit.length;
                      result += '<b class="search-keyword">' + text.substring(hit.position, end) + '</b>';
                      prevEnd = end;
                    });
                    result += text.substring(prevEnd, slice.end);
                    return result;
                  }

                  var resultItem = '';

                  if (slicesOfTitle.length != 0) {
                    resultItem += "<li><a href='" + articleUrl + "' class='search-result-title'>" + highlightKeyword(title, slicesOfTitle[0]) + "</a>";
                  } else {
                    resultItem += "<li><a href='" + articleUrl + "' class='search-result-title'>" + title + "</a>";
                  }

                  slicesOfContent.forEach(function (slice) {
                    resultItem += "<a href='" + articleUrl + "'>" +
                      "<p class=\"search-result\">" + highlightKeyword(content, slice) +
                      "...</p>" + "</a>";
                  });

                  resultItem += "</li>";
                  resultItems.push({
                    item: resultItem,
                    searchTextCount: searchTextCount,
                    hitCount: hitCount,
                    id: resultItems.length
                  });
                }
              })
            };
            if (keywords.length === 1 && keywords[0] === "") {
              resultContent.innerHTML = '<div id="no-result"><i class="fa fa-search fa-5x"></i></div>'
            } else if (resultItems.length === 0) {
              resultContent.innerHTML = '<div id="no-result"><i class="fa fa-frown-o fa-5x"></i></div>'
            } else {
              resultItems.sort(function (resultLeft, resultRight) {
                if (resultLeft.searchTextCount !== resultRight.searchTextCount) {
                  return resultRight.searchTextCount - resultLeft.searchTextCount;
                } else if (resultLeft.hitCount !== resultRight.hitCount) {
                  return resultRight.hitCount - resultLeft.hitCount;
                } else {
                  return resultRight.id - resultLeft.id;
                }
              });
              var searchResultList = '<ul class=\"search-result-list\">';
              resultItems.forEach(function (result) {
                searchResultList += result.item;
              })
              searchResultList += "</ul>";
              resultContent.innerHTML = searchResultList;
            }
          }

          if ('auto' === 'auto') {
            input.addEventListener('input', inputEventFunction);
          } else {
            $('.search-icon').click(inputEventFunction);
            input.addEventListener('keypress', function (event) {
              if (event.keyCode === 13) {
                inputEventFunction();
              }
            });
          }

          // remove loading animation
          $(".local-search-pop-overlay").remove();
          $('body').css('overflow', '');

          proceedsearch();
        }
      });
    }

    // handle and trigger popup window;
    $('.popup-trigger').click(function(e) {
      e.stopPropagation();
      if (isfetched === false) {
        searchFunc(path, 'local-search-input', 'local-search-result');
      } else {
        proceedsearch();
      };
    });

    $('.popup-btn-close').click(onPopupClose);
    $('.popup').click(function(e){
      e.stopPropagation();
    });
    $(document).on('keyup', function (event) {
      var shouldDismissSearchPopup = event.which === 27 &&
        $('.search-popup').is(':visible');
      if (shouldDismissSearchPopup) {
        onPopupClose();
      }
    });
  </script>





  

  

  
  

  
  
    
      
    
      
    
      
    
      
    
      
    
      
    
      
    
      
    
      
    
      
    
  

  
    
      <script type="text/x-mathjax-config">
  

  MathJax.Hub.Config({
    tex2jax: {
      inlineMath: [ ['$', '$'], ['\\(', '\\)'] ],
      processEscapes: true,
      skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
    },
    TeX: {
      
      equationNumbers: {
        autoNumber: 'AMS'
      }
    }
  });
  MathJax.Hub.Register.StartupHook('TeX Jax Ready', function() {
    MathJax.InputJax.TeX.prefilterHooks.Add(function(data) {
      if (data.display) {
        var next = data.script.nextSibling;
        while (next && next.nodeName.toLowerCase() === '#text') { next = next.nextSibling }
        if (next && next.nodeName.toLowerCase() === 'br') { next.parentNode.removeChild(next) }
      }
    });
  });
</script>

<script type="text/x-mathjax-config">
  MathJax.Hub.Queue(function() {
    var all = MathJax.Hub.getAllJax(), i;
    for (i = 0; i < all.length; i += 1) {
      document.getElementById(all[i].inputID + '-Frame').parentNode.className += ' has-jax';
    }
  });
</script>
<script src="//cdn.jsdelivr.net/npm/mathjax@2/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script><!-- hexo-inject:begin --><!-- Begin: Injected MathJax -->
<script type="text/x-mathjax-config">
  MathJax.Hub.Config({"tex2jax":{"inlineMath":[["$","$"],["\\(","\\)"]],"skipTags":["script","noscript","style","textarea","pre","code"],"processEscapes":true},"TeX":{"equationNumbers":{"autoNumber":"AMS"}}});
</script>

<script type="text/x-mathjax-config">
  MathJax.Hub.Queue(function() {
    var all = MathJax.Hub.getAllJax(), i;
    for(i=0; i < all.length; i += 1) {
      all[i].SourceElement().parentNode.className += ' has-jax';
    }
  });
</script>

<script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js">
</script>
<!-- End: Injected MathJax -->
<!-- hexo-inject:end -->

    
  


  

  

  

  

  

  

  

  

  

  

  

</body>
</html>
