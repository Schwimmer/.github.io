<!DOCTYPE html>












  


<html class="theme-next mist use-motion" lang="zh-CN">
<head><meta name="generator" content="Hexo 3.9.0">
  <!-- hexo-inject:begin --><!-- hexo-inject:end --><meta charset="UTF-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">






















<link rel="stylesheet" href="/lib/font-awesome/css/font-awesome.min.css?v=4.7.0">

<link rel="stylesheet" href="/css/main.css?v=7.2.0">


  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png?v=7.2.0">


  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png?v=7.2.0">


  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png?v=7.2.0">


  <link rel="mask-icon" href="/images/logo.svg?v=7.2.0" color="#222">







<script id="hexo.configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '/',
    scheme: 'Mist',
    version: '7.2.0',
    sidebar: {"position":"left","display":"post","offset":12,"onmobile":false,"dimmer":false},
    back2top: true,
    back2top_sidebar: false,
    fancybox: false,
    fastclick: false,
    lazyload: false,
    tabs: true,
    motion: {"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},
    algolia: {
      applicationID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    }
  };
</script>


  




  <meta name="description" content="Record and Think!">
<meta property="og:type" content="website">
<meta property="og:title" content="Schwimmer&#39;s Blog">
<meta property="og:url" content="https://schwimmer.github.io/page/23/index.html">
<meta property="og:site_name" content="Schwimmer&#39;s Blog">
<meta property="og:description" content="Record and Think!">
<meta property="og:locale" content="zh-CN">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Schwimmer&#39;s Blog">
<meta name="twitter:description" content="Record and Think!">





  
  
  <link rel="canonical" href="https://schwimmer.github.io/page/23/">



<script id="page.configurations">
  CONFIG.page = {
    sidebar: "",
  };
</script>

  <title>Schwimmer's Blog</title>
  




  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-143240576-1"></script>
  <script>
    var host = window.location.hostname;
    if (host !== "localhost" || !true) {
      window.dataLayer = window.dataLayer || [];
      function gtag(){dataLayer.push(arguments);}
      gtag('js', new Date());
      gtag('config', 'UA-143240576-1');
    }
  </script>









  <noscript>
  <style>
  .use-motion .motion-element,
  .use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-title { opacity: initial; }

  .use-motion .logo,
  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript><!-- hexo-inject:begin --><!-- hexo-inject:end -->

</head>

<body itemscope="" itemtype="http://schema.org/WebPage" lang="zh-CN">

  
  
    
  

  <!-- hexo-inject:begin --><!-- hexo-inject:end --><div class="container sidebar-position-left 
  page-home">
    <div class="headband"></div>

    <header id="header" class="header" itemscope="" itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-wrapper">
  <div class="site-meta">
    

    <div class="custom-logo-site-title">
      <a href="/" class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">Schwimmer's Blog</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
    
    
  </div>

  <div class="site-nav-toggle">
    <button aria-label="切换导航栏">
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
    </button>
  </div>
</div>



<nav class="site-nav">
  
    <ul id="menu" class="menu">
      
        
        
        
          
          <li class="menu-item menu-item-home">

    
    
      
    

    

    <a href="/" rel="section"><i class="menu-item-icon fa fa-fw fa-home"></i> <br>首页</a>

  </li>
        
        
        
          
          <li class="menu-item menu-item-tags">

    
    
      
    

    

    <a href="/tags/" rel="section"><i class="menu-item-icon fa fa-fw fa-tags"></i> <br>标签</a>

  </li>
        
        
        
          
          <li class="menu-item menu-item-categories">

    
    
      
    

    

    <a href="/categories/" rel="section"><i class="menu-item-icon fa fa-fw fa-th"></i> <br>分类</a>

  </li>
        
        
        
          
          <li class="menu-item menu-item-archives">

    
    
      
    

    

    <a href="/archives/" rel="section"><i class="menu-item-icon fa fa-fw fa-archive"></i> <br>归档</a>

  </li>

      
      
        <li class="menu-item menu-item-search">
          
            <a href="javascript:;" class="popup-trigger">
          
            
              <i class="menu-item-icon fa fa-search fa-fw"></i> <br>搜索</a>
        </li>
      
    </ul>
  

  
    

  

  
    <div class="site-search">
      
  <div class="popup search-popup local-search-popup">
  <div class="local-search-header clearfix">
    <span class="search-icon">
      <i class="fa fa-search"></i>
    </span>
    <span class="popup-btn-close">
      <i class="fa fa-times-circle"></i>
    </span>
    <div class="local-search-input-wrapper">
      <input autocomplete="off" placeholder="搜索..." spellcheck="false" type="text" id="local-search-input">
    </div>
  </div>
  <div id="local-search-result"></div>
</div>



    </div>
  
</nav>



  



</div>
    </header>

    


    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          
          <div id="content" class="content">
            
  <section id="posts" class="posts-expand">
    
      

  

  
  
  

  

  <article class="post post-type-normal" itemscope="" itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="https://schwimmer.github.io/2018/03/23/机器学习/NLP/新词发现/">

    <span hidden itemprop="author" itemscope="" itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Schwimmer">
      <meta itemprop="description" content="Record and Think!">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope="" itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Schwimmer's Blog">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                
                <a href="/2018/03/23/机器学习/NLP/新词发现/" class="post-title-link" itemprop="url">新词发现</a>
              
            
          </h1>
        

        <div class="post-meta">

          
          
          

          
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              

              
                
              

              <time title="创建时间：2018-03-23 21:02:13" itemprop="dateCreated datePublished" datetime="2018-03-23T21:02:13+08:00">2018-03-23</time>
            </span>
          

          

          
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope="" itemtype="http://schema.org/Thing"><a href="/categories/NLP/" itemprop="url" rel="index"><span itemprop="name">NLP</span></a></span>

                
                
              
            </span>
          

          
            
            
              
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="fa fa-comment-o"></i>
                </span>
            
                <span class="post-meta-item-text">评论数：</span>
                <a href="/2018/03/23/机器学习/NLP/新词发现/#comments" itemprop="discussionUrl">
                  <span class="post-comments-count disqus-comment-count" data-disqus-identifier="2018/03/23/机器学习/NLP/新词发现/" itemprop="commentCount"></span>
                </a>
              </span>
            
          

          
          

          

          <br>
          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>代码在</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">/spark-buzzads/src/main/scala/com/iclick/word_segmentation/WordSegment.scala</span><br></pre></td></tr></table></figure>
<p>自己测试的代码在</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">/spark-test/src/main/scala/com/iclick/word_segmentation/WordTest.scala</span><br></pre></td></tr></table></figure>
<p>新词发现的原理是</p>
<p><a href="http://blog.csdn.net/wendingzhulu/article/details/44464895" target="_blank" rel="noopener">中文新词发现算法解析</a></p>
<p><a href="http://www.matrix67.com/blog/archives/5044" target="_blank" rel="noopener">互联网时代的社会语言学：基于SNS的文本数据挖掘</a></p>
<p>从凝固度和自由度两个角度考虑你通过一元分词的相邻词组合而成的“新词”是否是语境中真正的一个词。</p>
<h1 id="算法原理"><a href="#算法原理" class="headerlink" title="算法原理"></a>算法原理</h1><p>把可能成词的文本片段全部提取出来，再跟已有词库比较，找出新词。</p>
<p>怎样的文本片段可以认为是词？</p>
<h2 id="凝固度"><a href="#凝固度" class="headerlink" title="凝固度"></a>凝固度</h2><p>光看词频是不够的，比如“的电影”出现300次，“电影院”出现100次。因为电影和院凝固的更紧一些。</p>
<p>首先要枚举凝固方式</p>
<p>令 p(x) 为文本片段 x 在整个语料中出现的概率，那么我们定义“电影院”的凝合程度就是 p(电影院) 与 p(电) · p(影院) 比值和 p(电影院) 与 p(电影) · p(院) 的比值中的较小值，“的电影”的凝合程度则是 p(的电影) 分别除以 p(的) · p(电影) 和 p(的电) · p(影) 所得的商的较小值。</p>
<h2 id="自由度"><a href="#自由度" class="headerlink" title="自由度"></a>自由度</h2><p>把一个文本片段的自由运用程度定义为它的左邻字信息熵和右邻字信息熵中的较小值。如果太小，就不能成单独的词（因为都是跟着左、右一起出现的）。</p>
<p>抽词后，按照频度从高到低排序。</p>
<p>定义候选词的最大长度，再为出现频数、凝固程度和自由程度各设定一个阈值，然后只需要提取出所有满足阈值要求的候选词即可。</p>
<p>左右邻字的熵取较小值。</p>
<p>熵较小，说明该词往往是固定搭配，不能成词。</p>
<p>示例文本是</p>
<p>ab我 ef</p>
<p>cd</p>
<h2 id="步骤"><a href="#步骤" class="headerlink" title="步骤"></a>步骤</h2><p>1、对语料用标点分隔，这里不需要去掉停用词。</p>
<p>2、在设定的最长词长度内，提取所有可能成词的词（至少大于2,小于max长度），并保存每个词的左邻近和右邻近字。</p>
<p>3、计算</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">val conf = new SparkConf().setAppName(&quot;wordSegname&quot;).setMaster(&quot;local[4]&quot;).</span><br><span class="line"></span><br><span class="line">    set(&quot;spark.sql.shuffle.partitions&quot;,&quot;10&quot;).set(&quot;spark.network.timeout&quot;,&quot;30s&quot;)</span><br></pre></td></tr></table></figure>
<p>local[4]是指在本地运行，用4核CPU。</p>
<p>spark.sql.shuffle.partitions是指partition的数量。SparkSQL在运行时，将一个查询任务分解成多个task，一个task就是一个partition。默认是200个partition，而如果实际集群只能并行3个task，则跑完200个partition要200/3=67次。</p>
<p>spark.network.timeout是指所有网络通信的超时时间，默认是120s</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">val word1=sc.textFile(path).map&#123;x=&gt; </span><br><span class="line"></span><br><span class="line">      val x_filter=x.replaceAll(&quot;\p&#123;Punct&#125;&quot;, &quot; &quot;).replaceAll(&quot;\pP&quot;, &quot; &quot;)</span><br><span class="line">                .replaceAll(&quot;　&quot;, &quot; &quot;).replaceAll(&quot;[&quot; + AtomsUitl.stopwords + &quot;]&quot;, &quot; &quot;).replaceAll(&quot;\p&#123;Blank&#125;&quot;, &quot; &quot;).replaceAll(&quot;\p&#123;Space&#125;&quot;, &quot; &quot;).replaceAll(&quot;\p&#123;Cntrl&#125;&quot;, &quot; &quot;)</span><br><span class="line">      x_filter</span><br><span class="line">    &#125;</span><br></pre></td></tr></table></figure>
<p>停用词，标点等转换为空格。</p>
<p>replaceAll中是正则表达式。上文中，是将所有的特殊字符都用空格代替</p>
<p>AtomsUitl.stopwords停用词是”的很了么呢是嘛个都也比还这于不与才上用就好在和对挺去后没说”</p>
<p>sc.textFile读取文件后，生成一个RDD，以行为单位，所以后面的map是对每行的操作</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">val sum_document = word1.count()</span><br></pre></td></tr></table></figure>
<p>打印出所有的元素，用</p>
<p>word1.foreach { x =&gt; println(x) }  </p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">val word_document = word1.zipWithIndex.filter &#123; x =&gt; !StringUtils.isBlank(x._1) &#125;.flatMap &#123; x =&gt;</span><br><span class="line">      val arr = ArrayBuffer[(String, Int)]()</span><br><span class="line">      val line = x._1.split(&quot; &quot;)    //对于每一行，都用空格分割</span><br><span class="line">      for (i &lt;- line) &#123;    </span><br><span class="line">        arr += ((i, x._2.toInt))    //分割后，每一个tuple加到数组中</span><br><span class="line">      &#125;</span><br><span class="line">      arr</span><br><span class="line">    &#125;.map &#123; x =&gt; (x._1.trim, x._2) &#125;.filter(x =&gt; !StringUtils.isBlank(x._1))</span><br></pre></td></tr></table></figure>
<p>zipWithIndex用带有index的来压缩RDD，索引从0开始</p>
<p>word1.zipWithIndex.foreach { x =&gt; println(x) }</p>
<p>(ab ef,0)</p>
<p>(cd,1)</p>
<p>上述代码得到的结果是</p>
<p>(ab,0)</p>
<p>(ef,0)</p>
<p>(cd,1)</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">val wordleft = word.map(x =&gt; AtomsUitl.reverse(x)).map &#123; x =&gt; &quot;&quot; + x + &quot;&quot; &#125;.flatMap &#123;</span><br><span class="line"></span><br><span class="line">  x =&gt;</span><br><span class="line"></span><br><span class="line">    var arr = ArrayBufferString</span><br><span class="line"></span><br><span class="line">    for (y &lt;- 1 to AtomsUitl.len(x) - 2) &#123;</span><br><span class="line"></span><br><span class="line">      //             arr+=x.substring(y, Math.min(maxLen + y,  x.length()))</span><br><span class="line"></span><br><span class="line">      arr += AtomsUitl.substring(x, y, Math.min(maxLen + y, AtomsUitl.len(x)))</span><br><span class="line"></span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    arr</span><br><span class="line"></span><br><span class="line">&#125;.sortBy(x =&gt; x)</span><br></pre></td></tr></table></figure>
<p>将每个句子倒序排列，提取每个子集</p>
<p>今$</p>
<p>四期星天今</p>
<p>处言语然自</p>
<p>天今$</p>
<p>星天今$</p>
<p>期星天今$</p>
<p>然自$</p>
<p>理处言语然</p>
<p>自$</p>
<p>言语然自</p>
<p>语然自$</p>
<p>$</p>
<p>\<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">val wordleft_caculate = wordleft.map &#123;</span><br><span class="line"></span><br><span class="line">​      s =&gt;</span><br><span class="line"></span><br><span class="line">​        val first = AtomsUitl.substring(s, 0, 1).toString</span><br><span class="line"></span><br><span class="line">​        (first, s)</span><br><span class="line"></span><br><span class="line">​    &#125;.groupBy(f =&gt; f._1).map &#123;</span><br><span class="line"></span><br><span class="line">​      x =&gt; x._2</span><br><span class="line"></span><br><span class="line">​    &#125;</span><br><span class="line"></span><br><span class="line">wordleft_caculate.foreach&#123;x=&gt; println(x.iterator.next())&#125;  </span><br><span class="line"></span><br><span class="line">\</span><br></pre></td></tr></table></figure></p>
<p>groupBy之后得到</p>
<p>(期, CompactBuffer((期,期星天今$))等</p>
<p>这个是Iterable，可迭代的。可以转换为一个迭代器x.iterator.next()。迭代出来就是</p>
<p>(期,期星天今$) 等</p>
<p>结果如：</p>
<p>[維他命,105,5.103775510263332,2.120730528309974,41,3362341]</p>
<p>[红庙路口,10,3.969704104467617,1.3592367006650063,6,3362341]</p>
<p>[红裙艳丽,8,4.516740790602718,1.2554823251787535,4,3362341]</p>
<p>[绛侯,85,3.85163302224936,1.8033243982880292,37,3362341]</p>
<p>其中，第一列是新词，第二列是总词频，第三列是凝聚度，第四列是左熵右熵取最小值，第五列是出现该词的文档数，最后一列是总文档数</p>

          
        
      
    </div>

    

    
    
    

    

    
      
    
    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  

  <article class="post post-type-normal" itemscope="" itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="https://schwimmer.github.io/2018/03/17/机器学习/GBDT/">

    <span hidden itemprop="author" itemscope="" itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Schwimmer">
      <meta itemprop="description" content="Record and Think!">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope="" itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Schwimmer's Blog">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                
                <a href="/2018/03/17/机器学习/GBDT/" class="post-title-link" itemprop="url">GBDT</a>
              
            
          </h1>
        

        <div class="post-meta">

          
          
          

          
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              

              
                
              

              <time title="创建时间：2018-03-17 20:50:55" itemprop="dateCreated datePublished" datetime="2018-03-17T20:50:55+08:00">2018-03-17</time>
            </span>
          

          
            

            
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="fa fa-calendar-check-o"></i>
                </span>
                
                  <span class="post-meta-item-text">更新于</span>
                
                <time title="修改时间：2018-09-14 12:58:36" itemprop="dateModified" datetime="2018-09-14T12:58:36+08:00">2018-09-14</time>
              </span>
            
          

          
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope="" itemtype="http://schema.org/Thing"><a href="/categories/机器学习/" itemprop="url" rel="index"><span itemprop="name">机器学习</span></a></span>

                
                
              
            </span>
          

          
            
            
              
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="fa fa-comment-o"></i>
                </span>
            
                <span class="post-meta-item-text">评论数：</span>
                <a href="/2018/03/17/机器学习/GBDT/#comments" itemprop="discussionUrl">
                  <span class="post-comments-count disqus-comment-count" data-disqus-identifier="2018/03/17/机器学习/GBDT/" itemprop="commentCount"></span>
                </a>
              </span>
            
          

          
          

          

          <br>
          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>tips</p>
<p>论文中GBDT的参数，树的数量最多500颗（500以上就没有提升了），每棵树的节点不多于12。</p>
<p> <a href="https://blog.csdn.net/shine19930820/article/details/71713680" target="_blank" rel="noopener">https://blog.csdn.net/shine19930820/article/details/71713680</a></p>
<h1 id="原理"><a href="#原理" class="headerlink" title="原理"></a>原理</h1><p><a href="https://blog.csdn.net/davidie/article/details/50897278" target="_blank" rel="noopener">算法原理整理</a></p>
<p><a href="http://blog.csdn.net/google19890102/article/details/51746402" target="_blank" rel="noopener">简单易学的GBDT原理</a></p>
<p><a href="">GBDT公式推导</a></p>
<p><a href="https://blog.csdn.net/yangxudong/article/details/53872141" target="_blank" rel="noopener">GBDT算法原理深入解析</a></p>
<p><a href="https://www.cnblogs.com/peizhe123/p/5086128.html" target="_blank" rel="noopener">GBDT详解</a></p>
<h2 id="梯度提升算法"><a href="#梯度提升算法" class="headerlink" title="梯度提升算法"></a>梯度提升算法</h2><p>Freidman提出了梯度提升算法，该方法是利用最速下降法的近似方法，其关键是利用损失函数的负梯度在当前模型的值  </p>
<script type="math/tex; mode=display">-[{\partial L(y,f(x_i)) \over \partial f(x_i)}]_{f(x) = f_{m-1}(x)}</script><blockquote>
<p>这个公式中，每个参数什么意思</p>
</blockquote>
<p>作为回归问题算法中的残差的近似值，拟合一个回归模型。</p>
<p>其算法流程如下：</p>
<ol>
<li>$F<em>0(x) = argmin</em>\rho \sum _{i=1}^N L(y_i, \rho)$</li>
<li>For $m = 1$ to $M$ do:  </li>
<li>$\qquad \tilde y<em>i = -[{\partial L(y,F(x_i)) \over \partial F(x_i)}]</em>{F(x) = F_{m-1}(x)}, i = 1, N$  </li>
<li>$\qquad a<em>m = argmin</em>{a,\beta}\sum_{i=1}^N[\tilde y_i - \beta h(x_i; a)]^2$ </li>
<li>$\qquad \rho<em>m = argmin</em>\rho \sum<em>{i=1}^N L(y_i, F</em>{m-1}(x_i) + \rho h(x_i; a_m))$ </li>
<li>$\qquad F<em>m(x) = F</em>{m-1}(x) + \rho_m h(x;a_m)$</li>
<li>endFor<br>endAlgorighm</li>
</ol>
<p>其中$h(x_i;a_m)$表示基本分类器（weak learner or base learner），4中$a_m$表示拟合负梯度能力最好的分类器参数<br>负梯度只是表示下降的方向，但是下降多少没有确定，5中$\rho_m$可以认为是下降最快的步长，可以让Loss最小，可以用线性搜索的方式来估计$\rho_m$的值</p>
<p>为何这里不直接利用负梯度来调节，而是需要用一个分类器来拟合呢？因为这里的负梯度是在训练集上求出的，不能被泛化测试集中。我们的参数是在一个函数空间里面，不能使用例如SGD这样的求解方式。使用一个分类器来拟合，是一个泛化的方式。</p>
<h4 id="回归树"><a href="#回归树" class="headerlink" title="回归树"></a>回归树</h4><p>当我们的基本分类器是一个包含J个节点的回归树时，回归树模型可以表示为  </p>
<script type="math/tex; mode=display">h(x;\{b_j, R_j\}_1^J) = \sum_{b=j}^Jb_jI(x\in R_j) \qquad (8)</script><p>其中${ R_j }_1^J$不相交的区域，它们的集合覆盖了预测值的空间，${ b_j }_1^J$是叶子节点的值，可以认为是模型$h$的系数</p>
<p>利用回归树模型，算法流程6中的公式可以被替换为：<script type="math/tex">F_m(x) = F_{m-1}(x) + \rho_m \sum_{j=1}^J b_{jm}I(x \in R_{jm})\qquad (9)</script> </p>
<p>其中${ R_{jm} }_1^J$是第m次迭代生成的树所产生的区域。第m次迭代的树用来预测流程3中由流程4中平方误差产生的${\tilde y_i}_i^N$  </p>
<p>${ b<em>{jm}}$可以被表示为 $$b</em>{jm} = ave<em>{x_i \in R</em>{jm}} \tilde y_i$$ 即用平均值表示该叶子节点拟合的值</p>
<p>有了下降的方向，我们还需要最好的步长，缩放因子$\rho_m$是流程5中线性搜索方式的一种解决方案</p>
<p>从上面可以看出，我们是先求的$b<em>{jm}$，然后在求解$\rho_m$，我们能否同时求解呢？<br>另$\gamma</em>{jm} = \rho<em>{m}b</em>{jm}$，公式9可以被表示为：<script type="math/tex">F_m(x) = F_{m-1}(x) + \sum_{j=1}^J \gamma_{jm}I(x \in R_{jm})\qquad (10)</script> </p>
<p>通过优化如下公式来获取最优的系数$\gamma_{jm}$：</p>
<script type="math/tex; mode=display">\{\gamma_{jm}\}_1^J = argmin_{\ \gamma_j {\ _1^J}}\sum_{i=1}^N L\left(y_i, F_{m-1}(x_i) + \sum_{j=1}^J\gamma_jI(x \in R_{jm})\right)\qquad 1)</script><p>由于回归树产生的叶子节点各个区域之间是不相交的，且所有的样本最终都会属于某个叶子节点，所以公式11可以表示为：</p>
<script type="math/tex; mode=display">\gamma_{jm} = argmin_\gamma \sum_{x_i\in R_{jm}} L(y_i, F_{m-1}(x_i) + \gamma)</script><p>给定当前$F<em>{m-1}(i)$，$\gamma</em>{jm}$可以作为叶子节点的值，该值可以看做是基于损失函数L的每个叶子节点的最理想的常数更新值，也可以认为$\gamma_{jm}$是即有下降方向又有下降步长的值。</p>
<p>综上，用回归树作为基本分类器的梯度提升算法流程可以如下表示：</p>
<ol>
<li>$F<em>0(x) = argmin</em>\rho \sum _{i=1}^N L(y_i, \rho)$</li>
<li>For $m = 1$ to $M$ do:  </li>
<li>$\qquad \tilde y<em>i = -[{\partial L(y,F(x_i)) \over \partial F(x_i)}]</em>{F(x) = F_{m-1}(x)}, i = 1, N$  </li>
<li>$\qquad {R_{jm}}_1^J = J-terminal\, node\, tree({ \tilde y_i, x_i }_i^N)$ </li>
<li>$\qquad \gamma<em>{jm} = argmin</em>\gamma \sum<em>{x_i\in R</em>{jm}} L(y<em>i, F</em>{m-1}(x_i) + \gamma)$</li>
<li>$\qquad F<em>m(x) = F</em>{m-1}(x) + \sum<em>{j=1}^J \gamma</em>{jm}I(x \in R_{jm})$</li>
<li>endFor<br>endAlgorighm</li>
</ol>
<p>其中3是计算残差（利用损失函数的负梯度在当前模型的值作为残差的近似值），4是拟合一颗含有J个叶子节点的回归树，5是估计回归树叶子节点的值</p>
<p>下面我们看一下二元分类、多元分类、回归中残差的计算、叶子节点值的估计。</p>
<h4 id="Two-class-logistic-regression-and-classification"><a href="#Two-class-logistic-regression-and-classification" class="headerlink" title="Two-class logistic regression and classification"></a>Two-class logistic regression and classification</h4><p>我们用negative binomial log-likehood作为我们的损失函数：</p>
<script type="math/tex; mode=display">L(y, F) = log(1 + exp(-2yF)), y \in {-1, 1}\qquad (12)</script><p>其中<script type="math/tex">F(x) = {1\over2}log\left[{Pr(y=1|x) \over Pr(y=-1|x)}\right]\qquad (13)</script><br>公式13是logit函数，log odds</p>
<p>如上公式是Freidman的论文中使用的公式，我认为使用在逻辑回归中常见的$L(y, F) = ylogF + (1-y)log(1-F)$，其中$F(z) ={ 1\over{1+exp(-z)}}$也可以</p>
<p>计算残差：<script type="math/tex">\tilde y_i = -[{\partial L(y,F(x_i)) \over \partial F(x_i)}]_{F(x) = F_{m-1}(x)} = {2y_i\over 1+exp(2y_iF_{m-1}(x_i))}\qquad(14)</script></p>
<p>叶子节点值的估计：</p>
<script type="math/tex; mode=display">\gamma_jm = argmin_\gamma \sum_{x_i \in R_{jm}} log(1+exp(-2y_i(F_{m-1}(x_i) + \gamma)))\qquad (15)</script><p>可以通过一步Newton-Raphson来近似公式15，估计结果为：</p>
<script type="math/tex; mode=display">\gamma_{jm} = {\sum_{x_i \in R_{jm}}\tilde y_i \over {\sum_{x_i \in R_{jm}}}|\tilde y_i|(2-|\tilde y_i|)}</script><p>最终得到的$F_M(x)$与对数几率 log-odds相关，我们可以用来进行概率估计</p>
<script type="math/tex; mode=display">F(x) = {1\over2}log\left({p \over 1-p}\right)</script><script type="math/tex; mode=display">e^{2F(x)} = {p\over(1-p)}</script><script type="math/tex; mode=display">P_+(x) = p = {e^{2F(x)}\over 1+e^{2F(x)}} = {1\over1+e^{-2F(x)}}</script><script type="math/tex; mode=display">P_-(x) = 1-p = {1\over1+e^{2F(x)}}</script><p>有了概率之后，我们接下来就可以利用概率进行分类</p>
<h4 id="Multi-class-logistic-regression-and-classification"><a href="#Multi-class-logistic-regression-and-classification" class="headerlink" title="Multi-class logistic regression and classification"></a>Multi-class logistic regression and classification</h4><p>我们使用multi-class log-loss作为损失函数：</p>
<script type="math/tex; mode=display">L(\{y_k, F_k(x)\}_1^K) = -\sum_{k=1}^K y_klogp_k(x)\qquad(16)</script><p>其中使用softmax来计算概率：<script type="math/tex">p_k(x) = exp(F_k(x)) / \sum_{l=1}^Kexp(F_l(x))\qquad(17)</script></p>
<p>从公式17可以得出，对于多分类问题，我们需要为每个类别创建一颗回归树$F_l(x)\, l=1,2,…,k$</p>
<p>计算残差：</p>
<script type="math/tex; mode=display">\tilde y_{ik} = -[{\partial L(\{y_{il},F_l(x_i)\}_{l=1}^K) \over \partial F_k(x_i)}]_{\{F_l(x) = F_{l, m-1(x)}\}_1^K} = y_{ik} - p_{k,m-1(i)}\qquad (18)</script><p>我们假定共分为3类，那么logloss为：</p>
<script type="math/tex; mode=display">L = -y_1log{exp(F_1(x))\over exp(F_1(x)) + exp(F_1(x)) + exp(F_1(x))} -y_2log{exp(F_2(x))\over exp(F_1(x)) + exp(F_1(x)) + exp(F_1(x))} _3log{exp(F_3(x))\over exp(F_1(x)) + exp(F_1(x)) + exp(F_1(x))}</script><script type="math/tex; mode=display">{\partial L \over \partial F_1(x)} = -y_1 + y_1p_1 + y_2p_2 + y_3p_3</script><script type="math/tex; mode=display">{\partial L \over \partial F_2(x)} = y_1p_1 - y_2 + y_2p_2 + y_3p_3</script><script type="math/tex; mode=display">{\partial L \over \partial F_3(x)} = y_1p_1 + y_2p_2 - y_3 + y_3p_3</script><p>如果当期样本的类别为(1,0,0)，那么</p>
<script type="math/tex; mode=display">{\partial L \over \partial F_1(x)} = -1 + p1</script><script type="math/tex; mode=display">{\partial L \over \partial F_2(x)} = p_2</script><script type="math/tex; mode=display">{\partial L \over \partial F_3(x)} = p_3</script><p>取负梯度，则</p>
<script type="math/tex; mode=display">-{\partial L \over \partial F_1(x)} = 1 - p_1</script><script type="math/tex; mode=display">-{\partial L \over \partial F_2(x)} = -p_2 = 0 - p_2</script><script type="math/tex; mode=display">-{\partial L \over \partial F_3(x)} = -p_3 = 0 - p_3</script><p>符合公式18中的$\tilde y<em>{ik} = y</em>{ik} - p_{k,m-1(x_i)}$</p>
<p>叶子节点值的估计：</p>
<script type="math/tex; mode=display">\{r_{jkm}\} = argmin_{\gamma_{jk}}\sum_{i=1}^N \sum_{k=1}^K \phi \left( y_{ik}, F_{k,m-1}(x_i) + \sum_{j=1}^J\gamma_{jk}I(x_i \in {jm})\}\right)\qquad(19)</script><p>可以通过一步Newton-Raphson来近似公式19，估计结果为：</p>
<script type="math/tex; mode=display">\gamma_{jkm} = {K-1\over K}{\sum_{x_i \in R_{jkm}}\tilde y_{ik} \over {\sum_{x_i \in R_{jkm}}}|\tilde y_{ik}|(1-|\tilde y_{ik}|)}</script><h4 id="Regression"><a href="#Regression" class="headerlink" title="Regression"></a>Regression</h4><p>我们使用Least-squares作为损失函数：<script type="math/tex">L(y, F) = {(y-F)^2\over 2}</script></p>
<p>计算残差：<script type="math/tex">\tilde y_i = -[{\partial L(y,F(x_i)) \over \partial F(x_i)}]_{F(x) = F_{m-1}(x)} = {y_i - F_{m-1}(x_i)}\qquad(20)</script></p>
<p>叶子节点值的估计：</p>
<script type="math/tex; mode=display">\gamma_{jm} = argmin_\gamma \sum_{x_i \in R_{jm}} {1\over 2}(y_i - (F_{m-1}(x_i) + \gamma))^2\qquad (21)</script><script type="math/tex; mode=display">\gamma_{jm} = argmin_\gamma \sum_{x_i \in R_{jm}} {1\over 2}(y_i - F_{m-1}(x_i) - \gamma)^2</script><script type="math/tex; mode=display">\gamma_{jm} = argmin_\gamma \sum_{x_i \in R_{jm}} {1\over 2}(\tilde y_i -  \gamma)^2</script><p>容易得出以下结果：<script type="math/tex">\gamma_{jm} = ave_{x_i \in R_{jm}} \tilde y_i</script></p>
<h4 id="回归树的创建"><a href="#回归树的创建" class="headerlink" title="回归树的创建"></a>回归树的创建</h4><p>拟合残数是一个回归问题，所以在分割样本时，我们不会采用基尼指数（Gini）、信息增益（IG）等用于分类的标准。<br>我们可以选用MSE(mean square error impurity criterion)作为分割样本的标准。<br>也可是采用Friedman在论文中的the least-squares improvement criterion，公式如下：</p>
<script type="math/tex; mode=display">i_2(R_l, R_r) = {w_lw_r\over w_l + w_r}(\bar y_l - \bar y_r)^2</script><p>其中$\bar y_l \, \bar y_r$分别是左右孩子的平均值，$w_l \, w_r$分别是左右孩子对应的权重和</p>
<p>本文是针对具体的损失函数进行的相关推导，泛化能力差，大家可以参考xgboost作者的这篇<a href="http://www.52cs.org/?p=429" target="_blank" rel="noopener">文章</a>，作者进行了更加一般的推导，这一个抽象的形式对于实现机器学习工具也是非常有帮助的。</p>
<p>引用：<br>Greedy Function Approximation: A Gradient Boosting Machine</p>
<h2 id="与RF的区别"><a href="#与RF的区别" class="headerlink" title="与RF的区别"></a>与RF的区别</h2><h2 id="实现"><a href="#实现" class="headerlink" title="实现"></a>实现</h2><p><a href="https://github.com/liudragonfly/GBDT" target="_blank" rel="noopener">GBDT的python实现</a></p>
<h1 id="python配置XGB"><a href="#python配置XGB" class="headerlink" title="python配置XGB"></a>python配置XGB</h1><p>参考</p>
<p>gbdt</p>
<p><a href="http://www.itopmarketing.com/index.php/News/show/id/7951/lmid/197/utm_source/tuicool/utm_medium/referral/" target="_blank" rel="noopener">http://www.itopmarketing.com/index.php/News/show/id/7951/lmid/197/utm_source/tuicool/utm_medium/referral/</a> 【关于点击率模型，你知道这三点就够了】</p>
<p><a href="http://www.cnblogs.com/zhouxiaohui888/p/6008368.html" target="_blank" rel="noopener">http://www.cnblogs.com/zhouxiaohui888/p/6008368.html</a> 【xgboost原理及应用】</p>
<p>官网介绍的原理：<a href="https://xgboost.readthedocs.io/en/latest/model.html" target="_blank" rel="noopener">https://xgboost.readthedocs.io/en/latest/model.html</a></p>
<p>原理的中文解释<a href="http://dataunion.org/15787.html" target="_blank" rel="noopener">http://dataunion.org/15787.html</a></p>
<p><a href="https://github.com/dmlc/xgboost" target="_blank" rel="noopener">https://github.com/dmlc/xgboost</a></p>
<p><a href="https://github.com/Schwimmer/xgboost/tree/master/jvm-packages/xgboost4j-example/src/main/scala/ml/dmlc/xgboost4j/scala/example/spark" target="_blank" rel="noopener">https://github.com/Schwimmer/xgboost/tree/master/jvm-packages/xgboost4j-example/src/main/scala/ml/dmlc/xgboost4j/scala/example/spark</a></p>
<p>GBDT</p>
<p>（Gradient Boost Decision Tree）是一种常用的非线性模型[6][7][8][9]，它基于集成学习中的boosting思想[10]，每次迭代都在减少残差的梯度方向新建立一颗决策树，迭代多少次就会生成多少颗决策树。</p>
<p>GBDT</p>
<p>的思想使其具有天然优势可以发现多种有区分性的特征以及特征组合，决策树的路径可以直接作为LR输入特征使用，省去了人工寻找特征、特征组合的步骤。这种通过</p>
<p>GBDT</p>
<p>生成LR特征的方式（</p>
<p>GBDT</p>
<p>+LR），业界已有实践（Facebook，Kaggle-2014），且效果不错</p>
<p>来源： <a href="http://blog.csdn.net/lilyth_lilyth/article/details/48032119" target="_blank" rel="noopener">http://blog.csdn.net/lilyth_lilyth/article/details/48032119</a></p>
<p>XGBoost</p>
<p><a href="http://blog.csdn.net/dusj1993/article/details/51925387【" target="_blank" rel="noopener">http://blog.csdn.net/dusj1993/article/details/51925387【</a> 在集群上部署xgboost踩过的坑】</p>
<p><a href="http://blog.csdn.net/u010306433/article/details/51403894" target="_blank" rel="noopener">http://blog.csdn.net/u010306433/article/details/51403894</a> 【xgboost 分布式部署教程】</p>
<p>mvn install:install-file -Dfile=D:\code\jar_package\xgboost4j-spark-0.5-jar-with-dependencies.jar -DgroupId=ml.dmlc -DartifactId=xgboost4j -Dversion=0.5 -Dpackaging=jar</p>
<dependency>

  <groupid>ml.dmlc</groupid>

  <artifactid>xgboost4j</artifactid>

  <version>0.7</version>

</dependency>

<p>\<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">http://blog.csdn.net/zhangweijiqn/article/details/53214186</span><br><span class="line"></span><br><span class="line">XGBoost4J:</span><br><span class="line"></span><br><span class="line">Distributed XGBoost for Scala/Java (XFBoost 4 JVM environment)，目前看来还比较小众，文档不够多，网上xgboost4j的资料也很少，社区不够活跃。</span><br><span class="line"></span><br><span class="line">Portable Distributed XGBoost in Spark, Flink and Dataflow: </span><br><span class="line"></span><br><span class="line">http://dmlc.ml/2016/03/14/xgboost4j-portable-distributed-xgboost-in-spark-flink-and-dataflow.html</span><br><span class="line"></span><br><span class="line">Scala和Spark等分布式的包在jvm-packages下。</span><br><span class="line"></span><br><span class="line">安装：http://xgboost.readthedocs.io/en/latest/jvm/</span><br><span class="line"></span><br><span class="line">目前安装仅支持从源码安装:</span><br><span class="line"></span><br><span class="line">$ git clone --recursive </span><br><span class="line"></span><br><span class="line">https://github.com/dmlc/xgboost</span><br><span class="line"></span><br><span class="line">$ cd xgboost/jvm-packages</span><br><span class="line"></span><br><span class="line">$ mvn package</span><br><span class="line"></span><br><span class="line">安装scala/java的jvm版xgboost:</span><br><span class="line"></span><br><span class="line">$ cd jvm-packages/xgboost4j</span><br><span class="line"></span><br><span class="line">$ mvn install:install-file -Dfile=target/xgboost4j-0.7.jar -DgroupId=ml.dmlc -DartifactId=xgboost4j -Dversion=0.7 -Dpackaging=jar</span><br><span class="line"></span><br><span class="line">安装spark版的xgboost:</span><br><span class="line"></span><br><span class="line">$ cd jvm-packages/xgboost4j-spark</span><br><span class="line"></span><br><span class="line">$ mvn install:install-file -Dfile=target/xgboost4j-spark-0.7.jar -DgroupId=ml.dmlc -DartifactId=xgboost4j-spark -Dversion=0.7 -Dpackaging=jar</span><br><span class="line"></span><br><span class="line">Maven pom.xml file:</span><br><span class="line"></span><br><span class="line">&lt;dependency&gt;</span><br><span class="line"></span><br><span class="line">&lt;groupId&gt;ml.dmlc&lt;/groupId&gt;</span><br><span class="line"></span><br><span class="line">&lt;artifactId&gt;xgboost4j-spark&lt;/artifactId&gt;</span><br><span class="line"></span><br><span class="line">&lt;version&gt;0.7&lt;/version&gt;</span><br><span class="line"></span><br><span class="line">&lt;/dependency&gt;</span><br><span class="line"></span><br><span class="line">Spark code，参考https://github.com/dmlc/xgboost/tree/master/jvm-packages，分别有RDD版本和DataFrame版本:</span><br><span class="line"></span><br><span class="line">import</span><br><span class="line"></span><br><span class="line">ml.dmlc.xgboost4j.scala.spark.XGBoost</span><br><span class="line"></span><br><span class="line">\</span><br></pre></td></tr></table></figure></p>
<p>用maven安装xgboost4j时候的坑</p>
<p>执行</p>
<p>mvn clean -DskipTests=true package</p>
<p>1、checkstyle报错</p>
<p>xgboost4j的pom中增加了checkstyple插件，在win7下package会报错</p>
<p>\<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">method name must match pattern</span><br><span class="line"></span><br><span class="line">no-trailing-spaces</span><br><span class="line"></span><br><span class="line">等</span><br><span class="line"></span><br><span class="line">\</span><br></pre></td></tr></table></figure></p>
<p>解决：在pom.xml中去掉checkstyle插件</p>
<p>\<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">            &lt;plugin&gt;</span><br><span class="line"></span><br><span class="line">                &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt;</span><br><span class="line"></span><br><span class="line">                &lt;artifactId&gt;maven-checkstyle-plugin&lt;/artifactId&gt;</span><br><span class="line"></span><br><span class="line">                &lt;version&gt;2.17&lt;/version&gt;</span><br><span class="line"></span><br><span class="line">                &lt;configuration&gt;</span><br><span class="line"></span><br><span class="line">                    &lt;configLocation&gt;checkstyle.xml&lt;/configLocation&gt;</span><br><span class="line"></span><br><span class="line">                    &lt;failOnViolation&gt;true&lt;/failOnViolation&gt;</span><br><span class="line"></span><br><span class="line">                &lt;/configuration&gt;</span><br><span class="line"></span><br><span class="line">                &lt;executions&gt;</span><br><span class="line"></span><br><span class="line">                    &lt;execution&gt;</span><br><span class="line"></span><br><span class="line">                        &lt;id&gt;checkstyle&lt;/id&gt;</span><br><span class="line"></span><br><span class="line">                        &lt;phase&gt;validate&lt;/phase&gt;</span><br><span class="line"></span><br><span class="line">                        &lt;goals&gt;</span><br><span class="line"></span><br><span class="line">                            &lt;goal&gt;check&lt;/goal&gt;</span><br><span class="line"></span><br><span class="line">                        &lt;/goals&gt;</span><br><span class="line"></span><br><span class="line">                    &lt;/execution&gt;</span><br><span class="line"></span><br><span class="line">                &lt;/executions&gt;</span><br><span class="line"></span><br><span class="line">            &lt;/plugin&gt;</span><br><span class="line"></span><br><span class="line">                &lt;executions&gt;</span><br><span class="line"></span><br><span class="line">                    &lt;execution&gt;</span><br><span class="line"></span><br><span class="line">                        &lt;id&gt;checkstyle&lt;/id&gt;</span><br><span class="line"></span><br><span class="line">                        &lt;phase&gt;validate&lt;/phase&gt;</span><br><span class="line"></span><br><span class="line">                        &lt;goals&gt;</span><br><span class="line"></span><br><span class="line">                            &lt;goal&gt;check&lt;/goal&gt;</span><br><span class="line"></span><br><span class="line">                        &lt;/goals&gt;</span><br><span class="line"></span><br><span class="line">                    &lt;/execution&gt;</span><br><span class="line"></span><br><span class="line">                &lt;/executions&gt;</span><br><span class="line"></span><br><span class="line">\</span><br></pre></td></tr></table></figure></p>
<p>2、用scala的例子<strong>BasicWalkThrough.scala</strong>报错</p>
<p>\<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">ERROR [main] (DMatrix.java:41) - java.io.FileNotFoundException: File /lib/xgboost4j.dll was not found inside JAR.</span><br><span class="line"></span><br><span class="line">\</span><br></pre></td></tr></table></figure></p>
<p>参考：<a href="https://github.com/dmlc/xgboost/issues/1148" target="_blank" rel="noopener">https://github.com/dmlc/xgboost/issues/1148</a></p>
<p><a href="https://www.ibm.com/developerworks/community/blogs/jfp/entry/Installing_XGBoost_For_Anaconda_on_Windows?lang=en" target="_blank" rel="noopener">https://www.ibm.com/developerworks/community/blogs/jfp/entry/Installing_XGBoost_For_Anaconda_on_Windows?lang=en</a></p>
<p>需要装MINGW，然后make jvm，但是会报错</p>
<p>\<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">mingw32-make: *** No rule to make target &apos;jvm&apos;.  Stop.</span><br><span class="line"></span><br><span class="line">\</span><br></pre></td></tr></table></figure></p>
<p>应该在有MakeFile的目录下执行，也就是根目录D:\gitlab\xgboost。并且，要从git上手动下载项目中的dmlc-core和rabit，再执行，继续报错</p>
<p>\<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">process_begin: CreateProcess(NULL, uname, ...) failed.</span><br><span class="line"></span><br><span class="line">mingw32-make: Makefile:44: pipe: No error</span><br><span class="line"></span><br><span class="line">g++ -std=c++0x -Wall -Wno-unknown-pragmas -Iinclude   -Idmlc-core/include -Irabi</span><br><span class="line"></span><br><span class="line">t/include -O3 -funroll-loops -msse2 -fopenmp -MM -MT build/learner.o src/learner</span><br><span class="line"></span><br><span class="line">.cc &gt;build/learner.d</span><br><span class="line"></span><br><span class="line">g++ -c -std=c++0x -Wall -Wno-unknown-pragmas -Iinclude   -Idmlc-core/include -Ir</span><br><span class="line"></span><br><span class="line">abit/include -O3 -funroll-loops -msse2 -fopenmp src/learner.cc -o build/learner.</span><br><span class="line"></span><br><span class="line">o</span><br><span class="line"></span><br><span class="line">子目录或文件 -p 已经存在。</span><br><span class="line"></span><br><span class="line">处理: -p 时出错。</span><br><span class="line"></span><br><span class="line">子目录或文件 build 已经存在。</span><br><span class="line"></span><br><span class="line">处理: build 时出错。</span><br><span class="line"></span><br><span class="line">Makefile:113: recipe for target &apos;build/logging.o&apos; failed</span><br><span class="line"></span><br><span class="line">mingw32-make: *** [build/logging.o] Error 1</span><br><span class="line"></span><br><span class="line">\</span><br></pre></td></tr></table></figure></p>
<p>应该用git-bash来执行，然后接着报错</p>
<p>\<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">\</span><br></pre></td></tr></table></figure></p>
<p><a href="https://github.com/dmlc/xgboost/issues/1267" target="_blank" rel="noopener">https://github.com/dmlc/xgboost/issues/1267</a></p>
<p>跟着一步步执行，再报错</p>
<p>\<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">cc1plus.exe: sorry, unimplemented: 64-bit mode not compiled in</span><br><span class="line"></span><br><span class="line">\</span><br></pre></td></tr></table></figure></p>
<p>windows安装失败，在ubuntu环境下安装</p>
<h1 id="CART"><a href="#CART" class="headerlink" title="CART"></a>CART</h1><p><a href="https://www.cnblogs.com/qwj-sysu/p/5974421.html" target="_blank" rel="noopener">https://www.cnblogs.com/qwj-sysu/p/5974421.html</a> 离散值处理</p>
<p><a href="https://www.cnblogs.com/qwj-sysu/p/5981231.html" target="_blank" rel="noopener">https://www.cnblogs.com/qwj-sysu/p/5981231.html</a> 连续值处理</p>
<p>经典算法详解—CART分类决策树、回归树和模型树</p>
<p><a href="https://blog.csdn.net/jiede1/article/details/76034328" target="_blank" rel="noopener">https://blog.csdn.net/jiede1/article/details/76034328</a></p>

          
        
      
    </div>

    

    
    
    

    

    
      
    
    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  

  <article class="post post-type-normal" itemscope="" itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="https://schwimmer.github.io/2018/03/17/编程语言学习/PYTHON/Numpy/">

    <span hidden itemprop="author" itemscope="" itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Schwimmer">
      <meta itemprop="description" content="Record and Think!">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope="" itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Schwimmer's Blog">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                
                <a href="/2018/03/17/编程语言学习/PYTHON/Numpy/" class="post-title-link" itemprop="url">Numpy技巧总结</a>
              
            
          </h1>
        

        <div class="post-meta">

          
          
          

          
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              

              
                
              

              <time title="创建时间：2018-03-17 20:50:31" itemprop="dateCreated datePublished" datetime="2018-03-17T20:50:31+08:00">2018-03-17</time>
            </span>
          

          
            

            
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="fa fa-calendar-check-o"></i>
                </span>
                
                  <span class="post-meta-item-text">更新于</span>
                
                <time title="修改时间：2019-07-03 23:17:56" itemprop="dateModified" datetime="2019-07-03T23:17:56+08:00">2019-07-03</time>
              </span>
            
          

          
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope="" itemtype="http://schema.org/Thing"><a href="/categories/Python/" itemprop="url" rel="index"><span itemprop="name">Python</span></a></span>

                
                
              
            </span>
          

          
            
            
              
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="fa fa-comment-o"></i>
                </span>
            
                <span class="post-meta-item-text">评论数：</span>
                <a href="/2018/03/17/编程语言学习/PYTHON/Numpy/#comments" itemprop="discussionUrl">
                  <span class="post-comments-count disqus-comment-count" data-disqus-identifier="2018/03/17/编程语言学习/PYTHON/Numpy/" itemprop="commentCount"></span>
                </a>
              </span>
            
          

          
          

          

          <br>
          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1 id="创建数据"><a href="#创建数据" class="headerlink" title="创建数据"></a>创建数据</h1><h2 id="创建ndarray"><a href="#创建ndarray" class="headerlink" title="创建ndarray"></a>创建ndarray</h2><p>NumPy的数组类被称作ndarray。通常被称作数组。</p>
<p>Numpy库中的矩阵模块为ndarray对象，有很多属性：T，data, dtype,flags,flat,imag,real,size,</p>
<p>itemsize,nbytes,ndim,shape,strides,ctypes,base等等。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">import numpy as np</span><br><span class="line">vector = np.array([10,20,30])</span><br><span class="line">matrix=np.array([[1,2,3],[4,5,6],[7,8,9]])</span><br><span class="line"></span><br><span class="line"># 创建10个float32的一维数组</span><br><span class="line">np.random.rand(10).astype(np.float32)</span><br><span class="line"># 这样就是10*2的二维数组</span><br><span class="line">np.random.rand(10,2).astype(np.float32)</span><br></pre></td></tr></table></figure>
<h3 id="随机array"><a href="#随机array" class="headerlink" title="随机array"></a>随机array</h3><p><code>np.random.randn</code>可以返回一个随机数组</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">np.random.randn(1,2)</span><br><span class="line">Out[11]: array([[-2.67809797,  1.49728361]])</span><br><span class="line"></span><br><span class="line"># 在0-5之间生成随机数</span><br><span class="line">np.random.rand(2,3)*5</span><br><span class="line"># 或者</span><br><span class="line">np.dot(5,np.random.rand(2,3))</span><br><span class="line"># 指定生成随机数的范围</span><br><span class="line">np.random.randint(0, 20, size=[2,3])</span><br></pre></td></tr></table></figure>
<ul>
<li>np.random.rand  随机样本位于[0,1)中</li>
<li>np.random.randn 从标准正态分布$N=(\mu , \sigma ^2)$中返回样本，默认的范围是$N(0,1)$，等价于np.random.standard_normal</li>
</ul>
<blockquote>
<p>如果要返回2*4的$N(3,6.25)$的随机分布，可知均值是3，标准差是2.5，则</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">&gt; 3+2.5*np.random.randn(2,4)</span><br><span class="line">&gt;</span><br></pre></td></tr></table></figure>
</blockquote>
<h3 id="指定随机数类型"><a href="#指定随机数类型" class="headerlink" title="指定随机数类型"></a>指定随机数类型</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">x_data = np.random.rand(100).astype(np.float32)</span><br></pre></td></tr></table></figure>
<h3 id="创建空的array"><a href="#创建空的array" class="headerlink" title="创建空的array"></a>创建空的array</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">np.zeros((5,1))</span><br></pre></td></tr></table></figure>
<p>注意有两层括号，因为参数是一个shape</p>
<h3 id="随机数的seed"><a href="#随机数的seed" class="headerlink" title="随机数的seed"></a>随机数的seed</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">numpy.random.seed()</span><br></pre></td></tr></table></figure>
<p>seed( ) 用于指定随机数生成时所用算法开始的整数值，如果使用相同的seed( )值，则每次生成的随即数都相同，如果不设置这个值，则系统根据时间来自己选择这个值，此时每次生成的随机数因时间差异而不同。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">from numpy import *</span><br><span class="line">num=0</span><br><span class="line">while(num&lt;5):</span><br><span class="line">    random.seed(5)</span><br><span class="line">    print(random.random())</span><br><span class="line">    num+=1</span><br></pre></td></tr></table></figure>
<p>每次都一样</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">from numpy import *</span><br><span class="line">num=0</span><br><span class="line">random.seed(5)</span><br><span class="line">while(num&lt;5):</span><br><span class="line">    print(random.random())</span><br><span class="line">    num+=1</span><br></pre></td></tr></table></figure>
<p>每次不一样</p>
<p>也就是一次有效。</p>
<h3 id="创建等差数列"><a href="#创建等差数列" class="headerlink" title="创建等差数列"></a>创建等差数列</h3><p>创建等差数列，默认是创建50个，一般写成</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">x2 = np.linspace(1,10,10)</span><br></pre></td></tr></table></figure>
<h3 id="由函数创建"><a href="#由函数创建" class="headerlink" title="由函数创建"></a>由函数创建</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">&gt;&gt;&gt; def func (i):</span><br><span class="line"></span><br><span class="line">...        return  i%4+1</span><br><span class="line"></span><br><span class="line">&gt;&gt;&gt;  np. fromfunction(func, (10 ,))</span><br><span class="line"></span><br><span class="line">array([ 1., 2., 3., 4., 1., 2., 3., 4., 1., 2.])</span><br></pre></td></tr></table></figure>
<p>首先，定义一个func函数，模4加1。<br>然后，调用np对象的fromfunction内建函数，第一个参数是我们自定义的func,第二个参数（m,n），他处理的逻辑是这个样的：第一行第一列取（0，0）带入func函数，第一行第二列取（0，1）带入func函数，第一行第三列取（0，2）带入func函数……循环往复，直到取到值（0,n-1）带入函数以后，开始取第二行。。因为我们定义的函数只有一个参数，所以m从0取到9即可。最后返回数列：array([ 1., 2., 3., 4., 1., 2., 3., 4., 1., 2.]) 。</p>
<h3 id="读取csv转为numpy"><a href="#读取csv转为numpy" class="headerlink" title="读取csv转为numpy"></a>读取csv转为numpy</h3><p>假设第一行是描述，第二行起是数据；第一列是标签，后面是特征项</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">import numpy as np</span><br><span class="line"></span><br><span class="line">data = np.loadtxt(open(&apos;sample.csv&apos;,&apos;rb&apos;), delimiter=&apos;,&apos;, skiprows=1)</span><br><span class="line">y_train = data[:,0]</span><br><span class="line">x_train = data[:,1:-1]</span><br></pre></td></tr></table></figure>
<p><code>np.random.randn</code>可以返回一个随机数组</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">np.random.randn(1,2)</span><br><span class="line"></span><br><span class="line">Out[11]: array([[-2.67809797,  1.49728361]])</span><br></pre></td></tr></table></figure>
<ul>
<li>np.random.rand  随机样本位于[0,1)中</li>
<li>np.random.randn 从标准正态分布$N=(\mu , \sigma ^2)$中返回样本，默认的范围是$N(0,1)$，等价于np.random.standard_normal</li>
</ul>
<blockquote>
<p>如果要返回2*4的$N(3,6.25)$的随机分布，可知均值是3，标准差是2.5，则</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">&gt; 3+2.5*np.random.randn(2,4)</span><br><span class="line">&gt;</span><br></pre></td></tr></table></figure>
</blockquote>
<p>如果在matlib模块中使用，则返回的是matrix而不是array</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy.matlib</span><br><span class="line">np.matlib.randn(<span class="number">1</span>,<span class="number">2</span>)</span><br><span class="line"></span><br><span class="line">Out[<span class="number">13</span>]: matrix([[ <span class="number">0.13107513</span>, <span class="number">-0.87977247</span>]])</span><br></pre></td></tr></table></figure>
<h1 id="矩阵变换"><a href="#矩阵变换" class="headerlink" title="矩阵变换"></a>矩阵变换</h1><h2 id="shape"><a href="#shape" class="headerlink" title="shape"></a>shape</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">vector_shape = vector.shape</span><br><span class="line">matrix_shape = matrix.shape</span><br></pre></td></tr></table></figure>
<p>(3,)</p>
<p>(3, 3)</p>
<h2 id="reshape"><a href="#reshape" class="headerlink" title="reshape"></a>reshape</h2><p>生成新矩阵</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>xdata</span><br><span class="line">array([<span class="number">2</span>, <span class="number">4</span>, <span class="number">0</span>, <span class="number">3</span>, <span class="number">5</span>, <span class="number">2</span>, <span class="number">6</span>, <span class="number">0</span>, <span class="number">1</span>, <span class="number">8</span>])</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>len(xdata)</span><br><span class="line"><span class="number">10</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>xdata.reshape(<span class="number">5</span>,<span class="number">-1</span>)</span><br><span class="line">array([[<span class="number">2</span>, <span class="number">4</span>],</span><br><span class="line">       [<span class="number">0</span>, <span class="number">3</span>],</span><br><span class="line">       [<span class="number">5</span>, <span class="number">2</span>],</span><br><span class="line">       [<span class="number">6</span>, <span class="number">0</span>],</span><br><span class="line">       [<span class="number">1</span>, <span class="number">8</span>]])</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>xdata.reshape(<span class="number">5</span>,<span class="number">2</span>)</span><br><span class="line">array([[<span class="number">2</span>, <span class="number">4</span>],</span><br><span class="line">       [<span class="number">0</span>, <span class="number">3</span>],</span><br><span class="line">       [<span class="number">5</span>, <span class="number">2</span>],</span><br><span class="line">       [<span class="number">6</span>, <span class="number">0</span>],</span><br><span class="line">       [<span class="number">1</span>, <span class="number">8</span>]])</span><br></pre></td></tr></table></figure>
<p>指定了第一维后，第二维可以不指定，写为-1</p>
<h3 id="flatten"><a href="#flatten" class="headerlink" title="flatten"></a>flatten</h3><p>把(a,b,c,d)的X reshape为<code>(b*c*d, a)</code></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">X_flatten = X.reshape(-1, X.shape[0])</span><br></pre></td></tr></table></figure>
<h3 id="获得x的转置"><a href="#获得x的转置" class="headerlink" title="获得x的转置"></a>获得x的转置</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">print(x.T)</span><br></pre></td></tr></table></figure>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">[[1 4 7]</span><br><span class="line"> [2 5 8]</span><br><span class="line"> [3 6 9]]</span><br></pre></td></tr></table></figure>
<p>返回数组内部的信息</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">print(x.flags)</span><br></pre></td></tr></table></figure>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">C_CONTIGUOUS : True</span><br><span class="line">F_CONTIGUOUS : False</span><br><span class="line">OWNDATA : True</span><br><span class="line">WRITEABLE : True</span><br><span class="line">ALIGNED : True</span><br><span class="line">UPDATEIFCOPY : False</span><br></pre></td></tr></table></figure>
<p>将数组变为1维数组，并获取其中的一部分数据</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">print(x.flat[2:6])</span><br></pre></td></tr></table></figure>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[3 4 5 6]</span><br></pre></td></tr></table></figure>
<p>将值赋给1维数组，再转化成有原有数组的大小形式</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">x.flat=4;x</span><br><span class="line">print(x)</span><br></pre></td></tr></table></figure>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">[[4 4 4]</span><br><span class="line"> [4 4 4]</span><br><span class="line"> [4 4 4]]</span><br></pre></td></tr></table></figure>
<p>轴的个数（秩）</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">print(x.ndim)</span><br></pre></td></tr></table></figure>
<p>2</p>
<p>数组的维度，翻坠一个整数构成的元组。元组的长度就是秩</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">print(x.shape)</span><br></pre></td></tr></table></figure>
<p>(3,3)</p>
<p>可以取任意维的shape</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"># 取到第二维</span><br><span class="line">print(x.shape[:2])</span><br></pre></td></tr></table></figure>
<p>数组元素的总数</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">print(x.size)</span><br></pre></td></tr></table></figure>
<p>9</p>
<h1 id="axis理解"><a href="#axis理解" class="headerlink" title="axis理解"></a>axis理解</h1><p>NumPy数组的维数称为轴（axes），轴的个数叫秩（rank），一维数组的秩为1，二维数组的秩为2。</p>
<p><a href="https://www.jianshu.com/p/9aa448ea397c" target="_blank" rel="noopener">Stackoverflow系列(1) -Python Pandas与Numpy中axis参数的二义性</a></p>
<h1 id="取数组元素"><a href="#取数组元素" class="headerlink" title="取数组元素"></a>取数组元素</h1><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">x = np.array([2,  4,  0,  3,  5])</span><br><span class="line"># 不包括倒数第一个</span><br><span class="line">x[:-1]</span><br></pre></td></tr></table></figure>
<p>[2,4,0,3]</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">x=np.array([[1,2,3],[4,5,6],[7,8,9]])</span><br><span class="line"># 二维数组，逗号前后表示要取的行和列，:就是全部取，0:2就是取第0列和第1列，不包括第2列</span><br><span class="line">print(x[:,0:2])</span><br></pre></td></tr></table></figure>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">[[1 2]</span><br><span class="line"> [4 5]</span><br><span class="line"> [7 8]]</span><br></pre></td></tr></table></figure>
<p>如果只取一列，下面这种形式就会变成一个一位数组，要加上一个[]，才可以维持原有的二维数组的形式。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">print(x[:,-1])</span><br></pre></td></tr></table></figure>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[3 6 9]</span><br></pre></td></tr></table></figure>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">print(x[:,[-1]])</span><br></pre></td></tr></table></figure>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">[[3]</span><br><span class="line"> [6]</span><br><span class="line"> [9]]</span><br></pre></td></tr></table></figure>
<h1 id="排序"><a href="#排序" class="headerlink" title="排序"></a>排序</h1><p><a href="http://blog.csdn.net/pipisorry/article/details/51822775" target="_blank" rel="noopener">numpy教程：排序、搜索和计数</a></p>
<p>默认是升序排序。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">list1 = [[<span class="number">1</span>,<span class="number">3</span>,<span class="number">2</span>], [<span class="number">3</span>,<span class="number">5</span>,<span class="number">4</span>]]</span><br><span class="line">array = numpy.array(list1)</span><br><span class="line">array = sort(array, axis=<span class="number">1</span>)   <span class="comment">#对第1维升序排序</span></span><br><span class="line"><span class="comment">#array = sort(array, axis=0)   #对第0维</span></span><br><span class="line">print(array)</span><br><span class="line">[[<span class="number">1</span> <span class="number">2</span> <span class="number">3</span>]</span><br><span class="line"> [<span class="number">3</span> <span class="number">4</span> <span class="number">5</span>]]</span><br></pre></td></tr></table></figure>
<p>降序排序的实现:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">array = -sort(-array, axis=<span class="number">1</span>)   <span class="comment">#降序</span></span><br><span class="line">[[<span class="number">3</span> <span class="number">2</span> <span class="number">1</span>]</span><br><span class="line"> [<span class="number">5</span> <span class="number">4</span> <span class="number">3</span>]]</span><br></pre></td></tr></table></figure>
<p>参考</p>
<p>【1】<a href="http://blog.csdn.net/qq403977698/article/details/47254597" target="_blank" rel="noopener">numpy中的ndarray方法和属性</a></p>
<h1 id="运算、索引、切片"><a href="#运算、索引、切片" class="headerlink" title="运算、索引、切片"></a>运算、索引、切片</h1><p><a href="http://blog.csdn.net/liangzuojiayi/article/details/51534164" target="_blank" rel="noopener">http://blog.csdn.net/liangzuojiayi/article/details/51534164</a></p>
<h1 id="矩阵的各类乘法"><a href="#矩阵的各类乘法" class="headerlink" title="矩阵的各类乘法"></a>矩阵的各类乘法</h1><h2 id="dot-product点积"><a href="#dot-product点积" class="headerlink" title="dot product点积"></a>dot product点积</h2><script type="math/tex; mode=display">
a \cdot b = a_1b_1+a_2b_2...a_nb_n</script><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">x1 = [<span class="number">9</span>, <span class="number">2</span>, <span class="number">5</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">7</span>, <span class="number">5</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">9</span>, <span class="number">2</span>, <span class="number">5</span>, <span class="number">0</span>, <span class="number">0</span>]</span><br><span class="line">x2 = [<span class="number">9</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">9</span>, <span class="number">0</span>, <span class="number">9</span>, <span class="number">2</span>, <span class="number">5</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">9</span>, <span class="number">2</span>, <span class="number">5</span>, <span class="number">0</span>, <span class="number">0</span>]</span><br><span class="line"><span class="comment">### VECTORIZED DOT PRODUCT OF VECTORS ###</span></span><br><span class="line">tic = time.process_time()</span><br><span class="line">dot = np.dot(x1,x2)</span><br><span class="line">toc = time.process_time()</span><br><span class="line"><span class="keyword">print</span> (<span class="string">"dot = "</span> + str(dot) + <span class="string">"\n ----- Computation time = "</span> + str(<span class="number">1000</span>*(toc - tic)) + <span class="string">"ms"</span>)</span><br></pre></td></tr></table></figure>
<p>只有两个值是普通数组的时候才可以是点积，如果是np.array，则dot会变成矩阵乘法。也就是</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">x1 = np.array([[1,2,3]])</span><br><span class="line">x2 = np.array([[1,2,3]])</span><br><span class="line">np.dot(x1,x2)</span><br></pre></td></tr></table></figure>
<p>会报错</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ValueError: shapes (1,3) and (1,3) not aligned: 3 (dim 1) != 1 (dim 0)</span><br></pre></td></tr></table></figure>
<h2 id="outer-product外积"><a href="#outer-product外积" class="headerlink" title="outer product外积"></a>outer product外积</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">x1 = [<span class="number">9</span>, <span class="number">2</span>, <span class="number">5</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">7</span>, <span class="number">5</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">9</span>, <span class="number">2</span>, <span class="number">5</span>, <span class="number">0</span>, <span class="number">0</span>]</span><br><span class="line">x2 = [<span class="number">9</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">9</span>, <span class="number">0</span>, <span class="number">9</span>, <span class="number">2</span>, <span class="number">5</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">9</span>, <span class="number">2</span>, <span class="number">5</span>, <span class="number">0</span>, <span class="number">0</span>]</span><br><span class="line"><span class="comment">### VECTORIZED OUTER PRODUCT ###</span></span><br><span class="line">outer = np.outer(x1,x2)</span><br></pre></td></tr></table></figure>
<h2 id="element-wise-multipulation按位乘"><a href="#element-wise-multipulation按位乘" class="headerlink" title="element-wise multipulation按位乘"></a>element-wise multipulation按位乘</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">mul = np.multiply(x1,x2)</span><br></pre></td></tr></table></figure>
<h2 id="general-dot-product矩阵乘法"><a href="#general-dot-product矩阵乘法" class="headerlink" title="general dot product矩阵乘法"></a>general dot product矩阵乘法</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">W = np.random.rand(3,len(x1))</span><br><span class="line">dot = np.dot(W,x1)</span><br></pre></td></tr></table></figure>
<p>可以看出dot既可以用作点积，也可以执行矩阵乘法</p>
<h1 id="Broadcasting"><a href="#Broadcasting" class="headerlink" title="Broadcasting"></a>Broadcasting</h1><p>广播用以描述numpy中对两个形状不同的阵列进行数学计算的处理机制。较小的阵列“广播”到较大阵列相同的形状尺度上，使它们对等以可以进行数学计算。广播提供了一种向量化阵列的操作方式，因此Python不需要像C一样循环。广播操作不需要数据复制，通常执行效率非常高。然而，有时广播是个坏主意，可能会导致内存浪费以致计算减慢。</p>
<p>Numpy操作通常由成对的阵列完成，阵列间逐个元素对元素地执行。最简单的情形是两个阵列有一样的形状，例如：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">&gt;&gt;&gt; a = np.array([1.0, 2.0, 3.0])</span><br><span class="line">&gt;&gt;&gt; b = np.array([2.0, 2.0, 2.0])</span><br><span class="line">&gt;&gt;&gt; a * b</span><br><span class="line">array([ 2.,  4.,  6.])</span><br></pre></td></tr></table></figure>
<p>Numpy的广播机制放宽了对阵列形状的限制。最简单的情形是一个阵列和一个尺度值相乘：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">&gt;&gt;&gt; a = np.array([1.0, 2.0, 3.0])</span><br><span class="line">&gt;&gt;&gt; b = 2.0</span><br><span class="line">&gt;&gt;&gt; a * b</span><br><span class="line">array([ 2.,  4.,  6.])</span><br></pre></td></tr></table></figure>
<p>上面两种结果是一样的，我们可以认为尺度值b在计算时被延展得和a一样的形状。延展后的b的每一个元素都是原来尺度值的复制。延展的类比只是一种概念性的。实际上，Numpy并不需要真的复制这些尺度值，所以广播运算在内存和计算效率上尽量高效。</p>
<p>上面的第二个例子比第一个更高效，因为广播在乘法计算时动用更少的内存。</p>
<h2 id="exp"><a href="#exp" class="headerlink" title="exp"></a>exp</h2><p>broadcast运算</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">x = np.array([<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>])</span><br><span class="line">np.exp(x)</span><br></pre></td></tr></table></figure>
<h2 id="sum"><a href="#sum" class="headerlink" title="sum"></a>sum</h2><p>broadcast运算。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">softmax</span><span class="params">(x)</span>:</span></span><br><span class="line">	x_exp = np.exp(x)</span><br><span class="line">	x_sum = np.sum(x_exp, axis=<span class="number">1</span>, keepdims=<span class="keyword">True</span>)</span><br><span class="line">	s = x_exp/x_sum</span><br></pre></td></tr></table></figure>
<h1 id="matrix"><a href="#matrix" class="headerlink" title="matrix"></a>matrix</h1><h2 id="array转matrix"><a href="#array转matrix" class="headerlink" title="array转matrix"></a>array转matrix</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">s = np.array([5,5,0,0,0,5])</span><br><span class="line">np.matrix(s)</span><br></pre></td></tr></table></figure>
<h1 id="加载数据"><a href="#加载数据" class="headerlink" title="加载数据"></a>加载数据</h1><h2 id="loadtxt"><a href="#loadtxt" class="headerlink" title="loadtxt"></a>loadtxt</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">numpy.loadtxt(fname, dtype=&lt;type &apos;float&apos;&gt;, comments=&apos;#&apos;, delimiter=None, converters=None, skiprows=0, usecols=None, unpack=False, ndmin=0)[source]</span><br></pre></td></tr></table></figure>
<p>参数</p>
<p><strong>fname</strong> : file, str, or pathlib.Path</p>
<blockquote>
<p>File, filename, or generator to read. If the filename extension is <code>.gz</code> or <code>.bz2</code>, the file is first decompressed. Note that generators should return byte strings for Python 3k.</p>
</blockquote>
<p><strong>dtype</strong> : data-type, optional</p>
<blockquote>
<p>Data-type of the resulting array; default: float. If this is a structured data-type, the resulting array will be 1-dimensional, and each row will be interpreted as an element of the array. In this case, the number of columns used must match the number of fields in the data-type.</p>
</blockquote>
<p><strong>comments</strong> : str or sequence, optional</p>
<blockquote>
<p>The characters or list of characters used to indicate the start of a comment; default: ‘#’.</p>
</blockquote>
<p><strong>delimiter</strong> : str, optional</p>
<blockquote>
<p>The string used to separate values. By default, this is any whitespace.</p>
</blockquote>
<p><strong>converters</strong> : dict, optional</p>
<blockquote>
<p>A dictionary mapping column number to a function that will convert that column to a float. E.g., if column 0 is a date string: <code>converters = {0: datestr2num}</code>. Converters can also be used to provide a default value for missing data (but see also <a href="https://docs.scipy.org/doc/numpy/reference/generated/numpy.genfromtxt.html#numpy.genfromtxt" target="_blank" rel="noopener"><code>genfromtxt</code></a>):<code>converters = {3: lambda s: float(s.strip() or 0)}</code>. Default: None.</p>
</blockquote>
<p><strong>skiprows</strong> : int, optional</p>
<blockquote>
<p>Skip the first <em>skiprows</em> lines; default: 0.</p>
</blockquote>
<p><strong>usecols</strong> : int or sequence, optional</p>
<blockquote>
<p>Which columns to read, with 0 being the first. For example, usecols = (1,4,5) will extract the 2nd, 5th and 6th columns. The default, None, results in all columns being read.</p>
<p>New in version 1.11.0.</p>
<p>Also when a single column has to be read it is possible to use an integer instead of a tuple. E.g <code>usecols = 3</code> reads the fourth column the same way as <em>usecols = (3,)`</em> would.</p>
</blockquote>
<p><strong>unpack</strong> : bool, optional</p>
<blockquote>
<p>If True, the returned array is transposed, so that arguments may be unpacked using <code>x, y, z = loadtxt(...)</code>. When used with a structured data-type, arrays are returned for each field. Default is False.</p>
</blockquote>
<p><strong>ndmin</strong> : int, optional</p>
<blockquote>
<p>The returned array will have at least <em>ndmin</em> dimensions. Otherwise mono-dimensional axes will be squeezed. Legal values: 0 (default), 1 or 2.</p>
<p>New in version 1.6.0.</p>
</blockquote>
<p>返回</p>
<p><strong>out</strong> : ndarray</p>
<blockquote>
<p>Data read from the text file.</p>
</blockquote>
<h2 id="genfromtxt"><a href="#genfromtxt" class="headerlink" title="genfromtxt"></a>genfromtxt</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">import numpy</span><br><span class="line">nfl = numpy.genfromtxt(&quot;data.csv&quot;, delimiter=&quot;,&quot;)</span><br></pre></td></tr></table></figure>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"># U75就是将每个值作为一个75 byte的unicode来读取</span><br><span class="line">world_alcohol = np.genfromtxt(&apos;world_alcohol.csv&apos;, dtype=&apos;U75&apos;, skip_header=1, delimiter=&apos;,&apos;)</span><br></pre></td></tr></table></figure>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">data = np.genfromtxt(&apos;/Users/david/david/code/00project/carthage/scripts/adult.data&apos;, delimiter=&apos;, &apos;, dtype=str)</span><br><span class="line"># 取第14列</span><br><span class="line">labels = data[:,14]</span><br><span class="line"># 取除了倒数第二列之外的所有列</span><br><span class="line">data = data[:,:-1]</span><br></pre></td></tr></table></figure>
<h1 id="matrix转数组"><a href="#matrix转数组" class="headerlink" title="matrix转数组"></a>matrix转数组</h1><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">np.argsort(y_score, kind=&quot;mergesort&quot;)[::-1]</span><br></pre></td></tr></table></figure>
<h1 id="随机数字的矩阵"><a href="#随机数字的矩阵" class="headerlink" title="随机数字的矩阵"></a>随机数字的矩阵</h1><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">import numpy as np</span><br><span class="line">numpy_matrix = np.random.randint(10, size=[5,2])</span><br><span class="line"></span><br><span class="line">‘’‘</span><br><span class="line">array([[1, 0],</span><br><span class="line">       [8, 4],</span><br><span class="line">       [0, 5],</span><br><span class="line">       [2, 9],</span><br><span class="line">       [9, 9]])</span><br><span class="line">’‘’</span><br></pre></td></tr></table></figure>
<h1 id="获取排序后数据位置的下标"><a href="#获取排序后数据位置的下标" class="headerlink" title="获取排序后数据位置的下标"></a>获取排序后数据位置的下标</h1><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">import numpy as np</span><br><span class="line">dd=np.mat([4,5,1]) </span><br><span class="line">dd1 = dd.argsort()</span><br><span class="line">print dd</span><br><span class="line">print dd1		#matrix([[2, 0, 1]], dtype=int64)</span><br></pre></td></tr></table></figure>
<h1 id="squeeze"><a href="#squeeze" class="headerlink" title="squeeze"></a>squeeze</h1><p>从数组的形状中删除单维条目，即把shape中为1的维度去掉</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">x = np.array([[[0], [1], [2]]])  </span><br><span class="line">np.squeeze(x)</span><br></pre></td></tr></table></figure>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">array([0, 1, 2])</span><br></pre></td></tr></table></figure>
<p>如果本来就是(1,1)的矩阵，则变成常数</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">cost = np.array([[1]])</span><br><span class="line">cost = np.squeeze(cost)</span><br></pre></td></tr></table></figure>
<p>得到1，cost的shape变成<code>()</code></p>
<h1 id="获取符合条件的行列集合"><a href="#获取符合条件的行列集合" class="headerlink" title="获取符合条件的行列集合"></a>获取符合条件的行列集合</h1><p>数据如</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">1,1,1,0,0,0</span><br><span class="line">0,1,1,1,1,0</span><br><span class="line">1,0,0,1,1,0</span><br><span class="line">0,0,0,1,1,0</span><br></pre></td></tr></table></figure>
<p>第一列作为y_train，后面矩阵作为x_train，需要获取y_train中为1的x_train的行</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">pos_rows = (y_train == 1)</span><br><span class="line">x_train[pos_rows,:]</span><br></pre></td></tr></table></figure>
<p>还有个例子</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">vector = numpy.array([5, 10, 15, 20])</span><br><span class="line">vector == 10</span><br></pre></td></tr></table></figure>
<p>[False, True, False, False]</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">matrix = numpy.array([</span><br><span class="line">                    [5, 10, 15], </span><br><span class="line">                    [20, 25, 30],</span><br><span class="line">                    [35, 40, 45]</span><br><span class="line">                 ])</span><br><span class="line">    matrix == 25</span><br></pre></td></tr></table></figure>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">[</span><br><span class="line">    [False, False, False], </span><br><span class="line">    [False, True,  False],</span><br><span class="line">    [False, False, False]</span><br><span class="line">]</span><br></pre></td></tr></table></figure>
<p>比如要找第二列中是25的那一行</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">matrix = np.array([</span><br><span class="line">                [5, 10, 15], </span><br><span class="line">                [20, 25, 30],</span><br><span class="line">                [35, 40, 45]</span><br><span class="line">             ])</span><br><span class="line">    second_column_25 = (matrix[:,1] == 25)</span><br><span class="line">    # 等同于print(matrix[second_column_25])</span><br><span class="line">    print(matrix[second_column_25, :])</span><br></pre></td></tr></table></figure>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">[</span><br><span class="line">    [20, 25, 30]</span><br><span class="line">]</span><br></pre></td></tr></table></figure>
<p>多个条件的比较</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">vector = numpy.array([5, 10, 15, 20])</span><br><span class="line">equal_to_ten_and_five = (vector == 10) &amp; (vector == 5)</span><br></pre></td></tr></table></figure>
<p><code>[False, False, False, False]</code></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">vector = numpy.array([5, 10, 15, 20])</span><br><span class="line">equal_to_ten_or_five = (vector == 10) | (vector == 5)</span><br></pre></td></tr></table></figure>
<p><code>[True, True, False, False]</code></p>
<p>也可以根据比较的结果改变值</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">vector = numpy.array([5, 10, 15, 20])</span><br><span class="line">equal_to_ten_or_five = (vector == 10) | (vector == 5)</span><br><span class="line">vector[equal_to_ten_or_five] = 50</span><br><span class="line">print(vector)</span><br></pre></td></tr></table></figure>
<p>true的都变成了50</p>
<p><code>[50, 50, 15, 20]</code></p>
<h1 id="判断条件并转成0和1的输出"><a href="#判断条件并转成0和1的输出" class="headerlink" title="判断条件并转成0和1的输出"></a>判断条件并转成0和1的输出</h1><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"># x是numpy的数组，如</span><br><span class="line"># x = np.array([-1.0, 1.0, 2.0])</span><br><span class="line">def step_function(x):</span><br><span class="line">    return np.array(x &gt; 0, dtype=np.int)</span><br><span class="line">    </span><br><span class="line"># 或者</span><br><span class="line">def step_function(x):</span><br><span class="line">	y = x &gt; 0</span><br><span class="line">	# astype把bool转成int</span><br><span class="line">	return y.astype(np.int)</span><br></pre></td></tr></table></figure>

          
        
      
    </div>

    

    
    
    

    

    
      
    
    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  

  <article class="post post-type-normal" itemscope="" itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="https://schwimmer.github.io/2018/03/17/算法与数据结构/数学问题综合/">

    <span hidden itemprop="author" itemscope="" itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Schwimmer">
      <meta itemprop="description" content="Record and Think!">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope="" itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Schwimmer's Blog">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                
                <a href="/2018/03/17/算法与数据结构/数学问题综合/" class="post-title-link" itemprop="url">数学问题综合</a>
              
            
          </h1>
        

        <div class="post-meta">

          
          
          

          
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              

              
                
              

              <time title="创建时间：2018-03-17 20:50:31" itemprop="dateCreated datePublished" datetime="2018-03-17T20:50:31+08:00">2018-03-17</time>
            </span>
          

          

          
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope="" itemtype="http://schema.org/Thing"><a href="/categories/算法与数据结构/" itemprop="url" rel="index"><span itemprop="name">算法与数据结构</span></a></span>

                
                
              
            </span>
          

          
            
            
              
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="fa fa-comment-o"></i>
                </span>
            
                <span class="post-meta-item-text">评论数：</span>
                <a href="/2018/03/17/算法与数据结构/数学问题综合/#comments" itemprop="discussionUrl">
                  <span class="post-comments-count disqus-comment-count" data-disqus-identifier="2018/03/17/算法与数据结构/数学问题综合/" itemprop="commentCount"></span>
                </a>
              </span>
            
          

          
          

          

          <br>
          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1 id="从1-200中任意选出101个自然数-其中一个数必是另一个数的整数倍"><a href="#从1-200中任意选出101个自然数-其中一个数必是另一个数的整数倍" class="headerlink" title="从1-200中任意选出101个自然数,其中一个数必是另一个数的整数倍"></a>从1-200中任意选出101个自然数,其中一个数必是另一个数的整数倍</h1><p>把这200个数分类如下：</p>
<p><img src="https://s10.sinaimg.cn/mw690/001qZCIpzy7d4N8k2xP79&amp;690" alt=""></p>
<p>以上共分为100类，即100个抽屉。显然在同一类中的数若不少于两个，那么这类中的任意两个数都有倍数关系。从中任取101个数，根据抽屉原理，一定至少有两个数取自同一类，因此其中一个数是另一个数的倍数。</p>

          
        
      
    </div>

    

    
    
    

    

    
      
    
    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  

  <article class="post post-type-normal" itemscope="" itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="https://schwimmer.github.io/2018/03/17/算法与数据结构/硬币问题/">

    <span hidden itemprop="author" itemscope="" itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Schwimmer">
      <meta itemprop="description" content="Record and Think!">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope="" itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Schwimmer's Blog">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                
                <a href="/2018/03/17/算法与数据结构/硬币问题/" class="post-title-link" itemprop="url">硬币问题</a>
              
            
          </h1>
        

        <div class="post-meta">

          
          
          

          
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              

              
                
              

              <time title="创建时间：2018-03-17 20:50:31" itemprop="dateCreated datePublished" datetime="2018-03-17T20:50:31+08:00">2018-03-17</time>
            </span>
          

          

          
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope="" itemtype="http://schema.org/Thing"><a href="/categories/算法与数据结构/" itemprop="url" rel="index"><span itemprop="name">算法与数据结构</span></a></span>

                
                
              
            </span>
          

          
            
            
              
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="fa fa-comment-o"></i>
                </span>
            
                <span class="post-meta-item-text">评论数：</span>
                <a href="/2018/03/17/算法与数据结构/硬币问题/#comments" itemprop="discussionUrl">
                  <span class="post-comments-count disqus-comment-count" data-disqus-identifier="2018/03/17/算法与数据结构/硬币问题/" itemprop="commentCount"></span>
                </a>
              </span>
            
          

          
          

          

          <br>
          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>转自 <a href="http://www.cnblogs.com/z941030/p/4908115.html" target="_blank" rel="noopener">动态规划之硬币组合问题</a></p>
<p>动态规划的本质是将原问题分解为同性质的若干相同子结构，在求解最优值的过程中将子结构的最优值记录到一个表中以避免有时会有大量的重复计算。</p>
<p>例如硬币组合问题，若求凑够11元的最少硬币数，可以先从凑够0元、1元、2元……的子结构开始分析。</p>
<p>假设d(i)为凑够i元所需最少硬币数，则</p>
<p>d(0) = 0 　　　　　　　　理所当然</p>
<p>d(1) = 1 　　　　　　　　要凑够1元，需要从面值小于等于1元的硬币中选择，目前只有面值为1元的硬币</p>
<p>　　　　　　　　　　　　此时d(1) = d(0) + 1</p>
<p>d(2) = d(2 - 1) + 1 = 2， 从面值小于等于2元的硬币中选择，符合要求的硬币面值为：1元。</p>
<p>　　　　　　　　　　　　此时d(2) = d(2-1) + 1</p>
<p>d(3) = d(3 - 3) + 1 = 1， 从面值小于等于3元的硬币中选择，符合要求的硬币面值为：1元，3元。</p>
<p>　　　　　　　　　　　　此时有有两种选择：是否选择含有面值3元的硬币</p>
<p>　　　　　　　　　　　　含有3元硬币：d(3) = d(3 - 3) + 1 = 1</p>
<p>　　　　　　　　　　　　不含3元硬币：d(3) = d(3 - 1) + 1 = d(2) + 1 = 3</p>
<p>　　　　　　　　　　　　自然是选择二者中较小值</p>
<p>依次类推…</p>
<p>就该问题总结一下，随着要凑够钱数的增加：</p>
<p>1、首先要知道所有不大于该钱数的面值;</p>
<p>2、对于每种面值的硬币，求出当选择一个该面值的硬币时所需的硬币数</p>
<p>当选择一个硬币后，所需硬币数+1，所要凑够的钱数=原所要凑的钱数-该硬币面值，所要凑够的钱数减少，求减少后要凑钱数最少所需硬币数，属于原问题的子结构，已求出解</p>
<p>3.在上述求出的结果集中，选择最小值，即为要凑够该钱数所需的最少硬币数</p>
<p>由此可以看出，每个问题的最优值都是借其子结构的最优值得到的。</p>
<p>而该算法的最小的子结构的最优解是已知的，即：当要凑钱数为0元时，最少需要0枚硬币。</p>
<p>利用这个最小的子结构，通过递推式便可求出所指定值凑够钱数的最优值</p>
<p>上面所提到的递推式，便是<strong>状态转移方程</strong>。利用已知状态，不断通过状态转移方程求解，便得到了最优值和最优解。</p>
<p>下面看一下硬币组合问题的数学描述：</p>
<p>d(i)=min{ d(i-vj)+1 }，其中i-vj &gt;=0，vj表示第j个硬币的面值，i表示要凑够i元，d(i)表示凑够i元最少需要的硬币数。即：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">                     　　　　0  　　　　 i == 0 时</span><br><span class="line">min_coin_num(i) = &#123;</span><br><span class="line">                  　　　　　min&#123; min_coin_num( i-coin_value(j) )+1 | i-coin_value(j)&gt;0&#125; coin_value(j)表示第j种硬币的面值 　　i &gt; 0 时</span><br></pre></td></tr></table></figure>
<p>当总值total_value为i时， 对于所有的 coin_value(j) &lt; i的硬币j ,取min{ min_coin_num(i-coin_value(j)) }</p>
<p>代码在 <code>dynamic_programming/coin.py</code></p>

          
        
      
    </div>

    

    
    
    

    

    
      
    
    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  

  <article class="post post-type-normal" itemscope="" itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="https://schwimmer.github.io/2018/03/17/算法与数据结构/排序/">

    <span hidden itemprop="author" itemscope="" itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Schwimmer">
      <meta itemprop="description" content="Record and Think!">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope="" itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Schwimmer's Blog">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                
                <a href="/2018/03/17/算法与数据结构/排序/" class="post-title-link" itemprop="url">排序</a>
              
            
          </h1>
        

        <div class="post-meta">

          
          
          

          
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              

              
                
              

              <time title="创建时间：2018-03-17 20:50:31" itemprop="dateCreated datePublished" datetime="2018-03-17T20:50:31+08:00">2018-03-17</time>
            </span>
          

          

          
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope="" itemtype="http://schema.org/Thing"><a href="/categories/算法与数据结构/" itemprop="url" rel="index"><span itemprop="name">算法与数据结构</span></a></span>

                
                
              
            </span>
          

          
            
            
              
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="fa fa-comment-o"></i>
                </span>
            
                <span class="post-meta-item-text">评论数：</span>
                <a href="/2018/03/17/算法与数据结构/排序/#comments" itemprop="discussionUrl">
                  <span class="post-comments-count disqus-comment-count" data-disqus-identifier="2018/03/17/算法与数据结构/排序/" itemprop="commentCount"></span>
                </a>
              </span>
            
          

          
          

          

          <br>
          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>堆排序</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#!/usr/bin/env python2</span></span><br><span class="line"><span class="comment"># -*- coding: utf-8 -*-</span></span><br><span class="line"><span class="string">"""</span></span><br><span class="line"><span class="string">Created on Tue Mar 13 09:46:42 2018</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">@author: david</span></span><br><span class="line"><span class="string">"""</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">sift_down</span><span class="params">(array, start, end)</span>:</span></span><br><span class="line">    <span class="string">"""</span></span><br><span class="line"><span class="string">    调整成大顶堆，初始堆时，从下往上；交换堆顶与堆尾后，从上往下调整</span></span><br><span class="line"><span class="string">    :param array: 列表的引用</span></span><br><span class="line"><span class="string">    :param start: 父结点</span></span><br><span class="line"><span class="string">    :param end: 结束的下标</span></span><br><span class="line"><span class="string">    :return: 无</span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line">    <span class="keyword">while</span> <span class="keyword">True</span>:</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 当列表第一个是以下标0开始，结点下标为i,左孩子则为2*i+1,右孩子下标则为2*i+2;</span></span><br><span class="line">        <span class="comment"># 若下标以1开始，左孩子则为2*i,右孩子则为2*i+１</span></span><br><span class="line">        left_child = <span class="number">2</span>*start + <span class="number">1</span>  <span class="comment"># 左孩子的结点下标</span></span><br><span class="line">        <span class="comment"># 当结点的右孩子存在，且大于结点的左孩子时</span></span><br><span class="line">        <span class="keyword">if</span> left_child &gt; end:</span><br><span class="line">            <span class="keyword">break</span></span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> left_child+<span class="number">1</span> &lt;= end <span class="keyword">and</span> array[left_child+<span class="number">1</span>] &gt; array[left_child]:</span><br><span class="line">            left_child += <span class="number">1</span></span><br><span class="line">        <span class="keyword">if</span> array[left_child] &gt; array[start]:  <span class="comment"># 当左右孩子的最大值大于父结点时，则交换</span></span><br><span class="line">            array[left_child], array[start] = array[start], array[left_child]</span><br><span class="line"></span><br><span class="line">            start = left_child  <span class="comment"># 交换之后以交换子结点为根的堆可能不是大顶堆，需重新调整</span></span><br><span class="line">        <span class="keyword">else</span>:  <span class="comment"># 若父结点大于左右孩子，则退出循环</span></span><br><span class="line">            <span class="keyword">break</span></span><br><span class="line"></span><br><span class="line">        print(<span class="string">"&gt;&gt;"</span>, array)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">heap_sort</span><span class="params">(array)</span>:</span>  <span class="comment"># 堆排序</span></span><br><span class="line">    <span class="comment"># 先初始化大顶堆</span></span><br><span class="line">    first = len(array)//<span class="number">2</span> <span class="number">-1</span>  <span class="comment"># 最后一个有孩子的节点(//表示取整的意思)</span></span><br><span class="line">    <span class="comment"># 第一个结点的下标为０，很多博客&amp;课本教材是从下标1开始，无所谓吧，你随意</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(first, <span class="number">-1</span>, <span class="number">-1</span>):  <span class="comment"># 从最后一个有孩子的节点开始往上调整</span></span><br><span class="line">        print(array[i])</span><br><span class="line">        sift_down(array, i, len(array)<span class="number">-1</span>)  <span class="comment"># 初始化大顶堆</span></span><br><span class="line"></span><br><span class="line">    print(<span class="string">"初始化大顶堆结果:"</span>, array)</span><br><span class="line">    <span class="comment"># 交换堆顶与堆尾</span></span><br><span class="line">    <span class="keyword">for</span> head_end <span class="keyword">in</span> range(len(array)<span class="number">-1</span>, <span class="number">0</span>, <span class="number">-1</span>):  <span class="comment"># start stop step</span></span><br><span class="line">        array[head_end], array[<span class="number">0</span>] = array[<span class="number">0</span>], array[head_end] <span class="comment"># 交换堆顶与堆尾</span></span><br><span class="line">        sift_down(array, <span class="number">0</span>, head_end<span class="number">-1</span>)  <span class="comment"># 堆长度减一(head_end-1)，再从上往下调整成大顶堆</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">"__main__"</span>:</span><br><span class="line">    array = [<span class="number">16</span>, <span class="number">7</span>, <span class="number">3</span>, <span class="number">20</span>, <span class="number">17</span>, <span class="number">8</span>]</span><br><span class="line">    print(array)</span><br><span class="line">    heap_sort(array)</span><br><span class="line">    print(<span class="string">"堆排序最终结果:"</span>, array)</span><br></pre></td></tr></table></figure>

          
        
      
    </div>

    

    
    
    

    

    
      
    
    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  

  <article class="post post-type-normal" itemscope="" itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="https://schwimmer.github.io/2018/03/17/机器学习/逻辑回归/">

    <span hidden itemprop="author" itemscope="" itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Schwimmer">
      <meta itemprop="description" content="Record and Think!">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope="" itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Schwimmer's Blog">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                
                <a href="/2018/03/17/机器学习/逻辑回归/" class="post-title-link" itemprop="url">逻辑回归</a>
              
            
          </h1>
        

        <div class="post-meta">

          
          
          

          
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              

              
                
              

              <time title="创建时间：2018-03-17 20:50:31" itemprop="dateCreated datePublished" datetime="2018-03-17T20:50:31+08:00">2018-03-17</time>
            </span>
          

          
            

            
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="fa fa-calendar-check-o"></i>
                </span>
                
                  <span class="post-meta-item-text">更新于</span>
                
                <time title="修改时间：2019-07-06 14:33:39" itemprop="dateModified" datetime="2019-07-06T14:33:39+08:00">2019-07-06</time>
              </span>
            
          

          
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope="" itemtype="http://schema.org/Thing"><a href="/categories/机器学习/" itemprop="url" rel="index"><span itemprop="name">机器学习</span></a></span>

                
                
              
            </span>
          

          
            
            
              
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="fa fa-comment-o"></i>
                </span>
            
                <span class="post-meta-item-text">评论数：</span>
                <a href="/2018/03/17/机器学习/逻辑回归/#comments" itemprop="discussionUrl">
                  <span class="post-comments-count disqus-comment-count" data-disqus-identifier="2018/03/17/机器学习/逻辑回归/" itemprop="commentCount"></span>
                </a>
              </span>
            
          

          
          

          

          <br>
          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">'''</span></span><br><span class="line"><span class="string">Created on Oct 27, 2010</span></span><br><span class="line"><span class="string">Logistic Regression Working Module</span></span><br><span class="line"><span class="string">@author: Peter</span></span><br><span class="line"><span class="string">'''</span></span><br><span class="line"><span class="keyword">from</span> numpy <span class="keyword">import</span> *</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">loadDataSet</span><span class="params">()</span>:</span></span><br><span class="line">    dataMat = []; labelMat = []</span><br><span class="line">    fr = open(<span class="string">'testSet.txt'</span>)</span><br><span class="line">    <span class="keyword">for</span> line <span class="keyword">in</span> fr.readlines():</span><br><span class="line">        lineArr = line.strip().split()</span><br><span class="line">        dataMat.append([<span class="number">1.0</span>, float(lineArr[<span class="number">0</span>]), float(lineArr[<span class="number">1</span>])])</span><br><span class="line">        labelMat.append(int(lineArr[<span class="number">2</span>]))</span><br><span class="line">    <span class="keyword">return</span> dataMat,labelMat</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">sigmoid</span><span class="params">(inX)</span>:</span></span><br><span class="line">    <span class="keyword">return</span> <span class="number">1.0</span>/(<span class="number">1</span>+exp(-inX))</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">gradAscent</span><span class="params">(dataMatIn, classLabels)</span>:</span></span><br><span class="line">    dataMatrix = mat(dataMatIn)             <span class="comment">#convert to NumPy matrix</span></span><br><span class="line">    labelMat = mat(classLabels).transpose() <span class="comment">#convert to NumPy matrix</span></span><br><span class="line">    m,n = shape(dataMatrix)</span><br><span class="line">    alpha = <span class="number">0.001</span></span><br><span class="line">    maxCycles = <span class="number">500</span></span><br><span class="line">    weights = ones((n,<span class="number">1</span>))</span><br><span class="line">    <span class="keyword">for</span> k <span class="keyword">in</span> range(maxCycles):              <span class="comment">#heavy on matrix operations</span></span><br><span class="line">        h = sigmoid(dataMatrix*weights)     <span class="comment">#matrix mult</span></span><br><span class="line">        error = (labelMat - h)              <span class="comment">#vector subtraction</span></span><br><span class="line">        weights = weights + alpha * dataMatrix.transpose()* error <span class="comment">#matrix mult</span></span><br><span class="line">    <span class="keyword">return</span> weights</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">plotBestFit</span><span class="params">(weights)</span>:</span></span><br><span class="line">    <span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line">    dataMat,labelMat=loadDataSet()</span><br><span class="line">    dataArr = array(dataMat)</span><br><span class="line">    n = shape(dataArr)[<span class="number">0</span>] </span><br><span class="line">    xcord1 = []; ycord1 = []</span><br><span class="line">    xcord2 = []; ycord2 = []</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(n):</span><br><span class="line">        <span class="keyword">if</span> int(labelMat[i])== <span class="number">1</span>:</span><br><span class="line">            xcord1.append(dataArr[i,<span class="number">1</span>]); ycord1.append(dataArr[i,<span class="number">2</span>])</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            xcord2.append(dataArr[i,<span class="number">1</span>]); ycord2.append(dataArr[i,<span class="number">2</span>])</span><br><span class="line">    fig = plt.figure()</span><br><span class="line">    ax = fig.add_subplot(<span class="number">111</span>)</span><br><span class="line">    ax.scatter(xcord1, ycord1, s=<span class="number">30</span>, c=<span class="string">'red'</span>, marker=<span class="string">'s'</span>)</span><br><span class="line">    ax.scatter(xcord2, ycord2, s=<span class="number">30</span>, c=<span class="string">'green'</span>)</span><br><span class="line">    x = arange(<span class="number">-3.0</span>, <span class="number">3.0</span>, <span class="number">0.1</span>)</span><br><span class="line">    y = (-weights[<span class="number">0</span>]-weights[<span class="number">1</span>]*x)/weights[<span class="number">2</span>]</span><br><span class="line">    ax.plot(x, y)</span><br><span class="line">    plt.xlabel(<span class="string">'X1'</span>); plt.ylabel(<span class="string">'X2'</span>);</span><br><span class="line">    plt.show()</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">stocGradAscent0</span><span class="params">(dataMatrix, classLabels)</span>:</span></span><br><span class="line">    m,n = shape(dataMatrix)</span><br><span class="line">    alpha = <span class="number">0.01</span></span><br><span class="line">    weights = ones(n)   <span class="comment">#initialize to all ones</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(m):</span><br><span class="line">        h = sigmoid(sum(dataMatrix[i]*weights))</span><br><span class="line">        error = classLabels[i] - h</span><br><span class="line">        weights = weights + alpha * error * dataMatrix[i]</span><br><span class="line">    <span class="keyword">return</span> weights</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">stocGradAscent1</span><span class="params">(dataMatrix, classLabels, numIter=<span class="number">150</span>)</span>:</span></span><br><span class="line">    m,n = shape(dataMatrix)</span><br><span class="line">    weights = ones(n)   <span class="comment">#initialize to all ones</span></span><br><span class="line">    <span class="keyword">for</span> j <span class="keyword">in</span> range(numIter):</span><br><span class="line">        dataIndex = range(m)</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> range(m):</span><br><span class="line">            alpha = <span class="number">4</span>/(<span class="number">1.0</span>+j+i)+<span class="number">0.0001</span>    <span class="comment">#apha decreases with iteration, does not </span></span><br><span class="line">            randIndex = int(random.uniform(<span class="number">0</span>,len(dataIndex)))<span class="comment">#go to 0 because of the constant</span></span><br><span class="line">            h = sigmoid(sum(dataMatrix[randIndex]*weights))</span><br><span class="line">            error = classLabels[randIndex] - h</span><br><span class="line">            weights = weights + alpha * error * dataMatrix[randIndex]</span><br><span class="line">            <span class="keyword">del</span>(dataIndex[randIndex])</span><br><span class="line">    <span class="keyword">return</span> weights</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">classifyVector</span><span class="params">(inX, weights)</span>:</span></span><br><span class="line">    prob = sigmoid(sum(inX*weights))</span><br><span class="line">    <span class="keyword">if</span> prob &gt; <span class="number">0.5</span>: <span class="keyword">return</span> <span class="number">1.0</span></span><br><span class="line">    <span class="keyword">else</span>: <span class="keyword">return</span> <span class="number">0.0</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">colicTest</span><span class="params">()</span>:</span></span><br><span class="line">    frTrain = open(<span class="string">'horseColicTraining.txt'</span>); frTest = open(<span class="string">'horseColicTest.txt'</span>)</span><br><span class="line">    trainingSet = []; trainingLabels = []</span><br><span class="line">    <span class="keyword">for</span> line <span class="keyword">in</span> frTrain.readlines():</span><br><span class="line">        currLine = line.strip().split(<span class="string">'\t'</span>)</span><br><span class="line">        lineArr =[]</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">21</span>):</span><br><span class="line">            lineArr.append(float(currLine[i]))</span><br><span class="line">        trainingSet.append(lineArr)</span><br><span class="line">        trainingLabels.append(float(currLine[<span class="number">21</span>]))</span><br><span class="line">    trainWeights = stocGradAscent1(array(trainingSet), trainingLabels, <span class="number">1000</span>)</span><br><span class="line">    errorCount = <span class="number">0</span>; numTestVec = <span class="number">0.0</span></span><br><span class="line">    <span class="keyword">for</span> line <span class="keyword">in</span> frTest.readlines():</span><br><span class="line">        numTestVec += <span class="number">1.0</span></span><br><span class="line">        currLine = line.strip().split(<span class="string">'\t'</span>)</span><br><span class="line">        lineArr =[]</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">21</span>):</span><br><span class="line">            lineArr.append(float(currLine[i]))</span><br><span class="line">        <span class="keyword">if</span> int(classifyVector(array(lineArr), trainWeights))!= int(currLine[<span class="number">21</span>]):</span><br><span class="line">            errorCount += <span class="number">1</span></span><br><span class="line">    errorRate = (float(errorCount)/numTestVec)</span><br><span class="line">    <span class="keyword">print</span> <span class="string">"the error rate of this test is: %f"</span> % errorRate</span><br><span class="line">    <span class="keyword">return</span> errorRate</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">multiTest</span><span class="params">()</span>:</span></span><br><span class="line">    numTests = <span class="number">10</span>; errorSum=<span class="number">0.0</span></span><br><span class="line">    <span class="keyword">for</span> k <span class="keyword">in</span> range(numTests):</span><br><span class="line">        errorSum += colicTest()</span><br><span class="line">    <span class="keyword">print</span> <span class="string">"after %d iterations the average error rate is: %f"</span> % (numTests, errorSum/float(numTests))</span><br></pre></td></tr></table></figure>
<p><a href="http://blog.csdn.net/ljn113399/article/details/52725736" target="_blank" rel="noopener">逻辑回归详解</a></p>
<p>对随机梯度下降算法，我们做两处改进来避免上述的波动问题：</p>
<p>1）在每次迭代时，调整更新步长alpha的值。随着迭代的进行，alpha越来越小，这会缓解系数的高频波动（也就是每次迭代系数改变得太大，跳的跨度太大）。当然了，为了避免alpha随着迭代不断减小到接近于0（这时候，系数几乎没有调整，那么迭代也没有意义了），我们约束alpha一定大于一个稍微大点的常数项，具体见代码。</p>
<p>2）每次迭代，改变样本的优化顺序。也就是随机选择样本来更新回归系数。这样做可以减少周期性的波动，因为样本顺序的改变，使得每次迭代不再形成周期性。</p>
<h1 id="sklearn的LR"><a href="#sklearn的LR" class="headerlink" title="sklearn的LR"></a>sklearn的LR</h1><p><a href="http://www.cnblogs.com/pinard/p/6035872.html" target="_blank" rel="noopener">scikit-learn 逻辑回归类库使用小结</a></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># coding: utf-8</span></span><br><span class="line"><span class="comment"># pylint: disable = invalid-name, C0111</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">from</span> itertools <span class="keyword">import</span> cycle</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">from</span> sklearn <span class="keyword">import</span> svm, datasets</span><br><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> roc_curve, auc</span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> train_test_split</span><br><span class="line"><span class="keyword">from</span> sklearn.preprocessing <span class="keyword">import</span> label_binarize</span><br><span class="line"><span class="keyword">from</span> sklearn.multiclass <span class="keyword">import</span> OneVsRestClassifier</span><br><span class="line"><span class="keyword">from</span> scipy <span class="keyword">import</span> interp</span><br><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> confusion_matrix</span><br><span class="line"><span class="keyword">from</span> sklearn.preprocessing <span class="keyword">import</span> OneHotEncoder</span><br><span class="line"><span class="keyword">import</span> zipfile</span><br><span class="line"><span class="keyword">from</span> sklearn.linear_model <span class="keyword">import</span> LogisticRegression</span><br><span class="line"><span class="keyword">from</span> sklearn.externals <span class="keyword">import</span> joblib</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># with zipfile.ZipFile('df_allfeature_train1-7.csv.zip', 'r') as z:</span></span><br><span class="line"><span class="comment">#     f = z.open('df_allfeature_train1-7.csv')</span></span><br><span class="line"><span class="comment">#     df = pd.read_csv(f, header=0)</span></span><br><span class="line"></span><br><span class="line">df = pd.read_csv(<span class="string">'df_allfeature_train_lite.csv'</span>, header=<span class="number">0</span>)</span><br><span class="line"></span><br><span class="line">col_imp = [<span class="string">'product_code'</span>, <span class="string">'now_term_rate'</span>, <span class="string">'label'</span>]</span><br><span class="line">df = pd.DataFrame(df, columns=col_imp)</span><br><span class="line"></span><br><span class="line">y_train = df.label</span><br><span class="line">X_train = df.drop([<span class="string">'label'</span>], axis=<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">f</span><span class="params">(col)</span>:</span></span><br><span class="line">    y = abs(col) * <span class="number">100000</span></span><br><span class="line">    colDict = dict()</span><br><span class="line">    <span class="keyword">for</span> idx, val <span class="keyword">in</span> enumerate(set(y)):</span><br><span class="line">        colDict[int(val)] = int(idx)</span><br><span class="line">    print(colDict)</span><br><span class="line">    <span class="keyword">return</span> pd.Series([colDict[int(x)] <span class="keyword">for</span> x <span class="keyword">in</span> y])</span><br><span class="line"></span><br><span class="line"><span class="comment"># 每一列的WOE处理成int的编号</span></span><br><span class="line">X_train = X_train.apply(f, axis=<span class="number">0</span>)</span><br><span class="line">print(X_train)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 变成one-hot encoder</span></span><br><span class="line">enc = OneHotEncoder()</span><br><span class="line">enc.fit(X_train)</span><br><span class="line">print(enc.n_values_)</span><br><span class="line">print(enc.feature_indices_)</span><br><span class="line"></span><br><span class="line">X_train = pd.DataFrame(enc.fit_transform(X_train).todense())</span><br><span class="line">print(X_train.shape)</span><br><span class="line">print(X_train.head(<span class="number">2</span>))</span><br><span class="line"></span><br><span class="line">classifier = LogisticRegression()  <span class="comment"># 使用类，参数全是默认的</span></span><br><span class="line">classifier.fit(X_train, y_train)  <span class="comment"># 训练数据来学习，不需要返回值</span></span><br><span class="line">print(<span class="string">"Coefficients:%s, intercept %s"</span>%(classifier.coef_,classifier.intercept_))</span><br><span class="line"><span class="comment"># joblib.dump(classifier, 'lr.m')</span></span><br></pre></td></tr></table></figure>
<p><code>clf.coef_</code>就是权重矩阵，<code>classifier.intercept_</code>是偏置</p>
<h1 id="逻辑回归的结果解释"><a href="#逻辑回归的结果解释" class="headerlink" title="逻辑回归的结果解释"></a>逻辑回归的结果解释</h1><p><a href="https://www.jianshu.com/p/a72302fa03d7" target="_blank" rel="noopener">https://www.jianshu.com/p/a72302fa03d7</a></p>
<p><a href="https://blog.csdn.net/sjpljr/article/details/70169046" target="_blank" rel="noopener">https://blog.csdn.net/sjpljr/article/details/70169046</a></p>
<p><a href="https://wenku.baidu.com/view/953be54268eae009581b6bd97f1922791688be6c.html" target="_blank" rel="noopener">https://wenku.baidu.com/view/953be54268eae009581b6bd97f1922791688be6c.html</a></p>
<h1 id="原理讲解"><a href="#原理讲解" class="headerlink" title="原理讲解"></a>原理讲解</h1><p><a href="http://blog.sina.com.cn/s/blog_44befaf60102vznn.html" target="_blank" rel="noopener">http://blog.sina.com.cn/s/blog_44befaf60102vznn.html</a></p>
<p>Logistic回归虽然名字叫”回归” ，但却是一种分类学习方法。使用场景大概有两个：第一用来预测，第二寻找因变量的影响因素。 </p>
<p><strong>一 从线性回归到Logistic回归</strong></p>
<p>线性回归和Logistic回归都是广义线性模型的特例。</p>
<p>假设有一个因变量y和一组自变量x1, x2, x3, … , xn，其中y为连续变量，我们可以拟合一个线性方程：</p>
<p>y =β0 +β1<em>x1 +β2</em>x2 +β3<em>x3 +…+βn</em>xn</p>
<p>并通过最小二乘法估计各个β系数的值。</p>
<p>如果y为二分类变量，只能取值0或1，那么线性回归方程就会遇到困难: 方程右侧是一个连续的值，取值为负无穷到正无穷，而左侧只能取值[0,1]，无法对应。为了继续使用线性回归的思想，统计学家想到了一个变换方法，就是将方程右边的取值变换为[0,1]。最后选中了Logistic函数：</p>
<p>y = 1 / (1+e-x)</p>
<p>这是一个S型函数，值域为(0,1)，能将任何数值映射到(0,1)，且具有无限阶可导等优良数学性质。</p>
<h1 id="机器学习sklearn19-0——Logistic回归算法"><a href="#机器学习sklearn19-0——Logistic回归算法" class="headerlink" title="机器学习sklearn19.0——Logistic回归算法"></a>机器学习sklearn19.0——Logistic回归算法</h1><p><a href="https://blog.csdn.net/loveliuzz/article/details/78708359" target="_blank" rel="noopener">https://blog.csdn.net/loveliuzz/article/details/78708359</a></p>
<p>参数讲解全面</p>

          
        
      
    </div>

    

    
    
    

    

    
      
    
    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  

  <article class="post post-type-normal" itemscope="" itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="https://schwimmer.github.io/2018/03/17/机器学习/评价指标/">

    <span hidden itemprop="author" itemscope="" itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Schwimmer">
      <meta itemprop="description" content="Record and Think!">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope="" itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Schwimmer's Blog">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                
                <a href="/2018/03/17/机器学习/评价指标/" class="post-title-link" itemprop="url">评价指标</a>
              
            
          </h1>
        

        <div class="post-meta">

          
          
          

          
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              

              
                
              

              <time title="创建时间：2018-03-17 20:50:31" itemprop="dateCreated datePublished" datetime="2018-03-17T20:50:31+08:00">2018-03-17</time>
            </span>
          

          
            

            
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="fa fa-calendar-check-o"></i>
                </span>
                
                  <span class="post-meta-item-text">更新于</span>
                
                <time title="修改时间：2018-08-21 16:50:47" itemprop="dateModified" datetime="2018-08-21T16:50:47+08:00">2018-08-21</time>
              </span>
            
          

          
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope="" itemtype="http://schema.org/Thing"><a href="/categories/机器学习/" itemprop="url" rel="index"><span itemprop="name">机器学习</span></a></span>

                
                
              
            </span>
          

          
            
            
              
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="fa fa-comment-o"></i>
                </span>
            
                <span class="post-meta-item-text">评论数：</span>
                <a href="/2018/03/17/机器学习/评价指标/#comments" itemprop="discussionUrl">
                  <span class="post-comments-count disqus-comment-count" data-disqus-identifier="2018/03/17/机器学习/评价指标/" itemprop="commentCount"></span>
                </a>
              </span>
            
          

          
          

          

          <br>
          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1 id="准确率Accuracy"><a href="#准确率Accuracy" class="headerlink" title="准确率Accuracy"></a>准确率Accuracy</h1><p>分类器正确分类的样本数与总样本数之比。</p>
<h1 id="ROC-AUC"><a href="#ROC-AUC" class="headerlink" title="ROC AUC"></a>ROC AUC</h1><div class="table-container">
<table>
<thead>
<tr>
<th><strong> </strong></th>
<th><strong>相关(Relevant),正类</strong></th>
<th><strong>无关(NonRelevant),负类</strong></th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>被检索到(Retrieved)</strong></td>
<td>true positives(TP 正类判定为正类,例子中就是正确的判定”这位是女生”)</td>
<td>false positives(FP 负类判定为正类,”存伪”,例子中就是分明是男生却判断为女生,当下伪娘横行,这个错常有人犯)</td>
</tr>
<tr>
<td><strong>未被检索到(Not Retrieved)</strong></td>
<td>false negatives(FN 正类判定为负类,”去真”,例子中就是,分明是女生,这哥们却判断为男生—梁山伯同学犯的错就是这个)</td>
<td>true negatives(TN 负类判定为负类,也就是一个男生被判断为男生,像我这样的纯爷们一准儿就会在此处)</td>
</tr>
</tbody>
</table>
</div>
<blockquote>
<p>假如某个班级有男生<strong>80</strong>人,女生<strong>20</strong>人,共计<strong>100</strong>人.目标是找出所有女生.<br>现在某人挑选出<strong>50</strong>个人,其中<strong>20</strong>人是女生,另外还错误的把30个男生也当作女生挑选出来了.<br>作为评估者的你需要来评估(<strong>evaluation</strong>)下他的工作</p>
<p>TP=20<br>FP=30<br>FN=0<br>TN=50</p>
</blockquote>
<p><img src="http://alexkong.net/images/Roccurves.png" alt=""></p>
<p><img src="http://alexkong.net/images/fpr-and-tpr.png" alt=""></p>
<p>考虑ROC曲线图中的四个点和一条线。第一个点，(0,1)，即FPR=0, TPR=1，这意味着FN（false negative）=0，并且FP（false positive）=0。    </p>
<p><strong>ROC曲线越接近左上角，该分类器的性能越好。</strong></p>
<p>曲线就是一系列FPR和TPR的结果。就是将每次分类结果的（0,1）的点作为分类的阈值。</p>
<blockquote>
<p>但是，ROC的曲线——如上面几位已经说过——有数据均衡的问题。在数据极度不平衡的情况下，譬如说1万封邮件中只有1封垃圾邮件，那么如果我挑出10封，50封，100，。。封垃圾邮件（假设全部包含真正的那封垃圾邮件），Recall都是100%，但是FPR分别是9/9999, 49/9999, 99/9999（数据都比较好看：FPR越低越好），而Precision却只有1/10，1/50， 1/100 （数据很差：Precision越高越好）。所以在数据非常不均衡的情况下，看ROC的AUC可能是看不出太多好坏的，而PR curve就要敏感的多。（不过真实世界中，垃圾邮件也许与你的有用的邮件一样多——甚至比有用的还更多。。。）作者：竹间智能 Emotibot链接：<a href="https://www.zhihu.com/question/30643044/answer/161955532来源：知乎著作权归作者所有。商业转载请联系作者获得授权，非商业转载请注明出处。" target="_blank" rel="noopener">https://www.zhihu.com/question/30643044/answer/161955532来源：知乎著作权归作者所有。商业转载请联系作者获得授权，非商业转载请注明出处。</a></p>
</blockquote>
<h1 id="精确率Precision"><a href="#精确率Precision" class="headerlink" title="精确率Precision"></a>精确率Precision</h1><p>TP/(TP+FP) 检索到的结果中是正确的比例，比如检索出50个女生只有20个是正确的</p>
<h1 id="召回率Recall"><a href="#召回率Recall" class="headerlink" title="召回率Recall"></a>召回率Recall</h1><p>TP/(TP+FN) 检索到的结果占应该检索结果的比例。比如检索的结果里面有20个女生，全班一共有20个女生，所以是100%</p>
<h1 id="F1"><a href="#F1" class="headerlink" title="F1"></a>F1</h1><p>精确值和召回率的调和均值</p>
<script type="math/tex; mode=display">
F_1 = \frac{2PR}{P+R} = \frac{2TP}{2TP + FP + FN}</script><h1 id="多分类的精确率和召回率"><a href="#多分类的精确率和召回率" class="headerlink" title="多分类的精确率和召回率"></a>多分类的精确率和召回率</h1><p><a href="http://blog.csdn.net/lanchunhui/article/details/51221729" target="_blank" rel="noopener">http://blog.csdn.net/lanchunhui/article/details/51221729</a></p>
<p>把每个类别单独视为”正“，所有其它类型视为”负“</p>
<p>就是看每行对角线的P和R</p>
<p>代码见<code>multi_recall.py</code></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">M = [</span><br><span class="line">    [<span class="number">14371</span>, <span class="number">6500</span>, <span class="number">9</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">2</span>, <span class="number">316</span>],</span><br><span class="line">    [<span class="number">5700</span>, <span class="number">22205</span>, <span class="number">454</span>, <span class="number">20</span>, <span class="number">0</span>, <span class="number">11</span>, <span class="number">23</span>],</span><br><span class="line">    [<span class="number">0</span>, <span class="number">445</span>, <span class="number">3115</span>, <span class="number">71</span>, <span class="number">0</span>, <span class="number">11</span>, <span class="number">0</span>],</span><br><span class="line">    [<span class="number">0</span>, <span class="number">0</span>, <span class="number">160</span>, <span class="number">112</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>],</span><br><span class="line">    [<span class="number">0</span>, <span class="number">888</span>, <span class="number">39</span>, <span class="number">2</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>],</span><br><span class="line">    [<span class="number">0</span>, <span class="number">486</span>, <span class="number">1196</span>, <span class="number">30</span>, <span class="number">0</span>, <span class="number">74</span>, <span class="number">0</span>],</span><br><span class="line">    [<span class="number">1139</span>, <span class="number">35</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">865</span>]</span><br><span class="line">]</span><br><span class="line"></span><br><span class="line">n = len(M)</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> range(n):</span><br><span class="line">    rowsum, colsum = sum(M[i]), sum(M[r][i] <span class="keyword">for</span> r <span class="keyword">in</span> range(n))</span><br><span class="line">    <span class="keyword">try</span>:</span><br><span class="line">        <span class="keyword">print</span> <span class="string">'precision: %s'</span> % (M[i][i]/float(colsum)), <span class="string">'recall: %s'</span> % (M[i][i]/float(rowsum))</span><br><span class="line">    <span class="keyword">except</span> ZeroDivisionError:</span><br><span class="line">        <span class="keyword">print</span> <span class="string">'precision: %s'</span> % <span class="number">0</span>, <span class="string">'recall: %s'</span> %<span class="number">0</span></span><br></pre></td></tr></table></figure>
<h1 id="回归的混淆矩阵"><a href="#回归的混淆矩阵" class="headerlink" title="回归的混淆矩阵"></a>回归的混淆矩阵</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">y_test = df_base_pred.dpd</span><br><span class="line">y_pred = gbm.predict(X_test, num_iteration=gbm.best_iteration)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">cm1 = confusion_matrix(np.where(y_pred &gt; <span class="number">0.8</span>, <span class="number">0</span>, <span class="number">1</span>), np.where(y_test &gt; <span class="number">0.8</span>, <span class="number">0</span>, <span class="number">1</span>))</span><br><span class="line">cm2 = confusion_matrix(np.where(((y_test &gt; <span class="number">0.5</span>) &amp; (y_test &lt; <span class="number">0.8</span>)), <span class="number">0</span>, <span class="number">1</span>), np.where(((y_pred &gt; <span class="number">0.5</span>) &amp; (y_pred &lt; <span class="number">0.8</span>)), <span class="number">0</span>, <span class="number">1</span>))</span><br><span class="line">cm3 = confusion_matrix(np.where(((y_test &gt; <span class="number">0.1</span>) &amp; (y_test &lt; <span class="number">0.5</span>)), <span class="number">0</span>, <span class="number">1</span>), np.where(((y_pred &gt; <span class="number">0.1</span>) &amp; (y_pred &lt; <span class="number">0.5</span>)), <span class="number">0</span>, <span class="number">1</span>))</span><br></pre></td></tr></table></figure>
<h1 id="K-S"><a href="#K-S" class="headerlink" title="K-S"></a>K-S</h1><p><a href="http://www.sohu.com/a/211697143_793685" target="_blank" rel="noopener">http://www.sohu.com/a/211697143_793685</a></p>
<p><a href="https://blog.csdn.net/sinat_30316741/article/details/80018932" target="_blank" rel="noopener">https://blog.csdn.net/sinat_30316741/article/details/80018932</a></p>
<p><a href="https://www.cnblogs.com/nxld/p/6208613.html" target="_blank" rel="noopener">https://www.cnblogs.com/nxld/p/6208613.html</a></p>
<p><a href="https://blog.csdn.net/pzw_0612/article/details/45280411" target="_blank" rel="noopener">https://blog.csdn.net/pzw_0612/article/details/45280411</a></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line">def compute_ks(data):</span><br><span class="line">    sorted_list = data.sort_values([&apos;predict_proba&apos;], ascending=[True])#按照样本为正样本的概率值升序排序 ，也即坏样本的概率从高到低排序</span><br><span class="line">    total_good=sorted_list[&apos;label&apos;].sum()</span><br><span class="line">    total_bad = sorted_list.shape[0] - total_good  </span><br><span class="line">    max_ks = 0.0</span><br><span class="line">    good_count = 0.0</span><br><span class="line">    bad_count = 0.0</span><br><span class="line">    for index, row in sorted_list.iterrows(): #按照标签和每行拆开</span><br><span class="line">        if row[&apos;label&apos;] == 0:</span><br><span class="line">            bad_count +=1</span><br><span class="line">        else:</span><br><span class="line">            good_count +=1</span><br><span class="line">        val = abs(bad_count/total_bad - good_count/total_good)</span><br><span class="line">        max_ks = max(max_ks, val)</span><br><span class="line">    return max_ks </span><br><span class="line">test_pd=pd.DataFrame()</span><br><span class="line">y_predict_proba=est.predict_proba(X_test)[:,1]#取被分为正样本的概率那一列</span><br><span class="line">Y_test_1=np.array(Y_test)</span><br><span class="line">test_pd[&apos;label&apos;]=Y_test_1</span><br><span class="line">test_pd[&apos;predict_proba&apos;]=y_predict_proba</span><br><span class="line">print (&quot;测试集 KS:&quot;,compute_ks(test_pd))</span><br><span class="line"></span><br><span class="line">作者：暸望塔</span><br><span class="line">链接：https://www.jianshu.com/p/fec4105a60d7</span><br><span class="line">來源：简书</span><br><span class="line">简书著作权归作者所有，任何形式的转载都请联系作者获得授权并注明出处。</span><br></pre></td></tr></table></figure>
<h1 id="回归模型的评价"><a href="#回归模型的评价" class="headerlink" title="回归模型的评价"></a>回归模型的评价</h1><p><a href="https://blog.csdn.net/shy19890510/article/details/79375062" target="_blank" rel="noopener">https://blog.csdn.net/shy19890510/article/details/79375062</a></p>
<p>对于回归模型效果的判断指标经过了几个过程，从SSE到R-square再到Ajusted R-square, 是一个完善的过程：</p>
<p>SSE(误差平方和)：The sum of squares due to error</p>
<p>R-square(决定系数)：Coefficient of determination</p>
<p>Adjusted R-square：Degree-of-freedom adjusted coefficient of determination</p>
<p>下面我对以上几个名词进行详细的解释下，相信能给大家带来一定的帮助！！</p>
<p><strong>一、SSE(误差平方和)</strong></p>
<p>计算公式如下：</p>
<p>​     <img src="https://img-blog.csdn.net/20180226141307251" alt="img"></p>
<ul>
<li>同样的数据集的情况下，SSE越小，误差越小，模型效果越好</li>
<li>缺点：</li>
</ul>
<p>SSE数值大小本身没有意义，随着样本增加，SSE必然增加，也就是说，不同的数据集的情况下，SSE比较没有意义</p>
<p><strong>二、R-square(决定系数)</strong></p>
<p><img src="https://img-blog.csdn.net/20180226141109847" alt="img"></p>
<ul>
<li><strong>数学理解：</strong> 分母理解为原始数据的离散程度，分子为预测数据和原始数据的误差，二者相除可以消除原始数据离散程度的影响</li>
<li>其实“决定系数”是通过数据的变化来表征一个拟合的好坏。</li>
<li>理论上取值范围（-∞，1], 正常取值范围为[0 1] ———实际操作中通常会选择拟合较好的曲线计算R²，因此很少出现-∞</li>
</ul>
<p>越接近1，表明方程的变量对y的解释能力越强，这个模型对数据拟合的也较好</p>
<p>越接近0，表明模型拟合的越差</p>
<p>经验值：&gt;0.4， 拟合效果好</p>
<ul>
<li>缺点：</li>
</ul>
<p>数据集的样本越大，R²越大，因此，不同数据集的模型结果比较会有一定的误差</p>
<p><strong>三、Adjusted R-Square (校正决定系数）</strong></p>
<p>​      <img src="https://img-blog.csdn.net/20180226141125835" alt="img"></p>
<p>n为样本数量，p为特征数量</p>
<ul>
<li>消除了样本数量和特征数量的影响</li>
</ul>

          
        
      
    </div>

    

    
    
    

    

    
      
    
    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  

  <article class="post post-type-normal" itemscope="" itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="https://schwimmer.github.io/2018/03/17/机器学习/知识点/">

    <span hidden itemprop="author" itemscope="" itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Schwimmer">
      <meta itemprop="description" content="Record and Think!">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope="" itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Schwimmer's Blog">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                
                <a href="/2018/03/17/机器学习/知识点/" class="post-title-link" itemprop="url">知识点</a>
              
            
          </h1>
        

        <div class="post-meta">

          
          
          

          
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              

              
                
              

              <time title="创建时间：2018-03-17 20:50:31" itemprop="dateCreated datePublished" datetime="2018-03-17T20:50:31+08:00">2018-03-17</time>
            </span>
          

          

          
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope="" itemtype="http://schema.org/Thing"><a href="/categories/机器学习/" itemprop="url" rel="index"><span itemprop="name">机器学习</span></a></span>

                
                
              
            </span>
          

          
            
            
              
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="fa fa-comment-o"></i>
                </span>
            
                <span class="post-meta-item-text">评论数：</span>
                <a href="/2018/03/17/机器学习/知识点/#comments" itemprop="discussionUrl">
                  <span class="post-comments-count disqus-comment-count" data-disqus-identifier="2018/03/17/机器学习/知识点/" itemprop="commentCount"></span>
                </a>
              </span>
            
          

          
          

          

          <br>
          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h3 id="特征选择"><a href="#特征选择" class="headerlink" title="特征选择"></a>特征选择</h3><h1 id="经典算法"><a href="#经典算法" class="headerlink" title="经典算法"></a>经典算法</h1><h2 id="LR"><a href="#LR" class="headerlink" title="LR"></a>LR</h2><p>线性回归模型的映射函数是一个线性方程。逻辑回归要解决分类问题，用logistic function代替线性方程，通过y的取值判断类别，y的取值是一个概率。</p>
<p>优点是，输出是0,1满足概率分布的要求。函数可微。</p>
<p>LR的L2正则</p>
<p>BFGS</p>
<h2 id="贝叶斯"><a href="#贝叶斯" class="headerlink" title="贝叶斯"></a>贝叶斯</h2><p>在多项式模型中：</p>
<blockquote>
<p>在多项式模型中， 设某文档d=(t1,t2,…,tk)，tk是该文档中出现过的单词，允许重复，则</p>
<p>先验概率P(c)= 类c下单词总数（包括重复的）/整个训练样本的单词总数</p>
<p>类条件概率P(tk|c)=(类c下单词tk在各个文档中出现过的次数之和+1)/(类c下单词总数+|V|)</p>
<p>V是训练样本的单词表（即抽取单词，单词出现多次，只算一个），|V|则表示训练样本包含多少种单词。 P(tk|c)可以看作是单词tk在证明d属于类c上提供了多大的证据，而P(c)则可以认为是类别c在整体上占多大比例(有多大可能性)。</p>
</blockquote>
<p>在伯努利模型中：</p>
<blockquote>
<p>P(c)= 类c下文件总数/整个训练样本的文件总数</p>
<p>P(tk|c)=(类c下包含单词tk的文件数+1)/(类c下文件总数+2)</p>
</blockquote>
<p>平滑项是应对没有特征的情况。</p>
<p><a href="http://blog.sina.com.cn/s/blog_15183f5750102vr62.html" target="_blank" rel="noopener">朴素贝叶斯算法的12条建议</a></p>
<h2 id="SVM"><a href="#SVM" class="headerlink" title="SVM"></a>SVM</h2><p>SVM在哪个地方引入的核函数?如果用高斯核可以升到多少维?</p>
<h2 id="BP的推导"><a href="#BP的推导" class="headerlink" title="BP的推导"></a>BP的推导</h2><p>反向传播的原理</p>
<h2 id="随机森林"><a href="#随机森林" class="headerlink" title="随机森林"></a>随机森林</h2><p>解决决策树容易过拟合的缺点。采用多个决策树的投票机制来改善决策树。RF有多个决策树，不能用全样本去训练，要用到采样方法。</p>
<p>1、每棵树选择样本时，通过重采样产生n个样本</p>
<p>2、从m个特征中随机选择k个特征，构建决策树。</p>
<p>3、多数投票制预测</p>
<h2 id="决策树"><a href="#决策树" class="headerlink" title="决策树"></a>决策树</h2><p>IC3，用信息增益找分裂特征。</p>
<p>C4.5，用信息增益比找特征。</p>
<h2 id="GBDT"><a href="#GBDT" class="headerlink" title="GBDT"></a>GBDT</h2><p><a href="http://www.cnblogs.com/ModifyRong/p/7744987.html" target="_blank" rel="noopener">机器学习算法GBDT的面试要点总结-上篇</a></p>
<p><a href="https://www.zhihu.com/question/41354392" target="_blank" rel="noopener">机器学习算法中GBDT和XGBOOST的区别有哪些？</a></p>
<p>推荐系统稍微看看</p>
<p>k折交叉验证中k取值多少有什么关系, 和bias和variance有关系吗?</p>
<p>翻转二叉树</p>
<p>平衡二叉树</p>
<p>hadoop和spark的应用场景</p>
<h3 id="样本倾斜的处理"><a href="#样本倾斜的处理" class="headerlink" title="样本倾斜的处理"></a>样本倾斜的处理</h3><p>样本不均衡的情况下，用AUC会偏高。</p>
<h6 id="分类算法的比较"><a href="#分类算法的比较" class="headerlink" title="分类算法的比较"></a>分类算法的比较</h6><p><a href="https://www.zhihu.com/question/24169940#answer-6100729" target="_blank" rel="noopener">用于数据挖掘的分类算法有哪些，各有何优劣？</a></p>
<h3 id="预测的评价指标"><a href="#预测的评价指标" class="headerlink" title="预测的评价指标"></a>预测的评价指标</h3><p><a href="https://www.zhihu.com/question/30643044" target="_blank" rel="noopener">精确率、召回率、F1 值、ROC、AUC 各自的优缺点是什么？</a></p>
<h4 id="ROC和AUC"><a href="#ROC和AUC" class="headerlink" title="ROC和AUC"></a>ROC和AUC</h4><p>构建一个混淆矩阵</p>
<p>TP FP</p>
<p>FN TN</p>
<p>精确率<code>(tp+tn)/(tp+fp+fn+tn)</code> 分类器对整个样本分类能力，正为正，负为负</p>
<p>准确率 TP/TP+FP 分类器判定为正例中，真正的正例样本比重。</p>
<p>召回率 tp/tp+fn 判定为正例在所有正例的比重</p>
<p>word2vec的原理</p>
<p>如何增量训练</p>
<p>是一个词转向量的工具，语料是收集的百万篇的url。</p>
<p>如何将词转成向量表达的？</p>
<p>模型的目标函数是什么</p>
<script type="math/tex; mode=display">
L=\sum_{w \in C} \log p(w|Context(w))</script><p> 如何推导的？</p>
<blockquote>
<p>ngram模型+对数似然函数</p>
</blockquote>
<p>基于神经网络的模型是如何做的</p>
<blockquote>
<p>输入层是(Context(w),w)的训练样本。输入的时候是n-1个词向量首尾拼接。（词向量还没训练呢是怎么得到的？在[0,1]之间随机取值初始化）</p>
<p>输入层到隐藏层用双曲正切函数作为激活函数。</p>
<p>隐藏层到输出层再用一个线性函数。这样输出的y只是一个普通向量，需要用softmax再做一个归一化处理。</p>
</blockquote>
<p>有了目标函数后，如何构建CBOW网络结构？</p>
<blockquote>
<p>网络结构：</p>
<p>输入层：前后各c个词，共2c个词的词向量。</p>
<p>投影层：向量做sum再取平均。</p>
<p>输出层：输出到Huffman树。每个叶子节点是一个词典中的词。</p>
<p>与神经网络模型的区别：</p>
<p>1）前者是拼接，后者是累加。2）后者没有隐藏层。3）前者是线性结构；后者是树形结构。</p>
</blockquote>
<p>如何利用Huffman树来定义目标函数？</p>
<blockquote>
<p>对于每个词，都存在一个路径，路径上存在分支，将每个分支看成一个二分类，每次分类产生一个概率。将这些概率连乘，就是目标函数。</p>
<p>公式见《NLP/Word2Vec原理》</p>
<p>权重初始化为0，词向量初始化为[0-1]的随机数。权重向量的长度就是所有词*词向量的长度。因为每层都有一个权重。</p>
<p>用了多线程方法加速训练。</p>
</blockquote>
<p>为什么叫层次softmax？</p>
<blockquote>
<p>每层都是一个二分类问题</p>
</blockquote>
<p>为什么同义词的向量也相近</p>
<blockquote>
<p>我理解是上下文接近，对于CBOW，训练每个词后更新的是上下文，对于近义词往往有类似的上下文</p>
</blockquote>
<p>如何计算距一个词最近的向量？</p>
<blockquote>
<p>KD树搜索。（<a href="https://www.cnblogs.com/21207-iHome/p/6084670.html）" target="_blank" rel="noopener">https://www.cnblogs.com/21207-iHome/p/6084670.html）</a></p>
<p>构建方法：任选一个特征（或者数据方差最大的特征，说明分散，越可能不属于同一个区间），以此为坐标轴划分，将最近的点落在坐标轴上。</p>
<p><img src="https://images2015.cnblogs.com/blog/890966/201611/890966-20161123134503362-571302342.png" alt=""></p>
<p>KD树搜索</p>
<p>先从根节点往下找到叶子节点，再回溯，回溯到每层时要判断是否跟另一区间相交。</p>
<p><img src="https://images2015.cnblogs.com/blog/890966/201611/890966-20161123150431143-1520224794.png" alt=""></p>
<p>但是KD是递归查找，效率低。递归效率低是函数调用的开销导致的（函数调用需要准备资源），且有栈溢出的风险。</p>
<p>idistance</p>
<p><a href="https://en.m.wikipedia.org/wiki/IDistance" target="_blank" rel="noopener">https://en.m.wikipedia.org/wiki/IDistance</a></p>
<p>目前线上怎么做的</p>
</blockquote>
<p>如何用word2vec计算句子相似度</p>
<blockquote>
<p>词向量按tfidf权重求mean</p>
<p>也要分应用，需求是topic相关还是语义相关。比如我爱苹果，我不爱苹果，topic相似语义不相似。</p>
<p>如果从词的粒度比较，还要结合上下文，避免一词多义。</p>
</blockquote>
<p>文本分类</p>
<blockquote>
<p>可以直接用fasttext，也可以tfidf+svm</p>
</blockquote>
<p>熵</p>
<p>随机游走算法</p>
<p>动态规划算法</p>
<p>异常检测算法</p>
<h1 id="CTR预测"><a href="#CTR预测" class="headerlink" title="CTR预测"></a>CTR预测</h1><h2 id="如何预测CTR线上的效果"><a href="#如何预测CTR线上的效果" class="headerlink" title="如何预测CTR线上的效果"></a>如何预测CTR线上的效果</h2><p>线下的可以用log loss和AUC</p>
<p><strong>这里要特别强调一下用线上的其它业务指标如点击率、营收、利润、eCPC等等是不能给出CTR预估效果评价的</strong>。这些业务指标，受到整个广告系统其它模块如bid optimization,budget pacing等和外部竞价环境的综合影响，它的变化或者AB test中观察到的不同，不是简单地由于CTR预估变化带来的。换句话说，如果上了一个新的CTR预估模型的实验，发现业务指标变好了，这不等于说CTR预估更准了。一个简单的例子：如果一个CTR预估模型给出的预估总是比上帝视角的完美预估在低CTR区域低估，在高CTR区域高估，那么假设bid是base_bid*pCTR的话，相比完美预估，这个模型会赢得更多的高CTR区域的竞价，输掉更多在低CTR区域的竞价，最后会观察到实验组的CTR反而比完美预估的试验组更高。作者：Jian Xu链接：<a href="https://www.zhihu.com/question/54009615/answer/137820154来源：知乎著作权归作者所有。商业转载请联系作者获得授权，非商业转载请注明出处。" target="_blank" rel="noopener">https://www.zhihu.com/question/54009615/answer/137820154来源：知乎著作权归作者所有。商业转载请联系作者获得授权，非商业转载请注明出处。</a></p>
<h3 id="为什么AUC可以评价CTR"><a href="#为什么AUC可以评价CTR" class="headerlink" title="为什么AUC可以评价CTR"></a>为什么AUC可以评价CTR</h3><p>它和Wilcoxon-Mann-Witney Test是等价的[3]。而Wilcoxon-Mann-Witney Test就是测试任意给一个正类样本和一个负类样本，正类样本的score有多大的概率大于负类样本的score。</p>
<p>如何平衡样本？平衡后的数据不是真实分布</p>
<h6 id="CTR评价"><a href="#CTR评价" class="headerlink" title="CTR评价"></a>CTR评价</h6><p>CTR的评价用logloss和AUC。因为是概率输出，不方便用PR。</p>
<h6 id="点击率各模型优缺点"><a href="#点击率各模型优缺点" class="headerlink" title="点击率各模型优缺点"></a>点击率各模型优缺点</h6><p><a href="https://www.zhihu.com/question/62109451?answer_deleted_redirect=true" target="_blank" rel="noopener">广告点击率模型中，LR, GBDT+LR, FM, DNN等模型的优点和缺点？实际效果如何?</a></p>
<p><a href="http://blog.csdn.net/lilyth_lilyth/article/details/48032119" target="_blank" rel="noopener">CTR预估中GBDT与LR融合方案</a></p>
<p><a href=""><a href="http://blog.csdn.net/bitcarmanlee/article/details/52138970" target="_blank" rel="noopener">CTR点击率预估干货分享</a></a></p>
<p>Ad Click Prediction: a View from the Trenches</p>
<p><img src="https://pic1.zhimg.com/80/v2-7a75ba913f11b4fb483228f70172003a_hd.jpg" alt=""></p>
<p>LR</p>
<p>优点：实现简单</p>
<p>缺点：需要寻找特征。我们也使用了FTRL，但实践中它并不能非常有效的产生稀疏模型，如果模型非常大，会导致同步模型变慢，一样会严重影响效果。</p>
<h6 id="点击率模型中特征如何选择"><a href="#点击率模型中特征如何选择" class="headerlink" title="点击率模型中特征如何选择"></a>点击率模型中特征如何选择</h6><p><a href="http://blog.csdn.net/ariessurfer/article/details/40380051" target="_blank" rel="noopener">广告点击率预估中的特征选择</a></p>
<p>不是看它分布均不均衡，而是看它符不符合原来的分布。如果符合原来的分布，那么训练误差最小化也就意味着整体分布误差的最小化，也就没有必要进行均衡。</p>
<p>如何降维，每个特征都对应的ctr，在构建模型时，根据ctr的区间将属于同一个区间的特征值作为一个特征；随着ctr区间越分越细来迭代。停止条件是不超过所有特征的一半或达到最小区间阈值。</p>
<h6 id="投放中出现的问题"><a href="#投放中出现的问题" class="headerlink" title="投放中出现的问题"></a>投放中出现的问题</h6><h6 id="spark数据倾斜"><a href="#spark数据倾斜" class="headerlink" title="spark数据倾斜"></a>spark数据倾斜</h6><p><a href="https://www.cnblogs.com/hd-zg/p/6089220.html" target="_blank" rel="noopener">https://www.cnblogs.com/hd-zg/p/6089220.html</a></p>
<h6 id="spark资源调优"><a href="#spark资源调优" class="headerlink" title="spark资源调优"></a>spark资源调优</h6><p><a href="http://blog.csdn.net/u012102306/article/details/51637366" target="_blank" rel="noopener">http://blog.csdn.net/u012102306/article/details/51637366</a></p>
<p>我们使用yarn作为资源管理集群。yarn集群管理器根据spark参数，在各个工作节点上，启动一定数量的Executor进程，每个进程有一定的内存和CPU  Core。</p>
<p>在申请到了作业执行所需的资源之后，Driver进程就会开始调度和执行我们编写的作业代码了。Driver将代码拆分为多个stage，为每个stage创建一批task。将这些task分配到各个Executor执行。</p>
<p>SparkConf的一些参数：</p>
<p>spark.sql.shuffle.partitions指partition的数量。SparkSQL在运行时，将一个查询任务分解成多个task，一个task就是一个partition。默认是200个partition，而如果实际集群只能并行3个task，则跑完200个partition要200/3=67次。</p>
<p>spark.network.timeout所有网络通信的超时时间，默认是120s</p>
<h6 id="mapreduce-shuffle过程"><a href="#mapreduce-shuffle过程" class="headerlink" title="mapreduce shuffle过程"></a>mapreduce shuffle过程</h6><p><a href="http://langyu.iteye.com/blog/992916" target="_blank" rel="noopener">http://langyu.iteye.com/blog/992916</a></p>
<p>map过程，阶段，将输入文本做split，并转成<k,v>格式，V的初始值是1</k,v></p>
<p>之后，partitioner可以根据key和value以及reduce的数量来决定map的输出放到那个reduce task。默认是key hash后对reduce取模。</p>
<p>接下来将output写入缓冲区，减少磁盘IO的影响。key，value，partitioner的结果都写入缓冲区。</p>
<p>当缓冲区内容达到一定比例，就调用单独线程溢写到磁盘。溢写前，如果设置了combiner，在这里就要做合并。当溢写启动后，需要对溢写内容的key做sort。</p>
<p>Merge。每次溢写生成一个文件，map task完成后内存缓冲区所有的数据也全部溢写生成一个文件。用Merge合并溢写文件。</p>
<p>reduce</p>
<p>执行之前，拉取每个job中每个map task的最终结果。从不同地方拉过来的做merge。作为reducer的输入，然后执行reducer，结果写入hdfs。</p>
<p>文本分类怎么优化特征</p>
<h6 id="CTR预测怎么优化特征"><a href="#CTR预测怎么优化特征" class="headerlink" title="CTR预测怎么优化特征"></a>CTR预测怎么优化特征</h6><p>选特征，版位id，版位类型，地理位置，曝光时间，ua信息（操作系统，浏览器等），人群特征因为样本稀疏所有没有选</p>
<p>根据直接观察CTR，卡方检验，单特征AUC。</p>
<p>用互信息、卡方检验有没有用</p>
<p>没有CTR的新版位</p>
<p>word2vec新词</p>
<p>es</p>
<p>java api常见操作，从hive导入，从文件导入，中文分词</p>
<p>user-gene，投放，tracking处理的流程图</p>
<p>domain黑名单</p>
<p>DFA算法过滤敏感词</p>
<p>二分查找</p>
<h6 id="特征稀疏怎么做"><a href="#特征稀疏怎么做" class="headerlink" title="特征稀疏怎么做"></a>特征稀疏怎么做</h6><p><a href="https://www.zhihu.com/question/48673581#answer-49246569" target="_blank" rel="noopener">传统的CTR或推荐系统拥有高维特征和稀疏数据，转向深度学习如何</a></p>
<p>如果可用特征值太少，就丢弃；要么就设值为unknown；xgboost有稀疏感知算法</p>
<p>怎么想到age预测算法的</p>
<p>哪些媒体获取？电商，微信</p>
<p>audience的重合度，距离代表相关度</p>
<p>hive的存储，ORC格式，以前用SequenceFile</p>
<p>pig，数据倾斜时的join用replicated，大表放左，其他放右。</p>
<p>动态规划</p>
<p>L1和L2有什么区别</p>
<h2 id="乱序数组找中位数"><a href="#乱序数组找中位数" class="headerlink" title="乱序数组找中位数"></a>乱序数组找中位数</h2><p>快排+二分。取partition后，去掉一半的数字。</p>
<p>直接拿一个素材的点击率当一个维度的特征？</p>
<p>随机森林和GBDT的区别</p>
<h6 id="如何提高召回率或精确率"><a href="#如何提高召回率或精确率" class="headerlink" title="如何提高召回率或精确率"></a>如何提高召回率或精确率</h6><p><a href="https://www.zhihu.com/question/39819838" target="_blank" rel="noopener">如何提高机器学习算法的召回率？（尤其在样本集不平衡时）</a></p>
<h6 id="引擎流程"><a href="#引擎流程" class="headerlink" title="引擎流程"></a>引擎流程</h6><p>用timeslot监控campaign参数变化，预测下一个slot。第一个slot内不投放。</p>
<p>1、计算的参数包括flowbiddingrate、利润区间。</p>
<p>fbr衡量擦camp能投放的量占总量的百分比。比如根据预算，剩余每个slot的预算/每个slot的最大预算；曝光就是每个slot剩余曝光量/最大曝光量。</p>
<p>2、然后预测ctr并计算松弛系数（实际-期望），判断是否可以投放。</p>
<p>3、计算竞价，计算初始值，对于CPM，根据投放和曝光速度进行调整。对于CPC，如果实际CTR较高，通过提高一些小CTR的出价来平滑。</p>
<p>4、通过版位历史价格计算预期利润，统计利润区间分布。根据fbr确定可投放的利润区间。</p>
<p>5、通过投放平衡率计算camp打分。</p>

          
        
      
    </div>

    

    
    
    

    

    
      
    
    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  

  <article class="post post-type-normal" itemscope="" itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="https://schwimmer.github.io/2018/03/17/机器学习/知识图谱入门/">

    <span hidden itemprop="author" itemscope="" itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Schwimmer">
      <meta itemprop="description" content="Record and Think!">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope="" itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Schwimmer's Blog">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                
                <a href="/2018/03/17/机器学习/知识图谱入门/" class="post-title-link" itemprop="url">知识图谱入门</a>
              
            
          </h1>
        

        <div class="post-meta">

          
          
          

          
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              

              
                
              

              <time title="创建时间：2018-03-17 20:50:31" itemprop="dateCreated datePublished" datetime="2018-03-17T20:50:31+08:00">2018-03-17</time>
            </span>
          

          

          
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope="" itemtype="http://schema.org/Thing"><a href="/categories/机器学习/" itemprop="url" rel="index"><span itemprop="name">机器学习</span></a></span>

                
                
              
            </span>
          

          
            
            
              
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="fa fa-comment-o"></i>
                </span>
            
                <span class="post-meta-item-text">评论数：</span>
                <a href="/2018/03/17/机器学习/知识图谱入门/#comments" itemprop="discussionUrl">
                  <span class="post-comments-count disqus-comment-count" data-disqus-identifier="2018/03/17/机器学习/知识图谱入门/" itemprop="commentCount"></span>
                </a>
              </span>
            
          

          
          

          

          <br>
          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p><a href="https://www.zhihu.com/question/52368821#answer-51023978" target="_blank" rel="noopener">知识图谱入门</a></p>
<p>知道RDF，OWL，SPARQL这些W3C技术堆栈，知道它们的长处和局限。会使用RDF数据库和推理机。</p>
<p>了解一点描述逻辑基础，知道描述逻辑和一阶逻辑的关系。知道模型论，不然完全没法理解RDF和OWL。</p>
<p>了解图灵机和基本的算法复杂性。知道什么是决策问题、可判定性、完备性和一致性、P、NP、NExpTime。</p>
<p>最好再知道一点逻辑程序（Logic Programming），涉猎一点答集程序（Answer Set Programming），知道LP和ASP的一些小工具。这些东西是规则引擎的核心。如果不满足于正则表达式和if-then-else，最好学一点这些。</p>
<p>从正则文法到自动机。不理解自动机很多高效的模式提取算法都理解不了。</p>
<p>熟悉常见的知识库，不必事事重新造轮子，如Freebase, Wikidata, Yago, DBPedia。</p>
<p>熟悉结构化数据建模的基本方法，如ER，面向对象，UML，脑图。</p>
<p>学会使用一些本体编辑器，如Protege。</p>
<p>熟悉任何一种关系数据库。会使用存储过程写递归查询。明白什么叫物化视图、传递闭包、推理闭包。</p>
<p>熟悉任何一种图数据库。明白图的局部索引和关系的全局索引的理论和实践性能差异。</p>
<p>熟悉词法分析的基本工具，如分词、词性标注</p>
<p>熟悉句法分析的基本工具，如成分分析、依存文法分析、深层文法分析</p>
<p>熟悉TFIDF、主题模型和分布式表示的基本概念和工具。知道怎么计算两个词的相似度、词和句子的关联度。</p>
<p>知道怎么做命名实体识别。知道一些常用的词表。知道怎么用规则做关系提取。</p>
<p>了解前人已经建好的各种Lexical数据库，如Wordnet, framenet,  BabelNet, PropBank。熟悉一些常用的Corpus。</p>
<p>知道信息检索的基本原理。知道各种结构的索引的代价。</p>
<p>掌握Lucene或者Solr/Elasticsearch的使用。</p>
<p><img src="https://pic4.zhimg.com/80/v2-c5b129d69119a5b5524bbfb63df9ee7b_hd.jpg" alt=""></p>
<h2 id="知识融合"><a href="#知识融合" class="headerlink" title="知识融合"></a>知识融合</h2><p>把结构化数据、半结构化数据、非结构化数据的知识表达形式都统一成RDF的形式，便于存储和查询。具体的知识融合主要包括如下两种类型：</p>
<ul>
<li>合并外部知识库： 数据层的融合、模式层的融合</li>
</ul>
<p>开放数据集成框架：LDIF</p>
<ul>
<li>合并关系型数据库：将关系型数据转换成RDF的格式，现有工具Triplify、 d2rServer 、OpenLink、 Virtuoso 、SparqlMap等</li>
</ul>
<p><img src="https://pic4.zhimg.com/80/v2-ea49d6925e7d1461b6c6f6d393861038_hd.jpg" alt=""></p>
<h2 id="知识推理"><a href="#知识推理" class="headerlink" title="知识推理"></a>知识推理</h2><ul>
<li>jena是一个java 的API，用来支持语义网的有关应用，学习jena需要了解XML 、RDF、 Ontology、OWL等方面的知识。</li>
<li>RDFox是一个高度可扩展的<strong>内存</strong>RDF三重存储，支持共享内存并行数据推理。它是一个用C ++编写的跨平台软件，带有一个Java包装器，可以与任何基于Java的解决方案轻松集成</li>
</ul>

          
        
      
    </div>

    

    
    
    

    

    
      
    
    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
  </section>

  
  <nav class="pagination">
    <a class="extend prev" rel="prev" href="/page/22/"><i class="fa fa-angle-left" aria-label="上一页"></i></a><a class="page-number" href="/">1</a><span class="space">&hellip;</span><a class="page-number" href="/page/22/">22</a><span class="page-number current">23</span><a class="page-number" href="/page/24/">24</a><span class="space">&hellip;</span><a class="page-number" href="/page/31/">31</a><a class="extend next" rel="next" href="/page/24/"><i class="fa fa-angle-right" aria-label="下一页"></i></a>
  </nav>



          </div>
          

        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    <div class="sidebar-inner">

      

      

      <div class="site-overview-wrap sidebar-panel sidebar-panel-active">
        <div class="site-overview">
          <div class="site-author motion-element" itemprop="author" itemscope="" itemtype="http://schema.org/Person">
            
              <p class="site-author-name" itemprop="name">Schwimmer</p>
              <div class="site-description motion-element" itemprop="description">Record and Think!</div>
          </div>

          
            <nav class="site-state motion-element">
              
                <div class="site-state-item site-state-posts">
                
                  <a href="/archives/">
                
                    <span class="site-state-item-count">308</span>
                    <span class="site-state-item-name">日志</span>
                  </a>
                </div>
              

              
                
                
                <div class="site-state-item site-state-categories">
                  
                    
                      <a href="/categories/">
                    
                  
                    
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                    <span class="site-state-item-count">25</span>
                    <span class="site-state-item-name">分类</span>
                  </a>
                </div>
              

              
                
                
                <div class="site-state-item site-state-tags">
                  
                    
                      <a href="/tags/">
                    
                  
                    
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                    <span class="site-state-item-count">61</span>
                    <span class="site-state-item-name">标签</span>
                  </a>
                </div>
              
            </nav>
          

          

          

          

          

          
          

          
            
          
          

        </div>
      </div>

      

      

    </div>
  </aside>
  


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <div class="copyright">&copy; <span itemprop="copyrightYear">2019</span>
  <span class="with-love" id="animate">
    <i class="fa fa-user"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">Schwimmer</span>

  

  
</div>


  <div class="powered-by">由 <a href="https://hexo.io" class="theme-link" rel="noopener" target="_blank">Hexo</a> 强力驱动 v3.9.0</div>



  <span class="post-meta-divider">|</span>



  <div class="theme-info">主题 – <a href="https://theme-next.org" class="theme-link" rel="noopener" target="_blank">NexT.Mist</a> v7.2.0</div>




        
<div class="busuanzi-count">
  <script async src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>

  
    <span class="post-meta-item-icon">
      <i class="fa fa-user"></i>
    </span>
    <span class="site-uv" title="总访客量">
      <span class="busuanzi-value" id="busuanzi_value_site_uv"></span>
    </span>
  

  
    <span class="post-meta-divider">|</span>
  

  
    <span class="post-meta-item-icon">
      <i class="fa fa-eye"></i>
    </span>
    <span class="site-pv" title="总访问量">
      <span class="busuanzi-value" id="busuanzi_value_site_pv"></span>
    </span>
  
</div>









        
      </div>
    </footer>

    
      <div class="back-to-top">
        <i class="fa fa-arrow-up"></i>
        
      </div>
    

    

    
      <div>
        
  <script>
    window._bd_share_config = {
      "common": {
        "bdText": "",
        "bdMini": "1",
        "bdMiniList": false,
        "bdPic": ""
      },
      "image": {
        "viewList": ["tsina", "douban", "sqq", "qzone", "weixin", "twi", "fbook"],
        "viewText": "分享到：",
        "viewSize": "16"
      },
      "slide": {
        "bdImg": "5",
        "bdPos": "left",
        "bdTop": "100"
      }
    }
  </script>

<script>
  with(document)0[(getElementsByTagName('head')[0]||body).appendChild(createElement('script')).src='//bdimg.share.baidu.com/static/api/js/share.js?cdnversion='+~(-new Date()/36e5)];
</script>

      </div>
    

    
  </div>

  

<script>
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>


























  
  <script src="/lib/jquery/index.js?v=3.4.1"></script>

  
  <script src="/lib/velocity/velocity.min.js?v=1.2.1"></script>

  
  <script src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>


  


  <script src="/js/utils.js?v=7.2.0"></script>

  <script src="/js/motion.js?v=7.2.0"></script>



  
  


  <script src="/js/schemes/muse.js?v=7.2.0"></script>




  

  


  <script src="/js/next-boot.js?v=7.2.0"></script>


  

  

  

  
  
<script>
  function loadCount() {
    var d = document, s = d.createElement('script');
    s.src = 'https://https-schwimmer-github-io.disqus.com/count.js';
    s.id = 'dsq-count-scr';
    (d.head || d.body).appendChild(s);
  }
  // defer loading until the whole page loading is completed
  window.addEventListener('load', loadCount, false);
</script>







  
  <script>
    // Popup Window;
    var isfetched = false;
    var isXml = true;
    // Search DB path;
    var search_path = "search.xml";
    if (search_path.length === 0) {
      search_path = "search.xml";
    } else if (/json$/i.test(search_path)) {
      isXml = false;
    }
    var path = "/" + search_path;
    // monitor main search box;

    var onPopupClose = function (e) {
      $('.popup').hide();
      $('#local-search-input').val('');
      $('.search-result-list').remove();
      $('#no-result').remove();
      $(".local-search-pop-overlay").remove();
      $('body').css('overflow', '');
    }

    function proceedsearch() {
      $("body")
        .append('<div class="search-popup-overlay local-search-pop-overlay"></div>')
        .css('overflow', 'hidden');
      $('.search-popup-overlay').click(onPopupClose);
      $('.popup').toggle();
      var $localSearchInput = $('#local-search-input');
      $localSearchInput.attr("autocapitalize", "none");
      $localSearchInput.attr("autocorrect", "off");
      $localSearchInput.focus();
    }

    // search function;
    var searchFunc = function(path, search_id, content_id) {
      'use strict';

      // start loading animation
      $("body")
        .append('<div class="search-popup-overlay local-search-pop-overlay">' +
          '<div id="search-loading-icon">' +
          '<i class="fa fa-spinner fa-pulse fa-5x fa-fw"></i>' +
          '</div>' +
          '</div>')
        .css('overflow', 'hidden');
      $("#search-loading-icon").css('margin', '20% auto 0 auto').css('text-align', 'center');

      

      $.ajax({
        url: path,
        dataType: isXml ? "xml" : "json",
        async: true,
        success: function(res) {
          // get the contents from search data
          isfetched = true;
          $('.popup').detach().appendTo('.header-inner');
          var datas = isXml ? $("entry", res).map(function() {
            return {
              title: $("title", this).text(),
              content: $("content",this).text(),
              url: $("url" , this).text()
            };
          }).get() : res;
          var input = document.getElementById(search_id);
          var resultContent = document.getElementById(content_id);
          var inputEventFunction = function() {
            var searchText = input.value.trim().toLowerCase();
            var keywords = searchText.split(/[\s\-]+/);
            if (keywords.length > 1) {
              keywords.push(searchText);
            }
            var resultItems = [];
            if (searchText.length > 0) {
              // perform local searching
              datas.forEach(function(data) {
                var isMatch = false;
                var hitCount = 0;
                var searchTextCount = 0;
                var title = data.title.trim();
                var titleInLowerCase = title.toLowerCase();
                var content = data.content.trim().replace(/<[^>]+>/g,"");
                
                var contentInLowerCase = content.toLowerCase();
                var articleUrl = decodeURIComponent(data.url).replace(/\/{2,}/g, '/');
                var indexOfTitle = [];
                var indexOfContent = [];
                // only match articles with not empty titles
                if(title != '') {
                  keywords.forEach(function(keyword) {
                    function getIndexByWord(word, text, caseSensitive) {
                      var wordLen = word.length;
                      if (wordLen === 0) {
                        return [];
                      }
                      var startPosition = 0, position = [], index = [];
                      if (!caseSensitive) {
                        text = text.toLowerCase();
                        word = word.toLowerCase();
                      }
                      while ((position = text.indexOf(word, startPosition)) > -1) {
                        index.push({position: position, word: word});
                        startPosition = position + wordLen;
                      }
                      return index;
                    }

                    indexOfTitle = indexOfTitle.concat(getIndexByWord(keyword, titleInLowerCase, false));
                    indexOfContent = indexOfContent.concat(getIndexByWord(keyword, contentInLowerCase, false));
                  });
                  if (indexOfTitle.length > 0 || indexOfContent.length > 0) {
                    isMatch = true;
                    hitCount = indexOfTitle.length + indexOfContent.length;
                  }
                }

                // show search results

                if (isMatch) {
                  // sort index by position of keyword

                  [indexOfTitle, indexOfContent].forEach(function (index) {
                    index.sort(function (itemLeft, itemRight) {
                      if (itemRight.position !== itemLeft.position) {
                        return itemRight.position - itemLeft.position;
                      } else {
                        return itemLeft.word.length - itemRight.word.length;
                      }
                    });
                  });

                  // merge hits into slices

                  function mergeIntoSlice(text, start, end, index) {
                    var item = index[index.length - 1];
                    var position = item.position;
                    var word = item.word;
                    var hits = [];
                    var searchTextCountInSlice = 0;
                    while (position + word.length <= end && index.length != 0) {
                      if (word === searchText) {
                        searchTextCountInSlice++;
                      }
                      hits.push({position: position, length: word.length});
                      var wordEnd = position + word.length;

                      // move to next position of hit

                      index.pop();
                      while (index.length != 0) {
                        item = index[index.length - 1];
                        position = item.position;
                        word = item.word;
                        if (wordEnd > position) {
                          index.pop();
                        } else {
                          break;
                        }
                      }
                    }
                    searchTextCount += searchTextCountInSlice;
                    return {
                      hits: hits,
                      start: start,
                      end: end,
                      searchTextCount: searchTextCountInSlice
                    };
                  }

                  var slicesOfTitle = [];
                  if (indexOfTitle.length != 0) {
                    slicesOfTitle.push(mergeIntoSlice(title, 0, title.length, indexOfTitle));
                  }

                  var slicesOfContent = [];
                  while (indexOfContent.length != 0) {
                    var item = indexOfContent[indexOfContent.length - 1];
                    var position = item.position;
                    var word = item.word;
                    // cut out 100 characters
                    var start = position - 20;
                    var end = position + 80;
                    if(start < 0){
                      start = 0;
                    }
                    if (end < position + word.length) {
                      end = position + word.length;
                    }
                    if(end > content.length){
                      end = content.length;
                    }
                    slicesOfContent.push(mergeIntoSlice(content, start, end, indexOfContent));
                  }

                  // sort slices in content by search text's count and hits' count

                  slicesOfContent.sort(function (sliceLeft, sliceRight) {
                    if (sliceLeft.searchTextCount !== sliceRight.searchTextCount) {
                      return sliceRight.searchTextCount - sliceLeft.searchTextCount;
                    } else if (sliceLeft.hits.length !== sliceRight.hits.length) {
                      return sliceRight.hits.length - sliceLeft.hits.length;
                    } else {
                      return sliceLeft.start - sliceRight.start;
                    }
                  });

                  // select top N slices in content

                  var upperBound = parseInt('1');
                  if (upperBound >= 0) {
                    slicesOfContent = slicesOfContent.slice(0, upperBound);
                  }

                  // highlight title and content

                  function highlightKeyword(text, slice) {
                    var result = '';
                    var prevEnd = slice.start;
                    slice.hits.forEach(function (hit) {
                      result += text.substring(prevEnd, hit.position);
                      var end = hit.position + hit.length;
                      result += '<b class="search-keyword">' + text.substring(hit.position, end) + '</b>';
                      prevEnd = end;
                    });
                    result += text.substring(prevEnd, slice.end);
                    return result;
                  }

                  var resultItem = '';

                  if (slicesOfTitle.length != 0) {
                    resultItem += "<li><a href='" + articleUrl + "' class='search-result-title'>" + highlightKeyword(title, slicesOfTitle[0]) + "</a>";
                  } else {
                    resultItem += "<li><a href='" + articleUrl + "' class='search-result-title'>" + title + "</a>";
                  }

                  slicesOfContent.forEach(function (slice) {
                    resultItem += "<a href='" + articleUrl + "'>" +
                      "<p class=\"search-result\">" + highlightKeyword(content, slice) +
                      "...</p>" + "</a>";
                  });

                  resultItem += "</li>";
                  resultItems.push({
                    item: resultItem,
                    searchTextCount: searchTextCount,
                    hitCount: hitCount,
                    id: resultItems.length
                  });
                }
              })
            };
            if (keywords.length === 1 && keywords[0] === "") {
              resultContent.innerHTML = '<div id="no-result"><i class="fa fa-search fa-5x"></i></div>'
            } else if (resultItems.length === 0) {
              resultContent.innerHTML = '<div id="no-result"><i class="fa fa-frown-o fa-5x"></i></div>'
            } else {
              resultItems.sort(function (resultLeft, resultRight) {
                if (resultLeft.searchTextCount !== resultRight.searchTextCount) {
                  return resultRight.searchTextCount - resultLeft.searchTextCount;
                } else if (resultLeft.hitCount !== resultRight.hitCount) {
                  return resultRight.hitCount - resultLeft.hitCount;
                } else {
                  return resultRight.id - resultLeft.id;
                }
              });
              var searchResultList = '<ul class=\"search-result-list\">';
              resultItems.forEach(function (result) {
                searchResultList += result.item;
              })
              searchResultList += "</ul>";
              resultContent.innerHTML = searchResultList;
            }
          }

          if ('auto' === 'auto') {
            input.addEventListener('input', inputEventFunction);
          } else {
            $('.search-icon').click(inputEventFunction);
            input.addEventListener('keypress', function (event) {
              if (event.keyCode === 13) {
                inputEventFunction();
              }
            });
          }

          // remove loading animation
          $(".local-search-pop-overlay").remove();
          $('body').css('overflow', '');

          proceedsearch();
        }
      });
    }

    // handle and trigger popup window;
    $('.popup-trigger').click(function(e) {
      e.stopPropagation();
      if (isfetched === false) {
        searchFunc(path, 'local-search-input', 'local-search-result');
      } else {
        proceedsearch();
      };
    });

    $('.popup-btn-close').click(onPopupClose);
    $('.popup').click(function(e){
      e.stopPropagation();
    });
    $(document).on('keyup', function (event) {
      var shouldDismissSearchPopup = event.which === 27 &&
        $('.search-popup').is(':visible');
      if (shouldDismissSearchPopup) {
        onPopupClose();
      }
    });
  </script>





  

  

  
  

  
  
    
      
    
      
    
      
    
      
    
      
    
      
    
      
    
      
    
      
    
      
    
  

  
    
      <script type="text/x-mathjax-config">
  

  MathJax.Hub.Config({
    tex2jax: {
      inlineMath: [ ['$', '$'], ['\\(', '\\)'] ],
      processEscapes: true,
      skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
    },
    TeX: {
      
      equationNumbers: {
        autoNumber: 'AMS'
      }
    }
  });
  MathJax.Hub.Register.StartupHook('TeX Jax Ready', function() {
    MathJax.InputJax.TeX.prefilterHooks.Add(function(data) {
      if (data.display) {
        var next = data.script.nextSibling;
        while (next && next.nodeName.toLowerCase() === '#text') { next = next.nextSibling }
        if (next && next.nodeName.toLowerCase() === 'br') { next.parentNode.removeChild(next) }
      }
    });
  });
</script>

<script type="text/x-mathjax-config">
  MathJax.Hub.Queue(function() {
    var all = MathJax.Hub.getAllJax(), i;
    for (i = 0; i < all.length; i += 1) {
      document.getElementById(all[i].inputID + '-Frame').parentNode.className += ' has-jax';
    }
  });
</script>
<script src="//cdn.jsdelivr.net/npm/mathjax@2/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script><!-- hexo-inject:begin --><!-- Begin: Injected MathJax -->
<script type="text/x-mathjax-config">
  MathJax.Hub.Config({"tex2jax":{"inlineMath":[["$","$"],["\\(","\\)"]],"skipTags":["script","noscript","style","textarea","pre","code"],"processEscapes":true},"TeX":{"equationNumbers":{"autoNumber":"AMS"}}});
</script>

<script type="text/x-mathjax-config">
  MathJax.Hub.Queue(function() {
    var all = MathJax.Hub.getAllJax(), i;
    for(i=0; i < all.length; i += 1) {
      all[i].SourceElement().parentNode.className += ' has-jax';
    }
  });
</script>

<script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js">
</script>
<!-- End: Injected MathJax -->
<!-- hexo-inject:end -->

    
  


  

  

  

  

  

  

  

  

  

  

  

</body>
</html>
