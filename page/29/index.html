<!DOCTYPE html>












  


<html class="theme-next mist use-motion" lang="zh-CN">
<head><meta name="generator" content="Hexo 3.9.0">
  <!-- hexo-inject:begin --><!-- hexo-inject:end --><meta charset="UTF-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">






















<link rel="stylesheet" href="/lib/font-awesome/css/font-awesome.min.css?v=4.7.0">

<link rel="stylesheet" href="/css/main.css?v=7.2.0">


  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png?v=7.2.0">


  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png?v=7.2.0">


  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png?v=7.2.0">


  <link rel="mask-icon" href="/images/logo.svg?v=7.2.0" color="#222">







<script id="hexo.configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '/',
    scheme: 'Mist',
    version: '7.2.0',
    sidebar: {"position":"left","display":"post","offset":12,"onmobile":false,"dimmer":false},
    back2top: true,
    back2top_sidebar: false,
    fancybox: false,
    fastclick: false,
    lazyload: false,
    tabs: true,
    motion: {"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},
    algolia: {
      applicationID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    }
  };
</script>


  




  <meta name="description" content="Record and Think!">
<meta property="og:type" content="website">
<meta property="og:title" content="Schwimmer&#39;s Blog">
<meta property="og:url" content="https://schwimmer.github.io/page/29/index.html">
<meta property="og:site_name" content="Schwimmer&#39;s Blog">
<meta property="og:description" content="Record and Think!">
<meta property="og:locale" content="zh-CN">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Schwimmer&#39;s Blog">
<meta name="twitter:description" content="Record and Think!">





  
  
  <link rel="canonical" href="https://schwimmer.github.io/page/29/">



<script id="page.configurations">
  CONFIG.page = {
    sidebar: "",
  };
</script>

  <title>Schwimmer's Blog</title>
  




  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-143240576-1"></script>
  <script>
    var host = window.location.hostname;
    if (host !== "localhost" || !true) {
      window.dataLayer = window.dataLayer || [];
      function gtag(){dataLayer.push(arguments);}
      gtag('js', new Date());
      gtag('config', 'UA-143240576-1');
    }
  </script>









  <noscript>
  <style>
  .use-motion .motion-element,
  .use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-title { opacity: initial; }

  .use-motion .logo,
  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript><!-- hexo-inject:begin --><!-- hexo-inject:end -->

</head>

<body itemscope="" itemtype="http://schema.org/WebPage" lang="zh-CN">

  
  
    
  

  <!-- hexo-inject:begin --><!-- hexo-inject:end --><div class="container sidebar-position-left 
  page-home">
    <div class="headband"></div>

    <header id="header" class="header" itemscope="" itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-wrapper">
  <div class="site-meta">
    

    <div class="custom-logo-site-title">
      <a href="/" class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">Schwimmer's Blog</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
    
    
  </div>

  <div class="site-nav-toggle">
    <button aria-label="切换导航栏">
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
    </button>
  </div>
</div>



<nav class="site-nav">
  
    <ul id="menu" class="menu">
      
        
        
        
          
          <li class="menu-item menu-item-home">

    
    
      
    

    

    <a href="/" rel="section"><i class="menu-item-icon fa fa-fw fa-home"></i> <br>首页</a>

  </li>
        
        
        
          
          <li class="menu-item menu-item-tags">

    
    
      
    

    

    <a href="/tags/" rel="section"><i class="menu-item-icon fa fa-fw fa-tags"></i> <br>标签</a>

  </li>
        
        
        
          
          <li class="menu-item menu-item-categories">

    
    
      
    

    

    <a href="/categories/" rel="section"><i class="menu-item-icon fa fa-fw fa-th"></i> <br>分类</a>

  </li>
        
        
        
          
          <li class="menu-item menu-item-archives">

    
    
      
    

    

    <a href="/archives/" rel="section"><i class="menu-item-icon fa fa-fw fa-archive"></i> <br>归档</a>

  </li>

      
      
        <li class="menu-item menu-item-search">
          
            <a href="javascript:;" class="popup-trigger">
          
            
              <i class="menu-item-icon fa fa-search fa-fw"></i> <br>搜索</a>
        </li>
      
    </ul>
  

  
    

  

  
    <div class="site-search">
      
  <div class="popup search-popup local-search-popup">
  <div class="local-search-header clearfix">
    <span class="search-icon">
      <i class="fa fa-search"></i>
    </span>
    <span class="popup-btn-close">
      <i class="fa fa-times-circle"></i>
    </span>
    <div class="local-search-input-wrapper">
      <input autocomplete="off" placeholder="搜索..." spellcheck="false" type="text" id="local-search-input">
    </div>
  </div>
  <div id="local-search-result"></div>
</div>



    </div>
  
</nav>



  



</div>
    </header>

    


    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          
          <div id="content" class="content">
            
  <section id="posts" class="posts-expand">
    
      

  

  
  
  

  

  <article class="post post-type-normal" itemscope="" itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="https://schwimmer.github.io/2017/07/12/hadoop-spark/spark/spark笔记/">

    <span hidden itemprop="author" itemscope="" itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Schwimmer">
      <meta itemprop="description" content="Record and Think!">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope="" itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Schwimmer's Blog">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                
                <a href="/2017/07/12/hadoop-spark/spark/spark笔记/" class="post-title-link" itemprop="url">spark笔记</a>
              
            
          </h1>
        

        <div class="post-meta">

          
          
          

          
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              

              
                
              

              <time title="创建时间：2017-07-12 11:49:53" itemprop="dateCreated datePublished" datetime="2017-07-12T11:49:53+08:00">2017-07-12</time>
            </span>
          

          
            

            
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="fa fa-calendar-check-o"></i>
                </span>
                
                  <span class="post-meta-item-text">更新于</span>
                
                <time title="修改时间：2019-04-15 09:30:56" itemprop="dateModified" datetime="2019-04-15T09:30:56+08:00">2019-04-15</time>
              </span>
            
          

          
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope="" itemtype="http://schema.org/Thing"><a href="/categories/hadoop-spark/" itemprop="url" rel="index"><span itemprop="name">hadoop-spark</span></a></span>

                
                
              
            </span>
          

          
            
            
              
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="fa fa-comment-o"></i>
                </span>
            
                <span class="post-meta-item-text">评论数：</span>
                <a href="/2017/07/12/hadoop-spark/spark/spark笔记/#comments" itemprop="discussionUrl">
                  <span class="post-comments-count disqus-comment-count" data-disqus-identifier="2017/07/12/hadoop-spark/spark/spark笔记/" itemprop="commentCount"></span>
                </a>
              </span>
            
          

          
          

          

          <br>
          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1 id="算圆周率pi"><a href="#算圆周率pi" class="headerlink" title="算圆周率pi"></a>算圆周率pi</h1><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"><span class="keyword">import</span> org.apache.spark.<span class="type">SparkConf</span>;</span><br><span class="line"><span class="keyword">import</span>  org.apache.spark.<span class="type">SparkContext</span>;</span><br><span class="line"><span class="keyword">case</span>  <span class="class"><span class="keyword">class</span> <span class="title">PerTypeson</span>[<span class="type">T</span>,<span class="type">S</span>](<span class="params">var name:<span class="type">T</span>,var age:<span class="type">S</span></span>) </span>&#123;&#125;</span><br><span class="line"><span class="class"><span class="keyword">object</span>   <span class="title">SparkTest</span></span>&#123;</span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">main</span></span>(args: <span class="type">Array</span>[<span class="type">String</span>]) &#123;</span><br><span class="line">    <span class="keyword">val</span> conf = <span class="keyword">new</span> <span class="type">SparkConf</span>().setAppName(<span class="string">"Spark Pi"</span>).setMaster(<span class="string">"local"</span>)   <span class="comment">//关键</span></span><br><span class="line">    <span class="keyword">val</span> sc = <span class="keyword">new</span> <span class="type">SparkContext</span>(conf)</span><br><span class="line">    <span class="keyword">val</span>   <span class="type">NUM_SAMPLES</span>=<span class="number">100000</span></span><br><span class="line">    <span class="keyword">val</span>   count=sc.parallelize(<span class="number">1</span> to <span class="type">NUM_SAMPLES</span>).map&#123;i=&gt;</span><br><span class="line">       <span class="keyword">val</span> x=<span class="type">Math</span>.random()</span><br><span class="line">      <span class="keyword">val</span>  y=<span class="type">Math</span>.random()</span><br><span class="line">      <span class="keyword">if</span>(x*x+y*y&lt;<span class="number">1</span>)<span class="number">1</span> <span class="keyword">else</span> <span class="number">0</span></span><br><span class="line">    &#125;.reduce(_+_)</span><br><span class="line">    println(<span class="string">"pi is rougly"</span>+<span class="number">4.0</span>*count/<span class="type">NUM_SAMPLES</span>)</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h1 id="读取外部文件和链接数据库"><a href="#读取外部文件和链接数据库" class="headerlink" title="读取外部文件和链接数据库"></a>读取外部文件和链接数据库</h1><p>（用spark 1.6的版本）</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> org.apache.spark.<span class="type">SparkConf</span>;</span><br><span class="line"><span class="keyword">import</span>  org.apache.spark.<span class="type">SparkContext</span></span><br><span class="line"><span class="keyword">import</span> org.apache.spark.ml.classification.<span class="type">LogisticRegression</span></span><br><span class="line"><span class="keyword">import</span>  org.apache.spark.sql.<span class="type">SQLContext</span></span><br><span class="line"><span class="keyword">import</span> scala.collection.mutable.<span class="type">Map</span></span><br><span class="line"><span class="keyword">case</span>  <span class="class"><span class="keyword">class</span> <span class="title">Person</span>(<span class="params">var name:<span class="type">String</span></span>)</span></span><br><span class="line"><span class="class"><span class="title">object</span>   <span class="title">SparkTest</span></span>&#123;</span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">main</span></span>(args: <span class="type">Array</span>[<span class="type">String</span>]) &#123;</span><br><span class="line">    <span class="comment">//    val conf = new SparkConf().setAppName("Spark Pi").setMaster("spark://hadoop:7070")   //关键</span></span><br><span class="line">    <span class="keyword">val</span> conf = <span class="keyword">new</span> <span class="type">SparkConf</span>().setAppName(<span class="string">"Spark Pi"</span>).setMaster(<span class="string">"local"</span>)   <span class="comment">//关键</span></span><br><span class="line">    <span class="keyword">val</span> sc = <span class="keyword">new</span> <span class="type">SparkContext</span>(conf)</span><br><span class="line"><span class="comment">//     val  textfile=sc.textFile("C:\\Users\\Administrator\\Desktop\\分词.txt")</span></span><br><span class="line"><span class="comment">//      textfile.collect().foreach(println)</span></span><br><span class="line">    <span class="keyword">val</span> sqlContext=<span class="keyword">new</span>  <span class="type">SQLContext</span>(sc)</span><br><span class="line">   <span class="keyword">val</span>  df=sqlContext.read.json(<span class="string">"F:\\people.json"</span>)</span><br><span class="line">    df.cache()</span><br><span class="line">   println(df.select(<span class="string">"age"</span>).show())</span><br><span class="line">    df.registerTempTable(<span class="string">"df1"</span>)</span><br><span class="line">    println(sqlContext.sql(<span class="string">"select * from  df1  where  age=19"</span>))</span><br><span class="line">    <span class="keyword">val</span>  map=<span class="type">Map</span>(<span class="string">"url"</span> -&gt; <span class="string">"jdbc:mysql://localhost:3306/test"</span>,</span><br><span class="line">      <span class="string">"user"</span>-&gt;<span class="string">"root"</span>,<span class="string">"password"</span>-&gt;<span class="string">""</span>)</span><br><span class="line">     map+=(<span class="string">"dbtable"</span> -&gt;<span class="string">"class"</span>)</span><br><span class="line">     <span class="string">"dbtable"</span> -&gt; <span class="string">"SELECT * FROM iteblog"</span></span><br><span class="line">    <span class="keyword">val</span>  jdbc=sqlContext.read.format(<span class="string">"jdbc"</span>).options(map).load()</span><br><span class="line">    println(jdbc.show(<span class="number">1</span>))</span><br><span class="line"><span class="comment">//    val lr = new LogisticRegression().setMaxIter(10)</span></span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h1 id="创建DataFrame并简单操作DataFrame"><a href="#创建DataFrame并简单操作DataFrame" class="headerlink" title="创建DataFrame并简单操作DataFrame"></a>创建DataFrame并简单操作DataFrame</h1><p>spark2.0就可以直接用RDD.toDF</p>
<p>spark1.6需要sqlContext.createDataFrame(sc.parallelize(data)).toDF(“id”, “features”, “clicked”)</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> org.apache.spark.<span class="type">SparkConf</span>;</span><br><span class="line"><span class="keyword">import</span>  org.apache.spark.<span class="type">SparkContext</span></span><br><span class="line"><span class="keyword">import</span> org.apache.spark.ml.classification.<span class="type">LogisticRegression</span></span><br><span class="line"><span class="keyword">import</span>  org.apache.spark.sql.<span class="type">SQLContext</span></span><br><span class="line"><span class="keyword">import</span> scala.collection.mutable.<span class="type">Map</span></span><br><span class="line"><span class="keyword">case</span>  <span class="class"><span class="keyword">class</span> <span class="title">Person</span>(<span class="params">var name:<span class="type">String</span></span>)</span></span><br><span class="line"><span class="class"><span class="title">case</span> <span class="title">class</span> <span class="title">Employee</span>(<span class="params">age: <span class="type">Int</span>, name: <span class="type">String</span></span>)</span></span><br><span class="line"><span class="class"><span class="title">object</span>   <span class="title">SparkTest</span></span>&#123;</span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">main</span></span>(args: <span class="type">Array</span>[<span class="type">String</span>]) &#123;</span><br><span class="line">    <span class="comment">//    val conf = new SparkConf().setAppName("Spark Pi").setMaster("spark://hadoop:7070")   //关键</span></span><br><span class="line">    <span class="keyword">val</span> conf = <span class="keyword">new</span> <span class="type">SparkConf</span>().setAppName(<span class="string">"Spark Pi"</span>).setMaster(<span class="string">"local"</span>)   <span class="comment">//关键</span></span><br><span class="line">    <span class="keyword">val</span> sc = <span class="keyword">new</span> <span class="type">SparkContext</span>(conf)</span><br><span class="line">    <span class="keyword">val</span> sqlContext=<span class="keyword">new</span> <span class="type">SQLContext</span>(sc)</span><br><span class="line">    <span class="comment">//第一种方式就创建DataFrame，读取外部文件</span></span><br><span class="line">    println(<span class="string">"第一种方式就创建DataFrame，读取外部文件"</span>)</span><br><span class="line">     <span class="keyword">val</span>  textfile=sc.textFile(<span class="string">"C:\\Users\\Administrator\\Desktop\\分词.txt"</span>)</span><br><span class="line">     <span class="keyword">val</span>  df_person=textfile.map(x=&gt;<span class="type">Person</span>(x))</span><br><span class="line">    <span class="keyword">val</span>  df_test=sqlContext.createDataFrame(df_person).withColumnRenamed(<span class="string">"name"</span>,<span class="string">"anmoyi"</span>)</span><br><span class="line">    println(df_test.filter(df_test(<span class="string">"anmoyi"</span>).contains(<span class="string">"使用"</span>)).count())</span><br><span class="line">    <span class="comment">//第二种方式创建DataFrame</span></span><br><span class="line">    println(<span class="string">"第二种方式创建DataFrame，通过List和case类的方式创建"</span>)</span><br><span class="line">    <span class="keyword">val</span>  listOfEmployee=<span class="type">List</span>(<span class="type">Employee</span>(<span class="number">1</span>,<span class="string">"zhou"</span>),<span class="type">Employee</span>(<span class="number">1</span>,<span class="string">"zhou"</span>),<span class="type">Employee</span>(<span class="number">2</span>,<span class="string">"mei"</span>),<span class="type">Employee</span>(<span class="number">3</span>,<span class="string">"xu"</span>))</span><br><span class="line">    <span class="keyword">val</span>  emFrame=sqlContext.createDataFrame(listOfEmployee)</span><br><span class="line">    println(emFrame.show())</span><br><span class="line">    emFrame.registerTempTable(<span class="string">"employeeTable"</span>)</span><br><span class="line">    <span class="keyword">val</span> sortedByNameEmployees = sqlContext.sql(<span class="string">"select * from employeeTable order by name desc"</span>)</span><br><span class="line">    println(sortedByNameEmployees.show())</span><br><span class="line">    println(emFrame.groupBy(<span class="string">"age"</span>).count().show())</span><br><span class="line">    println(emFrame.select(emFrame(<span class="string">"name"</span>),emFrame(<span class="string">"age"</span>),(emFrame(<span class="string">"age"</span>)+<span class="number">1</span>).as(<span class="string">"age1"</span>)).show())</span><br><span class="line">    println(sortedByNameEmployees.show())</span><br><span class="line">    <span class="comment">//第三种方式通过TupleN来创建DataFrame</span></span><br><span class="line">    println(<span class="string">"第三种方式通过TupleN，元祖的方式来创建DataFrame"</span>)</span><br><span class="line">    <span class="keyword">val</span> mobiles=sqlContext.createDataFrame(<span class="type">Seq</span>((<span class="number">1</span>,<span class="string">"Android"</span>), (<span class="number">2</span>, <span class="string">"iPhone"</span>))).toDF(<span class="string">"age"</span>,<span class="string">"mobile"</span>)</span><br><span class="line">    println(mobiles.show())</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h1 id="DataFrame转列的数据类型"><a href="#DataFrame转列的数据类型" class="headerlink" title="DataFrame转列的数据类型"></a>DataFrame转列的数据类型</h1><p><a href="https://blog.csdn.net/dkl12/article/details/80256585" target="_blank" rel="noopener">https://blog.csdn.net/dkl12/article/details/80256585</a></p>
<p>转所有列</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">import org.apache.spark.sql.functions._</span><br><span class="line"></span><br><span class="line">val cols = colNames.map(f =&gt; col(f).cast(DoubleType))</span><br><span class="line">df.select(cols: _*).show()</span><br></pre></td></tr></table></figure>
<p>转指定列</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">val name = &quot;col1,col3,col5&quot;</span><br><span class="line">df.select(name.split(&quot;,&quot;).map(name =&gt; col(name)): _*).show()</span><br><span class="line">df.select(name.split(&quot;,&quot;).map(name =&gt; col(name).cast(DoubleType)): _*).show()</span><br></pre></td></tr></table></figure>
<h1 id="Spark中统计相关的东西"><a href="#Spark中统计相关的东西" class="headerlink" title="Spark中统计相关的东西"></a>Spark中统计相关的东西</h1><p>spark shell中增加依赖包   <code>bin/spark-shell --packages com.databricks:spark-csv_2.10:1.0.3</code>  </p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span>  org.apache.spark.<span class="type">SparkConf</span></span><br><span class="line"><span class="keyword">import</span>  org.apache.spark.<span class="type">SparkContext</span></span><br><span class="line"><span class="keyword">import</span>  org.apache.spark.sql.<span class="type">SQLContext</span></span><br><span class="line"><span class="keyword">import</span> org.apache.spark.sql.functions._   <span class="comment">//包含了常见的统计函数和数学函数</span></span><br><span class="line"><span class="keyword">import</span> org.apache.log4j.&#123;<span class="type">Level</span>, <span class="type">Logger</span>&#125;</span><br><span class="line"><span class="comment">//import com.databricks.spark.csv._</span></span><br><span class="line"><span class="class"><span class="keyword">object</span> <span class="title">Test</span> </span>&#123;</span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">main</span></span>(args: <span class="type">Array</span>[<span class="type">String</span>]):<span class="type">Unit</span>=&#123;</span><br><span class="line"><span class="comment">// 屏蔽不必要的日志显示在终端上</span></span><br><span class="line"><span class="type">Logger</span>.getLogger(<span class="string">"org.apache.spark"</span>).setLevel(<span class="type">Level</span>.<span class="type">WARN</span>)</span><br><span class="line"><span class="type">Logger</span>.getLogger(<span class="string">"org.eclipse.jetty.server"</span>).setLevel(<span class="type">Level</span>.<span class="type">OFF</span>)</span><br><span class="line">    <span class="keyword">val</span> conf = <span class="keyword">new</span> <span class="type">SparkConf</span>().setAppName(<span class="string">"stastic"</span>).setMaster(<span class="string">"local"</span>)   <span class="comment">//关键</span></span><br><span class="line">    <span class="keyword">val</span> sc = <span class="keyword">new</span> <span class="type">SparkContext</span>(conf)</span><br><span class="line">    <span class="keyword">val</span> sqlContext=<span class="keyword">new</span> <span class="type">SQLContext</span>(sc)</span><br><span class="line">    <span class="keyword">import</span> sqlContext.implicits._ <span class="comment">//用于隐式转化，可以由RDD直接转换为DataFrame</span></span><br><span class="line">    <span class="keyword">val</span> df = sc.parallelize(<span class="number">0</span> until <span class="number">10</span>).toDF(<span class="string">"id"</span>).withColumn(<span class="string">"rand1"</span>, rand(<span class="number">10</span>))</span><br><span class="line">      .withColumn(<span class="string">"rand2"</span>, rand(seed=<span class="number">27</span>)).withColumn(<span class="string">"rand3"</span>,rand(<span class="number">20</span>))</span><br><span class="line">    println(df.columns)</span><br><span class="line">    println(df.describe().show())</span><br></pre></td></tr></table></figure>
<h1 id="Spark中的多对多JOIN"><a href="#Spark中的多对多JOIN" class="headerlink" title="Spark中的多对多JOIN"></a>Spark中的多对多JOIN</h1><p>如果存在多对多的情况下，则是以乘法得到最后结果，并不是以某列多的情况</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">val</span>  df2=sc.parallelize(<span class="number">0</span> until <span class="number">6</span>).toDF(<span class="string">"id"</span>).withColumn(<span class="string">"age"</span>,rand(<span class="number">10</span>))</span><br><span class="line">println(df.join(df2,df(<span class="string">"id"</span>)===df2(<span class="string">"id"</span>),<span class="string">"left"</span>).show())  <span class="comment">//左链接</span></span><br><span class="line">println(df.join(df2,df(<span class="string">"id"</span>)===df2(<span class="string">"id"</span>),<span class="string">"right"</span>).show())  <span class="comment">//右链接</span></span><br><span class="line">println(df.join(df2,df(<span class="string">"id"</span>)===df2(<span class="string">"id"</span>),<span class="string">"outer"</span>).show()) <span class="comment">//全链接</span></span><br><span class="line">println(df.join(df2,df(<span class="string">"id"</span>)===df2(<span class="string">"id"</span>),<span class="string">"inner"</span>).show())  <span class="comment">//inner 链接</span></span><br><span class="line">df.join(df2, $<span class="string">"df1Key"</span> === $<span class="string">"df2Key"</span>)</span><br><span class="line">df.join(df2).where($<span class="string">"df1Key"</span> === $<span class="string">"df2Key"</span>)</span><br><span class="line">df.join(df2, <span class="type">Seq</span>(<span class="string">"user_id"</span>, <span class="string">"user_name"</span>))</span><br><span class="line">    println(<span class="string">"统计函数开始"</span>)</span><br><span class="line">    println(df.groupBy($<span class="string">"id"</span>).agg(<span class="type">Map</span>(</span><br><span class="line">      <span class="string">"rand1"</span> -&gt; <span class="string">"avg"</span>,</span><br><span class="line">      <span class="string">"rand2"</span> -&gt; <span class="string">"max"</span>,</span><br><span class="line">      <span class="string">"rand3"</span> -&gt; <span class="string">"min"</span></span><br><span class="line">    )).show())</span><br><span class="line">    println(df.drop(<span class="string">"rand1"</span>).show())</span><br><span class="line">    println(df.stat.corr(<span class="string">"rand1"</span>,<span class="string">"rand2"</span>))</span><br><span class="line">    println(df.stat.cov(<span class="string">"rand1"</span>, <span class="string">"rand2"</span>))</span><br><span class="line">    <span class="keyword">val</span>  df1=sqlContext.createDataFrame(<span class="type">Seq</span>((<span class="number">1</span>, <span class="number">1</span>), (<span class="number">1</span>, <span class="number">2</span>), (<span class="number">2</span>, <span class="number">1</span>), (<span class="number">2</span>, <span class="number">1</span>), (<span class="number">2</span>, <span class="number">3</span>), (<span class="number">3</span>, <span class="number">2</span>),</span><br><span class="line">      (<span class="number">3</span>, <span class="number">3</span>))).toDF(<span class="string">"key"</span>, <span class="string">"value"</span>)</span><br><span class="line">    println(df1.stat.crosstab(<span class="string">"key"</span>,<span class="string">"value"</span>).show())</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h1 id="pyspark"><a href="#pyspark" class="headerlink" title="pyspark"></a>pyspark</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> pyspark <span class="keyword">import</span> SparkContext</span><br><span class="line">sc = SparkContext(<span class="string">"local"</span>, <span class="string">"Simple App"</span>)</span><br><span class="line">rdd = sc.parallelize([<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>])</span><br><span class="line">rdd.collect()</span><br><span class="line"><span class="comment">#[1, 2, 3]</span></span><br><span class="line">rdd1 = rdd.map(<span class="keyword">lambda</span> x : x+<span class="number">1</span>)</span><br><span class="line">rdd1.collect()</span><br><span class="line"><span class="comment">#[2, 3, 4]</span></span><br></pre></td></tr></table></figure>
<h1 id="spark作业提交"><a href="#spark作业提交" class="headerlink" title="spark作业提交"></a>spark作业提交</h1><p>以WordCount为例说明RDD从转换到作业提交的过程</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sc.textFile(<span class="string">"/User/david/key.txt"</span>).flatMap(line=&gt;line.split(<span class="string">" "</span>)).map(word=&gt;(word,<span class="number">1</span>)).reduceByKey(_+_)</span><br></pre></td></tr></table></figure>
<p>步骤1：<code>val rawFile = sc.textFile(&quot;/User/david/key.txt&quot;)</code></p>
<p>textFile先生成HadoopRDD，然后再通过map操作生成MappedRDD。在spark-shell中可以看到</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">scala&gt; val rawFile = sc.textFile(&quot;/User/david/key.txt&quot;)</span><br><span class="line">rawFile: org.apache.spark.rdd.RDD[String] = /User/david/key.txt MapPartitionsRDD[3] at textFile at &lt;console&gt;:27</span><br><span class="line">1.6.3版本变成了MapPartitionsRDD</span><br></pre></td></tr></table></figure>
<p>步骤2：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">val splittedText = rawFile.flatMap(line=&gt;line.split(&quot; &quot;))</span><br></pre></td></tr></table></figure>
<p>flatMap将原来的MappedRDD转换为FlatMappedRDD。</p>
<p>步骤3</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">val wordCount = splittedText.map(word=&gt;(word,1))</span><br></pre></td></tr></table></figure>
<p>步骤4：<code>reduceByKey</code></p>
<h2 id="作业执行"><a href="#作业执行" class="headerlink" title="作业执行"></a>作业执行</h2><p>spark执行中相关概念</p>
<p><a href="https://blog.csdn.net/u013013024/article/details/72876427" target="_blank" rel="noopener">Spark中Task，Partition，RDD、节点数、Executor数、core数目的关系和Application，Driver，Job，Task，Stage理解</a></p>
<p><img src="http://www.zezhi.net/wp-content/uploads/2016/04/spark-learning.png" alt=""></p>
<p>若干个block合并成一个输入分片InputSplit，一个InputSplit对应一个Task，一个Task生成一个Partition。</p>
<p>随后这些具体的Task每个都会被分配到集群上的某个节点的某个<strong>Executor</strong>去执行。</p>
<ul>
<li>每个节点可以启一个或多个Executor。</li>
<li>每个Executor由若干<strong>core</strong>组成，每个Executor的每个core<strong>一次只能执行一个</strong>Task。</li>
<li>每个<strong>Task</strong>执行的结果就是生成了目标<strong>RDD</strong>的一个<strong>partiton</strong>。每个partition再下一步又由一个task来执行。</li>
</ul>
<p><strong>注意: </strong>这里的core是虚拟的core而不是机器的物理CPU核，可以理解为就是Executor的一个工作线程。</p>
<p>而 Task被执行的并发度 = Executor数目 * 每个Executor核数。</p>
<p>所以，如果一共要执行8个task，但只有一个Executor，2个core，则并发度是2。那么需要分成4个批次，每次并发执行两个Task。</p>
<p>至于<strong>partition的数目</strong>：</p>
<ul>
<li>对于数据读入阶段，例如sc.textFile，输入文件被划分为多少InputSplit就会需要多少初始Task。</li>
<li>在Map阶段partition数目保持不变。</li>
<li>在Reduce阶段，RDD的聚合会触发shuffle操作，聚合后的RDD的partition数目跟具体操作有关，例如repartition操作会聚合成指定分区数，还有一些算子是可配置的。</li>
</ul>
<p>在任务提交中主要涉及Driver和Executor两个节点。</p>
<p><strong>Driver</strong>可以理解为我们自己编写的程序。主要解决</p>
<ul>
<li>RDD依赖性分析，以生成DAG</li>
<li>根据RDD DAG将Job分割为多个stage</li>
<li>Stage确认后，生成相应的task，分发到Executor执行。</li>
</ul>
<p><strong>Executor</strong>：在每个WorkerNode上为某应用启动的一个进程，是一个执行task的容器。一个Executor执行多个Task。</p>
<p>另外</p>
<p><strong>Job</strong>：包含很多task的并行计算，可以认为<strong>是Spark RDD 里面的action</strong>,每个action的计算会生成一个job。</p>
<p>　　用户提交的Job会提交给DAGScheduler，Job会被分解成Stage和Task。</p>
<p> Spark中的Job和MR中Job不一样。MR中Job主要是Map或者Reduce Job。而<strong>Spark的Job其实很好区别，一个action算子就算一个Job</strong>，比方说count，first等。</p>
<p><strong>Stage</strong>：</p>
<p><strong>一个Job会被拆分为多组Task，每组任务被称为一个Stage就像Map Stage， Reduce Stage</strong>。</p>
<p>　　Stage的划分在RDD的论文中有详细的介绍，简单的说是以shuffle和result这两种类型来划分。在Spark中有两类task，一类是shuffleMapTask，一类是resultTask，第一类task的输出是shuffle所需数据，第二类task的输出是result，stage的划分也以此为依据，shuffle之前的所有变换是一个stage，shuffle之后的操作是另一个stage。比如 rdd.parallize(1 to 10).foreach(println) 这个操作没有shuffle，直接就输出了，那么只有它的task是resultTask，stage也只有一个；如果是rdd.map(x =&gt; (x, 1)).reduceByKey(<em> + </em>).foreach(println), 这个job因为有reduce，所以有一个shuffle过程，那么reduceByKey之前的是一个stage，执行shuffleMapTask，输出shuffle所需的数据，reduceByKey到最后是一个stage，直接就输出结果了。如果job中有多次shuffle，那么每个shuffle之前都是一个stage。</p>
<p><strong>Task</strong></p>
<p>即 stage 下的一个任务执行单元，一般来说，<strong>一个 rdd 有多少个 partition，就会有多少个 task</strong>，因为每一个 task 只是处理一个 partition 上的数据.</p>
<h3 id="依赖性分析和stage划分"><a href="#依赖性分析和stage划分" class="headerlink" title="依赖性分析和stage划分"></a>依赖性分析和stage划分</h3><p>RDD之间的依赖分为窄依赖和宽依赖。</p>
<p>窄依赖是指父RDD所有输出都会被执行的子RDD消费，也就是输出路径固定。例如如下的Transformation：</p>
<p>map、flatMap、filter、sample</p>
<p>宽依赖是指父RDD输出会由不同子RDD消费，输出路径不固定。例如：</p>
<p>sortByKey、reduceByKey、groupByKey、cogroupByKey、join、cartensian</p>
<p>调度器（Scheduler）会计算RDD之间的依赖关系，将窄依赖的RDD归并到同一个stage，而宽依赖则作为划分不同Stage的判断标准。<strong>宽依赖和窄依赖的边界就是stage的划分点</strong></p>
<h2 id="任务的创建和分发"><a href="#任务的创建和分发" class="headerlink" title="任务的创建和分发"></a>任务的创建和分发</h2><p>由Executor执行的Task分为ShuffleMapTask和ResultTask两种，相当于Map和Reduce。</p>
<h1 id="RDD-API合集"><a href="#RDD-API合集" class="headerlink" title="RDD API合集"></a>RDD API合集</h1><p><a href="https://blog.csdn.net/xiefu5hh/article/details/51781074" target="_blank" rel="noopener">Spark JAVA RDD API 最全合集整理</a></p>
<p><a href="https://blog.csdn.net/guotong1988/article/details/50555185" target="_blank" rel="noopener">Spark API 详解/大白话解释 之 map、mapPartitions、mapValues、mapWith、flatMap、flatMapWith、flatMapValues</a></p>
<p><a href="https://blog.csdn.net/guotong1988/article/details/50554034" target="_blank" rel="noopener">Spark API 详解/大白话解释 之 RDD、partition、count、collect</a></p>
<h1 id="flatMap和map"><a href="#flatMap和map" class="headerlink" title="flatMap和map"></a>flatMap和map</h1><p><a href="http://blog.csdn.net/sicofield/article/details/50914050" target="_blank" rel="noopener">Spark之中map与flatMap的区别</a></p>
<p>map的作用就是对rdd之中的元素进行逐一进行函数操作映射为另外一个rdd。</p>
<p>flatMap的操作是将函数应用于rdd之中的每一个元素，将返回的<strong>迭代器</strong>的所有内容构成新的rdd。通常用来切分单词。</p>
<p><img src="http://img.blog.csdn.net/20160317150619505" alt=""></p>
<p>传递给flatMap的函数返回的类型是一个可迭代的类型（例如list）。</p>
<p><img src="http://img.blog.csdn.net/20160317151021948" alt=""></p>
<p><em>map会返回多个数组对象，flatmap返回一个</em></p>
<p>map函数会对每一条输入进行指定的操作，然后为每一条输入返回一个对象；而flatMap函数则是两个操作的集合——正是“先映射后扁平化”：</p>
<p>操作1：同map函数一样：对每一条输入进行指定的操作，然后为每一条输入返回一个对象</p>
<p>操作2：最后将所有对象合并为一个对象</p>
<h1 id="reduce和reduceByKey"><a href="#reduce和reduceByKey" class="headerlink" title="reduce和reduceByKey"></a>reduce和reduceByKey</h1><p>转自<a href="https://blog.csdn.net/guotong1988/article/details/50555671" target="_blank" rel="noopener">https://blog.csdn.net/guotong1988/article/details/50555671</a></p>
<p>reduce</p>
<p>reduce将RDD中元素前两个传给输入函数，产生一个新的return值，新产生的return值与RDD中下一个元素（第三个元素）组成两个元素，再被传给输入函数，直到最后只有一个值为止。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">val c = sc.parallelize(1 to 10)</span><br><span class="line">c.reduce((x, y) =&gt; x + y)//结果55</span><br></pre></td></tr></table></figure>
<p>具体过程，RDD有1 2 3 4 5 6 7 8 9 10个元素，<br>1+2=3<br>3+3=6<br>6+4=10<br>10+5=15<br>15+6=21<br>21+7=28<br>28+8=36<br>36+9=45<br>45+10=55</p>
<p>reduceByKey</p>
<p>reduceByKey就是对元素为KV对的RDD中Key相同的元素的Value进行binary_function的reduce操作，因此，Key相同的多个元素的值被reduce为一个值，然后与原RDD中的Key组成一个新的KV对。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">val a = sc.parallelize(List((1,2),(1,3),(3,4),(3,6)))</span><br><span class="line">a.reduceByKey((x,y) =&gt; x + y).collect</span><br></pre></td></tr></table></figure>
<p>结果 Array((1,5), (3,10))</p>
<h1 id="设置打印日志级别"><a href="#设置打印日志级别" class="headerlink" title="设置打印日志级别"></a>设置打印日志级别</h1><p>如果是log4j日志</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">import org.apache.log4j.&#123; Level, Logger &#125;</span><br><span class="line"></span><br><span class="line">Logger.getLogger(&quot;org.apache.spark&quot;).setLevel(Level.WARN)</span><br><span class="line">Logger.getLogger(&quot;org.eclipse.jetty.server&quot;).setLevel(Level.OFF)</span><br></pre></td></tr></table></figure>
<p>如果是console日志</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">val sc = new SparkContext(conf)</span><br><span class="line">sc.setLogLevel(&quot;WARN&quot;)</span><br></pre></td></tr></table></figure>
<h1 id="ml和mllib"><a href="#ml和mllib" class="headerlink" title="ml和mllib"></a>ml和mllib</h1><p><a href="https://www.cnblogs.com/itboys/p/6860953.html" target="_blank" rel="noopener">https://www.cnblogs.com/itboys/p/6860953.html</a></p>
<p>ml主要操作的是DataFrame, 而mllib操作的是RDD，也就是说二者面向的数据集不一样。相比于mllib在RDD提供的基础操作，ml在DataFrame上的抽象级别更高，数据和操作耦合度更低。</p>
<p> ml中的操作可以使用pipeline, 跟sklearn一样，可以把很多操作(算法/特征提取/特征转换)以管道的形式串起来，然后让数据在这个管道中流动。</p>
<p>ml中无论是什么模型，都提供了统一的算法操作接口，比如模型训练都是<code>fit</code>；不像mllib中不同模型会有各种各样的<code>trainXXX</code>。</p>
<p>mllib在spark2.0之后进入<code>维护状态</code>, 这个状态通常只修复BUG不增加新功能。</p>
<h1 id="cache的作用"><a href="#cache的作用" class="headerlink" title="cache的作用"></a>cache的作用</h1><p><a href="https://blog.csdn.net/Allenalex/article/details/79431047" target="_blank" rel="noopener">https://blog.csdn.net/Allenalex/article/details/79431047</a></p>
<p>如果要缓存的RDD太大的话，即使调用cache()，Spark也可能会丢掉和重新计算RDD的部分。所以在大的程序中，最后是使用RDD.filter(x=&gt;x&gt;0).persist(StorageLevel.MEMORY_AND_DISK)。</p>
<h1 id="性能调优"><a href="#性能调优" class="headerlink" title="性能调优"></a>性能调优</h1><p><a href="https://blog.csdn.net/u014236541/article/details/78834148" target="_blank" rel="noopener">Spark性能调优之合理设置并行度</a></p>
<p><a href="https://www.iteblog.com/archives/1657.html" target="_blank" rel="noopener">Spark性能优化：开发调优篇</a></p>
<p><a href="https://blog.csdn.net/stark_summer/article/details/42981201" target="_blank" rel="noopener">spark内核揭秘-14-Spark性能优化的10大问题及其解决方案</a></p>
<p><a href="https://blog.csdn.net/dax1n/article/details/53431373" target="_blank" rel="noopener">Spark 重分区函数：coalesce和repartition区别与实现，可以优化Spark程序性能</a></p>
<p><a href="https://blog.csdn.net/lalaguozhe/article/details/9053645" target="_blank" rel="noopener">Hive小文件合并调研</a></p>
<p><a href="https://blog.csdn.net/u010039929/article/details/68067194" target="_blank" rel="noopener">数据倾斜方案-全面</a></p>
<h1 id="shuffle解析"><a href="#shuffle解析" class="headerlink" title="shuffle解析"></a>shuffle解析</h1><p><a href="https://www.cnblogs.com/cenyuhai/p/3826227.html" target="_blank" rel="noopener">Spark源码系列（六）Shuffle的过程解析</a></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">java.math.BigDecimal cannot be cast to java.lang.String</span><br></pre></td></tr></table></figure>
<p>但是并没有bigDecimal类型的数据</p>
<h1 id="如何避免spark-dataframe的JOIN操作之后产生重复列"><a href="#如何避免spark-dataframe的JOIN操作之后产生重复列" class="headerlink" title="如何避免spark dataframe的JOIN操作之后产生重复列"></a>如何避免spark dataframe的JOIN操作之后产生重复列</h1><p><a href="https://blog.csdn.net/sparkexpert/article/details/52837269" target="_blank" rel="noopener">https://blog.csdn.net/sparkexpert/article/details/52837269</a></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">df.join(df2, Seq(&quot;key1&quot;, &quot;key2&quot;), &quot;left_outer&quot;).show()</span><br></pre></td></tr></table></figure>
<h1 id="DataFrame-Join"><a href="#DataFrame-Join" class="headerlink" title="DataFrame Join"></a>DataFrame Join</h1><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">val baseinfoContactDF = baseinfoDF.join(gpsDF, Seq(&quot;app_no&quot;), &quot;left_outer&quot;).na.fill(0.0)</span><br><span class="line"></span><br><span class="line">personDataFrame.join(orderDataFrame, personDataFrame(&quot;id_person&quot;) === orderDataFrame(&quot;id_person&quot;), &quot;inner&quot;).show()</span><br></pre></td></tr></table></figure>
<h1 id="spark-dataframe新增一列的四种方法"><a href="#spark-dataframe新增一列的四种方法" class="headerlink" title="spark dataframe新增一列的四种方法"></a>spark dataframe新增一列的四种方法</h1><p><a href="https://blog.csdn.net/li3xiao3jie2/article/details/81317249" target="_blank" rel="noopener">https://blog.csdn.net/li3xiao3jie2/article/details/81317249</a></p>
<h1 id="spark序列化问题"><a href="#spark序列化问题" class="headerlink" title="spark序列化问题"></a>spark序列化问题</h1><p><a href="https://blog.csdn.net/HFUTLXM/article/details/78621406" target="_blank" rel="noopener">https://blog.csdn.net/HFUTLXM/article/details/78621406</a></p>
<p>（一）理解spark闭包</p>
<p>什么叫闭包： 跨作用域访问函数变量。又指的一个拥有许多变量和绑定了这些变量的环境的表达式（通常是一个函数），因而这些变量也是该表达式的一部分。</p>
<p>Spark闭包的问题引出：<br>在spark中实现统计List(1,2,3)的和。如果使用下面的代码，程序打印的结果不是6，而是0。这个和我们编写单机程序的认识有很大不同。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">object Test &#123;</span><br><span class="line">  def main(args:Array[String]):Unit = &#123;</span><br><span class="line">      val conf = new SparkConf().setAppName(&quot;test&quot;);</span><br><span class="line">      val sc = new SparkContext(conf)</span><br><span class="line"> </span><br><span class="line">      val rdd = sc.parallelize(List(1,2,3))</span><br><span class="line">      var counter = 0</span><br><span class="line">      //warn: don&apos;t do this</span><br><span class="line">      rdd.foreach(x =&gt; counter += x)</span><br><span class="line">      println(&quot;Counter value: &quot;+counter)</span><br><span class="line">      sc.stop()</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>我也遇到类似情况，在RDD中实例化一个类并赋值，最后出来的结果会有问题</p>
<p>问题分析：<br>counter是在foreach函数外部定义的，也就是<strong>在driver程序中定义</strong>，而foreach函数是属于rdd对象的，rdd函数的执行位置是各个worker节点（或者说worker进程），main函数是在driver节点上（或者说driver进程上）执行的，所以当counter变量在driver中定义，被在rdd中使用的时候，出现了变量的“跨域”问题，也就是闭包问题。</p>
<h1 id="spark输出的part文件数量"><a href="#spark输出的part文件数量" class="headerlink" title="spark输出的part文件数量"></a>spark输出的part文件数量</h1><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">new SparkConf().setAppName(&quot;InstallAndPickup&quot;).set(&quot;spark.sql.shuffle.partitions&quot;, &quot;5&quot;)</span><br></pre></td></tr></table></figure>
<p>通过这个参数控制</p>

          
        
      
    </div>

    

    
    
    

    

    
      
    
    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  

  <article class="post post-type-normal" itemscope="" itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="https://schwimmer.github.io/2017/07/12/机器学习/NLP/网页关键词提取/">

    <span hidden itemprop="author" itemscope="" itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Schwimmer">
      <meta itemprop="description" content="Record and Think!">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope="" itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Schwimmer's Blog">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                
                <a href="/2017/07/12/机器学习/NLP/网页关键词提取/" class="post-title-link" itemprop="url">网页关键词提取</a>
              
            
          </h1>
        

        <div class="post-meta">

          
          
          

          
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              

              
                
              

              <time title="创建时间：2017-07-12 11:49:53" itemprop="dateCreated datePublished" datetime="2017-07-12T11:49:53+08:00">2017-07-12</time>
            </span>
          

          
            

            
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="fa fa-calendar-check-o"></i>
                </span>
                
                  <span class="post-meta-item-text">更新于</span>
                
                <time title="修改时间：2018-03-31 10:28:31" itemprop="dateModified" datetime="2018-03-31T10:28:31+08:00">2018-03-31</time>
              </span>
            
          

          
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope="" itemtype="http://schema.org/Thing"><a href="/categories/NLP/" itemprop="url" rel="index"><span itemprop="name">NLP</span></a></span>

                
                
              
            </span>
          

          
            
            
              
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="fa fa-comment-o"></i>
                </span>
            
                <span class="post-meta-item-text">评论数：</span>
                <a href="/2017/07/12/机器学习/NLP/网页关键词提取/#comments" itemprop="discussionUrl">
                  <span class="post-comments-count disqus-comment-count" data-disqus-identifier="2017/07/12/机器学习/NLP/网页关键词提取/" itemprop="commentCount"></span>
                </a>
              </span>
            
          

          
          

          

          <br>
          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>代码位于<code>nlp</code> 项目</p>
<h1 id="jsoup解析html的DOM"><a href="#jsoup解析html的DOM" class="headerlink" title="jsoup解析html的DOM"></a>jsoup解析html的DOM</h1><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Document doc =Jsoup.connect(url).userAgent(&quot;Mozilla&quot;).get();</span><br></pre></td></tr></table></figure>
<h1 id="提取网页"><a href="#提取网页" class="headerlink" title="提取网页"></a>提取网页</h1><p><code>getPageDetail</code>获取网页提取的结果，返回<code>WebPageInfo</code>类，该类包括</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> String domain;</span><br><span class="line"><span class="keyword">public</span> String url;</span><br><span class="line"><span class="keyword">public</span> String rawTitle;</span><br><span class="line"><span class="keyword">public</span> String title;</span><br><span class="line"><span class="keyword">public</span> String content;</span><br><span class="line"><span class="keyword">public</span> String summary;</span><br><span class="line"><span class="keyword">public</span> HashMap&lt;String, String&gt; meta;</span><br><span class="line"><span class="keyword">public</span> HashMap&lt;String, List&lt;String&gt;&gt; calculation;</span><br><span class="line"><span class="keyword">public</span> <span class="keyword">long</span> freq = <span class="number">1</span>;</span><br><span class="line"><span class="keyword">public</span> String createTime;</span><br></pre></td></tr></table></figure>
<p><code>meta_desc</code>，来自网页meta的<code>description</code>元素</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">meta.put(&quot;description&quot;, meta_desc);</span><br></pre></td></tr></table></figure>
<p><code>meta_keywords</code>，来自网页meta的<code>keywords</code> </p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">meta.put(&quot;keywords&quot;, meta_keywords);</span><br></pre></td></tr></table></figure>
<h2 id="标题"><a href="#标题" class="headerlink" title="标题"></a>标题</h2><p><code>rawTitle=doc.title()</code></p>
<p><code>title</code>，通过<code>ExtractUtil.extractTitle(doc.body(), rawTitle)</code>进一步抽取。目的是去掉标题中的无关信息，如网站信息等</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">extractTitle</span></span>(root: <span class="type">Element</span>, rawTitle:<span class="type">String</span>): <span class="type">String</span> = &#123;</span><br><span class="line">    <span class="keyword">if</span>(<span class="type">StringUtils</span>.isBlank(rawTitle)) </span><br><span class="line">      <span class="keyword">return</span> <span class="string">""</span>;</span><br><span class="line">    <span class="keyword">val</span> titleCnt = <span class="keyword">new</span> <span class="type">HashMap</span>[<span class="type">String</span>, <span class="type">Int</span>] <span class="keyword">with</span> <span class="type">HashMapUtil</span>.<span class="type">IntHashMap</span>[<span class="type">String</span>]</span><br><span class="line">    titleCnt.adjustOrPut(te.extract(rawTitle).trim, <span class="number">1</span>, <span class="number">1</span>)</span><br><span class="line">    titleCnt.adjustOrPut(te.extractFirst(rawTitle).trim, <span class="number">1</span>, <span class="number">1</span>)</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">val</span> tq = <span class="keyword">new</span> <span class="type">PriorityQueue</span>[<span class="type">String</span>](<span class="number">2</span>)</span><br><span class="line">    extractTitle0(root, rawTitle, <span class="number">1</span>, tq)</span><br><span class="line">    <span class="keyword">for</span> (candidate &lt;- tq.values) titleCnt.adjustOrPut(candidate.trim, <span class="number">1</span>, <span class="number">1</span>)</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">var</span> maxCnt = <span class="number">0</span></span><br><span class="line">    <span class="keyword">var</span> title = rawTitle</span><br><span class="line">    titleCnt.foreach &#123; <span class="keyword">case</span> (candidate, cnt) =&gt;</span><br><span class="line">      <span class="keyword">if</span> (maxCnt &lt; cnt) &#123;</span><br><span class="line">        maxCnt = cnt</span><br><span class="line">        title = candidate</span><br><span class="line">      &#125;</span><br><span class="line">      <span class="keyword">if</span> (maxCnt == cnt &amp;&amp; candidate.length &gt; title.length) title = candidate</span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line">    title</span><br><span class="line">  &#125;</span><br></pre></td></tr></table></figure>
<p><code>te.extract</code>，</p>
<p>首先要<code>split</code>。通过判断unicode字符的类别（<a href="http://blog.csdn.net/weixin_36082485/article/details/53154065" target="_blank" rel="noopener">Unicode字符类</a>）来分割标题 </p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; title.length(); i++) &#123;</span><br><span class="line">			<span class="keyword">char</span> ch = title.charAt(i);</span><br><span class="line">			<span class="keyword">int</span> type = Character.getType(ch);</span><br><span class="line">  			<span class="comment">// 标点，前引号</span></span><br><span class="line">			<span class="keyword">if</span> (type == Character.INITIAL_QUOTE_PUNCTUATION) quoteCnt++;</span><br><span class="line">  			<span class="comment">// 标点，开始</span></span><br><span class="line">			<span class="keyword">if</span> (type == Character.START_PUNCTUATION) quoteCnt++;</span><br><span class="line">			<span class="keyword">if</span> (quoteCnt == <span class="number">0</span> &amp;&amp; !lastLetter &amp;&amp; !lastDigit &amp;&amp; splitChars.contains(ch)) &#123;</span><br><span class="line">				parts.add(title.substring(last, i));</span><br><span class="line">				last = i + <span class="number">1</span>;</span><br><span class="line">			&#125;</span><br><span class="line">  			<span class="comment">// 标点，后引号</span></span><br><span class="line">			<span class="keyword">if</span> (type == Character.FINAL_QUOTE_PUNCTUATION) quoteCnt--;</span><br><span class="line">  			<span class="comment">// 标点，结束</span></span><br><span class="line">			<span class="keyword">if</span> (type == Character.END_PUNCTUATION) quoteCnt--;</span><br><span class="line">			<span class="keyword">if</span> (ch &gt;= <span class="string">'A'</span> &amp;&amp; ch &lt;= <span class="string">'Z'</span> || ch &gt;= <span class="string">'a'</span> &amp;&amp; ch &lt;= <span class="string">'z'</span>) lastLetter = <span class="keyword">true</span>;</span><br><span class="line">			<span class="keyword">else</span> lastLetter = <span class="keyword">false</span>;</span><br><span class="line">			<span class="keyword">if</span> (Character.isDigit(ch)) lastDigit = <span class="keyword">true</span>;</span><br><span class="line">			<span class="keyword">else</span> <span class="keyword">if</span> (!splitChars.contains(ch)) lastDigit = <span class="keyword">false</span>;</span><br><span class="line">		&#125;</span><br></pre></td></tr></table></figure>
<p>然后提取最长的part。提取的原则是，</p>
<p>1、如果出现不重要的字符前缀后缀<code>ignoreSuffixes</code>、<code>ignorePrefixes</code>，降低part的长度</p>
<p>2、第一个part的长度翻倍，可能是考虑到真的标题往往出现在第一块，如</p>
<p><code>清润饮食“熄灭”冬季之火 - 素食 - 大渡网-佛教资讯，生活，人文，心灵感悟，佛艺时尚杂志，佛教音乐，佛教常识，佛教视频</code></p>
<p><code>从草根到精英——大陆网络民族主义流变-观点评论-时事评论-四月网-青年思想门户-M4.CN</code></p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">private</span> <span class="keyword">static</span> List&lt;String&gt; ignoreSuffixes = Arrays.asList(<span class="string">"频道"</span>, <span class="string">"站"</span>, <span class="string">"网"</span>, <span class="string">"报"</span>, <span class="string">"集"</span>, <span class="string">"公司"</span>, <span class="string">".com"</span>, <span class="string">".cn"</span>, <span class="string">"平台"</span>, <span class="string">"门户"</span>, <span class="string">"博客"</span>, <span class="string">"精选"</span>, <span class="string">"博客精选"</span>);</span><br><span class="line">	<span class="keyword">private</span> <span class="keyword">static</span> List&lt;String&gt; ignorePrefixes = Arrays.asList(<span class="string">"Powered by"</span>);</span><br><span class="line">	<span class="keyword">private</span> <span class="keyword">static</span> HashSet&lt;Character&gt; splitChars = <span class="keyword">new</span> HashSet&lt;Character&gt;(Arrays.asList(<span class="string">'|'</span>, <span class="string">'_'</span>, <span class="string">'-'</span>, <span class="string">'—'</span>, <span class="string">'－'</span>, <span class="string">'&lt;'</span>, <span class="string">'&gt;'</span>, <span class="string">'«'</span>, <span class="string">'»'</span>));</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">private</span> String <span class="title">getLongestPart</span><span class="params">(List&lt;String&gt; parts)</span> </span>&#123;</span><br><span class="line">		<span class="keyword">double</span> longestNumWords = <span class="number">0</span>;</span><br><span class="line">		String longestPart = <span class="string">""</span>;</span><br><span class="line">		<span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; parts.size(); i++) &#123;</span><br><span class="line">			String p = parts.get(i).trim();</span><br><span class="line">			</span><br><span class="line">			<span class="keyword">int</span> ignoreCount = <span class="number">0</span>;</span><br><span class="line">			<span class="keyword">for</span> (String is: ignoreSuffixes) <span class="keyword">if</span> (p.toLowerCase().endsWith(is)) ignoreCount++;</span><br><span class="line">			<span class="keyword">for</span> (String ip: ignorePrefixes) <span class="keyword">if</span> (p.toLowerCase().startsWith(ip)) ignoreCount++;</span><br><span class="line">			<span class="keyword">int</span> colonCnt = StringUtils.countMatches(p, <span class="string">","</span>);</span><br><span class="line">			<span class="keyword">if</span> (colonCnt &gt; <span class="number">0</span>) ignoreCount += colonCnt - <span class="number">1</span>;</span><br><span class="line">			colonCnt = StringUtils.countMatches(p, <span class="string">"，"</span>);</span><br><span class="line">			<span class="keyword">if</span> (colonCnt &gt; <span class="number">0</span>) ignoreCount += colonCnt - <span class="number">1</span>;</span><br><span class="line">			<span class="keyword">double</span> numWords = TextUtil.countNumWords(p);</span><br><span class="line">			numWords = numWords / (<span class="number">1</span> + <span class="number">2</span> * ignoreCount);</span><br><span class="line">			<span class="keyword">if</span> (i == <span class="number">0</span>) numWords = numWords * <span class="number">2</span>;</span><br><span class="line">            <span class="keyword">if</span> (numWords &gt; longestNumWords) &#123;</span><br><span class="line">            	longestNumWords = numWords;</span><br><span class="line">            	longestPart = p;</span><br><span class="line">            &#125;</span><br><span class="line">		&#125;</span><br><span class="line">		<span class="keyword">if</span> (longestPart.length() == <span class="number">0</span>) <span class="keyword">return</span> <span class="string">""</span>;</span><br><span class="line">		<span class="keyword">else</span> <span class="keyword">return</span> longestPart.trim();</span><br><span class="line">	&#125;</span><br></pre></td></tr></table></figure>
<p><code>extractTitle0(root, rawTitle, 1, tq)</code> </p>
<p>传入root和刚才提取的rawTitle，递归遍历root的各个head元素，<code>h</code>，<code>title</code>，每种赋值不同权重。再寻找与rawTitle的最长公共子串。</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">private</span> <span class="function"><span class="keyword">def</span> <span class="title">extractTitle0</span></span>(node: <span class="type">Node</span>, title: <span class="type">String</span>, weight: <span class="type">Double</span>, tq: <span class="type">PriorityQueue</span>[<span class="type">String</span>], depth: <span class="type">Int</span> = <span class="number">0</span>): <span class="type">Unit</span> = &#123;</span><br><span class="line">    node <span class="keyword">match</span> &#123;</span><br><span class="line">      <span class="keyword">case</span> textNode: <span class="type">TextNode</span> =&gt; &#123;</span><br><span class="line">        <span class="keyword">val</span> text = textNode.text.trim</span><br><span class="line">        <span class="keyword">if</span> (text.length &gt; <span class="number">0</span>) &#123;</span><br><span class="line">          <span class="keyword">val</span> lcs = <span class="type">TextUtil</span>.findLcs(title, text)</span><br><span class="line">          <span class="keyword">val</span> nwords = <span class="type">TextUtil</span>.countNumWords(lcs)</span><br><span class="line">          <span class="keyword">val</span> pos = title.indexOf(lcs)</span><br><span class="line">          <span class="keyword">if</span> (pos != <span class="number">-1</span> &amp;&amp; nwords &gt; <span class="number">0</span>) &#123;</span><br><span class="line">            tq.add(nwords * weight / (<span class="number">1</span> + math.log(<span class="number">2</span> + pos)), lcs)</span><br><span class="line">          &#125;</span><br><span class="line">        &#125; </span><br><span class="line">      &#125;</span><br><span class="line">      <span class="keyword">case</span> e: <span class="type">Element</span> =&gt; &#123;</span><br><span class="line">        <span class="keyword">var</span> w = weight</span><br><span class="line">        <span class="keyword">if</span> (e.tagName.startsWith(<span class="string">"h"</span>)) w = w * <span class="number">1.2</span></span><br><span class="line">        <span class="keyword">if</span> (e.tagName == <span class="string">"a"</span>) w = w / <span class="number">2</span></span><br><span class="line">        <span class="keyword">if</span> (e.className.contains(<span class="string">"title"</span>)) w = w * <span class="number">1.5</span></span><br><span class="line">        <span class="keyword">if</span> (e.tagName != <span class="string">"title"</span> &amp;&amp; !isNegativeBlock(e.className + <span class="string">" "</span> + e.id) &amp;&amp; depth &lt; <span class="type">Extract_STOP_DEPTH</span>) &#123;</span><br><span class="line">          <span class="keyword">for</span> (n &lt;- e.childNodes.asScala) extractTitle0(n, title, w, tq, depth + <span class="number">1</span>)</span><br><span class="line">        &#125;</span><br><span class="line">      &#125;</span><br><span class="line">      <span class="keyword">case</span> _ =&gt; &#123;&#125;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br></pre></td></tr></table></figure>
<p>通过以上方法提取出各种title后，选出出现频率最高的作为最终的title。</p>
<h2 id="content"><a href="#content" class="headerlink" title="content"></a>content</h2><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">extractContent</span></span>(url: <span class="type">String</span>, doc: <span class="type">Document</span>): <span class="type">List</span>[<span class="type">String</span>] = &#123;</span><br><span class="line">    <span class="keyword">val</span> rawTitle = doc.title</span><br><span class="line">    <span class="keyword">if</span>(doc.body == <span class="literal">null</span>)</span><br><span class="line">      <span class="keyword">return</span> <span class="literal">null</span></span><br><span class="line">    <span class="type">ExtractUtil</span>.cleanup(doc.body)</span><br><span class="line">    <span class="keyword">val</span> title = <span class="type">ExtractUtil</span>.extractTitle(doc.body, rawTitle)</span><br><span class="line">    <span class="keyword">val</span> metaKeywords = <span class="type">ExtractUtil</span>.extractMeta(doc, <span class="string">"keywords"</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">val</span> blocks = <span class="type">ExtractUtil</span>.extractBlocks(doc, title) map &#123; block =&gt;</span><br><span class="line">      <span class="type">SnippetBlock</span>(block.snippets map &#123; snippet =&gt; <span class="type">TextProcess</span>.normalize(urlReg.matcher(snippet).replaceAll(<span class="string">""</span>)) &#125;, block.score, block.isArticle, block.imgs)</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">val</span> normalTitle = <span class="type">TextUtil</span>.fillText(title)</span><br><span class="line">    <span class="keyword">val</span> normalRawTitle = <span class="type">TextUtil</span>.fillText(doc.title)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">val</span> allsnippets = blocks.filter(_.isArticle).flatMap &#123; b =&gt; b.snippets &#125;</span><br><span class="line">    <span class="keyword">return</span> allsnippets;</span><br><span class="line">  &#125;</span><br></pre></td></tr></table></figure>
<h3 id="清洗doc"><a href="#清洗doc" class="headerlink" title="清洗doc"></a>清洗doc</h3><p><code>ExtractUtil.cleanup(doc.body)</code></p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">cleanup</span></span>(root: <span class="type">Element</span>): <span class="type">Unit</span> = &#123;</span><br><span class="line">    <span class="keyword">val</span> cleanNodes = <span class="keyword">for</span> &#123;</span><br><span class="line">      e &lt;- root.getAllElements.asScala</span><br><span class="line">      <span class="keyword">if</span> <span class="type">INVALID_TAGS</span>.contains(e.tagName) || e.attr(<span class="string">"style"</span>).contains(<span class="string">"display:none"</span>)</span><br><span class="line">    &#125; <span class="keyword">yield</span> e</span><br><span class="line">    <span class="keyword">for</span> (cn &lt;- cleanNodes) cn.remove</span><br><span class="line">  &#125;</span><br></pre></td></tr></table></figure>
<h3 id="提取title、metakeywords"><a href="#提取title、metakeywords" class="headerlink" title="提取title、metakeywords"></a>提取title、metakeywords</h3><h3 id="提取blocks"><a href="#提取blocks" class="headerlink" title="提取blocks"></a>提取blocks</h3><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">extractBlocks</span></span>(doc: <span class="type">Document</span>, title: <span class="type">String</span>): <span class="type">List</span>[<span class="type">SnippetBlock</span>] = &#123;</span><br><span class="line">    <span class="keyword">val</span> blocks = <span class="keyword">new</span> <span class="type">ListBuffer</span>[<span class="type">BlockDetail</span>]</span><br><span class="line">    <span class="keyword">val</span> bd = <span class="keyword">new</span> <span class="type">BlockDetailBuffer</span></span><br><span class="line">    extractBlocks(doc.body, blocks, bd)</span><br><span class="line">    <span class="keyword">if</span> (bd.isDefined) blocks += bd.result</span><br><span class="line">    calcScore(title, blocks.result filterNot(b =&gt; hasICP(b))) ++ <span class="type">List</span>(<span class="type">SnippetBlock</span>(<span class="type">List</span>(extractMeta(doc, <span class="string">"keywords"</span>)), <span class="number">1</span>d, <span class="literal">true</span>, <span class="type">List</span>()), <span class="type">SnippetBlock</span>(<span class="type">List</span>(extractMeta(doc, <span class="string">"description"</span>)), <span class="number">0</span>d, <span class="literal">false</span>, <span class="type">List</span>()))</span><br><span class="line">  &#125;</span><br></pre></td></tr></table></figure>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">private</span> <span class="function"><span class="keyword">def</span> <span class="title">extractBlocks</span></span>(root: <span class="type">Node</span>, blocks: <span class="type">ListBuffer</span>[<span class="type">BlockDetail</span>], bd: <span class="type">BlockDetailBuffer</span>, inLink: <span class="type">Boolean</span> = <span class="literal">false</span>, depth: <span class="type">Int</span> = <span class="number">0</span>): <span class="type">Unit</span> = &#123;</span><br><span class="line">  root <span class="keyword">match</span> &#123;</span><br><span class="line">    <span class="keyword">case</span> tn: <span class="type">TextNode</span> =&gt; &#123;</span><br><span class="line">      <span class="keyword">val</span> text = <span class="type">StringUtils</span>.replace(tn.text, <span class="string">"\u00a0"</span>, <span class="string">" "</span>).trim</span><br><span class="line">      <span class="keyword">if</span> (text.length &gt; <span class="number">0</span>) bd.add(text, inLink)</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">case</span> e: <span class="type">Element</span> =&gt; &#123;</span><br><span class="line">      <span class="keyword">val</span> isLink = inLink || (e.tagName == <span class="string">"a"</span>) </span><br><span class="line">      <span class="keyword">if</span>(depth &lt; <span class="type">Extract_STOP_DEPTH</span>)&#123;</span><br><span class="line">      	e.childNodes.asScala foreach &#123; c =&gt; extractBlocks(c, blocks, bd, isLink, depth + <span class="number">1</span>) &#125;</span><br><span class="line">      &#125;</span><br><span class="line">      </span><br><span class="line">      <span class="keyword">if</span> (e.tagName == <span class="string">"img"</span> || e.tagName == <span class="string">"embed"</span>) &#123;</span><br><span class="line">        bd.addImg(e)</span><br><span class="line">      &#125;</span><br><span class="line">      <span class="keyword">if</span> (e.isBlock) &#123;</span><br><span class="line">        <span class="keyword">if</span> (bd.isDefined) blocks += bd.result</span><br><span class="line">        bd.clear</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">case</span> _ =&gt; &#123;&#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>提取每个TextNode的文本，放到<code>BlockDetailBuffer</code>中。将每个<code>BlockDetailBuffer</code>的内容放到<code>BlockDetail</code>的list <code>blocks</code>中。</p>
<p>过滤掉包含<code>icp备</code>或<code>icp证</code>的文本，再对所有的blocks计算打分<code>calcScore</code></p>
<p>最后提取所有是文本的snippet，作为content</p>
<h3 id="提取keywords"><a href="#提取keywords" class="headerlink" title="提取keywords"></a>提取keywords</h3><p>同样是先clean，提取title、metaKeyword，</p>
<p>再提取blocks</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">val</span> blocks:<span class="type">List</span>[<span class="type">SnippetBlock</span>] =  <span class="type">ExtractUtil</span>.extractBlocks(doc, title).map &#123; block =&gt;</span><br><span class="line">      &#123;</span><br><span class="line">              <span class="type">SnippetBlock</span>(block.snippets map &#123; snippet =&gt; <span class="type">TextProcess</span>.normalize(urlReg.matcher(snippet).replaceAll(<span class="string">""</span>)) &#125;, block.score, block.isArticle, block.imgs)</span><br><span class="line"></span><br><span class="line">	      <span class="keyword">val</span> temp  = block.snippets map &#123; snippet =&gt; <span class="type">TextProcess</span>.normalize(urlReg.matcher(snippet).replaceAll(<span class="string">""</span>)) &#125;</span><br><span class="line">	      maxLen += temp.map(<span class="type">AtomSplit</span>.count(_)).sum	</span><br><span class="line">	      <span class="keyword">val</span> retVal:<span class="type">SnippetBlock</span> = <span class="keyword">if</span>(maxLen &lt; <span class="type">MAX_CONTENT_LENGTH</span> || maxflag)&#123;<span class="type">SnippetBlock</span>(temp, block.score, block.isArticle, block.imgs)&#125; <span class="keyword">else</span> <span class="literal">null</span></span><br><span class="line">	      <span class="keyword">if</span>(maxLen &gt; <span class="type">MAX_CONTENT_LENGTH</span>)&#123;</span><br><span class="line">	        maxflag = <span class="literal">false</span></span><br><span class="line">	      &#125;</span><br><span class="line">	      retVal</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;.filter( _ != <span class="literal">null</span>)</span><br></pre></td></tr></table></figure>
<h4 id="dlg"><a href="#dlg" class="headerlink" title="dlg"></a>dlg</h4><p>再提取dlg</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">val dlg = DlgExtractor.extract(normalTitle, TextUtil.fillText(doc.title), blocks, 6)/*.filter(_._2 &gt; 1.0)*/</span><br></pre></td></tr></table></figure>
<p>分词后，计算每个词的权重，</p>
<p>First of all, for any web page, we can use jsoup to  obtain the Document Object Model (DOM) , which can access all the HTML elements of it.</p>
<p>After that，we clean up  HTML elements by drop some invalid or useless tags, such as the tags with “display:none” property. </p>
<p>At last, We extract the Content and Keywords of HTML. </p>
<p>For extracting Content, we iterate through the DOM tree to find all TextNode elements, extract the text and take them as the Snippets. Then we calculate the scores of all Snippets, and get the available Snippets as Content.</p>
<p>For extracing Keywords, besides the Snippets from TextNode elements, we also collect the title, keywords and description from <meta> tag, store them as Blocks.   For every Block, we segment words to generate the corpus by ansj_seg, and calculate the weight of every word using TFIDF. Finally, we get the TOP 10 words as Keywords of web page.</p>
<p>我们解析了10万左右的网页，根据解析的网页content打上safe和unsafe的label，后期我们会对safe和unsafe进一步细分。</p>
<p>训练过程：我们载入所有含标签的训练样本，由于fasttext提供了适用于各种语言的Word2Vec预向量集，将网页内容转为词向量，通过fasttext训练出模型并保存到本地。</p>
<p>预测过程：载入模型到内存，当输入一个网页的content后，转为词向量，根据模型给出safe或unsafe的分类结果。</p>
<p>We have analyzed some 100 thousand web pages, classified text in categories, such as safe and unsafe by content of these web pages, and we will extent more categories in future.</p>
<p>In order to train the text classifier model, we load all samples containing a training sentence per line along with the labels, and transfer all words to vectors using  pre-trained word vectors model published by fastText.  Then we use the code from Github to run the training program. Once the model was trained, we save it on disk as a file.</p>
<p>When input a content of web page, we transfer it to word vectors and run the prediction program, as a result we get the category of this web page.</p>

          
        
      
    </div>

    

    
    
    

    

    
      
    
    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  

  <article class="post post-type-normal" itemscope="" itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="https://schwimmer.github.io/2017/07/12/机器学习/面试刷题/">

    <span hidden itemprop="author" itemscope="" itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Schwimmer">
      <meta itemprop="description" content="Record and Think!">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope="" itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Schwimmer's Blog">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                
                <a href="/2017/07/12/机器学习/面试刷题/" class="post-title-link" itemprop="url">面试刷题</a>
              
            
          </h1>
        

        <div class="post-meta">

          
          
          

          
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              

              
                
              

              <time title="创建时间：2017-07-12 11:49:53" itemprop="dateCreated datePublished" datetime="2017-07-12T11:49:53+08:00">2017-07-12</time>
            </span>
          

          
            

            
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="fa fa-calendar-check-o"></i>
                </span>
                
                  <span class="post-meta-item-text">更新于</span>
                
                <time title="修改时间：2018-03-17 20:50:31" itemprop="dateModified" datetime="2018-03-17T20:50:31+08:00">2018-03-17</time>
              </span>
            
          

          
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope="" itemtype="http://schema.org/Thing"><a href="/categories/机器学习/" itemprop="url" rel="index"><span itemprop="name">机器学习</span></a></span>

                
                
              
            </span>
          

          
            
            
              
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="fa fa-comment-o"></i>
                </span>
            
                <span class="post-meta-item-text">评论数：</span>
                <a href="/2017/07/12/机器学习/面试刷题/#comments" itemprop="discussionUrl">
                  <span class="post-comments-count disqus-comment-count" data-disqus-identifier="2017/07/12/机器学习/面试刷题/" itemprop="commentCount"></span>
                </a>
              </span>
            
          

          
          

          

          <br>
          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <ol>
<li><a href="https://zhuanlan.zhihu.com/p/29965072" target="_blank" rel="noopener">那些深度学习《面试》你可能需要知道的</a></li>
<li><a href="https://zhuanlan.zhihu.com/p/29969587" target="_blank" rel="noopener">如何准备机器学习工程师的面试 ？</a></li>
<li><a href="https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/mp/homepage%3F__biz%3DMzI4MTQ2NjU5NA%3D%3D%26hid%3D1%26sn%3D93c4875b14fa5ad6f174829b2b8b4463%26scene%3D18%26devicetype%3DiPhone%2BOS9.3.5%26version%3D16051327%26lang%3Dzh_CN%26nettype%3D3G%2B%26ascene%3D7%26session_us%3Dgh_58f9504ddd59%26fontScale%3D100%26pass_ticket%3Dg8f%252FuIJqlsyfsGEdnZPm0SWWYRiZWOQHMp6bSSJ39kpkzb%252BgyByne%252BKNjMf%252Fo4pp%26wx_header%3D1%26scene%3D1" target="_blank" rel="noopener">七月在线实验室—-BAT机器学习面试题</a></li>
<li><a href="https://www.zhihu.com/question/23259302" target="_blank" rel="noopener">如何准备机器学习工程师的面试 ？</a></li>
<li><a href="https://zhuanlan.zhihu.com/p/27238249" target="_blank" rel="noopener">读完这21个机器学习面试问题和答案，入职率提升99%</a></li>
<li><a href="https://www.zhihu.com/question/25565713#answer-8243688" target="_blank" rel="noopener">国内互联网公司机器学习数据挖掘类的职位面试主要考察什么方面的东西？</a></li>
<li>….等等</li>
</ol>
<p>如何判断一个而链表中是否有环？<br>给定一棵二叉查找树中的两个元素，求它们的最近公共祖先。<br>给一个栈排序<br>基于比较的排序算法的时间复杂度是什么？证明？<br>如何求一个带权图中两个结点直接按的最短路径？如果有些权值是负的怎么办？<br>求一个字符串中所有的回文子串。<br>对这些问题你都要能够推导你的解法的时间和空间复杂度（大 O 表示法），并且尽量用最低的复杂度解决。<br><strong>只有通过大量的练习才能将这些不同类型的问题烂熟于胸，从而在面试中迅速地给出一个高效的解法。常用的算法面试准备平台有 InterviewBit、LeetCode、Interview Cake、Pramp、<a href="http://interviewing.io/" target="_blank" rel="noopener">http://interviewing.io</a> 等。</strong></p>
<p>概率论和统计典型问题</p>
<p>给出一个群体中男性和女性各自的平均身高，求整个群体的平均身高。<br>一次调查表明意大利三分之一的汽车都是法拉利，并且在那之中一半的车都是红色的。如果你在意大利的街头看到一辆红色的汽车驶来，请问它是法拉利的可能性有多大？<br>你试图找出在自己的网站上放置版头的最佳方案。变量包括版头的尺寸（大、中、小）以及放置的位置（顶部、中间、底部）。假定需要 95% 的置信水平，请问你至少需要多少次访问和点击来确定某个方案比其他的组合都要好？<br><strong>很多机器学习算法都以概率论和统计作为理论基础。对于这些基础知识有清晰的概念是极为重要的。当然同时你也要能够将这些抽象的概念与现实联系起来。</strong><br>数据建模和评估典型问题</p>
<p>一位农民想搞明白是什么因素影响了他的牛奶产量。他记录了每天的气温（30 - 40 度）、湿度（60 - 90%）、饲料消耗（2000 - 2500 千克）以及牛奶产量（500 - 1000 升）。<br>假设问题是要预测每天的牛奶产量，你会如何处理数据并建立模型？<br>这是一个什么类型的机器学习问题？<br>你的公司在开发一个面部表情识别系统。这个系统接受 1920 x 1080 的图片作为输入，并告诉用户图片中的人脸处于以下哪种情绪状态：平常、高兴、悲伤、愤怒和恐惧。当图片中没有人脸时系统要能够分辨这种情况。<br>这是一个什么类型的机器学习问题？<br>如果每个像素点由 3 个值来表示（RGB），那么输入数据的原始维度有多大？有办法降维吗？<br>如何对系统的输出进行编码？为什么？<br>过去几个世纪的气象数据展现出一种循环的气温模式：一会升高一会下降。对于这样的数据（一个年平均气温的序列），你会如何建模并预测未来 5 年的平均气温？<br>你在一家在线新闻网站工作，需要从各处收集文本，并将不同来源的内容聚集成一篇报道。你会如何设计这样一个系统？会用到哪些机器学习技术？<br><strong>应用机器学习算法和库</strong></p>
<p>你用一个给定的数据集训练一个单隐层的神经网络，发现网络的权值在训练中强烈地震荡（有时在负值和正值之间变化）。为了解决这个问题你需要调整哪个参数？<br>支持向量机的训练在本质上是在最优化哪个值？<br>LASSO 回归用 L1-norm 作为惩罚项，而岭回归（Ridge Regression）则使用 L2-norm 作为惩罚项。这两者哪个更有可能得到一个稀疏（某些项的系数为 0）的模型？<br>在用反向传播法训练一个 10 层的神经网络时，你发现前 3 层的权值完全没有变化，而 4 ~ 6 层的权值则变化得非常慢。这是为什么？如何解决？<br>你手上有一个关于小麦产出的数据集，包括年降雨量 R、平均海拔 A 以及小麦产量 O。你经过初步分析认为产量跟年降雨量的平方以及平均海报的对数之间存在关系，即：O = β_0 + β_1 x R^2 + β_2 x log(A)。能用线性回归求出系数 β 吗？<br>你可以通过像 Kaggle 比赛那样的数据科学和机器学习挑战来了解各种各样的问题和它们之间的细微差别。多多参加这些比赛，并尝试应用不同的机器学习模型。<br>软件工程和系统设计典型问题</p>
<p>你有一个电商网站，当用户点击一个商品打开详情页面时，你想基于商品特征和用户的购买历史为用户推荐 5 个其他的商品显示在页面的底部。你需要哪些服务和数据表来实现这个功能？请写一个查询语句或一段过程式代码来返回所要推荐的 5 个商品。<br>对于 YouTube 那样的在线视频网站，你会收集哪些数据来衡量用户的参与度和视频的人气度？<br>一个简单的垃圾邮件检测系统是这样的：它每次处理一封邮件，统计不同单词的出现频率（Term frequency），并将这些频率与之前已经被标注为垃圾 / 正常邮件的那些频率进行比较。现在需要对这系统进行拓展来处理海量的邮件流量，请设计一个 Map-Reduce 方案在一个集群上部署这个系统。<br>你要生成一个实时的热力图，来展示用户正在浏览和点击一个网页的哪些部分。在客户端和服务端分别需要哪些组件 / 服务 / API 来实现这个功能？</p>
<p><a href="http://blog.csdn.net/u010496169/article/details/73743973" target="_blank" rel="noopener">机器学习岗位面试问题汇总 之 集成学习</a></p>

          
        
      
    </div>

    

    
    
    

    

    
      
    
    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  

  <article class="post post-type-normal" itemscope="" itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="https://schwimmer.github.io/2017/07/12/hadoop-spark/presto笔记/">

    <span hidden itemprop="author" itemscope="" itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Schwimmer">
      <meta itemprop="description" content="Record and Think!">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope="" itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Schwimmer's Blog">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                
                <a href="/2017/07/12/hadoop-spark/presto笔记/" class="post-title-link" itemprop="url">presto笔记</a>
              
            
          </h1>
        

        <div class="post-meta">

          
          
          

          
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              

              
                
              

              <time title="创建时间：2017-07-12 11:49:53" itemprop="dateCreated datePublished" datetime="2017-07-12T11:49:53+08:00">2017-07-12</time>
            </span>
          

          
            

            
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="fa fa-calendar-check-o"></i>
                </span>
                
                  <span class="post-meta-item-text">更新于</span>
                
                <time title="修改时间：2019-06-13 15:36:33" itemprop="dateModified" datetime="2019-06-13T15:36:33+08:00">2019-06-13</time>
              </span>
            
          

          
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope="" itemtype="http://schema.org/Thing"><a href="/categories/hadoop-spark/" itemprop="url" rel="index"><span itemprop="name">hadoop-spark</span></a></span>

                
                
              
            </span>
          

          
            
            
              
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="fa fa-comment-o"></i>
                </span>
            
                <span class="post-meta-item-text">评论数：</span>
                <a href="/2017/07/12/hadoop-spark/presto笔记/#comments" itemprop="discussionUrl">
                  <span class="post-comments-count disqus-comment-count" data-disqus-identifier="2017/07/12/hadoop-spark/presto笔记/" itemprop="commentCount"></span>
                </a>
              </span>
            
          

          
          

          

          <br>
          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1 id="增加kafka配置"><a href="#增加kafka配置" class="headerlink" title="增加kafka配置"></a>增加kafka配置</h1><p>1、在<code>/opt/presto-server-0.152/etc/catalog/</code>增加文件<code>kafka.properties</code>，内容是</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">connector.name=kafka</span><br><span class="line">kafka.table-names=showup,click    </span><br><span class="line">kafka.nodes=10.11.10.33:9092</span><br><span class="line">#kafka.hide-internal-columns-hidden=false</span><br><span class="line">kafka.default-schema=rawdata</span><br></pre></td></tr></table></figure>
<p>其中，</p>
<blockquote>
<p>kafka.table-names 跟topic名称相同，如果topic是带前缀的，比如rawdata.showup，那么schema就是rawdata。</p>
<p>kafka.hide-internal-columns-hidden 建表后有一系列内置column，默认这些是隐藏的，设为false使其显示。</p>
<p>kafka.default-schema 如果topic没有前缀，默认的schema是default，可以用该参数修改默认schema名称。</p>
</blockquote>
<p>2、在etc的config.propreties中的datasources增加kafka</p>
<p>3、增加topic描述文件</p>
<p>放在<code>etc/kafka</code>目录中，以<code>.json</code>结尾，文件名和表名最好一致。例如：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line">&#123;</span><br><span class="line">    &quot;tableName&quot;: &quot;click_dis&quot;,</span><br><span class="line">    &quot;schemaName&quot;: &quot;rawdata&quot;,</span><br><span class="line">    &quot;topicName&quot;: &quot;click_dis&quot;,</span><br><span class="line">    &quot;key&quot;: &#123;</span><br><span class="line">        &quot;dataFormat&quot;: &quot;raw&quot;,</span><br><span class="line">        &quot;fields&quot;: [</span><br><span class="line">            &#123;</span><br><span class="line">                &quot;name&quot;: &quot;kafka_key&quot;,</span><br><span class="line">                &quot;type&quot;: &quot;VARCHAR&quot;,</span><br><span class="line">                &quot;hidden&quot;: &quot;false&quot;</span><br><span class="line">            &#125;</span><br><span class="line">        ]</span><br><span class="line">    &#125;,</span><br><span class="line">    &quot;message&quot;: &#123;</span><br><span class="line">        &quot;dataFormat&quot;: &quot;json&quot;,</span><br><span class="line">        &quot;fields&quot;: [</span><br><span class="line">            &#123;</span><br><span class="line">                &quot;name&quot;: &quot;dt_i&quot;,</span><br><span class="line">                &quot;mapping&quot;: &quot;dt_i&quot;,</span><br><span class="line">                &quot;type&quot;: &quot;BIGINT&quot;</span><br><span class="line">            &#125;</span><br><span class="line">        ]</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>4、重启presto服务器</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">/opt/presto-server-0.152/bin/launcher restart</span><br></pre></td></tr></table></figure>
<p>5、连接服务器测试</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">/opt/jdk1.8.0_102/bin/java -jar /opt/presto-server-0.152/presto-cli --server 10.11.10.33:8082 --catalog kafka --schema rawdata</span><br></pre></td></tr></table></figure>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">select * from click limit 10;</span><br></pre></td></tr></table></figure>
<p>其中内置column的意思是：</p>
<div class="table-container">
<table>
<thead>
<tr>
<th>Column name</th>
<th>Type</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td>_partition_id</td>
<td>BIGINT</td>
<td>包含这行数据的kafka partition的id</td>
</tr>
<tr>
<td>_partition_offset</td>
<td>BIGINT</td>
<td>kafka partition的offset</td>
</tr>
<tr>
<td>_segment_start</td>
<td>BIGINT</td>
<td>在该segment中的最小offset</td>
</tr>
<tr>
<td>_segment_end</td>
<td>BIGINT</td>
<td>在该segment中的最大offset</td>
</tr>
<tr>
<td>_segment_count</td>
<td>BIGINT</td>
<td>对于一个未压缩的topic，_segment_start + _segment_count is equal to _partition_offset</td>
</tr>
<tr>
<td>_message_corrupt</td>
<td>BOOLEAN</td>
<td>为TRUE就说明解码器不能解析message</td>
</tr>
<tr>
<td>_message</td>
<td>VARCHAR</td>
<td>UTF-8编码的string，只对text的topic有效</td>
</tr>
<tr>
<td>_message_length</td>
<td>BIGINT</td>
<td>message长度</td>
</tr>
<tr>
<td>_key_corrupt</td>
<td>BOOLEAN</td>
<td>为TRUE就说明解码器不能解析key</td>
</tr>
<tr>
<td>_key</td>
<td>VARCHAR</td>
<td>UTF-8编码的string</td>
</tr>
<tr>
<td>_key_length</td>
<td>BIGINT</td>
<td>key的长度</td>
</tr>
</tbody>
</table>
</div>
<p>查询key</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">select count(1) from showup_dis where kafka_key like &apos;20161009%&apos;;</span><br></pre></td></tr></table></figure>
<h1 id="语法"><a href="#语法" class="headerlink" title="语法"></a>语法</h1><h2 id="string转日期"><a href="#string转日期" class="headerlink" title="string转日期"></a>string转日期</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">date(b.data_date)</span><br></pre></td></tr></table></figure>
<h2 id="日期转string"><a href="#日期转string" class="headerlink" title="日期转string"></a>日期转string</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">cast(gpstime as varchar)</span><br></pre></td></tr></table></figure>
<h2 id="时间的string转timestamp"><a href="#时间的string转timestamp" class="headerlink" title="时间的string转timestamp"></a>时间的string转timestamp</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">cast(&apos;2019-03-01 12:00:00&apos; as timestamp)</span><br></pre></td></tr></table></figure>
<h2 id="日期加减"><a href="#日期加减" class="headerlink" title="日期加减"></a>日期加减</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">cast((date(b.data_date) - interval &apos;1&apos; day) as varchar)</span><br></pre></td></tr></table></figure>
<h2 id="日期转时间戳"><a href="#日期转时间戳" class="headerlink" title="日期转时间戳"></a>日期转时间戳</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">select to_unixtime(timestamp &apos;2018-12-27&apos;)*1000</span><br></pre></td></tr></table></figure>
<h2 id="两个日期相差的天数"><a href="#两个日期相差的天数" class="headerlink" title="两个日期相差的天数"></a>两个日期相差的天数</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">date_diff(&apos;day&apos;, date(last_date), date(&apos;2019-03-05&apos;))</span><br></pre></td></tr></table></figure>
<h1 id="presto-ui实现总数的统计"><a href="#presto-ui实现总数的统计" class="headerlink" title="presto ui实现总数的统计"></a>presto ui实现总数的统计</h1><p>/Users/david/david/git/yanagishima/src/main/java/yanagishima/service/PrestoServiceImpl.java</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">private</span> <span class="keyword">void</span> <span class="title">processData</span><span class="params">(StatementClient client, String datasource, String queryId, String query, PrestoQueryResult prestoQueryResult, List&lt;String&gt; columns, List&lt;List&lt;String&gt;&gt; rowDataList, <span class="keyword">long</span> start, <span class="keyword">int</span> limit, String userName)</span> </span>&#123;</span><br><span class="line">        Duration queryMaxRunTime = <span class="keyword">new</span> Duration(<span class="keyword">this</span>.yanagishimaConfig.getQueryMaxRunTimeSeconds(datasource), TimeUnit.SECONDS);</span><br><span class="line">        Path dst = getResultFilePath(datasource, queryId, <span class="keyword">false</span>);</span><br><span class="line">        <span class="keyword">int</span> lineNumber = <span class="number">0</span>;</span><br><span class="line">        <span class="keyword">int</span> maxResultFileByteSize = yanagishimaConfig.getMaxResultFileByteSize();</span><br><span class="line">        <span class="keyword">int</span> resultBytes = <span class="number">0</span>;</span><br><span class="line">        <span class="keyword">try</span> (BufferedWriter bw = Files.newBufferedWriter(dst, StandardCharsets.UTF_8);</span><br><span class="line">             CSVPrinter csvPrinter = <span class="keyword">new</span> CSVPrinter(bw, CSVFormat.EXCEL.withDelimiter(<span class="string">'\t'</span>).withNullString(<span class="string">"\\N"</span>).withRecordSeparator(System.getProperty(<span class="string">"line.separator"</span>)));) &#123;</span><br><span class="line">            csvPrinter.printRecord(columns);</span><br><span class="line">            lineNumber++;</span><br><span class="line">            <span class="keyword">while</span> (client.isRunning()) &#123;</span><br><span class="line">                Iterable&lt;List&lt;Object&gt;&gt; data = client.currentData().getData();</span><br><span class="line">                <span class="keyword">if</span> (data != <span class="keyword">null</span>) &#123;</span><br><span class="line">                    <span class="keyword">for</span>(List&lt;Object&gt; row : data) &#123;</span><br><span class="line">                        List&lt;String&gt; columnDataList = <span class="keyword">new</span> ArrayList&lt;&gt;();</span><br><span class="line">                        List&lt;Object&gt; tmpColumnDataList = row.stream().collect(Collectors.toList());</span><br><span class="line">                        <span class="keyword">for</span> (Object tmpColumnData : tmpColumnDataList) &#123;</span><br><span class="line">                            <span class="keyword">if</span> (tmpColumnData <span class="keyword">instanceof</span> Long) &#123;</span><br><span class="line">                                columnDataList.add(((Long) tmpColumnData).toString());</span><br><span class="line">                            &#125; <span class="keyword">else</span> <span class="keyword">if</span> (tmpColumnData <span class="keyword">instanceof</span> Double) &#123;</span><br><span class="line">                                <span class="keyword">if</span>(Double.isNaN((Double)tmpColumnData) || Double.isInfinite((Double) tmpColumnData)) &#123;</span><br><span class="line">                                    columnDataList.add(tmpColumnData.toString());</span><br><span class="line">                                &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">                                    columnDataList.add(BigDecimal.valueOf((Double) tmpColumnData).toPlainString());</span><br><span class="line">                                &#125;</span><br><span class="line">                            &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">                                <span class="keyword">if</span> (tmpColumnData == <span class="keyword">null</span>) &#123;</span><br><span class="line">                                    columnDataList.add(<span class="keyword">null</span>);</span><br><span class="line">                                &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">                                    columnDataList.add(tmpColumnData.toString());</span><br><span class="line">                                &#125;</span><br><span class="line">                            &#125;</span><br><span class="line">                        &#125;</span><br><span class="line">                        <span class="keyword">try</span> &#123;</span><br><span class="line">                            csvPrinter.printRecord(columnDataList);</span><br><span class="line">                            lineNumber++;</span><br><span class="line">                            resultBytes += columnDataList.toString().getBytes(StandardCharsets.UTF_8).length;</span><br><span class="line">                            <span class="keyword">if</span>(resultBytes &gt; maxResultFileByteSize) &#123;</span><br><span class="line">                                String message = String.format(<span class="string">"Result file size exceeded %s bytes. queryId=%s, datasource=%s"</span>, maxResultFileByteSize, queryId, datasource);</span><br><span class="line">                                storeError(db, datasource, <span class="string">"presto"</span>, client.currentStatusInfo().getId(), query, userName, message);</span><br><span class="line">                                <span class="keyword">throw</span> <span class="keyword">new</span> RuntimeException(message);</span><br><span class="line">                            &#125;</span><br><span class="line">                        &#125; <span class="keyword">catch</span> (IOException e) &#123;</span><br><span class="line">                            <span class="keyword">throw</span> <span class="keyword">new</span> RuntimeException(e);</span><br><span class="line">                        &#125;</span><br><span class="line">                        <span class="keyword">if</span> (client.getQuery().toLowerCase().startsWith(<span class="string">"show"</span>) || rowDataList.size() &lt; limit) &#123;</span><br><span class="line">                            rowDataList.add(columnDataList);</span><br><span class="line">                        &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">                            prestoQueryResult.setWarningMessage(String.format(<span class="string">"now fetch size is %d. This is more than %d. So, fetch operation stopped."</span>, rowDataList.size(), limit));</span><br><span class="line">                        &#125;</span><br><span class="line">                    &#125;</span><br><span class="line">                &#125;</span><br><span class="line">                client.advance();</span><br><span class="line">                checkTimeout(db, queryMaxRunTime, start, datasource, <span class="string">"presto"</span>, queryId, query, userName);</span><br><span class="line">            &#125;</span><br><span class="line">        &#125; <span class="keyword">catch</span> (IOException e) &#123;</span><br><span class="line">            <span class="keyword">throw</span> <span class="keyword">new</span> RuntimeException(e);</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        prestoQueryResult.setLineNumber(lineNumber);</span><br><span class="line">        <span class="keyword">try</span> &#123;</span><br><span class="line">            <span class="keyword">long</span> size = Files.size(dst);</span><br><span class="line">            DataSize rawDataSize = <span class="keyword">new</span> DataSize(size, DataSize.Unit.BYTE);</span><br><span class="line">            prestoQueryResult.setRawDataSize(rawDataSize.convertToMostSuccinctDataSize());</span><br><span class="line">        &#125; <span class="keyword">catch</span> (IOException e) &#123;</span><br><span class="line">            <span class="keyword">throw</span> <span class="keyword">new</span> RuntimeException(e);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br></pre></td></tr></table></figure>
<h1 id="空值替换"><a href="#空值替换" class="headerlink" title="空值替换"></a>空值替换</h1><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">coalesce</span><br></pre></td></tr></table></figure>

          
        
      
    </div>

    

    
    
    

    

    
      
    
    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  

  <article class="post post-type-normal" itemscope="" itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="https://schwimmer.github.io/2017/07/12/算法与数据结构/最长公共子串/">

    <span hidden itemprop="author" itemscope="" itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Schwimmer">
      <meta itemprop="description" content="Record and Think!">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope="" itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Schwimmer's Blog">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                
                <a href="/2017/07/12/算法与数据结构/最长公共子串/" class="post-title-link" itemprop="url">最长公共子串</a>
              
            
          </h1>
        

        <div class="post-meta">

          
          
          

          
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              

              
                
              

              <time title="创建时间：2017-07-12 11:49:53" itemprop="dateCreated datePublished" datetime="2017-07-12T11:49:53+08:00">2017-07-12</time>
            </span>
          

          
            

            
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="fa fa-calendar-check-o"></i>
                </span>
                
                  <span class="post-meta-item-text">更新于</span>
                
                <time title="修改时间：2018-03-17 20:50:31" itemprop="dateModified" datetime="2018-03-17T20:50:31+08:00">2018-03-17</time>
              </span>
            
          

          
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope="" itemtype="http://schema.org/Thing"><a href="/categories/算法与数据结构/" itemprop="url" rel="index"><span itemprop="name">算法与数据结构</span></a></span>

                
                
              
            </span>
          

          
            
            
              
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="fa fa-comment-o"></i>
                </span>
            
                <span class="post-meta-item-text">评论数：</span>
                <a href="/2017/07/12/算法与数据结构/最长公共子串/#comments" itemprop="discussionUrl">
                  <span class="post-comments-count disqus-comment-count" data-disqus-identifier="2017/07/12/算法与数据结构/最长公共子串/" itemprop="commentCount"></span>
                </a>
              </span>
            
          

          
          

          

          <br>
          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>找出最长子串，需要知道子串的<strong>起始位置</strong>和子串的<strong>长度</strong>。</p>
<p>因此，维护一个二维数组，存放两个字符串的字符关系，再创建两个变量存放index和maxLen。</p>
<p><img src="https://segmentfault.com/img/remote/1460000007963599?w=684&amp;h=644" alt=""></p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">static</span> String <span class="title">findLcsNew</span><span class="params">(String str1, String str2)</span> </span>&#123;</span><br><span class="line">		<span class="keyword">int</span> len1, len2;</span><br><span class="line">		len1 = str1.length();</span><br><span class="line">		len2 = str2.length();</span><br><span class="line">		</span><br><span class="line">		<span class="keyword">int</span> maxLen = <span class="number">0</span>, index = <span class="number">0</span>;</span><br><span class="line">		<span class="keyword">int</span>[][] arr = <span class="keyword">new</span> <span class="keyword">int</span>[len1 + <span class="number">1</span>][len2 + <span class="number">1</span>];</span><br><span class="line">		</span><br><span class="line">		<span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; len1; i++) &#123;</span><br><span class="line">			<span class="keyword">for</span> (<span class="keyword">int</span> j = <span class="number">0</span>; j &lt; len2; j++) &#123;</span><br><span class="line">				<span class="keyword">if</span> ( i == <span class="number">0</span> || j == <span class="number">0</span> ) &#123;</span><br><span class="line">                  <span class="comment">// 第一行和第一列都是0</span></span><br><span class="line">					arr[i][j] = <span class="number">0</span>;</span><br><span class="line">				&#125; <span class="keyword">else</span> &#123;</span><br><span class="line">                  <span class="comment">// 该字符和上一个字符均相等时</span></span><br><span class="line">					<span class="keyword">if</span> (str1.charAt(i) == str2.charAt(j) &amp;&amp; str1.charAt(i-<span class="number">1</span>) == str2.charAt(j-<span class="number">1</span>)) &#123;</span><br><span class="line">						arr[i][j] = arr[i-<span class="number">1</span>][j-<span class="number">1</span>] + <span class="number">1</span>;</span><br><span class="line">					&#125; <span class="keyword">else</span> &#123;</span><br><span class="line">						arr[i][j] = <span class="number">0</span>;</span><br><span class="line">					&#125;</span><br><span class="line">				&#125;</span><br><span class="line">				</span><br><span class="line">				<span class="keyword">if</span> (arr[i][j] &gt; maxLen) &#123;</span><br><span class="line">					maxLen = arr[i][j];</span><br><span class="line">					index = i;</span><br><span class="line">				&#125;</span><br><span class="line">			&#125;</span><br><span class="line">		&#125;</span><br><span class="line">		</span><br><span class="line">		String newStr = str1.substring(index - maxLen, index + <span class="number">1</span>);</span><br><span class="line">		</span><br><span class="line">		<span class="keyword">return</span> newStr;</span><br><span class="line">	&#125;</span><br></pre></td></tr></table></figure>
<p>也可以用一维数组实现，同时可以记录多个相同长度的最长子串</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">static</span> String <span class="title">findLcs</span><span class="params">(String str1, String str2)</span> </span>&#123;</span><br><span class="line">	StringBuffer buff = <span class="keyword">new</span> StringBuffer();</span><br><span class="line">	<span class="keyword">int</span> i, j;</span><br><span class="line">	<span class="keyword">int</span> len1, len2;</span><br><span class="line">	len1 = str1.length();</span><br><span class="line">	len2 = str2.length();</span><br><span class="line">	<span class="keyword">int</span> maxLen = len1 &gt; len2 ? len1 : len2;</span><br><span class="line">	<span class="keyword">int</span>[] max = <span class="keyword">new</span> <span class="keyword">int</span>[maxLen];</span><br><span class="line">	<span class="keyword">int</span>[] maxIndex = <span class="keyword">new</span> <span class="keyword">int</span>[maxLen];</span><br><span class="line">	<span class="keyword">int</span>[] c = <span class="keyword">new</span> <span class="keyword">int</span>[maxLen];</span><br><span class="line"></span><br><span class="line">	<span class="keyword">for</span> (i = <span class="number">0</span>; i &lt; len2; i++) &#123;</span><br><span class="line">		<span class="keyword">for</span> (j = len1 - <span class="number">1</span>; j &gt;= <span class="number">0</span>; j--) &#123;</span><br><span class="line">			<span class="keyword">if</span> (str2.charAt(i) == str1.charAt(j)) &#123;</span><br><span class="line">				<span class="keyword">if</span> ((i == <span class="number">0</span>) || (j == <span class="number">0</span>))</span><br><span class="line">					c[j] = <span class="number">1</span>;</span><br><span class="line">				<span class="keyword">else</span></span><br><span class="line">					c[j] = c[j - <span class="number">1</span>] + <span class="number">1</span>;</span><br><span class="line">			&#125; <span class="keyword">else</span> &#123;</span><br><span class="line">				c[j] = <span class="number">0</span>;</span><br><span class="line">			&#125;</span><br><span class="line"></span><br><span class="line">			<span class="keyword">if</span> (c[j] &gt; max[<span class="number">0</span>]) &#123; <span class="comment">// 如果是大于那暂时只有一个是最长的,而且要把后面的清0;</span></span><br><span class="line">				max[<span class="number">0</span>] = c[j];</span><br><span class="line">				maxIndex[<span class="number">0</span>] = j;</span><br><span class="line"></span><br><span class="line">				<span class="keyword">for</span> (<span class="keyword">int</span> k = <span class="number">1</span>; k &lt; maxLen; k++) &#123;</span><br><span class="line">					max[k] = <span class="number">0</span>;</span><br><span class="line">					maxIndex[k] = <span class="number">0</span>;</span><br><span class="line">				&#125;</span><br><span class="line">			&#125; <span class="keyword">else</span> <span class="keyword">if</span> (c[j] == max[<span class="number">0</span>]) &#123; <span class="comment">// 有多个是相同长度的子串</span></span><br><span class="line">				<span class="keyword">for</span> (<span class="keyword">int</span> k = <span class="number">1</span>; k &lt; maxLen; k++) &#123;</span><br><span class="line">					<span class="keyword">if</span> (max[k] == <span class="number">0</span>) &#123;</span><br><span class="line">						max[k] = c[j];</span><br><span class="line">						maxIndex[k] = j;</span><br><span class="line">						<span class="keyword">break</span>; <span class="comment">// 在后面加一个就要退出循环了</span></span><br><span class="line">					&#125;</span><br><span class="line"></span><br><span class="line">				&#125;</span><br><span class="line">			&#125;</span><br><span class="line">		&#125;</span><br><span class="line">	&#125;</span><br><span class="line"></span><br><span class="line">	<span class="keyword">for</span> (j = <span class="number">0</span>; j &lt; maxLen; j++) &#123;</span><br><span class="line">		<span class="keyword">if</span> (max[j] &gt; <span class="number">0</span>) &#123;</span><br><span class="line">			<span class="keyword">for</span> (i = maxIndex[j] - max[j] + <span class="number">1</span>; i &lt;= maxIndex[j]; i++)</span><br><span class="line">				buff.append(str1.charAt(i));			</span><br><span class="line">		&#125;</span><br><span class="line">	&#125;</span><br><span class="line">	<span class="keyword">return</span> buff.toString();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

          
        
      
    </div>

    

    
    
    

    

    
      
    
    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  

  <article class="post post-type-normal" itemscope="" itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="https://schwimmer.github.io/2017/07/12/机器学习/浅谈在线最优化求解算法-以CTR预测模型为例/">

    <span hidden itemprop="author" itemscope="" itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Schwimmer">
      <meta itemprop="description" content="Record and Think!">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope="" itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Schwimmer's Blog">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                
                <a href="/2017/07/12/机器学习/浅谈在线最优化求解算法-以CTR预测模型为例/" class="post-title-link" itemprop="url">浅谈在线最优化求解算法-以CTR预测模型为例</a>
              
            
          </h1>
        

        <div class="post-meta">

          
          
          

          
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              

              
                
              

              <time title="创建时间：2017-07-12 11:49:53" itemprop="dateCreated datePublished" datetime="2017-07-12T11:49:53+08:00">2017-07-12</time>
            </span>
          

          
            

            
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="fa fa-calendar-check-o"></i>
                </span>
                
                  <span class="post-meta-item-text">更新于</span>
                
                <time title="修改时间：2019-07-06 16:14:01" itemprop="dateModified" datetime="2019-07-06T16:14:01+08:00">2019-07-06</time>
              </span>
            
          

          
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope="" itemtype="http://schema.org/Thing"><a href="/categories/机器学习/" itemprop="url" rel="index"><span itemprop="name">机器学习</span></a></span>

                
                
              
            </span>
          

          
            
            
              
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="fa fa-comment-o"></i>
                </span>
            
                <span class="post-meta-item-text">评论数：</span>
                <a href="/2017/07/12/机器学习/浅谈在线最优化求解算法-以CTR预测模型为例/#comments" itemprop="discussionUrl">
                  <span class="post-comments-count disqus-comment-count" data-disqus-identifier="2017/07/12/机器学习/浅谈在线最优化求解算法-以CTR预测模型为例/" itemprop="commentCount"></span>
                </a>
              </span>
            
          

          
          

          

          <br>
          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>[TOC]</p>
<h1 id="1、最优化求解问题"><a href="#1、最优化求解问题" class="headerlink" title="1、最优化求解问题"></a>1、最优化求解问题</h1><p>通常，我们需要求解的最优化问题有如下三类：</p>
<p><strong>（1）无约束优化问题</strong>：</p>
<script type="math/tex; mode=display">
X=\arg \underset{X}{min}f(X)</script><p>含义是求解X，令目标函数$f(X)$最小。</p>
<p>对于这类问题，在$f(X)$ 是凸函数的前提下，通常做法就是对$f(X)$ 求导，并令$\frac {\partial} {\partial X} f(X) =0$ ，求解可以得到最优值。</p>
<blockquote>
<p> <strong>凸函数</strong></p>
<p> 如果$f(x)$是定义在N维向量空间上的实变量函数，对于在$f(x)$的定义域C上的任意两个点$x_1$和$x_2$，以及任意[0,1]之间的值t都有：</p>
<script type="math/tex; mode=display">
 f(tX_1 + (1-t)X_2) \leq tf(X_1)+(1-t)f(X_2)\\
 \forall X_1,X_2 \in C,\ \ 0 \leq t \leq 1</script><p> 则称$f(x)$是凸函数。一个函数是凸函数是其存在最优解的充要条件。</p>
<p> 此外，如果$f(x)$满足</p>
<script type="math/tex; mode=display">
 f(tX_1 + (1-t)X_2)< tf(X_1)+(1-t)f(X_2)\\
 \forall X_1,X_2 \in C,\ \ 0 \leq t \leq 1</script><p> 则$f(x)$为严格凸函数。如下图所示，左边是严格凸函数，右边是凸函数</p>
<p> <img src="/.io//凸函数.png" alt="凸函数"></p>
</blockquote>
<p><strong>（2）有等式约束的最优化问题</strong>：</p>
<script type="math/tex; mode=display">
X=\arg \underset{X}{min}f(X)\\
s.t. h_k(X)=0;k=1,2,...,n</script><p>含义是在n个等式约束$h_k(X)$ 的条件下求解X，另目标函数$f(X)$最小。</p>
<p>针对有等式的最优化问题，采用<strong>拉格朗日乘数法</strong>进行求解，通过拉格朗日系数$A=[a_1,a_2,…,a_n]^T$ 把等式约束和目标函数组合成一个式子</p>
<script type="math/tex; mode=display">
X=\arg \underset{X}{min}[f(X)+ A^TH(X)]</script><p>相当于转化成无约束最优化求解问题，解决方法是分别对X，A求偏导并令其等于0。</p>
<p><strong>（3）不等式约束的优化问题求解</strong> ：</p>
<script type="math/tex; mode=display">
X=\arg \underset{X}{min}f(X)\\
s.t. h_k(X)=0;k=1,2,...,n\\
g_l(X)\leq 0;l=1,2,...,m</script><p>对于不等式约束，通过KKT条件求解。将所有的约束和目标函数写为一个式子</p>
<script type="math/tex; mode=display">
L(X,A,B)=f(X)+A^TH(X)+B^TG(X)</script><p>KKT条件是说最优值必须满足以下条件：</p>
<script type="math/tex; mode=display">
\frac \partial {\partial X} L(X,A,B)=0\\
H(X)=0\\
B^TG(X)=0</script><p>KKT条件是求解最优值的必要条件，要使其成为充要条件，还需要f(x)为凸函数。</p>
<h1 id="2、批量最优化求解算法"><a href="#2、批量最优化求解算法" class="headerlink" title="2、批量最优化求解算法"></a>2、批量最优化求解算法</h1><p>一些定义：</p>
<p>$i=1,2,…,N$表示向量维度</p>
<p>$j=1,2,…,M$表示样本个数</p>
<p>$t=1,2,…$表示迭代次数</p>
<h2 id="2-1-批量和随机求解"><a href="#2-1-批量和随机求解" class="headerlink" title="2.1 批量和随机求解"></a>2.1 批量和随机求解</h2><p>我们面对的最优化问题都是无约束的最优化问题（有约束的也可以转成无约束的），因此通常可以将其描述为</p>
<script type="math/tex; mode=display">
W=\arg \underset{W}{min}\   l(W,Z)\\
Z=\{ (X_j,y_j) | j=1,2,...,M  \}\\
y_j=h(W,X_j)
\tag {2-1-1}</script><p>就是<strong>在已知训练集的情况下，求使得目标函数最小的权重矩阵</strong>。其中，$Z$是训练集，$\mathbf{X}$是特征向量，$X_j$是其中一个样本，$Y$是预测值，$y_j$是其中一个样本对应的预测值。一共有M个样本。$h(W,X_j)$ 是特征向量到预测值的<strong>映射函数</strong>，$ l(W,Z)$ 最优化求解的目标函数，也称为<strong>损失函数</strong>，$W$ 为特征权重，也就是在损失函数中需要求解的参数。</p>
<blockquote>
<p> 损失函数一般包括损失项和正则项</p>
</blockquote>
<p>常用的损失函数有：</p>
<p>（1）<strong>平方损失函数</strong>（线性回归）</p>
<p>最小二乘法（Ordinary Least Squares）是常用的一种平方损失函数，最小二乘的基本原理是：最优拟合直线应该是使各点到回归直线的距离和最小的直线，即平方和最小。</p>
<p>线性回归的映射函数为：</p>
<script type="math/tex; mode=display">
h(W,X_j)=W^TX_j</script><p>损失函数可以表示为</p>
<script type="math/tex; mode=display">
l(W,Z)=\sum_{j=1}^M (y_j-W^TX_j)^2</script><p>（2）<strong>Logistics损失函数</strong>（逻辑回归）</p>
<p>逻辑回归的映射函数为：</p>
<script type="math/tex; mode=display">
h(W,X_j)=\frac 1 {1+e^{-W^TX_j}}</script><blockquote>
<p>logistic函数的优点是：</p>
<p>1、他的输入范围是$-\infty \rightarrow  + \infty $ ，<strong>输出范围是(0,1)，正好满足概率分布为（0，1）的要求</strong>。我们用概率去描述分类器，自然比单纯的某个阈值要方便很多； </p>
<p>2、是一个单调上升的函数，具有良好的连续性，<strong>不存在不连续点</strong>。</p>
</blockquote>
<p>由于该函数服从伯努利分布（0-1分布），通过最大似然估计，对于每一维的权重W，损失函数可以表示为</p>
<script type="math/tex; mode=display">
l(W,Z)=(Y-h_W(\mathbf X))X</script><blockquote>
<p><strong>推导过程</strong></p>
<p>令</p>
<script type="math/tex; mode=display">
h_W(X) = \frac 1 {1+e^{-W^T\mathbf X}}</script><p>该函数服从伯努利分布（一次点击要么成功，要么失败，通过训练集可以知道不同特征组合下成功和失败的概率）</p>
<script type="math/tex; mode=display">
P(Y=1 | \mathbf X;W) = h_W(\mathbf X)\\
P(Y=0 | \mathbf X;W) = 1-h_W(\mathbf X)</script><p>则概率分布函数为</p>
<script type="math/tex; mode=display">
P(Y|\mathbf X;W) = (h_W(\mathbf X))^Y*(1-h_W(\mathbf X))^{1-Y}</script><p>（<strong>也就是说，我们有样本，通过样本能知道概率分布，那么我们需要知道得到这个概率分布的最有可能的参数W。即我们通过样本知道一些特征组合下的点击率，现在需要求概率函数中的系数。</strong>）</p>
<p>我们假设样本数据相互独立，所以它们的联合分布可以表示为各边际分布的乘积，用似然函数表示为：</p>
<script type="math/tex; mode=display">
\begin{aligned} 
L(W)=P(Y|\mathbf X;W) &= (h_W(\mathbf X))^Y(1-h_W(\mathbf X))^{1-Y}\\
&=\prod_{j=1}^M(h_W(X_j))^{y_j}(1-h_W(X_j))^{1-y_j}
\end{aligned}
\tag {2-1-2}</script><p>从而，损失函数的求解，可以转化为求最有可能导致这样概率分布的W，也就是求L(W)的最大值。最简单的方法就是对W求偏导，并令导数为零。</p>
<p>在多数情况下，直接对变量进行求导反而会使得计算式子更加的复杂，此时可以借用对数函数。由于对数函数是单调增函数，因此与（2-1-2）具有相同的最大值，上式变为</p>
<script type="math/tex; mode=display">
\begin{aligned} 
l(W) &= Log\ L(W)\\
&=\sum_{j=1}^M(y_jln\ h(X_j)+(1-y_j)ln\ (1-h(X_j)))
\end{aligned}</script><p>对其求关于W的偏导</p>
<p>首先求logistic函数的导数，得（最后一个X是对$W^TX$的求导）</p>
<script type="math/tex; mode=display">
h_W^{'}(\mathbf X) = h_W(\mathbf X)(1-h_W(\mathbf X))</script><blockquote>
<p><strong>推导过程如下</strong></p>
<p><img src="/.io//求导的推导.jpg" alt="求导的推导"></p>
</blockquote>
<p>为了求解方便，将l(W)转为（其实1/M没用，完全可以去掉，不懂为何要加上）</p>
<script type="math/tex; mode=display">
J(W) = -\frac {1}{M} l(W)</script><p>则就变成求J(W)的最小值。求偏导的过程如下：</p>
<p><img src="/.io//最大似然估计求偏导.png" alt="最大似然估计求偏导"></p>
<p>最后得到目标函数（损失函数）为：</p>
<script type="math/tex; mode=display">
\frac {\partial }{\partial W}J(W) =-\frac{1}{M} (Y-h_W(\mathbf X))X</script></blockquote>
<p>对于损失函数的求解，一个典型的方法就是梯度下降法，由于损失函数是凸函数，因此沿着梯度下降的方向找到最小点。</p>
<p>假设样本总数为m，<strong>批量梯度下降</strong>是：</p>
<script type="math/tex; mode=display">
Repeat\ until\ convergence \{ \\
W^{(t+1)} := W^t - \eta^t\triangledown  _{W}l(W^{t},Z) \\
\}\\
 \tag{1-2}</script><p>而<strong>随机梯度下降（SGD）</strong>是：</p>
<script type="math/tex; mode=display">
Repeat\ until\ convergence \{ \\
      for\ j=1\ to\ M, \{ \\
          W^{(t+1)} := W^t - \eta^t\triangledown  _{W}l(W^{t},Z_j) \\
\}</script><p>两者的区别是：</p>
<p>前者每次更新$W$都需要遍历一次整个样本集合；而后者在遍历样本集合的时候，每个样本都能改变$W$ ，有更快的收敛速度 。由于SGD针对观测到的随机一条数据进行权重的更新，很适合进行增量计算，实现梯度下降的online模式。</p>
<h2 id="2-2-正则化"><a href="#2-2-正则化" class="headerlink" title="2.2 正则化"></a>2.2 正则化</h2><p>正则化的主要目的是防止过拟合。对于损失函数构成的模型，可能会出现有些权重很大，有些权重很小的情况，导致过拟合，使得模型的复杂度提高，泛化能力较差（对未知数据的预测能力）。</p>
<p> <img src="/.io//过拟合1.png" alt="过拟合1"></p>
<p>而正则化就是对损失函数中权重的限制，限制其模不要太大：</p>
<script type="math/tex; mode=display">
W=\arg \underset{W}{min}\   l(W,Z)\\
s.t. \Psi(W)<\delta</script><p>其中，$\Psi(W)$称为正则化因子，是一个关于W求模的函数，常用的正则化因子有L1和L2正则化。</p>
<script type="math/tex; mode=display">
L1\ Regularization \ \ \ \ \ \ \ \ \Psi(W)=||W||_1=\sum_{i=1}^N|w_i|\\
L2 \ Regularization\ \ \ \ \ \ \ \Psi(W)=||W||_2^2=\sum_{i=1}^N(w_i)^2=W^TW</script><p>L1和L2的主要区别有两个：</p>
<p>（1）L1在0处不可导，而L2可导。</p>
<p>（2）L1通常能产生更稀疏的模型，也就是W的更多维度是0。这些为0的权重就代表了不是很重要的维度，所以能起到特征选择的目的。</p>
<p>（3）L2能限制特征权重各个维度的模不要太大，解决过拟合。</p>
<blockquote>
<p><img src="/.io//正则化解空间.png" alt="正则化解空间"><br> 其中，左图的圆形区域是L2正则化的单位圆，右图的方形区域是L1正则化的单位圆。<br><strong>单位圆</strong></p>
<p>使$||X||_p=1$的图形，当p=1和2时，单位圆分别为$|x|+|y|=1$和$x^2+y^2=1$。</p>
</blockquote>
<p>但是在SGD中，由于每次W的更新并不是沿着全局梯度进行下降，而是沿着某个样本产生的梯度方向进行下降，这样即使采用L1的方式也很难产生稀疏解。因此在接下来的在线最优化求解算法中，稀疏性是一个主要的追求目标。</p>
<p>参考：</p>
<p><a href="http://www.mamicode.com/info-detail-517504.html【正则化方法：L1和L2" target="_blank" rel="noopener">http://www.mamicode.com/info-detail-517504.html【正则化方法：L1和L2</a> regularization、数据集扩增、dropout】</p>
<p><a href="http://blog.csdn.net/zouxy09/article/details/24971995/【机器学习中的范数规则化之（一）L0、L1与L2范数】" target="_blank" rel="noopener">http://blog.csdn.net/zouxy09/article/details/24971995/【机器学习中的范数规则化之（一）L0、L1与L2范数】</a></p>
<h1 id="3、在线最优化求解算法"><a href="#3、在线最优化求解算法" class="headerlink" title="3、在线最优化求解算法"></a>3、在线最优化求解算法</h1><h2 id="3-1-截断梯度法TG"><a href="#3-1-截断梯度法TG" class="headerlink" title="3.1 截断梯度法TG"></a>3.1 截断梯度法TG</h2><p>为了使特征权重W有更多的0，最简单的方法就是设一个阈值，当W的某个维度值小于这个阈值的时候置为0，这个称为<strong>简单截断法</strong>。但实际中W的某个系数比较小可能是由于该维度训练不足引起，所以这么做会导致这部分特征的丢失。于是又改进为<strong>截断梯度法Truncated Gradient</strong>。</p>
<h3 id="3-1-1-简单截断法"><a href="#3-1-1-简单截断法" class="headerlink" title="3.1.1 简单截断法"></a>3.1.1 简单截断法</h3><p>以$k$为窗口，当$t/k$不为整数时，采用标准的SGD；否则，采用如下的权重更新方式：</p>
<script type="math/tex; mode=display">
W^{t+1}=T_0(W^t - \eta^tG^t,\theta) \\
T_0(v_i,\theta) = \begin{Bmatrix}
0\ if\ |v_i|\leqslant \theta\\ 
v_i\ otherwise
\end{Bmatrix}</script><p>其中，$G^t=\triangledown  _{W}l(W^{t},Z^{t})$ 代表第t次迭代中损失函数的梯度，$\eta^{t}$ 是学习率，通常将其设置为 $1/\sqrt{t}$ 的函数。可以看出，简单截断法的思路是，如果某个维度的权重变化小于设定的$\theta$ ，则直接置为0。</p>
<h3 id="3-1-2-截断梯度法"><a href="#3-1-2-截断梯度法" class="headerlink" title="3.1.2 截断梯度法"></a>3.1.2 截断梯度法</h3><p>在前一种方法上的改进。加入了L1正则化项$\eta^{t}\lambda sgn(W^{t})$ 。</p>
<script type="math/tex; mode=display">
W^{t+1}=W^t-\eta ^tG^t-\eta^t\lambda sgn(W^t)</script><p>其中$sgn(v)$是符号函数。由于每次仅根据一个样本进行更新，因此也不再使用区分样本的下表$j$。</p>
<p>采用类似的方式表示为：</p>
<script type="math/tex; mode=display">
W^{t+1}=T_1(W^t - \eta^tG^t,\eta^t\lambda^t,\theta) \\
T_1(v_i,\alpha,\theta) = \begin{Bmatrix}
\begin{aligned}
& max(0,v_i-\alpha)\ if\ v_i\in [0,\theta]\\ 
& min(0,v_i+\alpha)\ if\ v_i\in [-\theta,0]\\
& v_i\ otherwise
\end{aligned}
\end{Bmatrix}</script><p>其中，$\lambda^{t} \in \mathbb{R}$且$\lambda^{t}\geqslant0 $ 。同样以k为窗口，每k步进行一次截断。当t/k不为整数时，$\lambda^{t}=0$， 否则，$\lambda^{t}=k\lambda$。可以看出，$\lambda$和$\theta$决定了权重的稀疏程度，这两个值越大越稀疏。</p>
<h2 id="3-2-前向后向切分FOBOS"><a href="#3-2-前向后向切分FOBOS" class="headerlink" title="3.2 前向后向切分FOBOS"></a>3.2 前向后向切分FOBOS</h2><h3 id="3-2-1-FOBOS算法原理"><a href="#3-2-1-FOBOS算法原理" class="headerlink" title="3.2.1 FOBOS算法原理"></a>3.2.1 FOBOS算法原理</h3><p>在FOBOS（Forward-backward Splitting）中，将权重的更新分为两个步骤：</p>
<script type="math/tex; mode=display">
W^{t+\frac{1}{2}} = W^t-\eta^tG^{t}\\
W^{t+1}=\arg \underset{W}{min} \{\frac {1} {2} ||W- W^{t+\frac{1}{2}}||_2^2+\eta^{t+\frac {1}{2}}\Psi (W)\}
\tag {3-2-1}</script><p>前一个步骤还是标准的梯度下降，后一个步骤可以理解为对梯度下降的结果进行微调，其中第一项是L2正则化，表示不能离损失迭代结果太远，第二项$\Psi (W)$是正则化项。</p>
<p>将上面两个式子合并，有</p>
<script type="math/tex; mode=display">
W^{t+1}=\arg \underset{W}{min} \{\frac {1} {2} ||W- W^{t}-\eta^{t}G^{t}||_2^2+\eta^{t+\frac {1}{2}}\Psi (W)\}</script><p>令</p>
<script type="math/tex; mode=display">
F(W)=\frac {1} {2} ||W- W^{t}-\eta^{t}G^{t}||_2^2+\eta^{t+\frac {1}{2}}\Psi (W)</script><p>如果$W^{t+1}$存在一个最优解，<strong><em>那么可以推断0向量一定属于$F(W)$的一维次梯度集合</em>。</strong></p>
<script type="math/tex; mode=display">
0 \in \partial F(W)=W-W^{t}+\eta^{t}G^{t}+\eta^{t+\frac 1 2}\partial \Psi(W)</script><blockquote>
<p><strong>次导数和次梯度</strong></p>
<p>参考SubGradient.pdf</p>
<p>次导数是一个区间，一维次梯度就是次导数</p>
</blockquote>
<p>由于$W^{t+1}=\arg \underset{x}{min} F(W)$，则有：</p>
<script type="math/tex; mode=display">
0=\left \{ W-W^{t} - \eta^{t}G^{t}+\eta^{t+\frac {1}{2}}\partial\Psi(W) \right \}|_{W=W^{t+1}}</script><p>便可以得到另一种更新权重的方式</p>
<script type="math/tex; mode=display">
W^{t+1}=W^{t}+ \eta^{t}G^{t}-\eta^{t+\frac {1}{2}}\partial\Psi(W^{t+1})</script><p>从上式可以看到权重的更新不仅与迭代前的状态有关，也与迭代后的$W^{t+1}$有关。</p>
<h3 id="3-2-2-L1-FOBOS"><a href="#3-2-2-L1-FOBOS" class="headerlink" title="3.2.2 L1-FOBOS"></a>3.2.2 L1-FOBOS</h3><p>在L1正则化下，有$\Psi (W)=\lambda||w||_1$ 。对于（2-3-1），</p>
<script type="math/tex; mode=display">
W^{t+1}=\arg \underset{W}{min} \{\frac {1} {2} ||W- W^{t+\frac{1}{2}}||_2^2+\eta^{t+\frac {1}{2}}\Psi (W)\}</script><p>用向量V来表示$W^{t+\frac 1 2}$ ，用标量$\tilde{\lambda} \in \mathbb{R}$来表示$\eta^{t+\frac 1 2}\lambda$ ，将公式展开，并改写为</p>
<script type="math/tex; mode=display">
W^{t+1}=\arg \underset{W}{min}\sum_{i=1}^N (\frac {1} {2}(w_i-v_i)^2+ \tilde{\lambda}|w_i|)
\tag {3-2-2}</script><p>可以看到，在求和公式中的每一项都是大于0的，所以公式（3-2-2）可以拆解成对特征权重W的每一维度单独求解</p>
<script type="math/tex; mode=display">
w_i^{t+1}=\arg \underset{w_i}{min}(\frac {1} {2}(w_i-v_i)^2+ \tilde{\lambda}|w_i|)
\tag {3-2-3}</script><p>假设$w_i^<em>$是一个维度上的最优解，通过反证法证明$w_i^</em>v_i\geq0$（证明略）。再分$v_i\geq0$和$v_i&lt;0$来讨论。</p>
<p><strong>（1）当$v_i\geq0$时</strong>，</p>
<p>由于$w_i^<em>v_i\geq0$，所以$w_i^</em> \geq0$ 。相当于给（2-3-3）增加了一个不等式约束条件：</p>
<script type="math/tex; mode=display">
w_i^{t+1}=\arg \underset{w_i}{min}(\frac {1} {2}(w_i-v_i)^2+ \tilde{\lambda}|w_i|)\\
s.t. -w_i\leq 0</script><p>通过拉格朗日乘子求解这个含不等式的约束问题。</p>
<p>引入拉格朗日系数$\beta \geq 0$ ，由KKT条件，有</p>
<script type="math/tex; mode=display">
\frac \partial {\partial w_i}\left ( \frac {1} {2}(w_i-v_i)^2+ \tilde{\lambda}|w_i|-\beta w_i \right )|_{w_i=w_i^*}=0 \\
\beta w_i^*=0</script><p>根据上面的求导可得</p>
<script type="math/tex; mode=display">
w_i^*=v_i-\tilde{\lambda}+\beta</script><p>再分为两种情况</p>
<p>① 当$w_i^<em> &gt; 0$ 时，由于$\beta w_i^</em>=0$ 所以$\beta=0$，此时有$w_i^*=v_i-\tilde{\lambda}$ ，从而$v_i-\tilde{\lambda} &gt; 0$ 。</p>
<p>② 当$w_i^* = 0$ 时，有$v_i-\tilde{\lambda}+\beta=0$ 。由于$\beta \geq 0$ ，所以$v_i-\tilde{\lambda} \leq 0$  。</p>
<p>可以得出，当$v_i\geq0$ 时，</p>
<script type="math/tex; mode=display">
w_i^* = max(0, v_i-\tilde{\lambda})</script><p><strong>（2）当$v_i&lt;0$时</strong>，</p>
<p>采用同样的分析方法，得到</p>
<script type="math/tex; mode=display">
w_i^* =- max(0, -v_i-\tilde{\lambda})</script><p>综上，可得FOBOS在L1正则化条件下，特征权重各个维度的更新方式为：</p>
<script type="math/tex; mode=display">
\begin{aligned} 
w_i^{t+1} &= sgn(v_i)max(0,|v_i|-\tilde{\lambda})\\
& = sgn(w_i^{t}-\eta^{t}g_i^{t})max \left \{ 0, |w_i^{t}-\eta^{t}g_i^{t}|-\eta^{t+ \frac {1} {2}} \lambda \right \}
 \end{aligned}
 \tag{3-2-4}</script><p>其中，$g_i^{t}$就是梯度在维度i上的取值。</p>
<p><strong>从公式（3-2-4）可以看出，L1-FOBOS每次更新W的时候，对W的每个维度都会进行判定，当$|w_i^{t}-\eta^{t}g_i^{t}|-\eta^{t+ \frac {1} {2}} \lambda&lt;0$的时候对齐进行截断，即权重置为0。</strong></p>
<p>换一种写法，</p>
<script type="math/tex; mode=display">
|w_i^{t}-\eta^{t}g_i^{t}|<\eta^{t+ \frac {1} {2}} \lambda
\tag {3-2-5}</script><p>可以看出截断的意义是，<strong>当一条样本产生的梯度不足以令对应维度上的权重值发生足够大的变大（$\eta^{t+ \frac {1} {2}} \lambda$ ），则认为在本次更新过程中该维度不重要，令其权重为0</strong>。</p>
<p>若对L1-FOBOS进行适当的变换，可以发现，L1-FOBOS就是TG在特定条件下的特殊形式。</p>
<h2 id="3-3-RDA"><a href="#3-3-RDA" class="headerlink" title="3.3 RDA"></a>3.3 RDA</h2><h3 id="3-3-1-RDA算法原理"><a href="#3-3-1-RDA算法原理" class="headerlink" title="3.3.1 RDA算法原理"></a>3.3.1 RDA算法原理</h3><p>TG和FOBOS都是建立在SGD的基础之上，属于梯度下降类型的方法，这类型方法的优点就是精度比较高，并且 TG、 FOBOS 也都能在稀疏性上得到提升。 但是有些其它类型的算法，例如 RDA，是从另一个方面来求解 Online Optimization 并且更有效地提升了特征权重的稀疏性。 </p>
<p>正则对偶平均（ RDA, Regularized Dual Averaging） 是微软十年的研究成果， RDA 是 Simple Dual Averaging Scheme 的一个扩展， 由 Lin Xiao 发表于 2010 年 。</p>
<p>在 RDA 中， 特征权重的更新策略为： </p>
<script type="math/tex; mode=display">
W^{t+1} = \arg \underset{W}{min} \left \{ \frac 1 t \sum_{r=1}^t \left \langle G^r,W \right \rangle  +\Psi(W)+\frac {\beta^{t}}{t}h(W) \right \}
\tag {3-3-1}</script><p>本质上，公式（3-3-1）包括了3个部分：</p>
<p>（1）线性函数$\frac 1 t \sum_{r=1}^t \left \langle G^r,W \right \rangle$ 包含了之前所有梯度（或次梯度）的平均值（dual average），$G^r$ 是梯度；</p>
<p>（2）$\Psi(W)$ 为正则项；</p>
<p>（3）额外正则项$\frac {\beta^{t}}{t}h(W)$。其中$h(W)$是一个辅助的严格凸函数。${\beta^{t}|t\geq 1}$ 是一个非负且非自减序列。</p>
<h3 id="3-3-2-L1-RDA"><a href="#3-3-2-L1-RDA" class="headerlink" title="3.3.2 L1-RDA"></a>3.3.2 L1-RDA</h3><p>在L1正则化下，有$\Psi (W)=\lambda||w||_1$，并且由于$h(W)$是一个关于W的严格凸函数，就令$h(W)=\frac {1} {2} ||W||_2^2 $ 。此外，将${\beta^{t}|t\geq 1}$定义为$\beta^{t}=\gamma \sqrt t $ 。再代入（2-4-1），有</p>
<script type="math/tex; mode=display">
W^{t+1} = \arg \underset{W}{min} \left \{ \frac 1 t \sum_{r=1}^t \left \langle G^r,W \right \rangle  +\lambda||w||_1+\frac {\gamma} {2\sqrt t}||W||_2^2 \right \}
\tag {3-3-2}</script><p>分解到每一个权重的维度上</p>
<script type="math/tex; mode=display">
w_i^{t+1} = \arg \underset{w_i}{min} \left \{ \bar{g_i}^{t}w_i +\lambda|w_i|+\frac {\gamma} {2\sqrt t}w_i^2 \right \}
\tag {3-3-3}</script><p>这里$\lambda &gt;0,\ \frac {\gamma} {\sqrt t}&gt;0,\  \bar{g<em>i}^{t} = \frac 1 t \sum</em>{r=1}^t g_i^{(r)}$ 。公式（2-4-3）就是一个无约束的非平滑最优化问题（因为第二项$\lambda|w_i|$ 在0处不可导）。所以用次导数求解。</p>
<p>假设$w_i^<em>$ 是其最优解，并且定义$\xi \in \partial  |w_i|$为$|w_i|$ 在$w_i^</em>$ 的次导数，则有</p>
<script type="math/tex; mode=display">
\partial |w_i^*| =  \left\{\begin{matrix}
-1<\xi<1  & if w_i^*=0\\ 
1 & if w_i^*>0\\ 
-1 & if w_i^*<0
\end{matrix}\right.</script><p>对公式（3-3-3）求次导数，并令其为0，则有</p>
<script type="math/tex; mode=display">
\bar{g_i}^{t} + \lambda\xi + \frac {\gamma} {\sqrt t} w_i = 0</script><p>由于$\lambda &gt;0$，再分情况讨论（略），可以得到L1-RDA特征权重的各个维度更新的方式为：</p>
<script type="math/tex; mode=display">
w_i^{t+1}=\begin{Bmatrix}
0 & if |\bar{g_i}^{t}|<\lambda\\ 
-\frac {\sqrt t}{\gamma}\left (\bar{g_i}^{t}-\lambda sgn(\bar{g_i}^{t})  \right ) & otherwise
\end{Bmatrix}
\tag {3-3-4}</script><p><strong>这里可以看出，当某个维度上累积梯度平均值的绝对值小于阈值$\lambda$ 时，产生截断</strong>。</p>
<h3 id="3-3-3-L1-RDA和L1-FOBOS的比较"><a href="#3-3-3-L1-RDA和L1-FOBOS的比较" class="headerlink" title="3.3.3 L1-RDA和L1-FOBOS的比较"></a>3.3.3 L1-RDA和L1-FOBOS的比较</h3><p>在L1-FOBOS中，进行截断的条件是</p>
<script type="math/tex; mode=display">
|w_i^{t}-\eta^{t}g_i^{t}|<\eta^{t+ \frac {1} {2}} \lambda</script><p>通常会定义$\eta$为与$\frac 1 {\sqrt t}$ 正相关的函数$\eta=\Theta \left ( \frac {1} {\sqrt t} \right )$ 。因此L1-FOBOS的<strong>截断阈值为$\Theta \left ( \frac {1} {\sqrt t} \right )\lambda$  ，</strong>随着**t的增加，这个阈值会逐渐降低。</p>
<p>相比较而言，L1-RDA的<strong>截断阈值是$\lambda$ </strong>。是一个常数，并不随着t变化，因此相对于L1-FOBOS更简单粗暴。这种性质使得L1-RDA更容易产生稀疏性。此外， RDA 中判定截断的对象是梯度的累加平均值$\bar{g_i}^{t} $ ， 不同于 TG或L1-FOBOS 中针对单次梯度计算的结果进行判定，避免了由于某些维度由于训练不足导致截断的问题。 并且通过调节一个参数$\lambda$，很容易在精度和稀疏性上进行权衡 。</p>
<h2 id="3-4-FTRL"><a href="#3-4-FTRL" class="headerlink" title="3.4 FTRL"></a>3.4 FTRL</h2><p>有实验证明， <strong>L1-FOBOS 这一类基于梯度下降的方法有比较高的精度，但是 L1-RDA 却能在损失一定精度的情况下产生更好的稀疏性。 FTRL则是结合了两者的优点</strong>。</p>
<h3 id="3-4-1-L1-FOBOS和L1-RDA在形式上的统一"><a href="#3-4-1-L1-FOBOS和L1-RDA在形式上的统一" class="headerlink" title="3.4.1 L1-FOBOS和L1-RDA在形式上的统一"></a>3.4.1 L1-FOBOS和L1-RDA在形式上的统一</h3><p>之前提到，L1-FOBOS可以表示为（这里令$\eta^{t+\frac 1 2}=\eta^t=\Theta(\frac 1 {\sqrt t})$  是一个随t变化的非增正序列） </p>
<script type="math/tex; mode=display">
W^{t+1}=\arg \underset{W}{min} \{\frac {1} {2} ||W- W^t-\eta^tG^t||^2+\eta^{t}\lambda||w||_1\}</script><p>将其按W的维度分解为N个独立的最优化步骤</p>
<script type="math/tex; mode=display">
\underset{w_i}{minimize} \left \{  \frac 1 2 (w_i-w_i^t+\eta^tg_i^t)^2+\eta^t\lambda|w_i| \right \}\\
=\underset{w_i}{minimize}\left \{  \frac 1 2 (w_i-w_i^t)^2 + \frac 1 2(\eta^tg_i^t)^2+w_i\eta^tg_i^t- w_i^t\eta^tg_i^t+    \eta^t\lambda|w_i| \right \}\\</script><p>同时除以$\eta^t$ ，得到</p>
<script type="math/tex; mode=display">
\underset{w_i}{minimize}\left \{ w_ig_i^t+\lambda|w_i|+\frac 1 {2\eta^t}(w_i-w_i^t)^2 + [\frac {\eta^t}{2}(g_i^t)2+w_i^tg_i^t] \right \}</script><p>由于$\frac {\eta^t}{2}(g_i^t)2+w_i^tg_i^t$ 与变量$w_i$ 无关，因此上式可以等价于</p>
<script type="math/tex; mode=display">
\underset{w_i}{minimize}\left \{ w_ig_i^t+\lambda|w_i|+\frac 1 {2\eta^t}(w_i-w_i^t)^2 +  \right \}</script><p>再将这N个独立的合并，则L1-FOBOS可以写成</p>
<script type="math/tex; mode=display">
W^{t+1} = \arg \underset{W}{min} \left \{ G^t\cdot W+\lambda||W||_1+\frac 1 {2\eta^t}||W-W^t||_2^2 \right \}</script><p>而对于L1-RDA的公式（3-3-2）</p>
<script type="math/tex; mode=display">
W^{t+1} = \arg \underset{W}{min} \left \{ \frac 1 t \sum_{r=1}^t \left \langle G^r,W \right \rangle  +\lambda||w||_1+\frac {\gamma} {2\sqrt t}||W||_2^2 \right \} \\</script><p>同时乘以t，得到</p>
<script type="math/tex; mode=display">
\begin{aligned} 
W^{t+1} & = \arg \underset{W}{min} \left \{ \sum_{r=1}^t  G^r \cdot W  +t\lambda||w||_1+\frac {1} {2\eta^t}||W-0||_2^2 \right \}\\
& =\arg \underset{W}{min} \left \{  G^{1:t} \cdot W  +t\lambda||w||_1+\frac {1} {2\eta^t}||W-0||_2^2 \right \}
\end{aligned}</script><p>如果令$\sigma ^s = \frac 1 {\eta^s}-\frac 1 {\eta^{s-1}}$  ，则$\sigma^{1:t} = \frac 1 {\eta^t}$ 。L1-FOBOS和L1-RDA的公式可以写成</p>
<script type="math/tex; mode=display">
W^{t+1} = \arg \underset{W}{min} \left \{ G^t\cdot W+\lambda||W||_1+\frac 1 2\sigma^{1:t}||W-W^t||_2^2 \right \}\\
W^{t+1} =\arg \underset{W}{min} \left \{  G^{1:t} \cdot W  +t\lambda||W||_1+\frac 1 2\sigma^{1:t}||W-0||_2^2 \right \}
\tag {3-4-1}</script><p>比较这两个公式，可以看出L1-FOBOS和L1-RDA的区别在于：</p>
<p>（1）前者对梯度只考虑当前的状态，而后者的梯度是累加的形式；</p>
<p>（2）前者的第三项限制了W的变化不能离已经迭代过的解太远，后者限制W不能离0太远。</p>
<h3 id="3-4-2-FTRL算法原理"><a href="#3-4-2-FTRL算法原理" class="headerlink" title="3.4.2 FTRL算法原理"></a>3.4.2 FTRL算法原理</h3><p>FTRL综合考虑了L1-FOBOS和L1-RDA中对正则项和W限制的区别，其特征权重的更新公式为</p>
<script type="math/tex; mode=display">
W^{t+1} =\arg \underset{W}{min} \left \{  G^{1:t} \cdot W  +\lambda_1||W||_1+\lambda_2||W||_2^2+\frac 1 2\sum_{s=1}^t \sigma^s ||W-W^s||_2^2 \right \}
\tag {3-4-2}</script><p>其中L2的正则项在论文中并没有出现，但是2013年的FTRL工程化实现的论文却使用。事实上该项的引入并不影响FRTL<br>的稀疏性， 后面的推导过程会显示这一点。 L2正则项的引入仅仅相当于对最优化过程多了一个约束，使得结果求解结果更加“平滑”。 </p>
<p>对（3-4-2）进行变换，将其的最后一项展开</p>
<script type="math/tex; mode=display">
W^{t+1} =\arg \underset{W}{min} \left \{  (G^{1:t}-\sum_{s=1}^t\sigma^sW^s) \cdot W  +\lambda_1||W||_1+\frac 1 2 (\lambda_2+\sum_{s=1}^t\sigma^s)||W||_2^2+\frac 1 2\sum_{s=1}^t \sigma^s ||W^s||_2^2 \right \}</script><p>其中，由于$\frac 1 2\sum_{s=1}^t \sigma^s ||W^s||_2^2$ 相对于W是常数项，再令</p>
<script type="math/tex; mode=display">
Z^{t} =G^{1:t}-\sum_{s=1}^t\sigma^sW^s
\tag {3-4-3}</script><p>上式等价于</p>
<script type="math/tex; mode=display">
W^{t+1} =\arg \underset{W}{min} \left \{  Z^t \cdot W  +\lambda_1||W||_1+\frac 1 2 (\lambda_2+\sum_{s=1}^t\sigma^s)||W||_2^2 \right \}</script><p>再针对每个维度将其拆解成N个独立的标量最小化问题</p>
<script type="math/tex; mode=display">
 \underset{w_i}{minimize} \left \{  z_i^tw_i  +\lambda_1|w_i|+\frac 1 2 (\lambda_2+\sum_{s=1}^t\sigma^s)w_i^2 \right \}</script><p>到这里，遇到了与L1-RDA的（3-3-3）类似的优化问题，用相同的分析方法可以得到</p>
<script type="math/tex; mode=display">
w_i^{t+1}=\left\{\begin{matrix}
0 & if\ |z_i^t|<\lambda_1\\ 
-\left ( \lambda_2+\sum_{s=1}^t\sigma^s \right )^{-1}\ \left ( z_i^t-\lambda_1 sgn(z_i^t) \right ) & otherwise
\end{matrix} \right.
\tag {3-4-4}</script><p>可以看出，引入L2并没有对FTRL结果的稀疏性产生影响。</p>
<h3 id="3-4-3-学习率"><a href="#3-4-3-学习率" class="headerlink" title="3.4.3 学习率"></a>3.4.3 学习率</h3><p>前面的推导中，学习率的选择和计算没有被提及。事实上在FTRL中，每个维度的学习率都是单独考虑的。</p>
<p>考虑特征维度的变化率：如果特征 1 比特征 2 的变化更快，那么在维度 1 上的学习率应该下降得更快。我们很容易就可以想到可以用某个维度上梯度分量来反映这种变化率。在FTRL 中，维度 i上的学习率是这样计算的<strong>（原作者没有推导过程）</strong>：</p>
<script type="math/tex; mode=display">
\eta_i^t=\frac {\alpha}{\beta + \sqrt {\sum_{s=1}^t (g_i^s)^2}}</script><p>由于$\sum_{s=1}^t\sigma^s=\frac 1 {\eta^t}$ ，因此（3-4-4）就变成</p>
<script type="math/tex; mode=display">
w_i^{t+1}=\left\{\begin{matrix}
0 & if\ |z_i^t|<\lambda_1\\ 
-\left ( \lambda_2 + \frac {\beta + \sqrt {\sum_{s=1}^t (g_i^s)^2}}{\alpha}  \right )^{-1}\ \left ( z_i^t-\lambda_1 sgn(z_i^t) \right ) & otherwise
\end{matrix} \right.
\tag {3-4-5}</script><p>这里的$\alpha, \beta$ 都是要输入的参数。</p>
<h3 id="2-5-4-伪代码解读"><a href="#2-5-4-伪代码解读" class="headerlink" title="2.5.4 伪代码解读"></a>2.5.4 伪代码解读</h3><p> <img src="/.io//FTRL伪代码.png" alt="FTRL伪代码"></p>
<p>首先设置各个参数的初始值，包括</p>
<ul>
<li>更新学习率的$\alpha,\beta$。</li>
<li>L1和L2正则化的参数$\lambda_1,\ \lambda_2$ </li>
<li>更新权重时用到的$z_i$ 一维数组（数组的长度是特征项个数），初始值是0</li>
<li>存放梯度累加的$n_i$ 一维数组（数组的长度是特征项个数），初始值是0</li>
</ul>
<p>算法步骤中：</p>
<p>（1）第一阶段，计算第t次迭代的预测值</p>
<p><strong>S1</strong>：用给定的初始值计算权重$w_{t,i}$，并计算出预测值$p_t$ 。见①</p>
<p>（2）第二阶段，更新第t+1次的权重，对当前样本不为0的每个特征项都要进行一次更新。在第i个特征项中，</p>
<p><strong>S1</strong>：采用logloss计算损失函数的梯度$g_{t+1}$，见②</p>
<p><strong>S2</strong>：可以看出①里面还需要计算$n_i$  和$z_i$ 在第t+1次的值。</p>
<p>对于$z_i$，根据公式（2-5-3）</p>
<script type="math/tex; mode=display">
Z^{t} =G^{1:t}-\sum_{s=1}^t\sigma^sW^s</script><p>可以看出z的更新可以通过下式计算</p>
<script type="math/tex; mode=display">
\begin {aligned}
Z^{t+1}& =G^{1:t+1}-\sum_{s=1}^{t+1}\sigma^sW^s\\
&=G^{1:t}-\sum_{s=1}^t\sigma^sW^s + G^{t+1} - \sigma^{t+1}W^{t+1}\\
&=Z^t + G^{t+1} - \sigma^{t+1}W^{t+1}
 \end{aligned}
 \tag {3-4-6}</script><p>则需要计算$\sigma^{t+1}$ 的值。而根据上文的推导</p>
<script type="math/tex; mode=display">
\sigma ^s = \frac 1 {\eta^s}-\frac 1 {\eta^{s-1}}</script><p>又</p>
<script type="math/tex; mode=display">
\eta_i^t=\frac {\alpha}{\beta + \sqrt {\sum_{s=1}^t (g_i^s)^2}}</script><p>则</p>
<script type="math/tex; mode=display">
\begin {aligned}
\sigma ^{t+1}& = \frac 1 {\eta^{t+1}}-\frac 1 {\eta^t}\\
&=\frac {\beta + \sqrt {\sum_{s=1}^{t+1} (g_i^s)^2}}{\alpha}-\frac {\beta + \sqrt {\sum_{s=1}^t (g_i^s)^2}}{\alpha}\\
&=\frac 1 \alpha \left ( \sqrt {\sum_{s=1}^{t+1} (g_i^s)^2}- \sqrt {\sum_{s=1}^t (g_i^s)^2}\right )
 \end{aligned}</script><p>由于用$n_i$ 记录$g_i$ 的累加和，上式可以变成</p>
<script type="math/tex; mode=display">
\sigma ^{t+1} = \sqrt {n^t+(g^{t+1})^2}-\sqrt {n^t}
\tag {3-4-7}</script><p>见③。再根据公式（3-4-6），计算$z_i$ 的值，见④。</p>
<p><strong>S3</strong>：对于$n_i$ ，根据公式（3-4-7），</p>
<script type="math/tex; mode=display">
n^{t+1} = n^t +(g^{t+1})^2</script><p>见⑤。</p>
<h3 id="2-5-5-实现代码"><a href="#2-5-5-实现代码" class="headerlink" title="2.5.5 实现代码"></a>2.5.5 实现代码</h3><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">predict</span></span>(x: <span class="type">Array</span>[<span class="type">Int</span>]): <span class="type">Double</span> = &#123;</span><br><span class="line">  <span class="keyword">var</span> wTx = <span class="number">0.0</span></span><br><span class="line"></span><br><span class="line">  x foreach &#123; x =&gt;</span><br><span class="line">    <span class="keyword">val</span> sign = <span class="keyword">if</span> (z(x) &lt; <span class="number">0</span>) <span class="number">-1.0</span> <span class="keyword">else</span> <span class="number">1.0</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> (sign * z(x) &lt;= <span class="type">L1</span>)</span><br><span class="line">      w(x) = <span class="number">0.0</span></span><br><span class="line">    <span class="keyword">else</span></span><br><span class="line">      w(x) = (sign * <span class="type">L1</span> - z(x)) / ((beta + math.sqrt(n(x))) / alpha + <span class="type">L2</span>)</span><br><span class="line"></span><br><span class="line">    wTx = wTx + w(x)</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="keyword">return</span> <span class="number">1.0</span> / (<span class="number">1.0</span> + math.exp(-math.max(math.min(wTx, <span class="number">35.0</span>), <span class="number">-35.0</span>)))</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">update</span></span>(x: <span class="type">Array</span>[<span class="type">Int</span>], p: <span class="type">Double</span>, y: <span class="type">Int</span>): <span class="type">Unit</span> = &#123;</span><br><span class="line">  <span class="keyword">val</span> g = p - y</span><br><span class="line"></span><br><span class="line">  x foreach &#123; x =&gt;</span><br><span class="line">    <span class="keyword">val</span> sigma = (math.sqrt(n(x) + g * g) - math.sqrt(n(x))) / alpha</span><br><span class="line">    z(x) = z(x) + g - sigma * w(x)</span><br><span class="line">    n(x) = n(x) + g * g</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>从代码可以看出，在更新权重时，SGD和FTRL的区别在于：</p>
<p><del>SGD在遍历每个样本的时候，都会更新所有维度的权重，而FTRL在遍历每个样本的时候只会更新样本对应维度的权重。从而可以节省训练的时间</del></p>
<p>并不是节省时间。SGD也可以用于在线学习，过拟合的限制上没有FTRL好。参数太多，会导致模型复杂度上升，容易过拟合。</p>
<h3 id="3-4-6-实验及结论"><a href="#3-4-6-实验及结论" class="headerlink" title="3.4.6 实验及结论"></a>3.4.6 实验及结论</h3><p>1、</p>
<p>训练：16-10-22的前7天数据</p>
<p>预测：16-10-22当天数据</p>
<p>维度：1048576</p>
<p>参数：默认</p>
<p> <img src="/.io//roc3.png" alt="roc3"></p>
<p>logloss：</p>
<p>线上方法：0.274321867859</p>
<p>FRTL：0.0326626593411</p>
<p>2、</p>
<p>训练：16-10-22的前7天数据</p>
<p>预测：16-10-22当天数据，其中每9条用于在线学习，预测第10条</p>
<p>维度：1048576</p>
<p>参数：默认</p>
<p>训练时间：11:54-12:18</p>
<p> <img src="/.io//roc1.png" alt="roc1"></p>
<p>logloss：</p>
<p>线上方法：0.275704770725</p>
<p>FRTL：0.032281346379</p>
<p>3、</p>
<p>训练集：16-10-18的前10天数据</p>
<p>预测：16-10-18当天数据，其中每9条用于在线学习，预测第10条</p>
<p>维度：4194304</p>
<p>参数：默认</p>
<p>训练时间：13:50-14:19</p>
<p> <img src="/.io//roc2.png" alt="roc2"></p>
<p>logloss</p>
<p>线上方法：0.073087783303</p>
<p>FTRL：0.022967801811</p>
<p>4、</p>
<p>训练集：16-10-18的前10天数据</p>
<p>预测：16-10-18当天数据，其中每9条用于在线学习，预测第10条</p>
<p>维度：4194304</p>
<p>参数：训练的特征项改为1-10</p>
<p>训练时间：17:07-17:45</p>
<p> <img src="/.io//roc4.png" alt="roc4"></p>
<p>logloss</p>
<p>线上方法：0.073087783303</p>
<p>FTRL：0.0221369813697</p>
<p>特征权重不为0的维度有11301个</p>
<h2 id="观点"><a href="#观点" class="headerlink" title="观点"></a>观点</h2><p>FTRL在线训练时间长了效果往往会下降，因为学习率会逐渐降低，必须要offline结合online。</p>
<h1 id="主要参考资料"><a href="#主要参考资料" class="headerlink" title="主要参考资料"></a>主要参考资料</h1><p>【在线最优化求解(Online Optimization)-冯扬】</p>
<p>【逻辑回归从入门到精通-腾讯柳超】</p>
<p>【FTRL的理论论文】Factorization machines with follow-the-regularized-leader for CTR prediction in display advertising  <a href="http://www0.cs.ucl.ac.uk/staff/w.zhang/rtb-papers/fm-ftrl.pdf" target="_blank" rel="noopener">http://www0.cs.ucl.ac.uk/staff/w.zhang/rtb-papers/fm-ftrl.pdf</a></p>
<p>【FTRL的工程实现论文】<a href="https://www.eecs.tufts.edu/~dsculley/papers/ad-click-prediction.pdf" target="_blank" rel="noopener">https://www.eecs.tufts.edu/~dsculley/papers/ad-click-prediction.pdf</a> </p>

          
        
      
    </div>

    

    
    
    

    

    
      
    
    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  

  <article class="post post-type-normal" itemscope="" itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="https://schwimmer.github.io/2017/07/12/机器学习/机器学习笔记-最大熵/">

    <span hidden itemprop="author" itemscope="" itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Schwimmer">
      <meta itemprop="description" content="Record and Think!">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope="" itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Schwimmer's Blog">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                
                <a href="/2017/07/12/机器学习/机器学习笔记-最大熵/" class="post-title-link" itemprop="url">机器学习笔记-最大熵</a>
              
            
          </h1>
        

        <div class="post-meta">

          
          
          

          
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              

              
                
              

              <time title="创建时间：2017-07-12 11:49:53" itemprop="dateCreated datePublished" datetime="2017-07-12T11:49:53+08:00">2017-07-12</time>
            </span>
          

          
            

            
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="fa fa-calendar-check-o"></i>
                </span>
                
                  <span class="post-meta-item-text">更新于</span>
                
                <time title="修改时间：2018-03-17 20:50:31" itemprop="dateModified" datetime="2018-03-17T20:50:31+08:00">2018-03-17</time>
              </span>
            
          

          
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope="" itemtype="http://schema.org/Thing"><a href="/categories/机器学习/" itemprop="url" rel="index"><span itemprop="name">机器学习</span></a></span>

                
                
              
            </span>
          

          
            
            
              
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="fa fa-comment-o"></i>
                </span>
            
                <span class="post-meta-item-text">评论数：</span>
                <a href="/2017/07/12/机器学习/机器学习笔记-最大熵/#comments" itemprop="discussionUrl">
                  <span class="post-comments-count disqus-comment-count" data-disqus-identifier="2017/07/12/机器学习/机器学习笔记-最大熵/" itemprop="commentCount"></span>
                </a>
              </span>
            
          

          
          

          

          <br>
          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1 id="1、最大熵原理"><a href="#1、最大熵原理" class="headerlink" title="1、最大熵原理"></a>1、最大熵原理</h1><p>日常生活中，很多事情的发生表现出一定的随机性，试验的结果往往是不确定的，也不知道这个随机现象所服从的概率分布。<strong>最大熵的实质</strong>就是，在已知部分知识的前提下，关于未知分布最合理的推断就是符合已知知识最不确定或者最随机的推断。任何其他的选择都意味着我们增加了其他的约束和假设。</p>
<p>将最大熵应用到分类，就是最大熵模型。给定一个训练集：</p>
<script type="math/tex; mode=display">
T = \{  (x_1,y_1),  (x_2,y_2),..., (x_N,y_N)\}</script><p>其中$x_i \in X$是输入，$y_i \in Y$是输出，X和Y表示输入和输出空间。N为样本数。<strong>目标是</strong>，利用最大熵原理选出一个最好的分类模型，即对于任意给定的输入$x \in X$，可以以概率$p(y|x)$输出$y \in Y$ 。</p>
<p>按照最大熵原理，应该<strong>优先保证模型满足已知的所有约束</strong>。思路是，从训练数据T中抽取若干有用的特征，要求这些特征在T上关于经验分布$\tilde{p}(x,y)$的数学期望与它们在模型中关于$p(x,y)$的数学期望相等。这样，一个特征就是一个约束了。</p>
<p>这里就涉及到，<strong>特征如何刻画？经验分布如何表示？</strong></p>
<h1 id="2、特征函数"><a href="#2、特征函数" class="headerlink" title="2、特征函数"></a>2、特征函数</h1><p>假设通过特征选择，抽取若干特征。特征通常由特征函数来表示。例如</p>
<script type="math/tex; mode=display">
f(x,y) =\left\{\begin{matrix}
\begin{aligned}
& 1，若x,y满足某个事实 \\ 
& 0，否则
\end{aligned}
\end{matrix}\right.</script><p>这里的特征不是指输入的某个特征，而是指输入和输出共同的特征。</p>
<blockquote>
<p>例如，假设我们需要判断“打”是动词还是量词，已知的训练数据有</p>
<p>(x1,y1)=(一打火柴，量词);</p>
<p>(x2,y2)=(三打啤酒，量词);</p>
<p>(x3,y3)=(打电话，动词);</p>
<p>(x4,y4)=(打篮球，动词);</p>
<p>通过观察，发现“打”前面是数字时，是量词，“打”后面是名词时，是动词。这就是从训练数据中提取的两个特征，可分别用特征函数表示为</p>
</blockquote>
<h1 id="3、经验分布"><a href="#3、经验分布" class="headerlink" title="3、经验分布"></a>3、经验分布</h1><p>经验（概率）分布就是通过对训练集T进行统计得到的分布，用$\tilde p$表示。这里列举两个经验分布</p>
<script type="math/tex; mode=display">
\tilde p(x,y) = \frac {count(x,y)} {N} , \tilde p(x)=\frac {count(x)} {N}</script><p>其中，count表示出现的次数。</p>
<h1 id="4、约束条件"><a href="#4、约束条件" class="headerlink" title="4、约束条件"></a>4、约束条件</h1><p>对于任意一个特征函数f，$E<em>{\tilde p}f$ 表示f在训练数据T上关于$\tilde p(x,y)$的数学期望， $E</em>{p}f$ 表示f在训练数据T上关于$p(x,y)$的数学期望。按照期望的定义，我们有</p>
<script type="math/tex; mode=display">
E_{\tilde p}f=\sum_{x,y}\tilde p(x,y)f(x,y)</script><script type="math/tex; mode=display">
E_{ p}f=\sum_{x,y} p(x,y)f(x,y)</script><p>其中，p(x,y)是未知的，而建模的目标是生成$p(y|x)$，因此，根据Bayes定理，$p(x,y)=p(x)p(y|x)$。在样本数量足够的条件下，$p(x)$可以用$\tilde p(x)$近似表示。这样</p>
<script type="math/tex; mode=display">
E_{ p}f=\sum_{x,y} \tilde p(x)p(y|x)f(x,y)</script><p>对于概率分布$p(y|x)$，我们希望特征f的期望值应该和从训练集中得到的特征期望值是一致的，因此，<strong>增加约束</strong></p>
<script type="math/tex; mode=display">
E_{ p}f=E_{\tilde p}f</script><p>假设我们从训练集中抽取了n个特征，相应的，便有n个特征函数$f_i(i=1,2,…,n)$以及n个约束条件</p>
<script type="math/tex; mode=display">
C_i:E_{ p}(f_i)=E_{\tilde p}(f_i) \tag {3-1}</script><blockquote>
<p>关于约束条件的几何解释</p>
<p><img src="/.io//最大熵1.png" alt="最大熵1"></p>
<p>（a）：P是所有可能的概率空间，此时没有约束条件，所有的概率模型$p(y|x)$都是允许的；</p>
<p>（b）：增加了一个线性约束条件$C_1$，此时，目标分布$p(y|x)$只能落在由$C_1$定义的线段上；</p>
<p>（c）：在（b）的基础上增加了另一个约束条件$C_2$ ，且$C_1 \cap C_2  \neq \varnothing$。此时，目标分布只能落在交点上，即被唯一确定；</p>
<p>（d）：在（b）基础上增加了另一个约束$C_3$，且$C_1 \cap C_2  = \varnothing$，此时不存在能够同时满足$C_1$和$C_3$的$p(y|x)$。</p>
</blockquote>
<p>利用（3-1）定义的约束条件，我们定义P的一个子空间</p>
<script type="math/tex; mode=display">
C=\{p \in P | E_p(f_i)={\tau}_i, i=1,2,...,n\}</script><h1 id="5、最大熵模型"><a href="#5、最大熵模型" class="headerlink" title="5、最大熵模型"></a>5、最大熵模型</h1><p>由于我们的目标是获得一个条件分布，因此这里也采用相应的条件熵</p>
<script type="math/tex; mode=display">
H(p(y|x))=-\sum_{x,y} \tilde p(x)p(y|x)\log p(y|x)</script><p>可以看出这里也是用$\tilde p(x)$来近似$p(x)$。以下将$H(p(y|x))$简记为$H(p)$。至此，可以给出最大熵模型的完整描述。</p>
<p>对于给定的训练集T，特征函数$f_i(x,y), i=1,2,…n$，最大熵模型就是求解</p>
<script type="math/tex; mode=display">
\underset {p \in C} {max} \ \  H(p) = \begin{pmatrix}
-\sum_{x,y} \tilde p(x)p(y|x)\log p(y|x)
\end{pmatrix}, \\
s.t. \sum_y p(y|x)=1 \tag {5-1} \\
s.t. \ C=\{p \in P | E_p(f_i)={\tau}_i, i=1,2,...,n\}</script><p>其中的s.t.是为了保证$p(y|x)$是一个（合法的）条件概率分布。</p>
<p>等价于一个求极小值问题</p>
<script type="math/tex; mode=display">
\underset {p \in C} {min} \ \  -H(p) = \begin{pmatrix}
\sum_{x,y} \tilde p(x)p(y|x)\log p(y|x)
\end{pmatrix}, \\
s.t. \sum_y p(y|x)=1 \tag {5-2} \\
s.t. \ C=\{p \in P | E_p(f_i)={\tau}_i, i=1,2,...,n\}</script><h1 id="6、模型求解"><a href="#6、模型求解" class="headerlink" title="6、模型求解"></a>6、模型求解</h1><p>对于5-1的求解，主要思路和步骤如下：</p>
<ol>
<li>利用Lagrange乘子将最大熵模型由一个带约束的最优化问题转为无约束的最优化问题，这是一个<strong>极小极大问题（min max）</strong>。</li>
<li>利用对偶问题等价性，转化为求解上一步得到的极大/极小问题的对偶问题，也是一个极大极小问题。</li>
</ol>
<h2 id="6-1-原始问题和对偶问题"><a href="#6-1-原始问题和对偶问题" class="headerlink" title="6.1 原始问题和对偶问题"></a>6.1 原始问题和对偶问题</h2><p>根据（5-2），引入拉格朗日乘子$\lambda=(\lambda_0,\lambda_1,…,\lambda_n)^T$，定义拉格朗日函数</p>
<script type="math/tex; mode=display">
L(p,\lambda) = -H(p) + \lambda_0(1-\sum_y p(y|x))+\sum_{i=1}^n\lambda_i(\tau_i-E_p(f_i))  \tag{6-1}</script><p>利用对偶性，求解（6-1）的<strong>原始问题</strong>表示为：</p>
<script type="math/tex; mode=display">
\underset {p \in C} {min}\  \underset {\lambda} {max}\ L(p,\lambda) \tag{6-2}</script><p><strong>对偶问题</strong>为：</p>
<script type="math/tex; mode=display">
\underset {\lambda} {max}\ \underset {p \in C} {min}\  L(p,\lambda) \tag{6-3}</script><p>由于$H(p)$是关于p的凸函数，因此要求解最大熵模型，只需求解对偶问题（6-3）即可。</p>
<h3 id="6-1-1-指数形式的解"><a href="#6-1-1-指数形式的解" class="headerlink" title="6.1.1 指数形式的解"></a>6.1.1 指数形式的解</h3><p>首先求解内部的极小问题。由于$\underset {p \in C} {min}\  L(p,\lambda)$是关于$\lambda$的函数，将其记做：</p>
<script type="math/tex; mode=display">
\Psi (\lambda) =\underset {p \in C} {min}\  L(p,\lambda) = L(p_{\lambda}, \lambda) \tag {6-4}</script><p>其中</p>
<script type="math/tex; mode=display">
p_{\lambda}=\underset {p \in C} {argmin}\ L(p,\lambda)=p_{\lambda}(y|x) \tag {6-5}</script><p>根据拉格朗日乘子法，求$L(p,\lambda)$对$p(y|x)$的偏导，得（求解过程略）：</p>
<script type="math/tex; mode=display">
p_{\lambda}=\frac {1} {Z_{\lambda}(x)} \ \exp(\sum_{i=1}^n \lambda_i f_i(x,y)) \tag{6-6}</script><p>其中，</p>
<script type="math/tex; mode=display">
Z_{\lambda}(x)=\sum_y \exp(\sum_{i=1}^n \lambda_i f_i(x,y)) \tag{6-7}</script><p>称为<strong>规范化因子</strong>（normalizing factor）。注意，此时已经没有$\lambda_0$了。</p>
<p>由（6-6）定义的$p_{\lambda}$就是最大熵模型的解，它具有<strong>指数形式</strong>。其中，$\lambda_i$就是特征$f_i$的权重，越大表示特征越重要。</p>
<h3 id="6-1-2-最大似然估计"><a href="#6-1-2-最大似然估计" class="headerlink" title="6.1.2 最大似然估计"></a>6.1.2 最大似然估计</h3><p>得到对偶问题的内层极小值问题的解之后，接着求解外层的极大值问题$\underset {\lambda} {max} \ \Psi(\lambda)$。</p>
<p>设其解为</p>
<script type="math/tex; mode=display">
\lambda^* = \underset {\lambda} {argmax} \ \Psi(\lambda) \tag{6-8}</script><p>则最大熵模型的解为</p>
<script type="math/tex; mode=display">
p^*=p_{\lambda^*} \tag{6-9}</script><p>根据推导，最大化$\Psi(\lambda)$与最大似然估计是等价的！</p>
<h1 id="7、最优化方法"><a href="#7、最优化方法" class="headerlink" title="7、最优化方法"></a>7、最优化方法</h1><p>通用的方法有梯度下降，拟牛顿法等，最大熵模型有两个量身定做的方法：通用迭代尺度法（Generalized Iterative Scaling，GIS）和改进的迭代尺度法（Impoved Iterative Scaling，IIS）。</p>
<h2 id="7-1-GIS算法"><a href="#7-1-GIS算法" class="headerlink" title="7.1 GIS算法"></a>7.1 GIS算法</h2><blockquote>
<p>算法1：</p>
<p>S1：初始化参数，令$\lambda=0$</p>
<p>S2：计算$E_{\tilde p}(f_i),\ i=1,2,…,n$</p>
<p>S3：执行一次迭代，对参数做一次刷新。</p>
<p>​    计算$E<em>{p</em>{\lambda}}(f_i)$</p>
<p>​    FOR i=1,2,…,n DO {</p>
<p>​        $\lambda<em>i\  += \ \eta \log\frac {E</em>{\tilde p}(f<em>i)} {E</em>{p_{\lambda}}(f_i)}$</p>
<p>​    }</p>
<p>S4：检查是否收敛，若未收敛则继续S3</p>
</blockquote>
<p>其中，$\eta$是学习率，在实际中取$\frac {1} {C}$，$$，表示训练数据中包含特征最多的那个样本所包含的特征个数。</p>
<script type="math/tex; mode=display">
\Delta\lambda_i=\eta \log\frac {E_{\tilde p}(f_i)} {E_{p_{\lambda}}(f_i)}</script><p>是校正量。</p>
<p>每次迭代，先用当前的权重估算每个特征$f<em>i$在训练数据中的概率分布的期望，然后逐个与相应的经验分布的期望比较，其偏差程度通过$\log\frac {E</em>{\tilde p}(f<em>i)} {E</em>{p_{\lambda}}(f_i)}$来进行刻画。</p>
<p>收敛条件就是当两次迭代的$\lambda$在一个较小的范围。</p>
<p>GIS每次迭代时间很长，不太稳定，容易溢出，一般不会使用。</p>
<h2 id="7-2-IIS算法"><a href="#7-2-IIS算法" class="headerlink" title="7.2 IIS算法"></a>7.2 IIS算法</h2><p>与GIS的不同主要在$\Delta\lambda_i$的计算上。IIS通过求解方程</p>
<script type="math/tex; mode=display">
\sum_{x,y} \tilde p(x)p(y|x)f_i(x,y)\exp(\Delta\lambda_i\sum_{i=1}^nf_i(x,y))=\tilde p(f_i)</script><p>1）若$\sum<em>{i=1}^nf_i(x,y)$为常数，即对任意样本(x,y)，都有$\sum</em>{i=1}^nf_i(x,y)=C$，则</p>
<script type="math/tex; mode=display">
\Delta\lambda_i=\frac {1} {C} \log\frac {E_{\tilde p}(f_i)} {E_{p_{\lambda}}(f_i)}</script><p>此时，IIS可以看做是GIS的一种推广。</p>
<p>2）若$\sum_{i=1}^nf_i(x,y)$不是常数，则需要通过数值方式来求解$\Delta\lambda_i$，如牛顿法。</p>
<h1 id="8、优缺点"><a href="#8、优缺点" class="headerlink" title="8、优缺点"></a>8、优缺点</h1><p>优点是：在建模时，只需要集中精力选取特征，不需要花费精力考虑如何使用这些特征，可以灵活使用不同类型的特征。</p>
<p>缺点是计算量大。</p>
<p>参考</p>
<p>【1】 <a href="http://blog.csdn.net/itplus/article/details/26550273" target="_blank" rel="noopener">最大熵学习笔记</a></p>
<p>【2】统计学习方法</p>

          
        
      
    </div>

    

    
    
    

    

    
      
    
    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  

  <article class="post post-type-normal" itemscope="" itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="https://schwimmer.github.io/2017/07/12/hadoop-spark/kafka笔记/">

    <span hidden itemprop="author" itemscope="" itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Schwimmer">
      <meta itemprop="description" content="Record and Think!">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope="" itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Schwimmer's Blog">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                
                <a href="/2017/07/12/hadoop-spark/kafka笔记/" class="post-title-link" itemprop="url">kafka笔记</a>
              
            
          </h1>
        

        <div class="post-meta">

          
          
          

          
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              

              
                
              

              <time title="创建时间：2017-07-12 11:49:53" itemprop="dateCreated datePublished" datetime="2017-07-12T11:49:53+08:00">2017-07-12</time>
            </span>
          

          
            

            
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="fa fa-calendar-check-o"></i>
                </span>
                
                  <span class="post-meta-item-text">更新于</span>
                
                <time title="修改时间：2018-01-30 15:46:08" itemprop="dateModified" datetime="2018-01-30T15:46:08+08:00">2018-01-30</time>
              </span>
            
          

          
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope="" itemtype="http://schema.org/Thing"><a href="/categories/hadoop-spark/" itemprop="url" rel="index"><span itemprop="name">hadoop-spark</span></a></span>

                
                
              
            </span>
          

          
            
            
              
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="fa fa-comment-o"></i>
                </span>
            
                <span class="post-meta-item-text">评论数：</span>
                <a href="/2017/07/12/hadoop-spark/kafka笔记/#comments" itemprop="discussionUrl">
                  <span class="post-comments-count disqus-comment-count" data-disqus-identifier="2017/07/12/hadoop-spark/kafka笔记/" itemprop="commentCount"></span>
                </a>
              </span>
            
          

          
          

          

          <br>
          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1 id="多个消费者读取一个topic，多次消费"><a href="#多个消费者读取一个topic，多次消费" class="headerlink" title="多个消费者读取一个topic，多次消费"></a>多个消费者读取一个topic，多次消费</h1><p>不同消费者设置不同的groupid</p>
 <figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">val</span> kafkaParm = <span class="type">Map</span>(<span class="string">"metadata.broker.list"</span> -&gt; <span class="string">"localhost:9092"</span>,</span><br><span class="line"><span class="string">"auto.offset.reset"</span> -&gt; <span class="string">"smallest"</span>, <span class="string">"group.id"</span> -&gt; <span class="string">"davidtopi1c1"</span>)</span><br></pre></td></tr></table></figure>
<h1 id="每个消费者不会重复消费数据"><a href="#每个消费者不会重复消费数据" class="headerlink" title="每个消费者不会重复消费数据"></a>每个消费者不会重复消费数据</h1><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"> kafkaStrem.foreachRDD&#123;</span><br><span class="line">      rdd=&gt;</span><br><span class="line">        km.updateZKOffsets(rdd)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>﻿</p>

          
        
      
    </div>

    

    
    
    

    

    
      
    
    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  

  <article class="post post-type-normal" itemscope="" itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="https://schwimmer.github.io/2017/07/12/hadoop-spark/hive笔记-orc格式读写/">

    <span hidden itemprop="author" itemscope="" itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Schwimmer">
      <meta itemprop="description" content="Record and Think!">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope="" itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Schwimmer's Blog">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                
                <a href="/2017/07/12/hadoop-spark/hive笔记-orc格式读写/" class="post-title-link" itemprop="url">hive笔记-orc格式读写</a>
              
            
          </h1>
        

        <div class="post-meta">

          
          
          

          
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              

              
                
              

              <time title="创建时间：2017-07-12 11:49:53" itemprop="dateCreated datePublished" datetime="2017-07-12T11:49:53+08:00">2017-07-12</time>
            </span>
          

          
            

            
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="fa fa-calendar-check-o"></i>
                </span>
                
                  <span class="post-meta-item-text">更新于</span>
                
                <time title="修改时间：2018-01-30 15:52:38" itemprop="dateModified" datetime="2018-01-30T15:52:38+08:00">2018-01-30</time>
              </span>
            
          

          
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope="" itemtype="http://schema.org/Thing"><a href="/categories/hadoop-spark/" itemprop="url" rel="index"><span itemprop="name">hadoop-spark</span></a></span>

                
                
              
            </span>
          

          
            
            
              
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="fa fa-comment-o"></i>
                </span>
            
                <span class="post-meta-item-text">评论数：</span>
                <a href="/2017/07/12/hadoop-spark/hive笔记-orc格式读写/#comments" itemprop="discussionUrl">
                  <span class="post-comments-count disqus-comment-count" data-disqus-identifier="2017/07/12/hadoop-spark/hive笔记-orc格式读写/" itemprop="commentCount"></span>
                </a>
              </span>
            
          

          
          

          

          <br>
          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>需要引入的包：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">&lt;dependency&gt;</span><br><span class="line">                        &lt;groupId&gt;org.apache.hadoop&lt;/groupId&gt;</span><br><span class="line">                        &lt;artifactId&gt;hadoop-core&lt;/artifactId&gt;</span><br><span class="line">                        &lt;version&gt;2.6.0-mr1-cdh5.9.1&lt;/version&gt;</span><br><span class="line">                &lt;/dependency&gt;</span><br><span class="line">&lt;dependency&gt;</span><br><span class="line">                        &lt;groupId&gt;org.apache.hive&lt;/groupId&gt;</span><br><span class="line">                        &lt;artifactId&gt;hive-common&lt;/artifactId&gt;</span><br><span class="line">                        &lt;version&gt;1.1.0-cdh5.9.1&lt;/version&gt;</span><br><span class="line">                &lt;/dependency&gt;</span><br><span class="line">                &lt;dependency&gt;</span><br><span class="line">                        &lt;groupId&gt;org.apache.hive&lt;/groupId&gt;</span><br><span class="line">                        &lt;artifactId&gt;hive-exec&lt;/artifactId&gt;</span><br><span class="line">                        &lt;version&gt;1.1.0-cdh5.9.1&lt;/version&gt;</span><br><span class="line">                &lt;/dependency&gt;</span><br></pre></td></tr></table></figure>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">val</span> fs = <span class="type">FileSystem</span>.get(conf);</span><br><span class="line"><span class="keyword">val</span> prop = <span class="type">Config</span>.getConfig(<span class="string">"config.properties"</span>)</span><br><span class="line">println(sdf.format(<span class="keyword">new</span> <span class="type">Date</span>))</span><br><span class="line"><span class="keyword">val</span> readerOpts = <span class="type">OrcFile</span>.readerOptions(conf)</span><br><span class="line"><span class="keyword">val</span> reader = <span class="type">OrcFile</span>.createReader(<span class="keyword">new</span> <span class="type">Path</span>(iaxReqPath+<span class="string">"/ds=17-08-21/20170821000000antispam_2529853576425433.orc"</span>), readerOpts)</span><br><span class="line"><span class="keyword">val</span> inspector = reader.getObjectInspector().asInstanceOf[<span class="type">StructObjectInspector</span>]</span><br><span class="line"></span><br><span class="line"><span class="keyword">val</span> count = reader.getNumberOfRows</span><br><span class="line">info(<span class="string">"the count is: "</span> + count.toString())</span><br><span class="line"></span><br><span class="line"><span class="keyword">val</span> fields = inspector.getAllStructFieldRefs()</span><br><span class="line"></span><br><span class="line">fields.foreach &#123; x =&gt; </span><br><span class="line">  println(x.getFieldObjectInspector.getCategory)  </span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">val</span> records = reader.rows()</span><br><span class="line"><span class="keyword">var</span> n=<span class="number">0</span></span><br><span class="line"><span class="keyword">val</span> loop = <span class="keyword">new</span> <span class="type">Breaks</span></span><br><span class="line">loop.breakable(&#123;</span><br><span class="line">  <span class="keyword">while</span>(records.hasNext)&#123;</span><br><span class="line">    <span class="keyword">if</span> (n&gt;<span class="number">5</span>) loop.<span class="keyword">break</span></span><br><span class="line">    <span class="keyword">val</span> row = records.next(<span class="literal">null</span>)</span><br><span class="line">    <span class="keyword">val</span> valueList = inspector.getStructFieldsDataAsList(row)</span><br><span class="line">    info(valueList.get(<span class="number">10</span>).toString)</span><br><span class="line">    info(row.toString())</span><br><span class="line">    n = n+<span class="number">1</span></span><br><span class="line">  &#125;</span><br><span class="line">&#125;)</span><br></pre></td></tr></table></figure>

          
        
      
    </div>

    

    
    
    

    

    
      
    
    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  

  <article class="post post-type-normal" itemscope="" itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="https://schwimmer.github.io/2017/07/12/hadoop-spark/hadoop笔记/">

    <span hidden itemprop="author" itemscope="" itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Schwimmer">
      <meta itemprop="description" content="Record and Think!">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope="" itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Schwimmer's Blog">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                
                <a href="/2017/07/12/hadoop-spark/hadoop笔记/" class="post-title-link" itemprop="url">hadoop笔记</a>
              
            
          </h1>
        

        <div class="post-meta">

          
          
          

          
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              

              
                
              

              <time title="创建时间：2017-07-12 11:49:53" itemprop="dateCreated datePublished" datetime="2017-07-12T11:49:53+08:00">2017-07-12</time>
            </span>
          

          
            

            
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="fa fa-calendar-check-o"></i>
                </span>
                
                  <span class="post-meta-item-text">更新于</span>
                
                <time title="修改时间：2018-03-17 20:50:31" itemprop="dateModified" datetime="2018-03-17T20:50:31+08:00">2018-03-17</time>
              </span>
            
          

          
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope="" itemtype="http://schema.org/Thing"><a href="/categories/hadoop-spark/" itemprop="url" rel="index"><span itemprop="name">hadoop-spark</span></a></span>

                
                
              
            </span>
          

          
            
            
              
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="fa fa-comment-o"></i>
                </span>
            
                <span class="post-meta-item-text">评论数：</span>
                <a href="/2017/07/12/hadoop-spark/hadoop笔记/#comments" itemprop="discussionUrl">
                  <span class="post-comments-count disqus-comment-count" data-disqus-identifier="2017/07/12/hadoop-spark/hadoop笔记/" itemprop="commentCount"></span>
                </a>
              </span>
            
          

          
          

          

          <br>
          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1 id="查看namenode"><a href="#查看namenode" class="headerlink" title="查看namenode"></a>查看namenode</h1><p>在集群的每个节点上都有配置文件，</p>
<p>vim /etc/hadoop/conf/hdfs-site.xml</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">&lt;property&gt;</span><br><span class="line"></span><br><span class="line">    &lt;name&gt;dfs.ha.namenodes.iclick&lt;/name&gt;</span><br><span class="line"></span><br><span class="line">    &lt;value&gt;srv-buzz-cloudpmnn1.buzz.com,srv-buzz-cloudpmnn2.buzz.com&lt;/value&gt;</span><br><span class="line"></span><br><span class="line">&lt;/property&gt;</span><br></pre></td></tr></table></figure>
<h1 id="常用IO操作"><a href="#常用IO操作" class="headerlink" title="常用IO操作"></a>常用IO操作</h1><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">public static void testIOUtils() throws IOException &#123;</span><br><span class="line">Configuration conf = new Configuration();</span><br><span class="line">FileSystem fs = FileSystem.get(conf);</span><br><span class="line">Path p = new Path(&quot;/test/in/point&quot;);</span><br><span class="line">FSDataInputStream fdis = fs.open(p);</span><br><span class="line">IOUtils.copyBytes(fdis, System.out, conf,false);</span><br><span class="line">IOUtils.closeStream(fdis);</span><br><span class="line">fs.close();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

          
        
      
    </div>

    

    
    
    

    

    
      
    
    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
  </section>

  
  <nav class="pagination">
    <a class="extend prev" rel="prev" href="/page/28/"><i class="fa fa-angle-left" aria-label="上一页"></i></a><a class="page-number" href="/">1</a><span class="space">&hellip;</span><a class="page-number" href="/page/28/">28</a><span class="page-number current">29</span><a class="page-number" href="/page/30/">30</a><a class="page-number" href="/page/31/">31</a><a class="extend next" rel="next" href="/page/30/"><i class="fa fa-angle-right" aria-label="下一页"></i></a>
  </nav>



          </div>
          

        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    <div class="sidebar-inner">

      

      

      <div class="site-overview-wrap sidebar-panel sidebar-panel-active">
        <div class="site-overview">
          <div class="site-author motion-element" itemprop="author" itemscope="" itemtype="http://schema.org/Person">
            
              <p class="site-author-name" itemprop="name">Schwimmer</p>
              <div class="site-description motion-element" itemprop="description">Record and Think!</div>
          </div>

          
            <nav class="site-state motion-element">
              
                <div class="site-state-item site-state-posts">
                
                  <a href="/archives/">
                
                    <span class="site-state-item-count">308</span>
                    <span class="site-state-item-name">日志</span>
                  </a>
                </div>
              

              
                
                
                <div class="site-state-item site-state-categories">
                  
                    
                      <a href="/categories/">
                    
                  
                    
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                    <span class="site-state-item-count">25</span>
                    <span class="site-state-item-name">分类</span>
                  </a>
                </div>
              

              
                
                
                <div class="site-state-item site-state-tags">
                  
                    
                      <a href="/tags/">
                    
                  
                    
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                    <span class="site-state-item-count">61</span>
                    <span class="site-state-item-name">标签</span>
                  </a>
                </div>
              
            </nav>
          

          

          

          

          

          
          

          
            
          
          

        </div>
      </div>

      

      

    </div>
  </aside>
  


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <div class="copyright">&copy; <span itemprop="copyrightYear">2019</span>
  <span class="with-love" id="animate">
    <i class="fa fa-user"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">Schwimmer</span>

  

  
</div>


  <div class="powered-by">由 <a href="https://hexo.io" class="theme-link" rel="noopener" target="_blank">Hexo</a> 强力驱动 v3.9.0</div>



  <span class="post-meta-divider">|</span>



  <div class="theme-info">主题 – <a href="https://theme-next.org" class="theme-link" rel="noopener" target="_blank">NexT.Mist</a> v7.2.0</div>




        
<div class="busuanzi-count">
  <script async src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>

  
    <span class="post-meta-item-icon">
      <i class="fa fa-user"></i>
    </span>
    <span class="site-uv" title="总访客量">
      <span class="busuanzi-value" id="busuanzi_value_site_uv"></span>
    </span>
  

  
    <span class="post-meta-divider">|</span>
  

  
    <span class="post-meta-item-icon">
      <i class="fa fa-eye"></i>
    </span>
    <span class="site-pv" title="总访问量">
      <span class="busuanzi-value" id="busuanzi_value_site_pv"></span>
    </span>
  
</div>









        
      </div>
    </footer>

    
      <div class="back-to-top">
        <i class="fa fa-arrow-up"></i>
        
      </div>
    

    

    
      <div>
        
  <script>
    window._bd_share_config = {
      "common": {
        "bdText": "",
        "bdMini": "1",
        "bdMiniList": false,
        "bdPic": ""
      },
      "image": {
        "viewList": ["tsina", "douban", "sqq", "qzone", "weixin", "twi", "fbook"],
        "viewText": "分享到：",
        "viewSize": "16"
      },
      "slide": {
        "bdImg": "5",
        "bdPos": "left",
        "bdTop": "100"
      }
    }
  </script>

<script>
  with(document)0[(getElementsByTagName('head')[0]||body).appendChild(createElement('script')).src='//bdimg.share.baidu.com/static/api/js/share.js?cdnversion='+~(-new Date()/36e5)];
</script>

      </div>
    

    
  </div>

  

<script>
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>


























  
  <script src="/lib/jquery/index.js?v=3.4.1"></script>

  
  <script src="/lib/velocity/velocity.min.js?v=1.2.1"></script>

  
  <script src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>


  


  <script src="/js/utils.js?v=7.2.0"></script>

  <script src="/js/motion.js?v=7.2.0"></script>



  
  


  <script src="/js/schemes/muse.js?v=7.2.0"></script>




  

  


  <script src="/js/next-boot.js?v=7.2.0"></script>


  

  

  

  
  
<script>
  function loadCount() {
    var d = document, s = d.createElement('script');
    s.src = 'https://https-schwimmer-github-io.disqus.com/count.js';
    s.id = 'dsq-count-scr';
    (d.head || d.body).appendChild(s);
  }
  // defer loading until the whole page loading is completed
  window.addEventListener('load', loadCount, false);
</script>







  
  <script>
    // Popup Window;
    var isfetched = false;
    var isXml = true;
    // Search DB path;
    var search_path = "search.xml";
    if (search_path.length === 0) {
      search_path = "search.xml";
    } else if (/json$/i.test(search_path)) {
      isXml = false;
    }
    var path = "/" + search_path;
    // monitor main search box;

    var onPopupClose = function (e) {
      $('.popup').hide();
      $('#local-search-input').val('');
      $('.search-result-list').remove();
      $('#no-result').remove();
      $(".local-search-pop-overlay").remove();
      $('body').css('overflow', '');
    }

    function proceedsearch() {
      $("body")
        .append('<div class="search-popup-overlay local-search-pop-overlay"></div>')
        .css('overflow', 'hidden');
      $('.search-popup-overlay').click(onPopupClose);
      $('.popup').toggle();
      var $localSearchInput = $('#local-search-input');
      $localSearchInput.attr("autocapitalize", "none");
      $localSearchInput.attr("autocorrect", "off");
      $localSearchInput.focus();
    }

    // search function;
    var searchFunc = function(path, search_id, content_id) {
      'use strict';

      // start loading animation
      $("body")
        .append('<div class="search-popup-overlay local-search-pop-overlay">' +
          '<div id="search-loading-icon">' +
          '<i class="fa fa-spinner fa-pulse fa-5x fa-fw"></i>' +
          '</div>' +
          '</div>')
        .css('overflow', 'hidden');
      $("#search-loading-icon").css('margin', '20% auto 0 auto').css('text-align', 'center');

      

      $.ajax({
        url: path,
        dataType: isXml ? "xml" : "json",
        async: true,
        success: function(res) {
          // get the contents from search data
          isfetched = true;
          $('.popup').detach().appendTo('.header-inner');
          var datas = isXml ? $("entry", res).map(function() {
            return {
              title: $("title", this).text(),
              content: $("content",this).text(),
              url: $("url" , this).text()
            };
          }).get() : res;
          var input = document.getElementById(search_id);
          var resultContent = document.getElementById(content_id);
          var inputEventFunction = function() {
            var searchText = input.value.trim().toLowerCase();
            var keywords = searchText.split(/[\s\-]+/);
            if (keywords.length > 1) {
              keywords.push(searchText);
            }
            var resultItems = [];
            if (searchText.length > 0) {
              // perform local searching
              datas.forEach(function(data) {
                var isMatch = false;
                var hitCount = 0;
                var searchTextCount = 0;
                var title = data.title.trim();
                var titleInLowerCase = title.toLowerCase();
                var content = data.content.trim().replace(/<[^>]+>/g,"");
                
                var contentInLowerCase = content.toLowerCase();
                var articleUrl = decodeURIComponent(data.url).replace(/\/{2,}/g, '/');
                var indexOfTitle = [];
                var indexOfContent = [];
                // only match articles with not empty titles
                if(title != '') {
                  keywords.forEach(function(keyword) {
                    function getIndexByWord(word, text, caseSensitive) {
                      var wordLen = word.length;
                      if (wordLen === 0) {
                        return [];
                      }
                      var startPosition = 0, position = [], index = [];
                      if (!caseSensitive) {
                        text = text.toLowerCase();
                        word = word.toLowerCase();
                      }
                      while ((position = text.indexOf(word, startPosition)) > -1) {
                        index.push({position: position, word: word});
                        startPosition = position + wordLen;
                      }
                      return index;
                    }

                    indexOfTitle = indexOfTitle.concat(getIndexByWord(keyword, titleInLowerCase, false));
                    indexOfContent = indexOfContent.concat(getIndexByWord(keyword, contentInLowerCase, false));
                  });
                  if (indexOfTitle.length > 0 || indexOfContent.length > 0) {
                    isMatch = true;
                    hitCount = indexOfTitle.length + indexOfContent.length;
                  }
                }

                // show search results

                if (isMatch) {
                  // sort index by position of keyword

                  [indexOfTitle, indexOfContent].forEach(function (index) {
                    index.sort(function (itemLeft, itemRight) {
                      if (itemRight.position !== itemLeft.position) {
                        return itemRight.position - itemLeft.position;
                      } else {
                        return itemLeft.word.length - itemRight.word.length;
                      }
                    });
                  });

                  // merge hits into slices

                  function mergeIntoSlice(text, start, end, index) {
                    var item = index[index.length - 1];
                    var position = item.position;
                    var word = item.word;
                    var hits = [];
                    var searchTextCountInSlice = 0;
                    while (position + word.length <= end && index.length != 0) {
                      if (word === searchText) {
                        searchTextCountInSlice++;
                      }
                      hits.push({position: position, length: word.length});
                      var wordEnd = position + word.length;

                      // move to next position of hit

                      index.pop();
                      while (index.length != 0) {
                        item = index[index.length - 1];
                        position = item.position;
                        word = item.word;
                        if (wordEnd > position) {
                          index.pop();
                        } else {
                          break;
                        }
                      }
                    }
                    searchTextCount += searchTextCountInSlice;
                    return {
                      hits: hits,
                      start: start,
                      end: end,
                      searchTextCount: searchTextCountInSlice
                    };
                  }

                  var slicesOfTitle = [];
                  if (indexOfTitle.length != 0) {
                    slicesOfTitle.push(mergeIntoSlice(title, 0, title.length, indexOfTitle));
                  }

                  var slicesOfContent = [];
                  while (indexOfContent.length != 0) {
                    var item = indexOfContent[indexOfContent.length - 1];
                    var position = item.position;
                    var word = item.word;
                    // cut out 100 characters
                    var start = position - 20;
                    var end = position + 80;
                    if(start < 0){
                      start = 0;
                    }
                    if (end < position + word.length) {
                      end = position + word.length;
                    }
                    if(end > content.length){
                      end = content.length;
                    }
                    slicesOfContent.push(mergeIntoSlice(content, start, end, indexOfContent));
                  }

                  // sort slices in content by search text's count and hits' count

                  slicesOfContent.sort(function (sliceLeft, sliceRight) {
                    if (sliceLeft.searchTextCount !== sliceRight.searchTextCount) {
                      return sliceRight.searchTextCount - sliceLeft.searchTextCount;
                    } else if (sliceLeft.hits.length !== sliceRight.hits.length) {
                      return sliceRight.hits.length - sliceLeft.hits.length;
                    } else {
                      return sliceLeft.start - sliceRight.start;
                    }
                  });

                  // select top N slices in content

                  var upperBound = parseInt('1');
                  if (upperBound >= 0) {
                    slicesOfContent = slicesOfContent.slice(0, upperBound);
                  }

                  // highlight title and content

                  function highlightKeyword(text, slice) {
                    var result = '';
                    var prevEnd = slice.start;
                    slice.hits.forEach(function (hit) {
                      result += text.substring(prevEnd, hit.position);
                      var end = hit.position + hit.length;
                      result += '<b class="search-keyword">' + text.substring(hit.position, end) + '</b>';
                      prevEnd = end;
                    });
                    result += text.substring(prevEnd, slice.end);
                    return result;
                  }

                  var resultItem = '';

                  if (slicesOfTitle.length != 0) {
                    resultItem += "<li><a href='" + articleUrl + "' class='search-result-title'>" + highlightKeyword(title, slicesOfTitle[0]) + "</a>";
                  } else {
                    resultItem += "<li><a href='" + articleUrl + "' class='search-result-title'>" + title + "</a>";
                  }

                  slicesOfContent.forEach(function (slice) {
                    resultItem += "<a href='" + articleUrl + "'>" +
                      "<p class=\"search-result\">" + highlightKeyword(content, slice) +
                      "...</p>" + "</a>";
                  });

                  resultItem += "</li>";
                  resultItems.push({
                    item: resultItem,
                    searchTextCount: searchTextCount,
                    hitCount: hitCount,
                    id: resultItems.length
                  });
                }
              })
            };
            if (keywords.length === 1 && keywords[0] === "") {
              resultContent.innerHTML = '<div id="no-result"><i class="fa fa-search fa-5x"></i></div>'
            } else if (resultItems.length === 0) {
              resultContent.innerHTML = '<div id="no-result"><i class="fa fa-frown-o fa-5x"></i></div>'
            } else {
              resultItems.sort(function (resultLeft, resultRight) {
                if (resultLeft.searchTextCount !== resultRight.searchTextCount) {
                  return resultRight.searchTextCount - resultLeft.searchTextCount;
                } else if (resultLeft.hitCount !== resultRight.hitCount) {
                  return resultRight.hitCount - resultLeft.hitCount;
                } else {
                  return resultRight.id - resultLeft.id;
                }
              });
              var searchResultList = '<ul class=\"search-result-list\">';
              resultItems.forEach(function (result) {
                searchResultList += result.item;
              })
              searchResultList += "</ul>";
              resultContent.innerHTML = searchResultList;
            }
          }

          if ('auto' === 'auto') {
            input.addEventListener('input', inputEventFunction);
          } else {
            $('.search-icon').click(inputEventFunction);
            input.addEventListener('keypress', function (event) {
              if (event.keyCode === 13) {
                inputEventFunction();
              }
            });
          }

          // remove loading animation
          $(".local-search-pop-overlay").remove();
          $('body').css('overflow', '');

          proceedsearch();
        }
      });
    }

    // handle and trigger popup window;
    $('.popup-trigger').click(function(e) {
      e.stopPropagation();
      if (isfetched === false) {
        searchFunc(path, 'local-search-input', 'local-search-result');
      } else {
        proceedsearch();
      };
    });

    $('.popup-btn-close').click(onPopupClose);
    $('.popup').click(function(e){
      e.stopPropagation();
    });
    $(document).on('keyup', function (event) {
      var shouldDismissSearchPopup = event.which === 27 &&
        $('.search-popup').is(':visible');
      if (shouldDismissSearchPopup) {
        onPopupClose();
      }
    });
  </script>





  

  

  
  

  
  
    
      
    
      
    
      
    
      
    
      
    
      
    
      
    
      
    
      
    
      
    
  

  
    
      <script type="text/x-mathjax-config">
  

  MathJax.Hub.Config({
    tex2jax: {
      inlineMath: [ ['$', '$'], ['\\(', '\\)'] ],
      processEscapes: true,
      skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
    },
    TeX: {
      
      equationNumbers: {
        autoNumber: 'AMS'
      }
    }
  });
  MathJax.Hub.Register.StartupHook('TeX Jax Ready', function() {
    MathJax.InputJax.TeX.prefilterHooks.Add(function(data) {
      if (data.display) {
        var next = data.script.nextSibling;
        while (next && next.nodeName.toLowerCase() === '#text') { next = next.nextSibling }
        if (next && next.nodeName.toLowerCase() === 'br') { next.parentNode.removeChild(next) }
      }
    });
  });
</script>

<script type="text/x-mathjax-config">
  MathJax.Hub.Queue(function() {
    var all = MathJax.Hub.getAllJax(), i;
    for (i = 0; i < all.length; i += 1) {
      document.getElementById(all[i].inputID + '-Frame').parentNode.className += ' has-jax';
    }
  });
</script>
<script src="//cdn.jsdelivr.net/npm/mathjax@2/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script><!-- hexo-inject:begin --><!-- Begin: Injected MathJax -->
<script type="text/x-mathjax-config">
  MathJax.Hub.Config({"tex2jax":{"inlineMath":[["$","$"],["\\(","\\)"]],"skipTags":["script","noscript","style","textarea","pre","code"],"processEscapes":true},"TeX":{"equationNumbers":{"autoNumber":"AMS"}}});
</script>

<script type="text/x-mathjax-config">
  MathJax.Hub.Queue(function() {
    var all = MathJax.Hub.getAllJax(), i;
    for(i=0; i < all.length; i += 1) {
      all[i].SourceElement().parentNode.className += ' has-jax';
    }
  });
</script>

<script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js">
</script>
<!-- End: Injected MathJax -->
<!-- hexo-inject:end -->

    
  


  

  

  

  

  

  

  

  

  

  

  

</body>
</html>
