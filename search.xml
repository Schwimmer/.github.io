<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[如何选定分区数量]]></title>
    <url>%2F2019%2F11%2F15%2Fkafka%2F%E7%99%BE%E9%97%AEkafka%2F%E5%A6%82%E4%BD%95%E9%80%89%E5%AE%9A%E5%88%86%E5%8C%BA%E6%95%B0%E9%87%8F%2F</url>
    <content type="text"><![CDATA[需要考虑： 1、topic需要多大吞吐量，每秒100KB还是1GB？ 2、从单个分区读取数据的最大吞吐量是多少？每个分区一般都会有一个消费者，如果知道消费者将写入数据库的速度不超过每秒50MB，那从一个分区读取数据的吞吐量不需要超过每秒50MB。 3、每个broker包含的分区个数，可用的磁盘空间和网络带宽。 4、如果消息按照不同键写入分区，则为已有主题增加分区就会困难。（为什么，键已经分布好了？） 5、单个broker对分区个数有限制，因为分区越多，占用内存越多，完成首领选举需要时间越长。 如果估算出topic的吞吐量和消费者的吞吐量，可以用 topic吞吐量 / 消费者吞吐量 = 分区个数即，如果每秒要从topic写入和读取1GB数据，且每个消费者每秒可处理50MB数据，那至少需要20个分区，这样可以让20个消费者同时读取这些分区。 每个分区的大小，经验值是25GB。]]></content>
      <categories>
        <category>百问kafka</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[topic常用配置项]]></title>
    <url>%2F2019%2F11%2F15%2Fkafka%2F%E7%99%BE%E9%97%AEkafka%2Ftopic%E5%B8%B8%E7%94%A8%E9%85%8D%E7%BD%AE%E9%A1%B9%2F</url>
    <content type="text"><![CDATA[num.partitions topic包含多少个分区，一旦设定后，只能增加不能减少；若需要减少，得新增一个topic。 kafka通过partitions对topic进行横向扩展，当有新broker加入时，通过分区个数实现集群的负载均衡。一般的，topic的partitions的个数大于broker个数。 log.retention.hours 过期时间。默认值是168小时，也就是一周。还有两个其他参数log.retention.minutes和log.retention.ms。如果指定多个，kafka优先使用最小值。 log.retention.bytes 通过保留的字节数判断过期。作用在每个分区。即假设有8个partitions，且设为1G，那该topic最多保留8GB的数据。所以，当topic的分区个数增加时，整个topic可保留的数据也随之增加。如果也设置了hours，只要任意一个条件满足，消息就会被删除。 log.segment.bytes 上面设置在日志片段上，而不是在单个消息上。当消息到达broker时，它们被追加到分区的当前日志片段上。当日志片段大小超过该参数上限（默认是1GB），当前日志片段会被关闭，产生一个新的日志片段。 如果一个日志片段被关闭，就开始等待过期。该参数值越小，就会频繁关闭和分配新文件，从而降低磁盘写入的整体效率。 如果topic消息量不大，那么如何调整该参数大小就很重要。比如，一个topic每天100MB，而该参数是默认值，那么10天才能填满一个日志片段。由于日志片段在被关闭之前是不会过期的，所以如果log.retention,ms=1周，则segment最多需要17天才会过期。 segment大小也会影响通过timestamp获取offset。在获取offset时，kafka会检查分区最后修改时间大于指定timestamp的segment，让该segment的前一个的最后修改时间小于指定timestamp。然后，kafka返回该segment文件开头的offset。 message.max.bytes broker设置这个来限制单个消息的大小，默认是1MB。若生产者发生的消息超过这个大小，不仅不会被接收，还会收到broker返回的错误信息。跟其他与字节相关配置参数一样，该参数指的是压缩后的消息大小，实际大小可以大于这个值。 该值对性能有很大影响。值越大，负责网络连接和请求的线程就要花更多时间处理这些请求。还会增加磁盘写入块的大小，从而影响IO吞吐量。 在服务端和客户端之间协调消息大小 客户端的fetch.message.max.bytes必须与服务端的参数进行协调。若该值更小，则消费者无法获取大的消息，导致消费者被阻塞。 在集群里的broker配置replica.fetch.max.bytes时，遵循同样原则。]]></content>
      <categories>
        <category>百问kafka</category>
      </categories>
  </entry>
</search>
