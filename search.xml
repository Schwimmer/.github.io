<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[百问rnn]]></title>
    <url>%2F2019%2F11%2F27%2F%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%AE%97%E6%B3%95%E4%B8%93%E9%A2%98%2Frnn%2F%E7%99%BE%E9%97%AErnn%2F</url>
    <content type="text"><![CDATA[RNN梯度消失和爆炸的原因参考： RNN梯度消失和爆炸的原因]]></content>
      <categories>
        <category>机器学习算法专题</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[lstm推导]]></title>
    <url>%2F2019%2F11%2F27%2F%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%AE%97%E6%B3%95%E4%B8%93%E9%A2%98%2Flstm%2Flstm%E6%8E%A8%E5%AF%BC%2F</url>
    <content type="text"><![CDATA[参考： https://blog.csdn.net/cherrylvlei/article/details/75945057 参考： https://blog.csdn.net/u010215313/article/details/81674525]]></content>
      <categories>
        <category>机器学习算法专题</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[lightgbm原理]]></title>
    <url>%2F2019%2F11%2F27%2F%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%AE%97%E6%B3%95%E4%B8%93%E9%A2%98%2Flightgbm%2Flightgbm%E5%8E%9F%E7%90%86%2F</url>
    <content type="text"><![CDATA[XGBoost的缺点（1）XGBoost是基于预排序的方法 对所有特征都按照特征的数值进行预排序在遍历分割点的时候用O(#data)的代价找到一个特征上的最好分割点。预排序算法的优点：能精确地找到分割点。（2）预排序的缺点： 空间消耗大。保存数据的特征值、排序结果（排序后的索引，为了后续快速的计算分割点），消耗训练数据两倍的内存。时间开销大。遍历每个分割点的时候，都需要进行分裂增益的计算。对cache优化不友好。在预排序后，特征对梯度的访问是一种随机访问，并且不同的特征访问的顺序不一样，无法对cache进行优化。同时，在每一层生长树的时候，需要随机访问一个行索引到叶子索引的数组，并且不同特征访问的顺序也不一样，也会造成较大的cache miss。 2. LightGBM做的优化 基于Histogram的决策树算法 带深度限制的Leaf-wise的叶子生长策略 直方图做差加速 支持类别特征 Cache命中率优化 基于直方图的稀疏特征多线程优化 2.1 Histogram算法直方图算法的基本思想：先把连续的浮点特征值离散化成k个整数（其实是分桶的思想，这些桶称为bin，比如[0,0.1)→0, [0.1,0.3)→1），同时构造一个宽度为k的直方图。 在遍历数据的时候，根据离散化后的值作为索引在直方图中累积统计量 当遍历一次数据后，直方图累积了需要的统计量 然后根据直方图的离散值，遍历寻找最优的分割点。 直方图算法的优点： 降低消耗的内存：不需要存储预排序的结果。只保存特征离散化后的值，而且一般用整型存储就够了，不再需要浮点类型。降低计算复杂度：预排序O(#data#feature)，直方图O(#bin#feature)直方图算法的缺点（也是它的优点）： 特征离散化后，分割点不精确。但实验表明影响并不大，甚至效果会更好一点。较粗的分割点也有正则化的效果，可以防止过拟合 2.2 带深度限制的Leaf-wise的叶子生长策略（1）XGBoost 的层次生长策略，称为 Level-wise tree growth 同一层的所有节点都做分裂 可以同时分裂同一层的叶子，容易多线程优化，也好控制模型复杂度，不容易过拟合 但算法低效，因为不加区分的对待同一层的叶子，带来了很多没必要的开销。 实际上很多叶子节点的分裂增益较低，没必要进行搜索和分裂。 （2）LightGBM 的带有深度限制的按叶子生长 (leaf-wise)策略 Leaf-wise是一种更高效的策略，每次从当前所有叶子中，找到分裂增益最大的一个叶子，然后分裂，如此循环。与Level-wise相比，在分裂次数相同的情况下，Leaf-wise可以降低更多的误差，得到更好的精度。Leaf-wise的缺点是可能会长出比较深的决策树，产生过拟合。因此增加了一个最大深度的限制，在保证高效率的同时防止过拟合。 2.3 直方图差加速现象：一个叶子的直方图可以由它的父亲节点的直方图与它兄弟节点的直方图做差得到。 通常构造直方图，需要遍历该叶子上的所有数据，但直方图做差仅需遍历直方图的k个桶。 用非常微小的代价得到它兄弟叶子的直方图，在速度上可以提升一倍。 2.4 数值型特征和XGBoost是一样的 在得到叶子节点的输出后，给定输出的叶子节点分割增益（左右子树累加起来）为： XGBoost的分割增益如下： 2.5 直接支持类别特征 实际上大多数机器学习工具都无法直接支持类别特征，一般需要把类别特征转化到多维的0/1特征，降低了空间和时间的效率。 LightGBM 可以直接输入类别特征，不需要额外的0/1展开。并在决策树算法上增加了类别特征的决策规则。 相比0/1展开的方法，训练速度可以加速很多倍，并且精度一致。LightGBM是第一个直接支持类别特征的GBDT工具。 3. LightGBM的并行化 在特征并行中，在本地保存全部数据避免对数据切分结果的通信； 在数据并行中，使用分散规约(Reduce scatter)把直方图合并的任务分摊到不同的机器，降低通信和计算，并利用直方图做差，进一步减少了一半的通信量。 4、LightGBM调参XGBoost有三类参数：通用参数、学习目标参数、Booster参数LightGBM：核心参数、学习控制参数、IO参数、目标参数、度量参数、网络参数、GPU参数、模型参数。其中比较重要的是【核心参数、学习控制参数、度量参数】 5.1 核心参数boosting：可选gbdt，rf等num_threadapplication：可选 regression，binary，multi-class，lambdarank等learning_rate：shrinkage_ratenum_leaves：默认31，一颗树上的叶子节点数num_iterationsdevice：可选cpu，gpu 5.2 学习控制参数max_depthfeature_fraction：也称sub_feature，colsample_bytreebagging_fraction：也称sub_row，subsampleearly_stopping_roundmin_data_in_leaf：默认20，一个叶子节点上数据的最小数量，用于防止过拟合min_gain_to_splitmax_bin：默认255，最大直方图数，越大越容易过拟合 参考： 详细说明]]></content>
      <categories>
        <category>机器学习算法专题</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[lightgbm参数]]></title>
    <url>%2F2019%2F11%2F27%2F%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%AE%97%E6%B3%95%E4%B8%93%E9%A2%98%2Flightgbm%2Flightgbm%E5%8F%82%E6%95%B0%2F</url>
    <content type="text"><![CDATA[]]></content>
      <categories>
        <category>机器学习算法专题</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[百问lightgbm]]></title>
    <url>%2F2019%2F11%2F27%2F%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%AE%97%E6%B3%95%E4%B8%93%E9%A2%98%2Flightgbm%2F%E7%99%BE%E9%97%AElightgbm%2F</url>
    <content type="text"><![CDATA[lightgbm的改进1.直方图差加速:直方图算法的基本思想是先把连续的浮点特征值离散化成k个整数，同时构造一个宽度为k的直方图。在遍历数据的时候，根据离散化后的值作为索引在直方图中累积统计量，当遍历一次数据后，直方图累积了需要的统计量，然后根据直方图的离散值，遍历寻找最优的分割点。内存消耗降低，计算上的代价也大幅降低 2.leaf-wise:每次从当前所有叶子中，找到分裂增益最大的一个叶子，然后分裂，如此循环。因此同Level-wise相比，在分裂次数相同的情况下，Leaf-wise可以降低更多的误差，得到更好的精度。可能会长出比较深的决策树，产生过拟合。因此LightGBM在Leaf-wise之上增加了一个最大深度限制，在保证高效率的同时防止过拟合。 3.特征并行和数据并行：特征并行的主要思想是在不同机器在不同的特征集合上分别寻找最优的分割点，然后在机器间同步最优的分割点。数据并行则是让不同的机器先在本地构造直方图，然后进行全局的合并，最后在合并的直方图上面寻找最优分割点。 4.直接支持类别特征：可以直接输入类别特征，不需要额外的0/1 展开,LightGBM 是第一个直接支持类别特征的 GBDT 工具。————————————————版权声明：本文为CSDN博主「千语_肉丸子」的原创文章，遵循 CC 4.0 BY-SA 版权协议，转载请附上原文出处链接及本声明。原文链接：https://blog.csdn.net/u012535605/article/details/83584775]]></content>
      <categories>
        <category>机器学习算法专题</category>
      </categories>
  </entry>
  <entry>
    <title></title>
    <url>%2F2019%2F11%2F27%2F%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%AE%97%E6%B3%95%E4%B8%93%E9%A2%98%2Fxgboost%2Fxgboost%E6%8E%A8%E5%AF%BC%2F</url>
    <content type="text"><![CDATA[1、首先是模型基学习器为树模型、采用boosting集成方法 2、接下来设定目标函数=损失函数+正则项。 2.1 不限定损失函数的具体形式，只要其二阶可导。这样我们不需要为每一个具体的损失函数单独推导一个模型，而是得到一个通用的模型 2.2 再看正则项 用这个来控制树的复杂度。 后一项是L2，是树的每个节点的L2正则的平方。前一项是xgboost的主要贡献，gamma相当于预剪枝，T是叶子节点数。 γ和λ是需要手动调整的超参，它们值越大那么树的模型就越简单。 3、如何得到树在第t轮，只考虑本轮的优化目标 然后通过泰勒展开，将f拿出来 令 并忽略可视为常数的第一项，即得到了 ： 这样就实现了工程上的模块化，只有g、h与损失函数有关，而树的结构无关。这样一方面f可以自定义，一方面g和h可以并行计算。 树怎么转换成权重对于f的定义做一下细化，把树拆分成结构函数q(输入x输出叶子节点索引)和叶子权重部分w(输入叶子节点索引输出叶子节点分数)，结构函数q把输入映射到叶子的索引号上面去，而w给定了每个索引号对应的叶子分数是什么。 这样，目标函数可以改写成 再令 目标函数改为 求偏导得出： 参考： https://zhuanlan.zhihu.com/p/91817667 https://www.jianshu.com/p/dcb75ec3145e https://blog.csdn.net/guoxinian/article/details/79243307]]></content>
  </entry>
  <entry>
    <title><![CDATA[word2vec源码解读]]></title>
    <url>%2F2019%2F11%2F26%2Fnlp%2Fword2vec%2Fword2vec%E6%BA%90%E7%A0%81%E8%A7%A3%E8%AF%BB%2F</url>
    <content type="text"><![CDATA[代码的主要工作包括： 预处理。变量声明，全局变量遍历； 构建词库。包括文本处理，以及是否需要有指定词库。 初始化网络结构。参数初始化，Huffman编码的生成。 多线程模型训练。 最终结果的处理。 以上的过程，可以用下图表示： 输入参数1234567891011121314151617181920212223242526-train text8 表示的是输入文件是text8-output vectors.bin 输出文件是vectors.bin-cbow 1 表示使用cbow模型，默认为Skip-Gram模型-size 200 每个单词的向量维度是200-window 8 训练的窗口大小为5就是考虑一个词前八个和后八个词语（实际代码中还有一个随机选窗口的过程，窗口大小小于等于8）-negative 0 使用ns的时候采样的样本数，默认0，通常是5-10-save-vocab 词汇表存储文件-read-vocab 词汇表加载文件-classes 输出单词类别数，默认为0，即不输出单词-hs 1不使用NEG方法，使用HS方法。--sample 亚采样拒绝概率的参数指的是采样的阈值，如果一个词语在训练样本中出现的频率越大，那么就越会被采样。-binary为1指的是结果二进制存储，为0是普通存储（普通存储的时候是可以打开看到词语和对应的向量的）-iter 15 迭代次数 全局变量int *vocab_hash 词在词库中的index，在构建词库时先初始化为-1 123456// 词的结构体struct vocab_word &#123; long long cn; // 出现的次数 int *point; // 从根结点到叶子节点的路径 char *word, *code, codelen;// 分别对应着词，Huffman编码，编码长度&#125;; vocab_word是词的结构体 vocab = (struct vocab_word *)calloc(vocab_max_size, sizeof(struct vocab_word)); vocab存储词 vocab_size ：词汇表的总量 syn0 ：上下文词 syn1 ：$\theta_{j-1}^w$ neu1 ：映射层的向量，就是输入层的向量之和 neu1e ：对应伪代码中的e 预处理 在预处理部分，对word2vec需要使用的参数进行初始化，在word2vec中是利用传入的方式对参数进行初始化的。 在预处理部分，实现了sigmoid函数值的近似计算。 如果每一次都请求计算sigmoid值，对性能将会有一定的影响，当sigmoid的值对精度的要求并不是非常严格时，可以采用近似计算。在word2vec中，将区间[−6,6]（设置的参数MAX_EXP为6）等距离划分成EXP_TABLE_SIZE等份，并将每个区间中的sigmoid值计算好存入到数组expTable中，需要使用时，直接从数组中查找。 1234567// 申请EXP_TABLE_SIZE+1个空间expTable = (real *)malloc((EXP_TABLE_SIZE + 1) * sizeof(real)); for (i = 0; i &lt; EXP_TABLE_SIZE; i++) &#123; expTable[i] = exp((i / (real)EXP_TABLE_SIZE * 2 - 1) * MAX_EXP); // 1/(1+e^6) ~ 1/(1+e^-6)即 0.01 ~ 1 的样子 expTable[i] = expTable[i] / (expTable[i] + 1); // Precompute f(x) = x / (x + 1) &#125; 注意：在上述代码中，作者使用的是小于EXP_TABLE_SIZE，实际的区间是[−6,6)。 构建词库在word2vec源码中，提供了两种构建词库的方法，分别为： 指定词库：ReadVocab()方法 从词的文本构建词库：LearnVocabFromTrainFile()方法 构建词库的过程在这里，我们以从词的文本构建词库为例。构建词库的过程如下所示： 在这部分中，最主要的工作是对文本进行处理，包括低频词的处理，hash表的处理等等。首先，会在词库中增加一个“&lt;/s&gt;”的词，同时，在读取文本的过程中，将换行符“\n”也表示成该该词 对词的哈希处理在存储词的过程中，同时保留这两个数组： 存储词的vocab 存储词的hash的vocab_hash 其中，在vocab中，存储的是词对应的结构体： 在vocab_hash中存储的是词在词库中的Index，vocab_hash的下标是词计算出的hash值。 在对词的处理过程中，主要包括： 计算词的hash值： 1234567// 取词的hash值int GetWordHash(char *word) &#123; unsigned long long a, hash = 0; for (a = 0; a &lt; strlen(word); a++) hash = hash * 257 + word[a]; hash = hash % vocab_hash_size; return hash;&#125; SearchVocab检索词是否存在。如不存在则返回-1，否则，返回该词在词库中的索引： 1234567while (1) &#123; if (vocab_hash[hash] == -1) return -1;// 不存在该词 //strcmp两个词相等，则返回0，所以要加上! if (!strcmp(word, vocab[vocab_hash[hash]].word)) return vocab_hash[hash];// 返回索引值 hash = (hash + 1) % vocab_hash_size;// 处理冲突&#125;return -1;// 不存在该词 在这个过程中，使用到了线性探测的开放定址法处理冲突，开放定址法就是一旦发生冲突，就去寻找下一个空的散列地址。 不存在，则插入新词。 对低频词的处理在循环读取每一个词的过程中，当出现“vocab_size &gt; vocab_hash_size * 0.7”时，需要对低频词进行处理。其中，vocab_size表示的是目前词库中词的个数，vocab_hash_size表示的是初始设定的hash表的大小。 ReduceVocab() 在处理低频词的过程中，通过参数“min_reduce”来控制，若词出现的次数小于等于该值时，则从词库中删除该词。 123456for (a = 0; a &lt; vocab_size; a++) if (vocab[a].cn &gt; min_reduce) &#123; vocab[b].cn = vocab[a].cn; vocab[b].word = vocab[a].word; b++; &#125; else free(vocab[a].word); vocab_size = b;// 删减后词的个数 在删除了低频词后，需要重新对词库中的词进行hash值的计算。 123456789for (a = 0; a &lt; vocab_hash_size; a++) vocab_hash[a] = -1;for (a = 0; a &lt; vocab_size; a++) &#123; // Hash will be re-computed, as it is not actual hash = GetWordHash(vocab[a].word); while (vocab_hash[hash] != -1) hash = (hash + 1) % vocab_hash_size; vocab_hash[hash] = a;&#125;fflush(stdout);min_reduce++; 根据词频对词库中的词排序基于以上的过程，程序已经将词从文件中提取出来，并存入到指定的词库中（vocab数组），接下来，需要根据每一个词的词频对词库中的词按照词频从大到小排序，其基本过程在函数SortVocab中，排序过程为 1qsort(&amp;vocab[1], vocab_size - 1, sizeof(struct vocab_word), VocabCompare); 原 型:void qsort(void base, int nelem, int width, int (fcmp)(const void ,const void )); 功 能: 使用快速排序例程进行排序 参 数： 1 待排序数组首地址 2 数组中待排序元素数量 3 各元素的占用空间大小 4 指向函数的指针，用于确定排序的顺序 说 明：qsort函数是ANSI C标准中提供的，其声明在stdlib.h文件中，是根据二分法写的，其时间复杂度为n*log(n)。 qsort要求提供的函数是需要自己定义的一个比较函数，比较函数使得qsort通用性更好。有了比较函数qsort可以实现对数组、字符串、结构体等结构进行升序或降序排序。如int cmp(const void a, const void b)中有两个元素作为参数（参数的格式不能变的。）返回一个int值，如果比较函数返回大于0，qsort就认为a &gt; b，返回小于0,qsort就认为a &lt; b。qsort知道元素的大小了，就可以把大的放前面去。如果你的比较函数返回本来应该是1的（即a &gt; b），而却返回-1（小于0的数），那么qsort认为a &lt; b，就把b放在前面去，但实际上是a &gt; b的，所以就造成了降序排序的差别了。简单来说，比较函数的作用就是给qsort指明元素的大小事怎么比较的。 保持字符“&lt; \s&gt;”在最开始的位置。排序后，根据“min_count”对低频词进行处理，与上述一样，再对剩下的词重新计算hash值。 至此，整个对词的处理过程就已经结束了。接下来，将是对网络结构的处理和词向量的训练。 初始化网络结构有了以上的对词的处理，就已经处理好了所有的训练样本，此时，便可以开始网络结构的初始化和接下来的网络训练。网络的初始化的过程在InitNet()函数中完成。 初始化网络参数在初始化的过程中，主要的参数包括词向量的初始化和映射层到输出层的权重的初始化，如下图所示： 词向量的初始化：为每个词分配空间，大小是vocab_size*layer1_size。 初始化的时候要分配所有词*词向量长度的空间？为何要这么大？12// layer1_size是词向量的长度a = posix_memalign((void **)&amp;syn0, 128, (long long)vocab_size * layer1_size * sizeof(real)); 1234&gt; int posix_memalign (void **memptr,&gt; size_t alignment,&gt; size_t size);&gt; &gt; 调用posix_memalign( )成功时会返回size字节的动态内存，并且这块内存的地址是alignment的倍数。参数alignment必须是2的幂，还是void指针的大小的倍数。返回的内存块的地址放在了memptr里面，函数返回值是0。 CBOW网络有两种可选的算法：层次Softmax和Negative Sampling。在输入参数时选择任意一种。 12345678910111213141516// 层次softmax的结构 if (hs) &#123; // 映射层到输出层之间的权重，就是Huffman树的非叶子结点的向量θ a = posix_memalign((void **)&amp;syn1, 128, (long long)vocab_size * layer1_size * sizeof(real)); if (syn1 == NULL) &#123;printf("Memory allocation failed\n"); exit(1);&#125; for (a = 0; a &lt; vocab_size; a++) for (b = 0; b &lt; layer1_size; b++) syn1[a * layer1_size + b] = 0;// 权重初始化为0 &#125; // 负采样的结构 if (negative&gt;0) &#123; a = posix_memalign((void **)&amp;syn1neg, 128, (long long)vocab_size * layer1_size * sizeof(real)); if (syn1neg == NULL) &#123;printf("Memory allocation failed\n"); exit(1);&#125; for (a = 0; a &lt; vocab_size; a++) for (b = 0; b &lt; layer1_size; b++) syn1neg[a * layer1_size + b] = 0; &#125; 在初始化的过程中，映射层到输出层的权重都初始化为0，而对于每一个词向量的初始化，作者的初始化方法如下代码所示： 12345678// 随机初始化 for (a = 0; a &lt; vocab_size; a++) for (b = 0; b &lt; layer1_size; b++) &#123; next_random = next_random * (unsigned long long)25214903917 + 11; // 1、与：相当于将数控制在一定范围内 // 2、0xFFFF：65536 // 3、/65536：[0,1]之间 syn0[a * layer1_size + b] = (((next_random &amp; 0xFFFF) / (real)65536) - 0.5) / layer1_size;// 初始化词向量 &#125; 首先，生成一个很大的next_random的数，通过与“0xFFFF”进行与运算截断，再除以65536得到[0,1]之间的数，最终，得到的初始化的向量的范围为：[−0.5/m,0.5/m]，其中，m为词向量的长度。 3.2、Huffman树的构建在层次Softmax中需要使用到Huffman树以及Huffman编码，因此，在网络结构的初始化过程中，也需要初始化Huffman树。在生成Huffman树的过程中，首先定义了3个长度为vocab_size*2+1的数组： 1234// 申请2倍的词的空间long long *count = (long long *)calloc(vocab_size * 2 + 1, sizeof(long long));long long *binary = (long long *)calloc(vocab_size * 2 + 1, sizeof(long long));long long *parent_node = (long long *)calloc(vocab_size * 2 + 1, sizeof(long long)); 其中，count数组中前vocab_size存储的是每一个词的对应的词频，词频是从高到低排序。后面的vocab_size先初始化为很大的数。 123// 分成两半进行初始化for (a = 0; a &lt; vocab_size; a++) count[a] = vocab[a].cn;// 前半部分初始化为每个词出现的次数for (a = vocab_size; a &lt; vocab_size * 2; a++) count[a] = 1e15;// 后半部分初始化为一个固定的常数 构建Huffman树的过程如下所示 首先，设置两个指针pos1和pos2，分别指向最后一个词和最后一个词的后一位 12345// 两个指针：// pos1指向前半截的尾部// pos2指向后半截的开始pos1 = vocab_size - 1;pos2 = vocab_size; 从两个指针所指的数中选择出最小的值，记为min1i， 如pos1所指的值最小，此时，将pos1左移，再比较pos1和pos2所指的数，选择出最小的值，记为min2i，将他们的和存储到pos2所指的位置。并将此时pos2所指的位置设置为min1i和min2i的父节点，同时，记min2i所指的位置的编码为1（这里令右子树的编码为1）。 如pos2所指的值小，此时，将pos2右移，再比较pos1和pos2，选出最小的值，记为min2i， 12345678910111213141516171819202122232425262728293031323334353637// Following algorithm constructs the Huffman tree by adding one node at a time // 每次增加一个节点，构建Huffman树 for (a = 0; a &lt; vocab_size - 1; a++) &#123; // First, find two smallest nodes &apos;min1, min2&apos; // 选择最小的节点min1 if (pos1 &gt;= 0) &#123; if (count[pos1] &lt; count[pos2]) &#123; min1i = pos1; pos1--; &#125; else &#123; min1i = pos2; pos2++; &#125; &#125; else &#123; min1i = pos2; pos2++; &#125; // 选择最小的节点min2 if (pos1 &gt;= 0) &#123; if (count[pos1] &lt; count[pos2]) &#123; min2i = pos1; pos1--; &#125; else &#123; min2i = pos2; pos2++; &#125; &#125; else &#123; min2i = pos2; pos2++; &#125; count[vocab_size + a] = count[min1i] + count[min2i]; // 设置父节点 parent_node[min1i] = vocab_size + a; parent_node[min2i] = vocab_size + a; binary[min2i] = 1;// 设置一个子树的编码为1 &#125; 构建好Huffman树后，此时，需要根据构建好的Huffman树生成对应节点的Huffman编码。假设，上述的数据生成的最终的Huffman树为： 此时，count数组，binary数组和parent_node数组分别为： 在生成Huffman编码的过程中，针对每一个词（词都在叶子节点上），从叶子节点开始，将编码存入到code数组中，如对于上图中的“R”节点来说，其code数组为{1,0}，再对其反转便是Huffman编码： 12345678910111213141516171819// Now assign binary code to each vocabulary word // 为每一个词分配二进制编码，即Huffman编码 for (a = 0; a &lt; vocab_size; a++) &#123;// 针对每一个词 b = a; i = 0; while (1) &#123; code[i] = binary[b];// 找到当前的节点的编码 point[i] = b;// 记录从叶子节点到根结点的序列 i++; b = parent_node[b];// 找到当前节点的父节点 if (b == vocab_size * 2 - 2) break;// 已经找到了根结点，根节点是没有编码的 &#125; vocab[a].codelen = i;// 词的编码长度 vocab[a].point[0] = vocab_size - 2;// 根结点 for (b = 0; b &lt; i; b++) &#123; vocab[a].code[i - b - 1] = code[b];// 编码的反转 vocab[a].point[i - b] = point[b] - vocab_size;// 记录的是从根结点到叶子节点的路径 &#125; &#125; 3.3、负样本选中表的初始化（自己没看） 如果是采用负采样的方法，此时还需要初始化每个词被选中的概率。在所有的词构成的词典中，每一个词出现的频率有高有低，我们希望，对于那些高频的词，被选中成为负样本的概率要大点，同时，对于那些出现频率比较低的词，我们希望其被选中成为负样本的频率低点。这个原理于“轮盘赌”的策略一致（详细可以参见“优化算法——遗传算法”）。在程序中，实现这部分功能的代码为： 12345678910111213141516171819// 生成负采样的概率表void InitUnigramTable() &#123; int a, i; double train_words_pow = 0; double d1, power = 0.75; table = (int *)malloc(table_size * sizeof(int));// int --&gt; int for (a = 0; a &lt; vocab_size; a++) train_words_pow += pow(vocab[a].cn, power); // 类似轮盘赌生成每个词的概率 i = 0; d1 = pow(vocab[i].cn, power) / train_words_pow; for (a = 0; a &lt; table_size; a++) &#123; table[a] = i; if (a / (double)table_size &gt; d1) &#123; i++; d1 += pow(vocab[i].cn, power) / train_words_pow; &#125; if (i &gt;= vocab_size) i = vocab_size - 1; &#125;&#125; 在实现的过程中，没有直接使用每一个词的频率，而是使用了词的0.75次方。 4、多线程模型训练以上的各个部分是为训练词向量做准备，即准备训练数据，构建训练模型。在上述的初始化完成后，接下来就是根据不同的方法对模型进行训练，在实现的过程中，作者使用了多线程的方法对其进行训练。 4.1、多线程的处理为了能够对文本进行加速训练，在实现的过程中，作者使用了多线程的方法，TrainModelThread() 对每一个线程上分配指定大小的文件： 12// 利用多线程对训练文件划分，每个线程训练一部分的数据fseek(fi, file_size / (long long)num_threads * (long long)id, SEEK_SET); 这个过程可以通过下图简单的描述： 在实现多线程的过程中，作者并没有加锁的操作，而是对模型参数和词向量的修改可以任意执行，这一点类似于基于随机梯度的方法，训练的过程与训练样本的训练是没有关系的，这样可以大大加快对词向量的训练。抛开多线程的部分，在每一个线程内执行的是对模型和词向量的训练。 作者在实现的过程中，主要实现了两个模型，即CBOW模型和Skip-gram模型，在每个模型中，又分别使用到了两种不同的训练方法，即层次Softmax和Negative Sampling方法。 4.2、CBOW模型4.2.1、从输入层到映射层首先找到每个词对应的词向量，并将这些词的词向量相加，程序代码如下所示： 12345678910111213141516// in -&gt; hiddencw = 0;//b是随机生成的0到window-1，相当于左右各看window-b/2个词for (a = b; a &lt; window * 2 + 1 - b; a++) if (a != window) &#123; //sentence_position 单词在句子中的位置 c = sentence_position - window + a; // 判断c是否越界 if (c &lt; 0) continue; if (c &gt;= sentence_length) continue; // 找到c对应的索引 last_word = sen[c]; if (last_word == -1) continue; // neu1就是隐藏层向量，也就是上下文对应vector的和 for (c = 0; c &lt; layer1_size; c++) neu1[c] += syn0[c + last_word * layer1_size]; cw++;&#125; 当累加完窗口内的所有的词向量的之后，存储在映射层neu1中，并取平均，程序代码如下所示： 1for (c = 0; c &lt; layer1_size; c++) neu1[c] /= cw; 当取得了映射层的结果后，此时就需要使用Hierarchical Softmax或者Negative Sampling对模型进行训练。 4.2.2、Hierarchical Softmax1234567891011121314151617181920if (hs) for (d = 0; d &lt; vocab[word].codelen; d++) &#123; f = 0; // point存储了从该词的叶子结点的编号到root的序号，这些序号可以对应到syn1的位置，也就是参数向量的位置 l2 = vocab[word].point[d] * layer1_size; // Propagate hidden -&gt; output // q=sigma(x*theta) for (c = 0; c &lt; layer1_size; c++) f += neu1[c] * syn1[c + l2]; if (f &lt;= -MAX_EXP) continue; else if (f &gt;= MAX_EXP) continue; // 查表得知sigma的值，省去计算的时间 else f = expTable[(int)((f + MAX_EXP) * (EXP_TABLE_SIZE / MAX_EXP / 2))]; // g = eta(1-d-q) g = (1 - vocab[word].code[d] - f) * alpha; // Propagate errors output -&gt; hidden // e = e + g*theta for (c = 0; c &lt; layer1_size; c++) neu1e[c] += g * syn1[c + l2]; // Learn weights hidden -&gt; output // theta = theta + g*x for (c = 0; c &lt; layer1_size; c++) syn1[c + l2] += g * neu1[c]; &#125; 接下来更新Context(w) 123456789// hidden -&gt; in for (a = b; a &lt; window * 2 + 1 - b; a++) if (a != window) &#123; c = sentence_position - window + a; if (c &lt; 0) continue; if (c &gt;= sentence_length) continue; last_word = sen[c]; if (last_word == -1) continue; for (c = 0; c &lt; layer1_size; c++) syn0[c + last_word * layer1_size] += neu1e[c]; &#125; Word2Vec为什么快 用查表代替计算sigmoid 相对于神经网络的结构，去掉了隐藏层 增量训练从搜索引擎爬包含新词的文本，加上一个小语料，训练一个w2v模型。 对于每个新词，找出小模型中最接近的10个词，以及每个词与新词的相似度打分score。 再从大模型中找出每个词的词向量，每个维度乘以小模型中的score，最多叠加5个。再对每个维度取加权平均。 最后转成单位向量。 参考： 机器学习算法实现解析——word2vec源码解析 源码在/home/david/code/nlp/word2vec/word2vecC/word2vec.c]]></content>
      <categories>
        <category>word2vec</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[百问word2vec]]></title>
    <url>%2F2019%2F11%2F26%2Fnlp%2Fword2vec%2F%E7%99%BE%E9%97%AEword2vec%2F</url>
    <content type="text"><![CDATA[word2vec与神经网络的区别 NN的输入是类似n-gram，取前N-1个词，w2v取前后各n-1个词 NN多了隐层，输入到隐层用双曲正切当激活函数。 NN的输入词向量是首尾拼接，W2V是加总。这样当窗口中向量不足时，也不需要补。 NN的输出是一个长度为N的向量，就是整个词汇表的长度，然后再做一个softmax归一化，得到给定上下文时下一个词恰好为词汇表的某个词的概率。 Word2vec为什么快 用查表代替计算sigmoid 相对于神经网络的结构，去掉了隐藏层 负采样模型，采样率对向量的影响采样率假如过小，那么很多低频的词可能无法保留下来。 word2vec哪个模型更快据论文说CBOW要更快一些(1天vs.3天的区别) word2vec为什么比以前的模型好]]></content>
      <categories>
        <category>word2vec</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[word2vec原理]]></title>
    <url>%2F2019%2F11%2F26%2Fnlp%2Fword2vec%2Fword2vec%E5%8E%9F%E7%90%86%2F</url>
    <content type="text"><![CDATA[CBOW与Skip-Gram用于神经网络语言模型​ 在word2vec出现之前，已经有用神经网络DNN来用训练词向量进而处理词与词之间的关系了。采用的方法一般是一个三层的神经网络结构（当然也可以多层），分为输入层，隐藏层和输出层(softmax层)。 ​ 这个模型是如何定义数据的输入和输出呢？一般分为CBOW（Continuous Bag-of-Words） 与Skip-Gram两种模型。两个模型都包含：输入层、投影层、输出层。 2.1 CBOW上下文相关的词对应的词向量，而输出就是这特定的一个词的词向量。比如下面这段话，我们的上下文大小取值为4，特定的这个词是”Learning”，也就是我们需要的输出词向量,上下文对应的词有8个，前后各4个，这8个词是我们模型的输入。由于CBOW使用的是词袋模型，因此这8个词都是平等的，也就是不考虑他们和我们关注的词之间的距离大小，只要在我们上下文之内即可。 在这个CBOW神经网络模型中，输入层有8个神经元（8个词向量），输出层有词汇表D大小的神经元。 目标函数通常为 L=\sum_{w \in C} \log p(w|Context(w)) 为什么是这个形式？ 根据n-gram模型和对数最大似然，得到这个目标函数。 包括四个层：输入、投影、隐藏、输出。 对于语料C中的任意一个词w，将Context(w)设为取前面的n-1个词，这样二元对(Context(w),w)就是一个训练样本。 投影层向量$x_w$的构造是，将输入层的n-1个词向量按顺序首尾相接的拼起来，长度就是m(n-1)了（每个词向量的长度是m）。 从而 z_w = tanh(W{x_w}+p) \\ y_w=Uz_w+q其中，tanh是双曲正切函数，用来做隐藏层的激活函数。 经过上面两步计算得到的$yw=(y{w,1},y{w,2},…,y{w,N})^T$是一个长度为N的向量，其分量不能代表概率。如果想要$y_{w,i}$表示当上下文为Context(w)时下一次为词典D中第i个词的概率，则还需要做一个softmax归一化，之后得到 p(w|Context(w))=\frac {e^{y_{w,i_w}}} {\sum_{i=1}^N e^{y_{w,i_w}}}其中$i_w$表示词w在词典D中的索引。 与n-gram相比，神经概率语言模型的优势是： 1、词语之间的相似性可以通过词向量来体现。 1）神经网络模型通过上下文来预测，那么相似的上下文的词的词向量也是相似的； 2）概率函数关于词向量是光滑的，即词向量的一个小变化对概率的影响也是一个小变化。 2、词向量自带平滑功能（因为$p(w|Context(w)) \in (0,1)$不会为零）。 2.2 Skip-Gram与CBOW相反，输入是一个特定向量，输出是特定词对应的上下文词向量。 Hierarchical Softmax，以及Negative Sampling都可以实现上述两种模型 基于Hierarchical Softmax的模型对于CBOW模型，目标函数是 L=\sum_{w \in C} \log p(w|Context(w)) 为什么是这个形式？ 根据n-gram模型和对数最大似然，得到这个目标函数。 网络的构建 定义0是正类， 与神经网络模型的区别： 1、（输入层到投影层）前者是拼接，后者是直接相加 2、（隐藏层）后者没有 3、（输出层）前者是线性结构，后者是树结构 定义几个变量： 为什么非叶子节点也需要定义向量？ 参与两分类问题的权重更新 层次Softmax的基本思想就是： 对于词典D中的任意词w，Huffman树中必存在一条从根结点到词w对应结点的路径$p^w$，且这条路径是唯一的。路径$p^w$上存在$l^w-1$个分支，将每个分支看做是一个二分类，每一次分类就产生一个概率，将这些概率连乘起来，就是所需的$p(w|Context(w))$ 。 条件概率连乘的公示可以写为 p(w|Context(w))=\prod_{j=2}^{l^w}p(d_j^w|x_w,\theta_{j-1}^w)其中， p(d_j^w|x_w,\theta_{j-1}^w)=[\sigma(x_w^T\theta_{j-1}^w)]^{1-d_j^w} \cdot [1-\sigma(x_w^T\theta_{j-1}^w)]^{d_j^w} \tag{3-1}这里$\sigma(xw^T\theta{j-1}^w)$表示分到正类的概率。 将3-1代入对数似然函数，得到 L=\sum_{w \in C} \sum_{j=2}^{l^w} \{ (1-d_j^w)\log [\sigma(x_w^T\theta_{j-1}^w)] + d_j^w \log[1-\sigma(x_w^T\theta_{j-1}^w)] \}其中，令 L(w,j)=(1-d_j^w)\log [\sigma(x_w^T\theta_{j-1}^w)] + d_j^w \log[1-\sigma(x_w^T\theta_{j-1}^w)]至此，已经推导出对数似然函数，这就是CBOW模型的目标函数。 基于Negative Sampling的模型NEG不使用Huffman树，而是利用随机负采样，能大幅度提高性能。 CBOW模型推到过程中，把w作为正样本，Context(w)作为负样本。对于一个给定的正样本，希望最大化 即增大正样本概率的同时降低负样本的概率。更新公式为 前面的原理差不多，也是用梯度下降，关键在于，h-softmax是通过Huffman树的路径长度来进行迭代和更新参数；NEG是通过找出负采样来迭代。 4.1 负采样算法这里的关键是，对于一个给定的词w，如何生成负样本子集$NEG(w)$？ 词典D中的词在语料C中出现的次数有高有低，对于那些高频词，被选为负采样的概率就应该比较大，反之较小。这是我们对采样过程的一个大致要求，本质上就是一个带权采样问题。 设词典D中的每个词w对应一条线段l(w)，则线段的长度可以表示为 len(w)=\frac {count(w)} {\sum_{u \in D} count(u)}也就是计算词频再归一化。现在将这些线段首尾相连拼接在一起，形成一个长度为1的单位线段。如果随机往这个单位线段上打点，则其中越长的线段命中概率越大。 通过这些线段得到一个非等距剖分（假设分成N个区间），再定义一个等距剖分（假设分成M个区间），$M &gt;&gt; N$ 。 建立如下的映射关系 Table(i) = w_k, \ where\ m_i \in I_k,\ i=1,2,...,M-1那么，采样就是每次生成一个[1,M-1]之间的整数r，Table(r)就是一个样本。如果负采样的时候选到正样本自己，就跳过再选。 源码细节]]></content>
      <categories>
        <category>word2vec</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[生成模型VS判别模型]]></title>
    <url>%2F2019%2F11%2F26%2F%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%AE%97%E6%B3%95%E4%B8%93%E9%A2%98%2F%E5%9F%BA%E7%A1%80%E7%90%86%E8%AE%BA%2F%E7%94%9F%E6%88%90%E6%A8%A1%E5%9E%8BVS%E5%88%A4%E5%88%AB%E6%A8%A1%E5%9E%8B%2F</url>
    <content type="text"><![CDATA[从概率分布的角度考虑，对于一堆样本数据，每个均有特征$X_i$对应分类标记$y_i$。 生成模型：学习得到联合概率分布P(x,y)，即特征x和标记y共同出现的概率，然后求条件概率分布。能够学习到数据生成的机制。 判别模型：学习得到条件概率分布P(y|x)，即在特征x出现的情况下标记y出现的概率。 典型的生成模型包括： 朴素贝叶斯、混合高斯模型、隐马尔可夫模型 判别模型： CRF、boosting、CNN]]></content>
      <categories>
        <category>机器学习基础理论</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[算法推导-朴素贝叶斯]]></title>
    <url>%2F2019%2F11%2F26%2F%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%AE%97%E6%B3%95%E4%B8%93%E9%A2%98%2F%E6%9C%B4%E7%B4%A0%E8%B4%9D%E5%8F%B6%E6%96%AF%2F%E7%AE%97%E6%B3%95%E6%8E%A8%E5%AF%BC-%E6%9C%B4%E7%B4%A0%E8%B4%9D%E5%8F%B6%E6%96%AF%2F</url>
    <content type="text"><![CDATA[假设朴素贝叶斯对条件概率分布做了条件独立性的假设。 给定$Y=c_k$的时候，X的概率可以表示为 朴素贝叶斯实际上学习到生成数据的机制，属于生成模型。 如何分类在分类时，对给定的输入x，通过学习到的模型计算后验概率分布$P(Y=c_k|X=x)$ 将后验概率最大的类作为x的类输出。根据公式， 将（4.3）代入后， （4.5）就是朴素贝叶斯分类的基本公式。于是，朴素贝叶斯分类器可表示为 由于（4.6）中分母对于所有$c_k$都是相同的，所以 参数估计极大似然估计模型训练意味着估计$P(Y=c_k)$ 和 $P(X^{(j)}=x^{(j)} | Y=c_k)$，可以应用极大似然估计相应的概率。 其中，先验概率$P(Y=c_k)$ 的极大似然估计是 设第j个特征$x^$可能取值的集合为${ a{j1},a{j2},… }$，条件概率 $P(X^{(j)}=x^{(j)} | Y=c_k)$的极大似然估计是 其中，$xi^{(j)}$表示第i个样本的第j个特征；$a{jl}$是第j个特征可能取的第l个值，I为指示函数。 贝叶斯估计极大似然估计可能会出现要估计的概率值为0的情况使分类产生偏差，解决方法是采用贝叶斯估计。 其中$\lambda &gt;= 0$，常取=1，称为拉普拉斯平滑。 同样，先验概率的贝叶斯估计是 参考： 统计学习方法]]></content>
      <categories>
        <category>朴素贝叶斯</category>
      </categories>
  </entry>
  <entry>
    <title></title>
    <url>%2F2019%2F11%2F25%2F%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%2FDropout%2F</url>
    <content type="text"><![CDATA[Dropout出现的原因如果模型的参数太多，而训练样本又太少，训练出来的模型很容易产生过拟合的现象。在训练神经网络的时候经常会遇到过拟合的问题，过拟合具体表现在：模型在在训练数据上损失函数较小，预测准确率较高；但是在测试数据上损失函数比较大，预测准确率较低。 Dropout可以比较有效的缓解过拟合的发生，在一定程度上达到正则化的效果。 什么是DropoutDropout可以作为训练深度神经网络的一种trick供选择。在每个训练批次中，通过忽略一半的特征检测器（让一半的隐层节点值为0），可以明显地减少过拟合现象。这种方式可以减少特征检测器（隐层节点）间的相互作用，检测器相互作用是指某些检测器依赖其他检测器才能发挥作用。 Dropout说的简单一点就是：我们在前向传播的时候，让某个神经元的激活值以一定的概率p停止工作，这样可以使模型泛化性更强，因为它不会太依赖某些局部的特征，如图1所示。 参考： https://cloud.tencent.com/developer/news/246964]]></content>
  </entry>
  <entry>
    <title></title>
    <url>%2F2019%2F11%2F25%2F%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%AE%97%E6%B3%95%E4%B8%93%E9%A2%98%2Flstm%2Flstm%E7%9A%84dense%2F</url>
    <content type="text"><![CDATA[LSTM模型后增加Dense（全连接）层的目的是什么LSTM的输出是最后一个时刻的h，是个unit维的向量，必须接一个全连接层才能把LSTM的输出转换成你想要的输出，可以简单理解成维度变换。]]></content>
  </entry>
  <entry>
    <title></title>
    <url>%2F2019%2F11%2F25%2F%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%AE%97%E6%B3%95%E4%B8%93%E9%A2%98%2Flstm%2FVanilla%20LSTM%2F</url>
    <content type="text"><![CDATA[Vanilla LSTM模型是LSTM模型的一种简单变种，其主要变化是在三个控制门的输入分别加入了细胞状态信息（下图中的黑线），这个连接被称为 peephole connection。]]></content>
  </entry>
  <entry>
    <title></title>
    <url>%2F2019%2F11%2F25%2F%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%AE%97%E6%B3%95%E4%B8%93%E9%A2%98%2Flstm%2Flstm%E4%B8%BA%E4%BB%80%E4%B9%88%E8%83%BD%E8%A7%A3%E5%86%B3%E6%A2%AF%E5%BA%A6%E6%B6%88%E5%A4%B1%2F</url>
    <content type="text"><![CDATA[相比于标准RNN模型，LSTM主要是增加了三个控制门单元：遗忘门，输入门和输出门。如果去掉三个门控制单元（或者将三个门控制函数都设置为1），LSTM就会退化成标准的RNN模型。 细胞状态：LSTM的关键就是细胞状态（如下图所示的水平线），在图上方贯穿运行，它类似于一条传送带，只有少量的信息交互，很容易保存信息不变。 图 6.2 LSTM模型的细胞状态 遗忘门：结构如下图所示，决定细胞状态的信息需要丢弃多少。其读取和的信息，输出一个0到1之间的数值个细胞状态，1表示细胞状态完全保留，0表示细胞状态完全丢弃。 图 6.3 LSTM模型的遗忘门 输入门：结构如下图所示，确定什么新的信息需要被添加到细胞状态中。这里包含两方面的内容：1. sigmod层决定了什么值需要被更新；2. tanh层用来生成新的候选信息向量会被更新到细胞状态中。 图 6.3 LSTM模型的输入门 对细胞状态的更新为：将旧状态与相乘，可以丢弃到确定的需要丢弃的状态，然后加上新的需要加入的信息即可完成细胞状态的更新。对细胞状态的更新表示如下图： 图 6.4 LSTM模型的细胞状态的更新 输出门：确定细胞状态的什么信息需要被输出，结构图如下所示。首先是需要一个 sigmod函数用来确定上一隐层和新输入信息有多少需要被保留，然后将更新后的细胞状态经过 tanh变到 [-1,1]的区间后再进行相乘，这样就确定了最终的输出信息。 图 6.5 LSTM模型的输出门]]></content>
  </entry>
  <entry>
    <title></title>
    <url>%2F2019%2F11%2F25%2F%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%AE%97%E6%B3%95%E4%B8%93%E9%A2%98%2F%E5%9F%BA%E7%A1%80%E7%90%86%E8%AE%BA%2F%E5%81%8F%E5%B7%AE-%E6%96%B9%E5%B7%AE%E6%9D%83%E8%A1%A1%2F</url>
    <content type="text"><![CDATA[参考： https://segmentfault.com/a/1190000012461409]]></content>
  </entry>
  <entry>
    <title><![CDATA[百问xgboost]]></title>
    <url>%2F2019%2F11%2F23%2F%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%AE%97%E6%B3%95%E4%B8%93%E9%A2%98%2Fxgboost%2F%E7%99%BE%E9%97%AExgboost%2F</url>
    <content type="text"><![CDATA[简单介绍一下XGBoost首先需要说一说GBDT，它是一种基于boosting增强策略的加法模型，训练的时候采用前向分布算法进行贪婪的学习，每次迭代都学习一棵CART树来拟合之前 t-1 棵树的预测结果与训练样本真实值的残差。 XGBoost对GBDT进行了一系列优化，比如损失函数进行了二阶泰勒展开、目标函数加入正则项、支持并行和默认缺失值处理等，在可扩展性和训练速度上有了巨大的提升，但其核心思想没有大的变化。 2. XGBoost与GBDT有什么不同基分类器：XGBoost的基分类器不仅支持CART决策树，还支持线性分类器，此时XGBoost相当于带L1和L2正则化项的Logistic回归（分类问题）或者线性回归（回归问题）。 导数信息：XGBoost对损失函数做了二阶泰勒展开，GBDT只用了一阶导数信息，并且XGBoost还支持自定义损失函数，只要损失函数一阶、二阶可导。 正则项：XGBoost的目标函数加了正则项， 相当于预剪枝，使得学习出来的模型更加不容易过拟合。 列抽样：XGBoost支持列采样，与随机森林类似，用于防止过拟合。 缺失值处理：对树中的每个非叶子结点，XGBoost可以自动学习出它的默认分裂方向。如果某个样本该特征值缺失，会将其划入默认分支。 并行化：注意不是tree维度的并行，而是特征维度的并行。XGBoost预先将每个特征按特征值排好序，存储为块结构，分裂结点时可以采用多线程并行查找每个特征的最佳分割点，极大提升训练速度。 3. XGBoost为什么使用泰勒二阶展开精准性：相对于GBDT的一阶泰勒展开，XGBoost采用二阶泰勒展开，可以更为精准的逼近真实的损失函数。泰勒的本质是尽量去模仿一个函数，我猜二阶泰勒展开已经足以近似大量损失函数了 可扩展性：损失函数支持自定义，只需要损失函数二阶可导。 4. XGBoost为什么可以并行训练XGBoost的并行，并不是说每棵树可以并行训练，XGB本质上仍然采用boosting思想，每棵树训练前需要等前面的树训练完成才能开始训练。 XGBoost的并行，指的是特征维度的并行：在训练之前，每个特征按特征值对样本进行预排序，并存储为Block结构，在后面查找特征分割点时可以重复使用，而且特征已经被存储为一个个block结构，那么在寻找每个特征的最佳分割点时，可以利用多线程对每个block并行计算。 XGBoost切分点算法切分点算法之贪婪算法【例】下表表示样本的某一列特征数值 根据特征大小对样本重新排序： 贪婪算法切分节点： 切分点算法之分位点算法若特征是连续值，按照上述的贪婪算法，运算量极大 。当样本量足够大的时候，使用特征分位点来切分特征。 【例】下表表示样本的某一列特征数值，用三分位作为切分节点 。 根据特征大小进行样本排序： 用特征的三分位点作切分节点： 切分点算法之权重分位点算法上节假设样本权重相等，根据样本的分位点来均分损失函数存在偏差，本节用样本权重来均分损失函数。 过程略。 参考： https://baijiahao.baidu.com/s?id=1621144293288522535&amp;wfr=spider&amp;for=pc 5. XGBoost为什么快分块并行：训练前每个特征按特征值进行排序并存储为Block结构，后面查找特征分割点时重复使用，并且支持并行查找每个特征的分割点 候选分位点：每个特征采用常数个分位点作为候选分割点 CPU cache 命中优化： 使用缓存预取的方法，对每个线程分配一个连续的buffer，读取每个block中样本的梯度信息并存入连续的Buffer中。 Block 处理优化：Block预先放入内存；Block按列进行解压缩；将Block划分到不同硬盘来提高吞吐 6. XGBoost防止过拟合的方法XGBoost在设计时，为了防止过拟合做了很多优化，具体如下： 目标函数添加正则项：叶子节点个数+叶子节点权重的L2正则化 列抽样：训练的时候只用一部分特征（不考虑剩余的block块即可） 子采样：每轮计算可以不使用全部样本，使算法更加保守 shrinkage: 可以叫学习率或步长，为了给后面的训练留出更多的学习空间 7. XGBoost如何处理缺失值XGBoost模型的一个优点就是允许特征存在缺失值。对缺失值的处理方式如下： 在特征k上寻找最佳 split point 时，不会对该列特征 missing 的样本进行遍历，而只对该列特征值为 non-missing 的样本上对应的特征值进行遍历，通过这个技巧来减少了为稀疏离散特征寻找 split point 的时间开销。 然后，在逻辑实现上，为了保证完备性，会将该特征值missing的样本分别分配到左叶子结点和右叶子结点，两种情形都计算一遍后，选择分裂后增益最大的那个方向（左分支或是右分支），作为预测时特征值缺失样本的默认分支方向。 如果在训练中没有缺失值而在预测中出现缺失，那么会自动将缺失值的划分方向放到右子结点。 XGBoost中的一棵树的停止生长条件 当新引入的一次分裂所带来的增益Gain&lt;0时，放弃当前的分裂。这是训练损失和模型结构复杂度的博弈过程。 当树达到最大深度时，停止建树，因为树的深度太深容易出现过拟合，这里需要设置一个超参数max_depth。 当引入一次分裂后，重新计算新生成的左、右两个叶子结点的样本权重和。如果任一个叶子结点的样本权重低于某一个阈值，也会放弃此次分裂。这涉及到一个超参数:最小样本权重和，是指如果一个叶子节点包含的样本数量太少也会放弃分裂，防止树分的太细。 RF和GBDT的区别相同点： 都是由多棵树组成，最终的结果都是由多棵树一起决定。 不同点： 集成学习：RF属于bagging思想，而GBDT是boosting思想 偏差-方差权衡：RF不断的降低模型的方差，而GBDT不断的降低模型的偏差 训练样本：RF每次迭代的样本是从全部训练集中有放回抽样形成的，而GBDT每次使用全部样本 并行性：RF的树可以并行生成，而GBDT只能顺序生成(需要等上一棵树完全生成) 最终结果：RF最终是多棵树进行多数表决（回归问题是取平均），而GBDT是加权融合 数据敏感性：RF对异常值不敏感，而GBDT对异常值比较敏感 泛化能力：RF不易过拟合，而GBDT容易过拟合 XGBoost如何处理不平衡数据对于不平衡的数据集，例如用户的购买行为，肯定是极其不平衡的，这对XGBoost的训练有很大的影响，XGBoost有两种自带的方法来解决： 第一种，如果你在意AUC，采用AUC来评估模型的性能，那你可以通过设置scale_pos_weight来平衡正样本和负样本的权重。例如，当正负样本比例为1:10时，scale_pos_weight可以取10；增大了少数样本的权重。 第二种，如果你在意概率(预测得分的合理性)，你不能重新平衡数据集(会破坏数据的真实分布)，应该设置max_delta_step为一个有限数字来帮助收敛（基模型为LR时有效）。 比较LR和GBDT，说说什么情景下GBDT不如LR先说说LR和GBDT的区别： LR是线性模型，可解释性强，很容易并行化，但学习能力有限，需要大量的人工特征工程 GBDT是非线性模型，具有天然的特征组合优势，特征表达能力强，但是树与树之间无法并行训练，而且树模型很容易过拟合； 当在高维稀疏特征的场景下，LR的效果一般会比GBDT好。原因如下： 先看一个例子： 假设一个二分类问题，label为0和1，特征有100维，如果有1w个样本，但其中只要10个正样本1，而这些样本的特征 f1的值为全为1，而其余9990条样本的f1特征都为0(在高维稀疏的情况下这种情况很常见)。 我们都知道在这种情况下，树模型很容易优化出一个使用f1特征作为重要分裂节点的树，因为这个结点直接能够将训练数据划分的很好，但是当测试的时候，却会发现效果很差，因为这个特征f1只是刚好偶然间跟y拟合到了这个规律，这也是我们常说的过拟合。 那么这种情况下，如果采用LR的话，应该也会出现类似过拟合的情况呀：y = W1f1 + Wifi+….，其中 W1特别大以拟合这10个样本。为什么此时树模型就过拟合的更严重呢？ 仔细想想发现，因为现在的模型普遍都会带着正则项，而 LR 等线性模型的正则项是对权重的惩罚，也就是 W1一旦过大，惩罚就会很大，进一步压缩 W1的值，使他不至于过大。但是，树模型则不一样，树模型的惩罚项通常为叶子节点数和深度等，而我们都知道，对于上面这种 case，树只需要一个节点就可以完美分割9990和10个样本，一个结点，最终产生的惩罚项极其之小。 这也就是为什么在高维稀疏特征的时候，线性模型会比非线性模型好的原因了：带正则化的线性模型比较不容易对稀疏特征过拟合。 XGBoost中如何对树进行剪枝 在目标函数中增加了正则项：使用叶子结点的数目和叶子结点权重的L2模的平方，控制树的复杂度。 在结点分裂时，定义了一个阈值，如果分裂后目标函数的增益小于该阈值，则不分裂。 当引入一次分裂后，重新计算新生成的左、右两个叶子结点的样本权重和。如果任一个叶子结点的样本权重低于某一个阈值（最小样本权重和），也会放弃此次分裂。 XGBoost 先从顶到底建立树直到最大深度，再从底到顶反向检查是否有不满足分裂条件的结点，进行剪枝。 gblinearYou want to use multiple rounds in gblinear in order to get back a single lasso regression. This was because it makes less sense to stacking linear models(which was again a linear model). So num_round steps of update was used jointly to solve a single lasso problem. eval_metric have nothing to do with objective function. The loss function are documented in the parameters.md reg:logistic for logistic regression, reg:linear for squared-loss and muti:softmax for softmax multiclass classification ————————————————版权声明：本文为CSDN博主「MachineLP」的原创文章，遵循 CC 4.0 BY-SA 版权协议，转载请附上原文出处链接及本声明。原文链接：https://blog.csdn.net/u014365862/article/details/101073433]]></content>
      <categories>
        <category>机器学习算法专题</category>
      </categories>
  </entry>
  <entry>
    <title></title>
    <url>%2F2019%2F11%2F23%2F%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%AE%97%E6%B3%95%E4%B8%93%E9%A2%98%2Fgbdt%2Fgbdt%2F</url>
    <content type="text"><![CDATA[gbdt的残差为什么用负梯度代替GBDT的求解过程就是梯度下降在函数空间中的优化过程 不是用负梯度代替残差，而是当损失函数是均方损失时，负梯度刚好是残差，残差只是特例。 boosting的思想作者：LancelotHolmes链接：https://www.nowcoder.com/discuss/36083?type=0&amp;order=0&amp;pos=8&amp;page=0来源：牛客网 boosting的思想是每一个基分类器纠正前一个基分类器的错误，至于纠正的方式不同所以有不同的boosting算法，比如通过调整样本权值分布训练基分类器对应的AdaBoost，通过拟合前一个基分类器与目标值的误差的负梯度来学习下一个基分类器的方法是gradient boosting 参考： https://www.zhihu.com/question/63560633/answer/379959040 https://blog.csdn.net/youhuakongzhi/article/details/94488888 GBDT算法原理以及实例理解]]></content>
  </entry>
  <entry>
    <title></title>
    <url>%2F2019%2F11%2F23%2F%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%AE%97%E6%B3%95%E4%B8%93%E9%A2%98%2Fgbdt%2Fcart%E6%A0%91%2F</url>
    <content type="text"><![CDATA[原理CART回归树预测回归连续型数据，假设X与Y分别是输入和输出变量，并且Y是连续变量。在训练数据集所在的输入空间中，递归的将每个区域划分为两个子区域并决定每个子区域上的输出值，构建二叉决策树 选择最优切分变量j与切分点s：遍历变量j，对规定的切分变量j扫描切分点s，选择使下式得到最小值时的(j,s)对。其中Rm是被划分的输入空间，cm是空间Rm对应的固定输出值。 1、c就是划分后，所有y取值的平均 2、这个公式的意义是什么 计算分裂后两组数据的平方损失。这里就是要找使得平方损失最小的划分点。 用选定的(j,s)对，划分区域并决定相应的输出值** 继续对两个子区域调用上述步骤，将输入空间划分为M个区域R1,R2,…,Rm，生成决策树。 当输入空间划分确定时，可以用平方误差来表示回归树对于训练数据的预测方法，用平方误差最小的准则求解每个单元上的最优输出值。 实例详解 考虑如上所示的连续性变量，根据给定的数据点，考虑1.5,2.5,3.5,4.5,5.5,6.5,7.5,8.5,9.5切分点。对各切分点依次求出R1,R2,c1,c2及m(s)，例如当切分点s=1.5时，得到R1={1},R2={2,3,4,5,6,7,8,9,10}，其中c1,c2,m(s)如下所示。 依次改变(j,s)对，可以得到s及m(s)的计算结果，如下表所示。 当x=6.5时，此时R1={1,2,3,4,5,6},R2={7,8,9,10},c1=6.24,c2=8.9。回归树T1(x)为 然后我们利用f1(x)拟合训练数据的残差，如下表所示 用f1(x)拟合训练数据得到平方误差 第二步求T2(x)与求T1(x)方法相同，只是拟合的数据是上表的残差。可以得到 用f2(x)拟合训练数据的平方误差 继续求得T3(x)、T4(x)、T5(x)、T6(x)，如下所示 用f6(x)拟合训练数据的平方损失误差如下所示，假设此时已经满足误差要求，那么f(x)=f6(x)便是所求的回归树。]]></content>
  </entry>
  <entry>
    <title></title>
    <url>%2F2019%2F11%2F22%2F%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%2F%E5%A6%82%E4%BD%95%E9%98%B2%E6%AD%A2%E8%BF%87%E6%8B%9F%E5%90%88%2F</url>
    <content type="text"><![CDATA[正则化或者相对熵（KLD、KL散度）]]></content>
  </entry>
  <entry>
    <title></title>
    <url>%2F2019%2F11%2F22%2F%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%2FAttention%E6%9C%BA%E5%88%B6%2F</url>
    <content type="text"></content>
  </entry>
  <entry>
    <title></title>
    <url>%2F2019%2F11%2F22%2F%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%2FGRU%E5%92%8CLSTM%E7%9A%84%E5%8C%BA%E5%88%AB%2F</url>
    <content type="text"></content>
  </entry>
  <entry>
    <title><![CDATA[lstm-自编码器]]></title>
    <url>%2F2019%2F11%2F22%2F%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%AE%97%E6%B3%95%E4%B8%93%E9%A2%98%2Flstm%2Flstm-%E8%87%AA%E7%BC%96%E7%A0%81%E5%99%A8%2F</url>
    <content type="text"><![CDATA[构建Encoder-Decoder LSTMs加法预测问题1.问题描述：给定输出的两个字符，计算加法输出： 12Input: [ &apos;1&apos; ,&apos;0&apos;, &apos;+&apos; ,&apos; 6&apos; ]Output: [ &apos;1&apos; ,&apos; 6&apos; ] 该问题是一个Seq2Seq问题： 为简化问题，将该问题分为以下几步： Generate Sum Pairs Integer to Padded Strings Integer Encoded Sequence One hot Encoded Sequences Sequence Generation Pipeline Decode Sequence (1)Generate Sum Pairs 123456789101112131415161718192021from random import seedfrom random import randint# generate lists of random integers and their sumdef random_sum_pairs(n_examples, n_numbers, largest): X, y = list(), list() for i in range(n_examples): in_pattern = [randint(1,largest) for _ in range (n_numbers)] out_pattern = sum (in_pattern) X.append(in_pattern) y.append(out_pattern) return X, y#seed(1)n_samples = 1n_numbers = 2largest = 10# generate pairsX, y = random_sum_pairs(n_samples, n_numbers, largest)print (X, y) 输出：[[5, 10]] [15] (2)Integer to Padded Strings 1234567891011121314151617181920212223242526272829303132333435from math import ceilfrom math import log10# convert data to stringsdef to_string(X, y, n_numbers, largest): #输入数字表达式转换为字符串的最大长度计算，考虑数字之间的加号 #如n_numbers=3,largest=10,最大字符串长度为8[‘1’,‘0’,‘+’,‘1’,‘0’,‘+’,‘1’,‘0’]，如果不满需要补足8位 max_length = n_numbers * ceil(log10(largest+1)) + n_numbers - 1 Xstr = list() for pattern in X: strp =&apos;+&apos; .join([ str (n) for n in pattern]) #填充空格符，以保证输入和输出长度相等，这里采用左侧填充，数据字符串在右侧 strp =&apos;&apos; .join([&apos; &apos; for _ in range(max_length- len (strp))]) + strp Xstr.append(strp) #输出数字表达式转换为字符串的最大长度计算，输出的结果中没有符号 max_length = ceil(log10(n_numbers * (largest+1))) ystr = list() for pattern in y: strp = str(pattern) #填充空格符，以保证输入和输出长度相等，这里采用左侧填充，数据字符串在右侧 strp =&apos;&apos; .join([&apos; &apos; for _ in range(max_length- len (strp))]) + strp ystr.append(strp) return Xstr, ystrseed(1)n_samples = 1n_numbers = 3largest = 10# generate pairsX, y = random_sum_pairs(n_samples, n_numbers, largest)print(X, y)#print(len(X[0]))# convert to stringsX, y = to_string(X, y, n_numbers, largest)print(X, y)#print(len(X[0]),len(y[0])) (3)Integer encode strings 1234567891011121314151617181920212223242526def integer_encode(X, y, alphabet): char_to_int = dict ((c, i) for i, c in enumerate (alphabet)) Xenc = list() for pattern in X: integer_encoded = [char_to_int[char] for char in pattern] Xenc.append(integer_encoded) yenc = list() for pattern in y: integer_encoded = [char_to_int[char] for char in pattern] yenc.append(integer_encoded) return Xenc, yencseed(1)n_samples = 1n_numbers = 2largest = 10# generate pairsX, y = random_sum_pairs(n_samples, n_numbers, largest)print(X, y)# convert to stringsX, y = to_string(X, y, n_numbers, largest)print (X, y)# integer encodealphabet = ['0','1','2','3','4','5','6','7','8','9','+',' ']X, y = integer_encode(X, y, alphabet)print (X, y) (4)one hot encode 参考： https://blog.csdn.net/cskywit/article/details/87721142 参考： https://blog.csdn.net/shenziheng1/article/details/80375481 自编码器参考： https://blog.csdn.net/avinswang/article/details/86607233]]></content>
      <categories>
        <category>深度学习</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[pytorch-Linear]]></title>
    <url>%2F2019%2F11%2F22%2Fpytorch%2Fpytorch-Linear%2F</url>
    <content type="text"><![CDATA[参考： http://www.digtime.cn/articles/159/pytorch-zhong-nn-linear-han-shu-jie-du]]></content>
      <categories>
        <category>pytorch</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[Batch_Size的选择]]></title>
    <url>%2F2019%2F11%2F22%2Fpytorch%2FBatch_Size%E7%9A%84%E9%80%89%E6%8B%A9%2F</url>
    <content type="text"><![CDATA[参考： https://www.zhihu.com/question/32673260]]></content>
      <categories>
        <category>pytorch</category>
      </categories>
  </entry>
  <entry>
    <title></title>
    <url>%2F2019%2F11%2F22%2Fpytorch%2Fpytorch-lstm%2F</url>
    <content type="text"><![CDATA[https://www.cnblogs.com/duye/p/9913386.html]]></content>
  </entry>
  <entry>
    <title></title>
    <url>%2F2019%2F11%2F22%2Fpytorch%2Fpytorch-%E8%87%AA%E7%BC%96%E7%A0%81%E5%99%A8%2F</url>
    <content type="text"><![CDATA[问题： 12345678910111213141516# 编码后解码效果import numpy as npimport matplotlib.pyplot as plttest_data = train_data.data[:5]for i in range(5): plt.subplot(2, 5, i+1) plt.imshow(test_data[i].numpy(), cmap=&apos;gray&apos;) plt.title(&apos;true&apos;) plt.subplot(2, 5, i+6) _, end_data = autoencoder(test_data[i].view(-1, 28*28).type(torch.FloatTensor)) plt.imshow(np.reshape(end_data.data.numpy(), (28, 28)), cmap=&apos;gray&apos;) plt.title(&apos;encode&apos;)plt.show() 这里的end_data是decode后的结果，那么中间结果如何获取？为何end_data就能代表降维的结果？输入输出的特征数量不是一致的吗 代码在： david/code/deep_learning/pytorch_sample/encoder.ipynb 参考： https://blog.csdn.net/zhouchen1998/article/details/89500941]]></content>
  </entry>
  <entry>
    <title><![CDATA[xgboost参数及调参]]></title>
    <url>%2F2019%2F11%2F22%2F%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%AE%97%E6%B3%95%E4%B8%93%E9%A2%98%2Fxgboost%2Fxgboost%E5%8F%82%E6%95%B0%E5%8F%8A%E8%B0%83%E5%8F%82%2F</url>
    <content type="text"><![CDATA[一般参数booster[default=gbtree]选择基分类器 gbtree、gblinear 树或线性分类器silent [default=0] 是否输出详细信息 0不输出 1输出nthread [default to maximum number of threads available if not set]线程数默认最大 Tree Booster参数1、eta [default=0.3]: 学习率。shrinkage参数，用于更新叶子节点权重时，乘以该系数，避免步长过大。参数值越大，越可能无法收敛。把学习率 eta 设置的小一些，小学习率可以使得后面的学习更加仔细。 2、min_child_weight [default=1]: 叶子节点的最小样本数。这个参数默认是 1，是每个叶子里面 h 的和至少是多少，对正负样本不均衡时的 0-1 分类而言，假设 h 在 0.01 附近，min_child_weight 为 1 意味着叶子节点中最少需要包含 100 个样本。这个参数非常影响结果，控制叶子节点中二阶导的和的最小值，该参数值越小，越容易 overfitting。 3、max_depth [default=6]: 每颗树的最大深度，树高越深，越容易过拟合。 4、gamma [default=0]：在树的叶子节点上作进一步分区所需的最小损失减少。越大，算法越保守。[0,∞] 5、max_delta_step [default=0]：这个参数在更新步骤中起作用，如果取0表示没有约束，如果取正值则使得更新步骤更加保守。可以防止做太大的更新步子，使更新更加平缓。 通常，这个参数是不需要的，但它可能有助于逻辑回归时，类是非常不平衡。设置它的值为1-10可能有助于控制更新。 6、subsample [default=1]：样本随机采样，较低的值使得算法更加保守，防止过拟合，但是太小的值也会造成欠拟合。 7、colsample_bytree [default=1]：列采样，对每棵树的生成用的特征进行列采样.一般设置为： 0.5-1 8、scale_pos_weight [default=1]如果取值大于0的话，在类别样本不平衡的情况下有助于快速收敛。 9、tree_method[default=’auto’]可选 {‘auto’, ‘exact’, ‘approx’} 贪心算法(小数据集)/近似算法(大数据集) https://www.cnblogs.com/mengnan/p/9307632.html]]></content>
      <categories>
        <category>机器学习算法专题</category>
      </categories>
  </entry>
  <entry>
    <title></title>
    <url>%2F2019%2F11%2F22%2Fsklearn%2FGridSearchCV%2F</url>
    <content type="text"><![CDATA[123456789101112from sklearn.grid_search import GridSearchCVparams = &#123;&apos;max_depth&apos;:range(2, 7), &apos;n_estimators&apos;:range(100, 1100, 200), &apos;learning_rate&apos;:[0.05, 0.1, 0.25, 0.5, 1.0]&#125;xgbc_best = XGBClassifier()gs = GridSearchCV(xgbc_best, params, n_jobs=-1, cv=5, verbose=1)gs.fit(X_train, y_train)————————————————版权声明：本文为CSDN博主「开心果汁」的原创文章，遵循 CC 4.0 BY-SA 版权协议，转载请附上原文出处链接及本声明。原文链接：https://blog.csdn.net/u013421629/article/details/78642834]]></content>
  </entry>
  <entry>
    <title></title>
    <url>%2F2019%2F11%2F21%2F%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%AE%97%E6%B3%95%E4%B8%93%E9%A2%98%2Fxgboost%2Fxgboost%E5%A4%9A%E5%88%86%E7%B1%BB%E5%8E%9F%E7%90%86%2F</url>
    <content type="text"></content>
  </entry>
  <entry>
    <title><![CDATA[Spark GraphX]]></title>
    <url>%2F2019%2F11%2F21%2Fspark%2Fspark%E5%BC%80%E5%8F%91%E7%82%B9%E6%BB%B4%2FSpark%20GraphX%2F</url>
    <content type="text"><![CDATA[找到逾期手机号，在通话记录中 MGCNN mobile-net]]></content>
      <categories>
        <category>spark开发点滴</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[avro]]></title>
    <url>%2F2019%2F11%2F20%2Fhadoop%2F%E7%99%BE%E9%97%AEhadoop%2Favro%2F</url>
    <content type="text"><![CDATA[Avro是一种序列化框架，使用JSON来定义schema，shcema由原始类型(null，boolean，int，long，float，double，bytes，string)和复杂类型(record，enum，array，map，union，fixed)组成，schema文件以.avsc结尾，表示avro schema，有2种序列化方式 二进制方式：也就是Specific方式，定义好schema asvc文件后，使用编译器(avro-tools.jar)编译生成相关语言(java)的业务类，类中会嵌入JSON schema JSON方式：也就是Generic方式，在代码中动态加载schema asvc文件，将FieldName - FieldValue，以Map的方式存储 序列化后的数据，是schema和data同时存在的，如下图]]></content>
      <categories>
        <category>百问hadoop</category>
      </categories>
  </entry>
  <entry>
    <title></title>
    <url>%2F2019%2F11%2F20%2Fspark%2F%E7%99%BE%E9%97%AESpark%2FThriftServer%2F</url>
    <content type="text"></content>
  </entry>
  <entry>
    <title><![CDATA[kafka为什么有高性能]]></title>
    <url>%2F2019%2F11%2F20%2Fkafka%2F%E7%99%BE%E9%97%AEkafka%2Fkafka%E4%B8%BA%E4%BB%80%E4%B9%88%E6%9C%89%E9%AB%98%E6%80%A7%E8%83%BD%2F</url>
    <content type="text"><![CDATA[1、高效使用磁盘顺序写磁盘将写磁盘的过程变为顺序写，可极大提高对磁盘的利用率。Consumer通过offset顺序消费这些数据，且不删除已经消费的数据，从而避免随机写磁盘的过程。 Kafka删除旧数据的方式是删除整个Segment对应的log文件和整个index文件，而不是删除部分内容。 充分利用Page CachePage Cache的优点： I/O Scheduler会将连续的小块写组装成大块的物理写从而提高性能。 I/O Scheduler会尝试将一些写操作重新按顺序排好，从而减少磁头移动时间。 充分利用所有空闲内存（非JVM内存）。 读操作可以直接在Page Cache内进行。如果消费和生产速度相当，甚至不需要通过物理磁盘交换数据。 如果进程重启，JVM内的Cache会失效，但Page Cache仍然可用 零拷贝Kafka中存在大量网络数据持久化到磁盘（Producer到Broker）和磁盘文件通过网络发送（Broker到Consumer）的过程，这个过程中，传统模式下要进行数据的四次拷贝，但是Kafka通过零拷贝技术将其减为了一次，大大增加了效率，原理可以在另一篇文章（https://www.jianshu.com/p/835ec2d4c170）中获得。 2.减少网络开销批处理​ 批处理减少了网络传输的overhead，又提高了写磁盘的效率。​ Kafka的API做中，从send接口来看，一次只能发送一个ProducerRecord，但是send方法并不是立即将消息发送出去，而是通过batch.size和linger.ms控制实际发送频率，从而实现批量发送。 数据压缩降低网络负载高效的序列化方式通过avro序列化 参考： 作者：阿猫阿狗Hakuna链接：https://www.jianshu.com/p/ff7dd5b349f1来源：简书著作权归作者所有。商业转载请联系作者获得授权，非商业转载请注明出处。]]></content>
      <categories>
        <category>百问kafka</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[kafka与传统消息系统]]></title>
    <url>%2F2019%2F11%2F17%2Fkafka%2F%E7%99%BE%E9%97%AEkafka%2FKafka%20%E4%B8%8E%E4%BC%A0%E7%BB%9F%E6%B6%88%E6%81%AF%E7%B3%BB%E7%BB%9F%2F</url>
    <content type="text"><![CDATA[(1).Kafka 持久化日志，这些日志可以被重复读取和无限期保留 (2).Kafka 是一个分布式系统：它以集群的方式运行，可以灵活伸缩，在内部通过复制数据 提升容错能力和高可用性 (3).Kafka 支持实时的流式处理]]></content>
      <categories>
        <category>百问kafka</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[kafka文件存储特点]]></title>
    <url>%2F2019%2F11%2F17%2Fkafka%2F%E7%99%BE%E9%97%AEkafka%2Fkafka%E6%96%87%E4%BB%B6%E5%AD%98%E5%82%A8%E7%89%B9%E7%82%B9%2F</url>
    <content type="text"><![CDATA[Kafka 把 topic 中一个 parition 大文件分成多个小文件段，通过多个小文件段，就容易定 期清除或删除已经消费完文件，减少磁盘占用。 通过索引信息可以快速定位 message 和确定 response 的最大大小。 通过 index 元数据全部映射到 memory，可以避免 segment file 的 IO 磁盘操作。 通过索引文件稀疏存储，可以大幅降低 index 文件元数据占用空间大小。（这个不理解） Kafka 新建的分区会在哪个目录下创建在启动 Kafka 集群之前，我们需要配置好 log.dirs 参数，其值是 Kafka 数据的存放目录， 这个参数可以配置多个目录，目录之间使用逗号分隔，通常这些目录是分布在不同的磁盘 上用于提高读写性能。 当然我们也可以配置 log.dir 参数，含义一样。只需要设置其中一个即可。 如果 log.dirs 参数只配置了一个目录，那么分配到各个 Broker 上的分区肯定只能在这个 目录下创建文件夹用于存放数据。 但是如果 log.dirs 参数配置了多个目录，那么 Kafka 会在哪个文件夹中创建分区目录呢？ 答案是：Kafka 会在含有分区目录最少的文件夹中创建新的分区目录，分区目录名为 Topic 名+分区 ID。注意，是分区文件夹总数最少的目录，而不是磁盘使用量最少的目录！也就 是说，如果你给 log.dirs 参数新增了一个新的磁盘，新的分区目录肯定是先在这个新的磁 盘上创建直到这个新的磁盘目录拥有的分区目录不是最少为止。]]></content>
      <categories>
        <category>百问kafka</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[kafka消息采用pull还是push模式]]></title>
    <url>%2F2019%2F11%2F17%2Fkafka%2F%E7%99%BE%E9%97%AEkafka%2Fkafka%E6%B6%88%E6%81%AF%E9%87%87%E7%94%A8pull%E8%BF%98%E6%98%AFpush%E6%A8%A1%E5%BC%8F%2F</url>
    <content type="text"><![CDATA[Kafka 最初考虑的问题是，customer 应该从 brokes 拉取消息还是 brokers 将消息推送到 consumer，也就是 pull 还 push。在这方面，Kafka 遵循了一种大部分消息系统共同的传统 的设计：producer 将消息推送到 broker，consumer 从 broker 拉取消息 一些消息系统比如 Scribe 和 Apache Flume 采用了 push 模式，将消息推送到下游的 consumer。这样做有好处也有坏处：由 broker 决定消息推送的速率，对于不同消费速率的 consumer 就不太好处理了。消息系统都致力于让 consumer 以最大的速率最快速的消费消 息，但不幸的是，push 模式下，当 broker 推送的速率远大于 consumer 消费的速率时， consumer 恐怕就要崩溃了。最终 Kafka 还是选取了传统的 pull 模式 Pull 模式的另外一个好处是 consumer 可以自主决定是否批量的从 broker 拉取数据。Push 模式必须在不知道下游 consumer 消费能力和消费策略的情况下决定是立即推送每条消息还 是缓存之后批量推送。如果为了避免 consumer 崩溃而采用较低的推送速率，将可能导致一 次只推送较少的消息而造成浪费。Pull 模式下，consumer 就可以根据自己的消费能力去决 定这些策略 Pull 有个缺点是，如果 broker 没有可供消费的消息，将导致 consumer 不断在循环中轮询， 直到新消息到达。为了避免这点，Kafka 有个参数可以让 consumer 阻塞知道新消息到达 (当然也可以阻塞知道消息的数量达到某个特定的量这样就可以批量发 参考： https://www.cnblogs.com/kx33389/p/11182082.html]]></content>
      <categories>
        <category>百问kafka</category>
      </categories>
  </entry>
  <entry>
    <title></title>
    <url>%2F2019%2F11%2F17%2F%E6%95%B0%E6%8D%AE%E4%BB%93%E5%BA%93%2F%E7%99%BE%E9%97%AE%E6%95%B0%E6%8D%AE%E4%BB%93%E5%BA%93%2FData%20Vault%2F</url>
    <content type="text"></content>
  </entry>
  <entry>
    <title><![CDATA[ODS]]></title>
    <url>%2F2019%2F11%2F17%2F%E6%95%B0%E6%8D%AE%E4%BB%93%E5%BA%93%2F%E7%99%BE%E9%97%AE%E6%95%B0%E6%8D%AE%E4%BB%93%E5%BA%93%2FODS%2F</url>
    <content type="text"><![CDATA[ODS 作业数据存储 Operational Data Store]]></content>
      <categories>
        <category>百问数据仓库</category>
      </categories>
  </entry>
  <entry>
    <title></title>
    <url>%2F2019%2F11%2F16%2Fspark%2Fspark%E5%BC%80%E5%8F%91%E7%82%B9%E6%BB%B4%2FSparkSQL%20ThriftServer%2F</url>
    <content type="text"></content>
  </entry>
  <entry>
    <title></title>
    <url>%2F2019%2F11%2F16%2Fkafka%2F%E7%99%BE%E9%97%AEkafka%2Fkafka%E5%A6%82%E4%BD%95%E4%BF%9D%E8%AF%81%E6%95%B0%E6%8D%AE%E4%B8%8D%E9%87%8D%E5%A4%8D%2F</url>
    <content type="text"></content>
  </entry>
  <entry>
    <title><![CDATA[kafka如何保持数据不丢失]]></title>
    <url>%2F2019%2F11%2F16%2Fkafka%2F%E7%99%BE%E9%97%AEkafka%2Fkafka%E5%A6%82%E4%BD%95%E4%BF%9D%E8%AF%81%E6%95%B0%E6%8D%AE%E4%B8%8D%E4%B8%A2%E5%A4%B1%2F</url>
    <content type="text"><![CDATA[主要三个部分会造成消息丢失 broker 端消息丢失 生产者端消息丢失 消费者端消息丢失 broker 端消息丢失broker端的消息不丢失，其实就是用partition副本机制来保证。 broker 端有三个重要的参数来保证消息可靠： 1、复制系数 创建topic时使用replication.factor，broker配置中使用default.replication.factor来配置自动创建的主题。 2、不完全的首领选举 broker中配置unclean.leader.election，默认为true 。该参数配置决定在分区首领不可用时、非同步副本是否可以被选举为首领副本;如果设置为true 则予许不同步的副本成为首领，但我们将面临丢失消息的风险、如果设置为false 就需要等待原先的首领副本重新上线 从而降低了可用性。 换个角度说就是:该参数配置为true时 且分区发生重新选举选举出的首领分区为不完全分区时 可能就会发生消息丢失 所以为了避免丢失，最好改成false 3、最小同步副本 topic和broker都可以配置min.insync.replicas &gt; 1 消息至少要被写入到这么多副本才算成功。 假如设置成3 那么至少要存在三个同步副本才能向分区写入数据(注意是 同步副本),如果同步副本数量小于3时broker就会停止接收所有生产者的消息、尝试发送消息的的生产者会受到NotEnoughReplicasException异常，消费者仍然可以读取已有数据、变成只读状态。 保证replication.factor &gt; min.insync.replicas 如果两者相等，当一个副本挂掉了分区也就没法正常工作了。通常设置replication.factor = min.insync.replicas + 1即可。 生产者端消息丢失1、有关ack的配置。 1）同步模式下，在配置为1（只保证写入leader成功）的话，如果刚好leader partition挂了，数据就会丢失。 2）异步模式下，当缓冲区满了，如果配置为0（还没有收到确认的情况下，缓冲池一满，就清空缓冲池里的消息），数据就会被立即丢弃掉。 2、max.in.flight.requests.per.connection=1。限制客户端在单个连接上能够发送的未响应请求的个数。设置此值是1表示kafka broker在响应请求之前client不能再向同一个broker发送请求。注意：设置此参数是为了避免消息乱序 消费者端消息丢失consumer端丢失消息的情形比较简单：如果在消息处理完成前就提交了offset，那么就有可能造成数据的丢失 为了避免数据丢失，现给出两点建议： enable.auto.commit=false 关闭自动提交位移 在消息被完整处理之后再手动提交位移 参考： https://blog.csdn.net/guokekanhai/article/details/90292106]]></content>
      <categories>
        <category>百问kafka</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[kafka如何保持数据一致性]]></title>
    <url>%2F2019%2F11%2F16%2Fkafka%2F%E7%99%BE%E9%97%AEkafka%2Fkafka%E5%A6%82%E4%BD%95%E4%BF%9D%E6%8C%81%E6%95%B0%E6%8D%AE%E4%B8%80%E8%87%B4%E6%80%A7%2F</url>
    <content type="text"><![CDATA[一致性就是说不论是老的 Leader 还是新选举的 Leader，Consumer 都能读到一样的数据。 假设分区的副本为3，其中副本0是 Leader，副本1和副本2是 follower，并且在 ISR 列表里面。虽然副本0已经写入了 Message4，但是 Consumer 只能读取到 Message2。因为所有的 ISR 都同步了 Message2，只有 High Water Mark 以上的消息才支持 Consumer 读取，而 High Water Mark 取决于 ISR 列表里面偏移量最小的分区，对应于上图的副本2，这个很类似于木桶原理。]]></content>
      <categories>
        <category>百问kafka</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[kafka的设计架构]]></title>
    <url>%2F2019%2F11%2F16%2Fkafka%2F%E7%99%BE%E9%97%AEkafka%2Fkafka%E7%9A%84%E8%AE%BE%E8%AE%A1%E6%9E%B6%E6%9E%84%2F</url>
    <content type="text"><![CDATA[简单架构如下 详细如下]]></content>
      <categories>
        <category>百问kafka</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[kafka应用场景]]></title>
    <url>%2F2019%2F11%2F16%2Fkafka%2F%E7%99%BE%E9%97%AEkafka%2Fkafka%E5%BA%94%E7%94%A8%E5%9C%BA%E6%99%AF%2F</url>
    <content type="text"><![CDATA[日志收集：一个公司可以用Kafka可以收集各种服务的log，通过kafka以统一接口服务的方式开放给各种consumer，例如hadoop、HBase、Solr等。 消息系统：解耦和生产者和消费者、缓存消息等。 用户活动跟踪：Kafka经常被用来记录web用户或者app用户的各种活动，如浏览网页、搜索、点击等活动，这些活动信息被各个服务器发布到kafka的topic中，然后订阅者通过订阅这些topic来做实时的监控分析，或者装载到hadoop、数据仓库中做离线分析和挖掘。 运营指标：Kafka也经常用来记录运营监控数据。包括收集各种分布式应用的数据，生产各种操作的集中反馈，比如报警和报告。 流式处理：比如spark streaming和 Flink]]></content>
      <categories>
        <category>百问kafka</category>
      </categories>
  </entry>
  <entry>
    <title></title>
    <url>%2F2019%2F11%2F16%2Fflink%2Fflink%E4%B8%8Espark%E7%9A%84%E5%8C%BA%E5%88%AB%2F</url>
    <content type="text"></content>
  </entry>
  <entry>
    <title></title>
    <url>%2F2019%2F11%2F16%2Fhadoop%2F%E7%99%BE%E9%97%AEhadoop%2F%E5%85%B3%E4%BA%8Eyarn%2F</url>
    <content type="text"></content>
  </entry>
  <entry>
    <title></title>
    <url>%2F2019%2F11%2F16%2Fhadoop%2F%E7%99%BE%E9%97%AEhadoop%2Fhadoop3.0%E7%9A%84%E6%94%B9%E8%BF%9B%2F</url>
    <content type="text"></content>
  </entry>
  <entry>
    <title></title>
    <url>%2F2019%2F11%2F16%2Fhadoop%2F%E7%99%BE%E9%97%AEhadoop%2Fhdfs%E6%9E%B6%E6%9E%84%E5%92%8C%E8%AF%BB%E5%86%99%E6%B5%81%E7%A8%8B%2F</url>
    <content type="text"></content>
  </entry>
  <entry>
    <title></title>
    <url>%2F2019%2F11%2F16%2F%E5%A4%A7%E6%95%B0%E6%8D%AE%E7%90%86%E8%AE%BA%E4%B8%8E%E6%A1%86%E6%9E%B6%2F%E5%AF%B9%E5%A4%A7%E6%95%B0%E6%8D%AE%E7%9A%84%E8%A7%81%E8%A7%A3%2F</url>
    <content type="text"></content>
  </entry>
  <entry>
    <title><![CDATA[java并发]]></title>
    <url>%2F2019%2F11%2F16%2Fjava%2Fjava%E5%BC%80%E5%8F%91%E7%82%B9%E6%BB%B4%2Fjava%E5%B9%B6%E5%8F%91%2F</url>
    <content type="text"><![CDATA[volatile]]></content>
      <categories>
        <category>java开发点滴</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[spark调优]]></title>
    <url>%2F2019%2F11%2F16%2Fspark%2Fspark%E5%BC%80%E5%8F%91%E7%82%B9%E6%BB%B4%2Fspark%E8%B0%83%E4%BC%98%2F</url>
    <content type="text"></content>
      <categories>
        <category>spark开发点滴</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[lag和lead]]></title>
    <url>%2F2019%2F11%2F16%2Fhive%2Fhive%E8%AF%AD%E6%B3%95%2Flag%E5%92%8Clead%2F</url>
    <content type="text"><![CDATA[lag 和lead 可以 获取结果集中，按一定排序所排列的当前行的上下相邻若干offset 的某个行的某个列(不用结果集的自关联）；lag ，lead 分别是向前，向后；lag 和lead 有三个参数，第一个参数是列名，第二个参数是偏移的offset，第三个参数是 超出记录窗口时的默认值） over()表示 lag()与lead()操作的数据都在over()的范围内，他里面可以使用partition by 语句（用于分组） order by 语句（用于排序）。partition by a order by b表示以a字段进行分组，再 以b字段进行排序，对数据进行查询。 例如：lead(field, num, defaultvalue) field需要查找的字段，num往后查找的num行的数据，defaultvalue没有符合条件的默认值。 举例如下：SQL&gt; select * from kkk; ID NAME 1 1name 2 2name 3 3name 4 4name 5 5name SQL&gt; select id,name,lag(name,1,0) over ( order by id ) from kkk; ID NAME LAG(NAME,1,0)OVER(ORDERBYID) 1 1name 0 2 2name 1name 3 3name 2name 4 4name 3name 5 5name 4name SQL&gt; select id,name,lead(name,1,0) over ( order by id ) from kkk; ID NAME LEAD(NAME,1,0)OVER(ORDERBYID) 1 1name 2name 2 2name 3name 3 3name 4name 4 4name 5name 5 5name 0 SQL&gt;SQL&gt; select id,name,lead(name,2,0) over ( order by id ) from kkk; ID NAME LEAD(NAME,2,0)OVER(ORDERBYID) 1 1name 3name 2 2name 4name 3 3name 5name 4 4name 0 5 5name 0 参考： https://blog.csdn.net/qq_34941023/article/details/52590176]]></content>
      <categories>
        <category>hive语法</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[蚂蚁森林植物申领统计]]></title>
    <url>%2F2019%2F11%2F16%2Fhive%2Fhive%E6%93%8D%E4%BD%9C%E7%82%B9%E6%BB%B4%2F%E8%9A%82%E8%9A%81%E6%A3%AE%E6%9E%97%E6%A4%8D%E7%89%A9%E7%94%B3%E9%A2%86%E7%BB%9F%E8%AE%A1%2F</url>
    <content type="text"><![CDATA[一道蚂蚁金服面试题： 一.题目说明：以下表记录了用户每天的蚂蚁森林低碳生活领取的记录流水。table_name：user_low_carbonuser_id data_dt low_carbon用户 日期 减少碳排放（g） 蚂蚁森林植物换购表，用于记录申领环保植物所需要减少的碳排放量table_name: plant_carbonplant_id plant_name low_carbon植物编号 植物名 换购植物所需要的碳 ——题目1.蚂蚁森林植物申领统计问题：假设2017年1月1日开始记录低碳数据（user_low_carbon），假设2017年10月1日之前满足申领条件的用户都申领了一颗p004-胡杨，剩余的能量全部用来领取“p002-沙柳” 。统计在10月1日累计申领“p002-沙柳” 排名前10的以用户信息；及他比后一名多领了几颗沙柳。得到的统计结果如下表样式：user_id plant_count less_count(比后一名多领了几颗沙柳)u_101 1000 100u_088 900 400u_103 500 … 2、蚂蚁森林低碳用户排名分析问题：查询user_low_carbon表中每日流水记录，条件为：用户在2017年，连续三天（或以上）的天数里，每天减少碳排放（low_carbon）都超过100g的用户低碳流水。需要查询返回满足以上条件的user_low_carbon表中的记录流水。例如用户u_002符合条件的记录如下，因为2017/1/2~2017/1/5连续四天的碳排放量之和都大于等于100g：seq（key） user_id data_dt low_carbonxxxxx10 u_002 2017/1/2 150xxxxx11 u_002 2017/1/2 70xxxxx12 u_002 2017/1/3 30xxxxx13 u_002 2017/1/3 80xxxxx14 u_002 2017/1/4 150xxxxx14 u_002 2017/1/5 101备注：统计方法不限于sql、procedure、python,java等 提供的数据说明：user_low_carbon：u_001 2017/1/1 10u_001 2017/1/2 150u_001 2017/1/2 110u_001 2017/1/2 10u_001 2017/1/4 50u_001 2017/1/4 10u_001 2017/1/6 45u_001 2017/1/6 90u_002 2017/1/1 10u_002 2017/1/2 150u_002 2017/1/2 70u_002 2017/1/3 30u_002 2017/1/3 80u_002 2017/1/4 150u_002 2017/1/5 101u_002 2017/1/6 68… plant_carbon：p001 梭梭树 17p002 沙柳 19p003 樟子树 146p004 胡杨 215… 1.创建表create table user_low_carbon(user_id String,data_dt String,low_carbon int) row format delimited fields terminated by ‘\t’;create table plant_carbon(plant_id string,plant_name String,low_carbon int) row format delimited fields terminated by ‘\t’; 2.加载数据load data local inpath “/opt/module/data/low_carbon.txt” into table user_low_carbon;load data local inpath “/opt/module/data/plant_carbon.txt” into table plant_carbon; 3.设置本地模式set hive.exec.mode.local.auto=true; 二.答案第一题 12345678910111213141516171819202122SELECT user_id, plant_count , plant_count - lead(plant_count, 1) OVER (ORDER BY plant_count DESC)FROM ( SELECT user_id, floor((sum - hy) / sl) AS plant_count FROM ( SELECT user_id, SUM(low_carbon) AS sum FROM user_low_carbon WHERE datediff(regexp_replace(data_dt, &apos;/&apos;, &apos;-&apos;), &apos;2017-1-1&apos;) &gt;= 0 AND datediff(regexp_replace(data_dt, &apos;/&apos;, &apos;-&apos;), &apos;2017-10-1&apos;) &lt;= 0 GROUP BY user_id ) t1, ( SELECT low_carbon AS hy FROM plant_carbon WHERE plant_id = &apos;p004&apos; ) t2, ( SELECT low_carbon AS sl FROM plant_carbon WHERE plant_id = &apos;p002&apos; ) t3) t4LIMIT 10; 参考： https://blog.csdn.net/weixin_44546916/article/details/88790579]]></content>
      <categories>
        <category>hive操作点滴</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[ISR、AR、HW、LEO、LSO、LW]]></title>
    <url>%2F2019%2F11%2F16%2Fkafka%2F%E7%99%BE%E9%97%AEkafka%2FISR%E3%80%81AR%E3%80%81HW%E3%80%81LEO%E3%80%81LSO%E3%80%81LW%2F</url>
    <content type="text"><![CDATA[ISR和AR分区中的所有副本统称为AR（Assigned Repllicas）。所有与leader副本保持一定程度同步的副本（包括Leader）组成ISR（In-Sync Replicas），ISR集合是AR集合中的一个子集。 消息会先发送到leader副本，然后follower副本才能从leader副本中拉取消息进行同步，同步期间内follower副本相对于leader副本而言会有一定程度的滞后。前面所说的“一定程度”是指可以忍受的滞后范围，这个范围可以通过参数进行配置。与leader副本同步滞后过多的副本（不包括leader）副本，组成OSR(Out-Sync Relipcas),由此可见：AR=ISR+OSR。在正常情况下，所有的follower副本都应该与leader副本保持一定程度的同步，即AR=ISR,OSR集合为空。 Leader副本负责维护和跟踪ISR集合中所有的follower副本的滞后状态，当follower副本落后太多或者失效时，leader副本会吧它从ISR集合中剔除。如果OSR集合中follower副本“追上”了Leader副本，之后在ISR集合中的副本才有资格被选举为leader，而在OSR集合中的副本则没有机会（这个原则可以通过修改对应的参数配置来改变） HW、LEO、LSO、LWHW是High Watermak的缩写， 俗称高水位，它表示了一个特定消息的偏移量（offset），消费者只能拉取到这个offset之前的消息。 如下，它代表一个日志文件，这个日志文件中有9条消息，第一消息的offset（LogStartOffset）为0，最后的一条消息offset为8，offset为9的消息用虚线框表示，代表下的一个待写入的消息。日志文件的HW为6.表示消费者只能拉取到offset0至5之间的消息，而offset为6的消息对消费者而言是不可见的 LEO是Log End Offset的缩写，它表示了当前日志文件中下一条待写入消息的offset，如上图offset为9的位置即为当前日志文件LEO,LEO的大小相当于当前日志分区中最后一条消息的offset值加1。分区ISR集合中的每个副本都会维护自身的LEO，而ISR集合中最小的LEO即为分区的HW，对消费这而言只能消费HW之前的消息。 HW指向的是实实在在的消息，而LEO总是指向下一条待写入消息，也就是说LEO指向的位置上是没有消息的，例如HW值是7，这表示前8条消息（位移从0计数）都已经处于“已备份状态”；而LEO值是12，则表示当前日志中写入了11条消息，而消息8、9、10、11尚未完全备份，即它们属于未提交消息。 如下图，假设某个分区的ISR集合中有三个副本，即一个leader副本和两个follower副本，此时分区的LEO和HW都为3。消息3和消息4从生产者发出之后会被先存入leader副本。 在消息写入leader副本之后，follower副本会发送拉取请求来拉取消息3和消息4以进行消息同步。 在同步过程中，不同的follower副本的同步效率也不尽相同。在某一时刻follower1完全跟上了leader副本而follower2只同步了消息3，如此leader副本的LEO为5，follower1的LEO为5，Follower2的LEO为4。那么当前分区的HW最小值4，此时消费者可以消费到offset为0-3之间的消息（注意这几个数字的关系）。 这种机制的好处是什么？ kafka的复制机制不是完全的同步复制，也不是单纯的异步复制，事实上，同步复制要求所有能工作的Follower副本都复制完，这条消息才会被确认为成功提交，这种复制方式影响了性能。而在异步复制的情况下， follower副本异步地从leader副本中复制数据，数据只要被leader副本写入就被认为已经成功提交。在这种情况下，如果follower副本都没有复制完而落后于leader副本，如果突然leader副本宕机，则会造成数据丢失。Kafka使用这种ISR的方式有效的权衡了数据可靠性与性能之间的关系。 LSO特指LastStableOffset。它具体与kafka的事务有关。对未完成的事务而言，LSO 的值等于事务中第一条消息的位置(firstUnstableOffset)，对已完成的事务而言，它的值同 HW 相同 LW Low Watermark 低水位, 代表 AR 集合中最小的 logStartOffset 值。 更新LEO的机制follower更新LEOfollower副本的LEO保存在2个地方： （1）follower副本所在的broker缓存里（2）leader所在broker的缓存里，也就是leader所在broker的缓存上保存了该分区所有副本的LEO 在follower发送FETCH请求后，leader将数据返回给follower，此时follower开始向底层log写数据，从而自动更新其LEO值，每当新写入一条消息，其LEO值就会加1。 leader更新LEOleader的LEO就保存在其所在broker的缓存里，leader写log时就自动更新其LEO值。 更新HW的机制follower更新HWfollower更新HW发生在其更新LEO之后，一旦follower向log写完数据，它就会尝试更新HW值。具体算法就是比较当前LEO值与FETCH响应中leader的HW值，取两者的小者作为新的HW值。这告诉我们一个事实：如果follower的LEO值超过了leader的HW值，那么follower HW值是不会越过leader HW值的。 leader更新HWleader更新HW的时机： producer 向 leader 写消息时 leader 处理 follower 的 fetch 请求时 某副本成为leader时 broker 崩溃导致副本被踢出ISR时 leader更新HW的方式： 当尝试确定分区HW时，它会选出所有满足条件的副本，比较它们的LEO（当然也包括leader自己的LEO），并选择最小的LEO值作为HW值。 这里的满足条件主要是指副本要满足以下两个条件之一： 处于ISR中 副本LEO落后于leader LEO的时长不大于replica.lag.time.max.ms参数值（默认值是10秒） 引入了 High Water Mark 机制，会导致 Broker 间的消息复制因为某些原因变慢，那么消息到达消费者的时间也会随之变长（因为我们会先等待消息复制完毕）。延迟时间可以通过参数 replica.lag.time.max.ms 参数配置，它指定了副本在复制消息时可被允许的最大延迟时间。 ISR的伸缩kafka何时缩减ISRKafka在启动的时候会开启两个与ISR相关的定时任务，名称分别为“isr-expiration”和”isr-change-propagation”.。isr-expiration任务会周期性的检测每个分区是否需要缩减其ISR集合。这个周期和“replica.lag.time.max.ms”参数有关。 当检测到ISR中有是失效的副本的时候，就会缩减ISR集合。如果某个分区的ISR集合发生变更， 则会将变更后的数据记录到zookeeper对应/brokers/topics/partition/state节点中。节点中数据示例如下： 1&#123;“controller_epoch&quot;:26,“leader”:0,“version”:1,“leader_epoch”:2,“isr”:&#123;0,1&#125;&#125; controller_epoch表示的是当前的kafka控制器epoch leader表示当前分区的leader副本所在的broker的id编号 isr表示变更后的isr列表 kafka何时扩充ISR的随着follower副本不断进行消息同步，follower副本LEO也会逐渐后移，并且最终赶上leader副本，此时follower副本就有资格进入ISR集合，追赶上leader副本的判定准侧是此副本的LEO是否小于leader副本HW，这里并不是和leader副本LEO相比。ISR扩充之后同样会更新ZooKeeper中的/broker/topics//partition//state节点和isrChangeSet，之后的步骤就和ISR收缩的时的相同。 参考： https://blog.csdn.net/weixin_43975220/article/details/93190906 https://blog.csdn.net/lukabruce/article/details/101012815]]></content>
      <categories>
        <category>百问kafka</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[kafka的ack机制]]></title>
    <url>%2F2019%2F11%2F16%2Fkafka%2F%E7%99%BE%E9%97%AEkafka%2Fkafka%E7%9A%84ack%E6%9C%BA%E5%88%B6%2F</url>
    <content type="text"><![CDATA[request.required.acks Kafka的ack机制，指的是producer的消息发送确认机制，这直接影响到Kafka集群的吞吐量和消息可靠性。而吞吐量和可靠性就像硬币的两面，两者不可兼得，只能平衡。 ack有3个可选值，分别是1，0，-1。 ack=1。写入leader成功。简单来说就是，producer只要收到一个分区副本成功写入的通知就认为推送消息成功了。这里有一个地方需要注意，这个副本必须是leader副本。只有leader副本成功写入了，producer才会认为消息发送成功。 注意，ack的默认值就是1。这个默认值其实就是吞吐量与可靠性的一个折中方案。生产上我们可以根据实际情况进行调整，比如如果你要追求高吞吐量，那么就要放弃可靠性。 ack=。不在乎是否写入成功。简单来说就是，producer发送一次就不再发送了，不管是否发送成功。 ack=-1，写入leader和所有副本都成功。简单来说就是，producer只有收到分区内所有副本的成功写入的通知才认为推送消息成功了。 ack=1的情况下，为什么消息也会丢失？ ack=1的情况下，producer只要收到分区leader成功写入的通知就会认为消息发送成功了。如果leader成功写入后，还没来得及把数据同步到follower节点就挂了，这时候消息就丢失了。 参考： https://www.jianshu.com/p/c98b934f2c2b]]></content>
      <categories>
        <category>百问kafka</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[Partition和Broker]]></title>
    <url>%2F2019%2F11%2F15%2Fkafka%2F%E7%99%BE%E9%97%AEkafka%2FPartition%E5%92%8CBroker%2F</url>
    <content type="text"><![CDATA[Partition分区数和Broker数关系 1.如果Partition数等于Broker数 Kafka集群将比较均衡！！！ 2.如果Partition数小于Broker数 某个Broker节点上不存在当前topic的分区，Broker节点可能被闲置！最终导致Kafka集群吞吐率下降 3.如果Partition数大于Broker数 抛异常：java.lang.IllegalArgumentException: Invalid partition given with record: 1 is not in the range [0…0]. 建议将Partition数必须设置为Broker数的整数倍！！！ 参考： https://blog.csdn.net/yk_3215123/article/details/99699210]]></content>
      <categories>
        <category>百问kafka</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[关于Rebalance]]></title>
    <url>%2F2019%2F11%2F15%2Fkafka%2F%E7%99%BE%E9%97%AEkafka%2F%E5%85%B3%E4%BA%8ERebalance%2F</url>
    <content type="text"><![CDATA[什么是Rebalance？Rebalance的起因： consumer通过向群组协调器（coordinator，也是一个broker）发送心跳来维持他们和群组的从属关系以及它们对分区的所有权关系。只要consumer以正常时间间隔发送心跳，就被认为是活跃的，说明还在读取分区里的消息。consumer会在轮询消息或提交偏移量时发送心跳。若停止发送心跳时间过长，会话就会过期，coordinator认为它已经死亡，就会触发一次Rebalance。]]></content>
      <categories>
        <category>百问kafka</category>
      </categories>
  </entry>
  <entry>
    <title></title>
    <url>%2F2019%2F11%2F15%2Fspark%2F%E7%99%BE%E9%97%AESpark%2Fspark%20streaming%E5%A6%82%E4%BD%95%E6%B6%88%E8%B4%B9kafka%2F</url>
    <content type="text"><![CDATA[与普通java程序消费kafka有何区别]]></content>
  </entry>
  <entry>
    <title></title>
    <url>%2F2019%2F11%2F15%2Fspark%2F%E7%99%BE%E9%97%AESpark%2Fspark%20streaming%E5%92%8Cflink%E7%9A%84%E5%8C%BA%E5%88%AB%2F</url>
    <content type="text"></content>
  </entry>
  <entry>
    <title><![CDATA[kafka和zookeeper的关系]]></title>
    <url>%2F2019%2F11%2F15%2Fkafka%2F%E7%99%BE%E9%97%AEkafka%2Fkafka%E5%92%8Czookeeper%E7%9A%84%E5%85%B3%E7%B3%BB%2F</url>
    <content type="text"><![CDATA[消费者可以选择将偏移量提交给zookeeper或kafka，还可以选择提交偏移量的时间间隔。 若提交到zookeeper，那么在每个提交时间上，消费者会为每个消息的分区往zookeeper写入一次偏移量。合理提交间隔是1分钟，因为这刚好是group的某个消费者发生失效时能读取到重复消息的时间。 并且，这些提交对zookeeper来说流量不算小，特别是当集群中有多个消费者的时候。若zookeeper无法处理太大的流量，就有必要使用长一点的提交时间间隔。 kafka在0.9.0.0后，引入一个新的消费者接口，允许broker直接维护group信息、topic信息、offset信息。建议使用该接口，消除对zookeeper的依赖。]]></content>
      <categories>
        <category>百问kafka</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[如何选定分区数量]]></title>
    <url>%2F2019%2F11%2F15%2Fkafka%2F%E7%99%BE%E9%97%AEkafka%2F%E5%A6%82%E4%BD%95%E9%80%89%E5%AE%9A%E5%88%86%E5%8C%BA%E6%95%B0%E9%87%8F%2F</url>
    <content type="text"><![CDATA[需要考虑： 1、topic需要多大吞吐量，每秒100KB还是1GB？ 2、从单个分区读取数据的最大吞吐量是多少？每个分区一般都会有一个消费者，如果知道消费者将写入数据库的速度不超过每秒50MB，那从一个分区读取数据的吞吐量不需要超过每秒50MB。 3、每个broker包含的分区个数，可用的磁盘空间和网络带宽。 4、如果消息按照不同键写入分区，则为已有主题增加分区就会困难。（为什么，键已经分布好了？） 5、单个broker对分区个数有限制，因为分区越多，占用内存越多，完成首领选举需要时间越长。 如果估算出topic的吞吐量和消费者的吞吐量，可以用 topic吞吐量 / 消费者吞吐量 = 分区个数即，如果每秒要从topic写入和读取1GB数据，且每个消费者每秒可处理50MB数据，那至少需要20个分区，这样可以让20个消费者同时读取这些分区。 每个分区的大小，经验值是25GB。]]></content>
      <categories>
        <category>百问kafka</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[topic常用配置项]]></title>
    <url>%2F2019%2F11%2F15%2Fkafka%2F%E7%99%BE%E9%97%AEkafka%2Ftopic%E5%B8%B8%E7%94%A8%E9%85%8D%E7%BD%AE%E9%A1%B9%2F</url>
    <content type="text"><![CDATA[Topic配置num.partitions topic包含多少个分区，一旦设定后，只能增加不能减少；若需要减少，得新增一个topic。 kafka通过partitions对topic进行横向扩展，当有新broker加入时，通过分区个数实现集群的负载均衡。一般的，topic的partitions的个数大于broker个数。 log.retention.hours 过期时间。默认值是168小时，也就是一周。还有两个其他参数log.retention.minutes和log.retention.ms。如果指定多个，kafka优先使用最小值。 log.retention.bytes 通过保留的字节数判断过期。作用在每个分区。即假设有8个partitions，且设为1G，那该topic最多保留8GB的数据。所以，当topic的分区个数增加时，整个topic可保留的数据也随之增加。如果也设置了hours，只要任意一个条件满足，消息就会被删除。 log.segment.bytes 上面设置在日志片段上，而不是在单个消息上。当消息到达broker时，它们被追加到分区的当前日志片段上。当日志片段大小超过该参数上限（默认是1GB），当前日志片段会被关闭，产生一个新的日志片段。 如果一个日志片段被关闭，就开始等待过期。该参数值越小，就会频繁关闭和分配新文件，从而降低磁盘写入的整体效率。 如果topic消息量不大，那么如何调整该参数大小就很重要。比如，一个topic每天100MB，而该参数是默认值，那么10天才能填满一个日志片段。由于日志片段在被关闭之前是不会过期的，所以如果log.retention,ms=1周，则segment最多需要17天才会过期。 segment大小也会影响通过timestamp获取offset。在获取offset时，kafka会检查分区最后修改时间大于指定timestamp的segment，让该segment的前一个的最后修改时间小于指定timestamp。然后，kafka返回该segment文件开头的offset。 message.max.bytes broker设置这个来限制单个消息的大小，默认是1MB。若生产者发生的消息超过这个大小，不仅不会被接收，还会收到broker返回的错误信息。跟其他与字节相关配置参数一样，该参数指的是压缩后的消息大小，实际大小可以大于这个值。 该值对性能有很大影响。值越大，负责网络连接和请求的线程就要花更多时间处理这些请求。还会增加磁盘写入块的大小，从而影响IO吞吐量。 在服务端和客户端之间协调消息大小 客户端的fetch.message.max.bytes必须与服务端的参数进行协调。若该值更小，则消费者无法获取大的消息，导致消费者被阻塞。 在集群里的broker配置replica.fetch.max.bytes时，遵循同样原则。 num.netword.threads 处理网络请求的线程数量，也就是接收消息的线程数 接收线程会将消息放入内存中，再写到磁盘 num.io.threads 消息从内存写入磁盘的线程数量 用来处理磁盘io的线程数量 producer配置partitioner.class 生产者生产的消息被发送到哪个block，需要一个分组策略 指定分区处理类。默认kafka.producer.DefaultPartitioner，通过key哈希到对应分区 compression.codec 生产者生产的消息可以通过一定的压缩策略（或者说压缩算法）来压缩。消息被压缩后发送到broker集群 而broker集群是不会进行解压缩的，broker集群只会把消息发送到消费者集群，然后由消费者来解压缩 是否压缩，默认0表示不压缩，1表示用gzip压缩，2表示用snappy压缩 参考： https://blog.csdn.net/yk_3215123/article/details/99699210]]></content>
      <categories>
        <category>百问kafka</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[百问机器学习-Softmax]]></title>
    <url>%2F2019%2F07%2F07%2F%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%AE%97%E6%B3%95%E4%B8%93%E9%A2%98%2Fsoftmax%2F%E7%99%BE%E9%97%AE%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0-Softmax%2F</url>
    <content type="text"><![CDATA[问题1：多分类下为什么用Softmax而不是其他的归一化方法转自知乎：多类分类下为什么用softmax而不是用其他归一化方法? 1.softmax设计的初衷，是希望特征对概率的影响是乘性的。即，$exp(\sumd w{id} xd)$ 可以看做是类别i的未归一化概率。$x_d$ 加上某个数，会导致这个概率乘上某个数，乘多少由 $w{id}$ 来控制。 2.多类分类问题的目标函数常常选为cross-entropy。即 L = -\sum_i t_i \cdot lnP(y=i)其中目标类的$t_i$为1，其余类的$t_i$为0。在神经网络模型中，输出层第i个神经元的输入为 a_i = \sum_d w_{id} x_d神经网络是用error back-propagation训练的，这个过程中有一个关键的量是 \frac {\partial L}{\partial a_i}可以算出，同时使用softmax和cross-entropy时， \frac {\partial L}{\partial a_i}=P(y=i)-t_i这个形式非常简洁，而且与线性回归（采用最小均方误差目标函数）、两类分类（采用cross-entropy目标函数）时的形式一致。 还是没看懂。]]></content>
      <categories>
        <category>机器学习算法专题</category>
      </categories>
      <tags>
        <tag>Softmax</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[机器学习算法推导（一）Softmax]]></title>
    <url>%2F2019%2F07%2F07%2F%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%AE%97%E6%B3%95%E4%B8%93%E9%A2%98%2Fsoftmax%2F%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%AE%97%E6%B3%95%E6%8E%A8%E5%AF%BC%EF%BC%88%E4%BA%8C%EF%BC%89Softmax%2F</url>
    <content type="text"><![CDATA[Softmax是否包含两个用途： 1）用于多分类 2）用于输出结果的概率化。 用作输出结果假设有一个数组V，$V_i$表示V中的第i个元素，那么这个元素的softmax值为: S_i = \frac{e^i}{\sum_j e^j}加上参数等的写法是 该元素的softmax值，就是该元素的指数与所有元素指数和的比值。 这个定义可以说很简单，也很直观。那为什么要定义成这个形式呢？原因主要如下。 Softmax求偏导在分类问题中，会使用交叉熵作为损失函数，可以表示为 Loss=-\sum_it_i\ln y_i参考小白都能看懂的softmax详解]]></content>
      <categories>
        <category>机器学习算法专题</category>
      </categories>
      <tags>
        <tag>算法推导</tag>
        <tag>Softmax</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[百问机器学习-逻辑回归]]></title>
    <url>%2F2019%2F07%2F06%2F%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%AE%97%E6%B3%95%E4%B8%93%E9%A2%98%2Flr%2F%E7%99%BE%E9%97%AE%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0-%E9%80%BB%E8%BE%91%E5%9B%9E%E5%BD%92%2F</url>
    <content type="text"><![CDATA[LR和线性回归，有何异同1、LR是分类问题，线性回归是回归问题，这是最本质的区别。 具体来说，LR中，y取值是一个几何分布，模型学习得出的是 E[y|x;\theta]这个公式的解释是，给定x和参数后，得到y的期望。 而线性回归求解的是 {y}' = \theta^Tx是我们对于假设的真实关系 {y} = \theta^Tx+\epsilon的一个近似。其中$\epsilon$代表误差项。我们用这个近似项来处理回归问题。 正因为是分类和回归问题，LR的因变量是离散的，线性回归的是连续的。 2、在x和参数确定的情况下，LR可以看做是广义线性模型（Generalized Linear Model）在y服从几何分布时的一个特殊情况。 暂时不理解，需要查一下，广义线性模型一般是什么样的。 而使用最小二乘求线性回归时，我们认为y服从正态分布。 3、都使用了极大似然估计来对训练样本进行建模。但是， 线性回归使用最小二乘法，就是在x和参数确定，y服从正态分布的假设下，使用极大似然估计的一个化简。 是不是个化简呢？这两个都不是一种求值的思路。 最大似然估计：现在已经拿到了很多个样本（你的数据集中所有因变量），这些样本值已经实现，最大似然估计就是去找到那个（组）参数估计值，使得前面已经实现的样本值发生概率最大。因为你手头上的样本已经实现了，其发生概率最大才符合逻辑。这时是求样本所有观测的联合概率最大化，是个连乘积，只要取对数，就变成了线性加总。此时通过对参数求导数，并令一阶导数为零，就可以通过解方程（组），得到最大似然估计值。最小二乘：找到一个（组）估计值，使得实际值与估计值的距离最小。本来用两者差的绝对值汇总并使之最小是最理想的，但绝对值在数学上求最小值比较麻烦，因而替代做法是，找一个（组）估计值，使得实际值与估计值之差的平方加总之后的值最小，称为最小二乘。“二乘”的英文为least square，其实英文的字面意思是“平方最小”。这时，将这个差的平方的和式对参数求导数，并取一阶导数为零，就是OLSE。作者：稻花香链接：https://www.zhihu.com/question/20447622/answer/23848605来源：知乎著作权归作者所有。商业转载请联系作者获得授权，非商业转载请注明出处。 Softmax和逻辑回归问题3：为什么要用Sigmoid因为线性回归模型的预测值为实数，而样本的类标记为（0,1），我们需要将分类任务的真实标记y与线性回归模型的预测值联系起来，也就是找到广义线性模型中的联系函数。如果选择单位阶跃函数的话，它是不连续的不可微。而如果选择sigmoid函数，它是连续的，而且能够将z转化为一个接近0或1的值。 问题4：为什么叫对数几率函数Sigmoid的定义是 y=\frac {1} {1+e^{-(w^Tx+b)}}可以推导出 \ln \frac y {1-y} = w^Tx+b若将y视为x作为正例的可能性，那么1-y是其反例的可能性，两者的比值就称为“几率”。反映了x作为正例的相对可能性。然后再取对数，可以看出，上式其实是在用线性回归模型的预测结果去逼近真实标记的对数几率。 问题5：逻辑回归的假设假设数据服从伯努利分布。 不同文章说法不一，伯努利、二项、几何分布都有。 问题6：为什么LR用最大似然而不是最小二乘作为损失函数简单的说，如果用最小二乘会导致损失函数是一个非凸函数。具体参考机器学习算法推导（一）逻辑回归。 问题7：逻辑回归在训练的过程当中，如果有很多的特征高度相关或者说有一个特征重复了100遍，会造成怎样的影响？ 先说结论，如果在损失函数最终收敛的情况下，其实就算有很多特征高度相关也不会影响分类器的效果。 但是对特征本身来说的话，假设只有一个特征，在不考虑采样的情况下，你现在将它重复100遍。训练以后完以后，数据还是这么多，但是这个特征本身重复了100遍，实质上将原来的特征分成了100份，每一个特征都是原来特征权重值的百分之一。 如果在随机采样的情况下，其实训练收敛完以后，还是可以认为这100个特征和原来那一个特征扮演的效果一样，只是可能中间很多特征的值正负相消了。 问题8：LR的缺点 很难处理数据不平衡的问题。举个例子：如果我们对于一个正负样本非常不平衡的问题比如正负样本比 10000:1.我们把所有样本都预测为正也能使损失函数的值比较小。但是作为一个分类器，它对正负样本的区分能力不会很好。 处理非线性数据较麻烦。逻辑回归在不引入其他方法的情况下，只能处理线性可分的数据，或者进一步说，处理二分类的问题 。 逻辑回归本身无法筛选特征。有时候，我们会用gbdt来筛选特征，然后再上逻辑回归。 问题9：LR和神经网络的关系LR可以看做是没有隐层的神经网络。因为LR有激活函数，有梯度下降更新权重，只是少了一层全连接的隐层。]]></content>
      <categories>
        <category>机器学习算法专题</category>
      </categories>
      <tags>
        <tag>逻辑回归</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[机器学习算法推导（一）逻辑回归]]></title>
    <url>%2F2019%2F07%2F06%2F%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%AE%97%E6%B3%95%E4%B8%93%E9%A2%98%2Flr%2F%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%AE%97%E6%B3%95%E6%8E%A8%E5%AF%BC%EF%BC%88%E4%B8%80%EF%BC%89%E9%80%BB%E8%BE%91%E5%9B%9E%E5%BD%92%2F</url>
    <content type="text"><![CDATA[前言我们知道，线性回归的公式是 h_{\theta}(x)={\theta}^Tx如果想实现分类功能，就需要把输出变成一个阶跃函数，比如 y=\left\{\begin{matrix} 0; & z\leqslant 0 \\ 1; & z \geqslant 0 \end{matrix}\right. ,z=h_{\theta}(x)但是这样就太粗糙了，而且不连续不可微。我们希望有一个理想的阶跃函数，而且是单调可微的函数。于是找到了对数几率函数（Logistic Function）。因为曲线像S，又称Sigmoid。 定义Sigmoid函数的定义是： y=\frac {1} {1+e^{-(\theta^Tx+b)}}接下来就是根据给定的训练集，求出参数w。首先要找到目标函数（代价函数/损失函数）。 目标函数、代价函数、损失函数，一般而言，这三个概念是一回事。 如果深究的话，有细微的差别。参考深入理解机器学习中的：目标函数，损失函数和代价函数 损失函数：计算的是一个样本的误差 代价函数：是整个训练集上所有样本误差的平均 目标函数：代价函数 + 正则化项 首先想到的就是模仿线性回归的思路，用最小二乘当损失函数。 J(\theta)=\sum_{i} \frac 1 2 (h_{\theta}(x^i) - \ y^i)^2但是，把Sigmoid带入后，会发现这是一个非凸函数，这就意味着代价函数有着许多的局部最小值，不利于求解。 后来人们想到，用极大似然函数作为损失函数，这样就是一个凸函数。 损失函数如果将$h_{\theta}(x)$看做是正类的后验概率，则有 h_{\theta}(x;\theta)=p(y=1|x;\theta)=\phi(x)=\frac {1} {1+e^{-(\theta^Tx+b)}}那么，有 p(y=0|x;\theta) = 1-\phi(x)将上面两式写成一般形式（概率分布函数） p(y|x;\theta)=h_{\theta}(x;\theta)^y(1-h_{\theta}(x;\theta))^{1-y}接下来用对数极大似然估计（加上对数是为了方便求导）根据训练集估计出参数$\theta$。 \begin{aligned} l(\theta) &= Log\ L(\theta)\\ &=\sum_{j=1}^M(y_jln\ h(x_j)+(1-y_j)ln\ (1-h(x_j))) \end{aligned}其中M是样本个数。对其求关于$\theta$的偏导。 1）首先求$h_{\theta}(x)$，即Sigmoid的偏导。 h_{\theta}^{'}(\mathbf X) = h_{\theta}(\mathbf X)(1-h_{\theta}(\mathbf X))推导过程如下： 2）有了第一步得出的公式后，得到 3）利用梯度下降法求解参数。由于损失函数是凸函数，沿着梯度下降方向找到最小点。 之所以是梯度下降，因为偏导取了负值 ① 批量梯度下降是： Repeat\ until\ convergence \{ \\ \theta^{(t+1)} := \theta^t - \eta^t\triangledown _{\theta}l(\theta^{t},Z) \\ \}\\ \tag{1-2}② 随机梯度下降（SGD）： Repeat\ until\ convergence \{ \\ for\ j=1\ to\ M, \{ \\ \theta^{(t+1)} := \theta^t - \eta^t\triangledown _{\theta}l(\theta^{t},Z_j) \\ \}两者的区别是： 前者每次更新$\theta$都需要遍历一次整个样本集合；而后者在遍历样本集合的时候，每个样本都能改变$\theta$ ，有更快的收敛速度 。由于SGD针对观测到的随机一条数据进行权重的更新，很适合进行增量计算，实现梯度下降的online模式。 ③ small batch梯度下降 结合了上述两点的优点，每次更新参数时仅使用一部分样本，减少了参数更新的次数，可以达到更加稳定的结果，一般在深度学习中采用这种方法。 参考： Logistic Regression——逻辑回归算法推导 逻辑回归与最大似然估计推导]]></content>
      <categories>
        <category>机器学习算法专题</category>
      </categories>
      <tags>
        <tag>逻辑回归</tag>
        <tag>算法推导</tag>
      </tags>
  </entry>
  <entry>
    <title></title>
    <url>%2F2019%2F07%2F06%2F%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%AE%97%E6%B3%95%E4%B8%93%E9%A2%98%2Flr%2F%E9%80%BB%E8%BE%91%E5%9B%9E%E5%BD%92%E7%9A%84Python%E5%AE%9E%E7%8E%B0%2F</url>
    <content type="text"></content>
  </entry>
  <entry>
    <title></title>
    <url>%2F2019%2F06%2F08%2F%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%AE%97%E6%B3%95%E4%B8%93%E9%A2%98%2Fsoftmax%2F%E8%BE%93%E5%87%BA%E5%B1%82%E7%9A%84Softmax%2F</url>
    <content type="text"><![CDATA[https://cloud.tencent.com/developer/news/307323 Softmax是假设不同特征是相互独立的 然而，这可能在许多情况下不成立，因为特征之间可能存在协同作用或冗余，种协同或者作用会直接影响输出概率。 解决方案可以是： 1）去除有协同作用或冗余的特征，如x3 =X1⋅x2x3=x1⋅x2（但是如果我们不知道哪些特征值是相关的，我们可能会引入更多无用的特征！ 2）当两个特征经常一起被激活时，训练过程将学习较小的权重W1和W2，使得它们的联合效果更接近真实效果 如何判断两个特征是否同时被激活]]></content>
  </entry>
  <entry>
    <title><![CDATA[熵、条件熵、相对熵、交叉熵]]></title>
    <url>%2F2018%2F03%2F17%2F%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%AE%97%E6%B3%95%E4%B8%93%E9%A2%98%2F%E5%9F%BA%E7%A1%80%E7%90%86%E8%AE%BA%2F%E7%86%B5%2F</url>
    <content type="text"><![CDATA[熵1、什么是信息量？假设X是一个离散型随机变量，其取值集合为X，概率分布函数为$p(x) = P(X=x), x \in X$，定义$X=x_0$的信息量为： I(x_0) = -log(p(x_0))可以理解为，一个事件发生的概率越大，携带的信息量越小。当$p(x_0)=1$时，信息量为0。 2、什么是熵？熵就是信息的不确定程度，信息熵越小，信息越确定 第一，假设存在一个随机变量，可以问一下自己当我们观测到该随机变量的一个样本时，我们可以接受到多少信息量呢？毫无疑问，当我们被告知一个极不可能发生的事情发生了，那我们就接收到了更多的信息；而当我们观测到一个非常常见的事情发生了，那么我们就接收到了相对较少的信息量。因此信息的量度应该依赖于概率分布，所以说熵的定义应该是概率的单调函数。 第二，假设两个随机变量和是相互独立的，那么分别观测两个变量得到的信息量应该和同时观测两个变量的信息量是相同的，即：$H(X+Y)=H(X)+H(Y)$ 。而从概率上来讲，两个独立随机变量就意味着$p(x,y)=p(x)p(y)$，所以此处可以得出结论熵的定义应该是概率的函数。因此一个随机变量的熵可以使用如下定义： 设$X \in {x_1,x_2,…,x_n} $ 为一个离散随机变量，其概率分布为$P(X=x_i)=p_i$。则X的熵为 H(X)=-\sum_{i=1}^np_i\log p_i其中，当$p_i=0$时，熵为0。 此处的负号仅仅是用来保证熵（即信息量）是正数或者为零。而函数基的选择是任意的（信息论中基常常选择为2，因此信息的单位为比特bits；而机器学习中基常常选择为自然常数，因此单位常常被称为nats）。 用熵来评价整个随机变量x平均的信息量，而平均最好的量度就是随机变量的期望。 熵的取值范围是 0 \leq H(X) \leq \log n两个随机变量一起发生的熵就是联合熵 3、条件熵设$Y \in {y_1,y_2,…,y_m}$为随机变量，在已知X的条件下，Y的条件熵（conditional entropy）为 H(Y|X) = \sum_{i=1}^n p(x_i)H(Y|X=x_i) = -\sum_{i=1}^np(x_i) \sum_{j=1}^m p(y_j|x_i)\log p(y_j|x_i)表示在已知X的条件下，Y的条件概率分布的熵对X的数学期望。 4、交叉熵例如： 箱子里面有小球任意个，但其中1/2是橙色球，1/4是紫色球，1/8是蓝色球及1/8是青色球。我从中拿出一个球，你猜我手中的球是什么颜色的？ 知道了每种颜色小球的比例，比如橙色占比二分之一，如果我猜橙色，很有可能第一次就猜中了。所以，根据策略2，1/2的概率是橙色球，小明需要猜一次，1/4的概率是紫色球，小明需要猜两次，1/8的概率是蓝色球，小明需要猜三次，1/8的概率是青色球，小明需要猜三次，所以小明预期的猜题次数为： H = 1/2 1 + 1/4 2 + 1/8 3 + 1/8 3= 1.75 针对概率为p的小球，需要猜球的次数$=log_2 \frac 1 p$ 。例如1/8是蓝色球，次数就是3。则预期的猜题次数就是熵。 因此，每个系统都会有一个真实的概率分布（真实分布）。根据真实分布，可以找到一个最优策略，以最小的代价消除系统的不确定性，这个不确定性的值就是熵（比如猜题次数，编码长度）。 如果小明不知道真实分布，认为小球的分布为（1/4，1/4，1/4，1/4），这个分布就是非真实分布。此时，小明猜中任何一种颜色的小球都需要猜两次，即1/2 2 + 1/4 2 + 1/8 2 + 1/8 2 = 2。 当我们使用非最优策略消除系统的不确定性，所需要付出的努力的大小我们该如何去衡量呢？ 这就需要引入交叉熵，其用来衡量在给定的真实分布下，使用非真实分布所指定的策略消除系统的不确定性所需要付出的努力的大小。 交叉熵的公式为： H = \sum_{i=1}^N p_i log_2 \frac 1 {q_i} 在网上看的其他文章，包括LR等的损失函数中，都是如下的形式 H = \sum_{i=1}^N p_i log_2 q_i不清楚哪种表达是正确的。 其中，$p_i$是真实分布，$q_i$是非真实分布。 因此，交叉熵越低，这个策略就越好，最低的交叉熵也就是使用了真实分布所计算出来的信息熵，因为此时$p_i=q_i$ ，交叉熵 = 信息熵。 这也是为什么在机器学习中的分类算法中，我们总是最小化交叉熵，因为交叉熵越低，就证明由算法所产生的策略最接近最优策略，也间接证明我们算法所算出的非真实分布越接近真实分布。 来自知乎王赟 交叉熵（Cross Entropy）和negative log likelihood当ground truth只有一类为1，其它类为0时，cross entropy就是negative log likelihood，可以认为只是叫了一个比较fancy的名字。当ground truth本身也是一个分布时（比如在知识蒸馏过程中），cross entropy这个名字就比较好理解了。 5、相对熵(KL散度)最后，我们如何去衡量不同策略之间的差异呢？这就需要用到相对熵，其用来衡量两个取值为正的函数或概率分布之间的差异，即： KL(f(x) || g(x)) = \sum_{x \in X} f(x) * log_2 \frac {f(x)} {g(x)}现在，假设我们想知道某个策略和最优策略之间的差异，我们就可以用相对熵来衡量这两者之间的差异。即，相对熵 = 某个策略的交叉熵 - 信息熵（根据系统真实分布计算而得的信息熵，为最优策略），公式如下： KL(p || q) = H(p,q)-H(p) = \sum_{k=1}^N p_k log_2 \frac 1 {q_k} - \sum_{k=1}^N p_k log_2 \frac 1 {p_k} = \sum_{k=1}^N p_k log_2 \frac {p_k} {q_k}互信息是相对熵的特殊形式。如果变量不是独立的，可以通过考察联合概率分布和边缘概率分布乘积之间的相对熵，来判断它们是否接近于相对独立。此时，散度表示为 这被称为变量 x 和变量 y 之间的互信息( mutual information )。根据 Kullback-Leibler 散度的性质,我们看到 I[x, y] ≥ 0 ,当且仅当 x 和 y 相互独立时等号成立。经过推导，得互信息公式为 互信息不能归一化，对连续变量计算不方便（连续变量需要先离散化）。最大信息系数首先寻求一种最优离散化方式，然后把互信息取值转换成一种度量方式，取值区间在[0，1]。 6、交叉熵作为损失函数由于信息熵描述的是消除 ppp (即真实分布) 的不确定性所需信息量的度量，所以其值应该是最小的、固定的。那么：优化减小相对熵也就是优化交叉熵，所以在机器学习中使用交叉熵就可以了。 交叉熵的损失函数定义： 交叉熵损失函数一般用来代替均方差损失函数与sigmoid激活函数组合。 与对数损失函数的关系是： 把所有样本取均值就把交叉熵转化成了对数损失函数 7、总结熵：衡量不确定性的度量 联合熵：X、Y在一起时的不确定性度量 条件熵：X确定时，Y的不确定性度量。也就是在X发生的前提下，新发生Y带来的熵 交叉熵：衡量p和q的相似性，越小越相似 相对熵：p和q的不相似度量。]]></content>
      <categories>
        <category>算法背后的数学原理</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[Hexo + Github 搭建博客入门]]></title>
    <url>%2F2018%2F02%2F01%2F%E5%B7%A5%E5%85%B7%E5%92%8C%E7%8E%AF%E5%A2%83%2FHexo%20%2B%20Github%20%E6%90%AD%E5%BB%BA%E5%8D%9A%E5%AE%A2%E5%85%A5%E9%97%A8%2F</url>
    <content type="text"><![CDATA[1、安装node.js12345$ sudo add-apt-repository ppa:chris-lea/node.js$ sudo apt-get update$ sudo apt-get install nodejs#原方法没有这一步，但是后面的操作会提示npm command not found$ sudo apt-get install npm 2、安装hexo1$ sudo npm install hexo -g 如果是mac，要用 1sudo npm install hexo --no-optional 不然会报错Error: Cannot find module ‘./build/Release/DTraceProviderBindings’] code: ‘MODULE_NOT_FOUND’这个错误。 如果报权限错误，需要用 1sudo npm install --unsafe-perm --verbose -g hexo 3、初始博客的根目录12$ cd ~/myblog$ hexo init mac的根目录在 1/Users/david/david/myblog 4、在github上新建仓库名称必须是 1gitusername.github.io 我的就是 1Schwimmer.github.io 并将本地的SSH KEY添加到git上（略） 5、让博客可以发布到git1）安装hexo-deployer-Git（不然会出现ERROR Deployer not found: git） 1npm install hexo-deployer-git --save 2） 配置你hexo博客根目录下的_config.yml文件(应该是最下面一行，修改成你的github) 1234deploy: type: git repo: git@github.com:Schwimmer/Schwimmer.github.io.git branch: master tips 冒号后面一定要跟空格 6、hexo常用命令12345hexo clean #清除缓存hexo new &quot;title&quot; #新建文章hexo g #生成html，或hexo generatehexo s #在本地启动服务，启动后访问localhost:4000就可以打开，或hexo serverhexo d #发布到git，发布后访问https://schwimmer.github.io/就可以打开，或hexo deploy tips 我目前用的新建文章的方法，就是直接在source/_posts/下面新建md文件 可以偷懒写成 cd ~/myblog hexo clean;hexo g;hexo s 或 hexo clean;hexo g;hexo d 支持数学公式Next 7的版本中，数学公式可以直接开启配置 Settings123456789101112131415161718192021222324252627282930313233343536# Math Equations Render Supportmath: enable: true # Default(true) will load mathjax/katex script on demand # That is it only render those page who has `mathjax: true` in Front-matter. # If you set it to false, it will load mathjax/katex srcipt EVERY PAGE. per_page: true engine: mathjax #engine: katex # hexo-renderer-pandoc (or hexo-renderer-kramed) needed to full MathJax support. mathjax: # Use 2.7.5 as default, jsdelivr as default CDN, works everywhere even in China cdn: //cdn.jsdelivr.net/npm/mathjax/MathJax.js?config=TeX-AMS-MML_HTMLorMML # For direct link to MathJax.js with CloudFlare CDN (cdnjs.cloudflare.com) #cdn: //cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-MML-AM_CHTML # See: https://mhchem.github.io/MathJax-mhchem/ #mhchem: //cdn.jsdelivr.net/npm/mathjax-mhchem@3 #mhchem: //cdnjs.cloudflare.com/ajax/libs/mathjax-mhchem/3.3.0 # hexo-renderer-markdown-it-plus (or hexo-renderer-markdown-it with markdown-it-katex plugin) needed to full Katex support. katex: # Use 0.7.1 as default, jsdelivr as default CDN, works everywhere even in China cdn: //cdn.jsdelivr.net/npm/katex@0.7.1/dist/katex.min.css # CDNJS, provided by cloudflare, maybe the best CDN, but not works in China #cdn: //cdnjs.cloudflare.com/ajax/libs/KaTeX/0.7.1/katex.min.css copy_tex: # See: https://github.com/KaTeX/KaTeX/tree/master/contrib/copy-tex enable: false copy_tex_js: //cdn.jsdelivr.net/npm/katex@0/dist/contrib/copy-tex.min.js copy_tex_css: //cdn.jsdelivr.net/npm/katex@0/dist/contrib/copy-tex.min.css 8、安装主题转自：NexT主题安装教程 9、文章阅读计数转自：Hexo添加不蒜子和LeanCloud统计无标题文章 找到站点的themes/next/layout/_partials目录下的footer.swig文件。插入代码如下。 123456789101112131415161718192021&#123;% if theme.copyright %&#125;&lt;div class=&quot;powered-by&quot;&gt; &#123;&#123; __(&apos;footer.powered&apos;, &apos;&lt;a class=&quot;theme-link&quot; href=&quot;https://hexo.io&quot;&gt;Hexo&lt;/a&gt;&apos;) &#125;&#125;&lt;/div&gt;&lt;div class=&quot;theme-info&quot;&gt; &#123;&#123; __(&apos;footer.theme&apos;) &#125;&#125; - &lt;a class=&quot;theme-link&quot; href=&quot;https://github.com/iissnan/hexo-theme-next&quot;&gt; NexT.&#123;&#123; theme.scheme &#125;&#125; &lt;/a&gt;&lt;/div&gt;# 此位置插入以下代码&lt;div&gt;&lt;script async src=&quot;https://dn-lbstatics.qbox.me/busuanzi/2.3/busuanzi.pure.mini.js&quot;&gt;&lt;/script&gt;本站总访问量 &lt;span id=&quot;busuanzi_value_site_pv&quot;&gt;&lt;/span&gt; 次&amp;nbsp&amp;nbsp&amp;nbsp本站访客数&lt;span id=&quot;busuanzi_value_site_uv&quot;&gt;&lt;/span&gt;人次&lt;/div&gt;&#123;% endif %&#125; 10、增加图片原来记录过一个只安装插件的方法，现在已经失效了。目前参考的是 hexo引用本地图片无法显示的方法，感谢。 1、安装插件 1npm install https://github.com/CodeFalling/hexo-asset-image --save 2、修改文件 打开/node_modules/hexo-asset-image/index.js，将内容更换为下面的代码 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061'use strict';var cheerio = require('cheerio');// http://stackoverflow.com/questions/14480345/how-to-get-the-nth-occurrence-in-a-stringfunction getPosition(str, m, i) &#123; return str.split(m, i).join(m).length;&#125;var version = String(hexo.version).split('.');hexo.extend.filter.register('after_post_render', function(data)&#123; var config = hexo.config; if(config.post_asset_folder)&#123; var link = data.permalink; if(version.length &gt; 0 &amp;&amp; Number(version[0]) == 3) var beginPos = getPosition(link, '/', 1) + 1; else var beginPos = getPosition(link, '/', 3) + 1; // In hexo 3.1.1, the permalink of "about" page is like ".../about/index.html". var endPos = link.lastIndexOf('/') + 1; link = link.substring(beginPos, endPos); var toprocess = ['excerpt', 'more', 'content']; for(var i = 0; i &lt; toprocess.length; i++)&#123; var key = toprocess[i]; var $ = cheerio.load(data[key], &#123; ignoreWhitespace: false, xmlMode: false, lowerCaseTags: false, decodeEntities: false &#125;); $('img').each(function()&#123; if ($(this).attr('src'))&#123; // For windows style path, we replace '\' to '/'. var src = $(this).attr('src').replace('\\', '/'); if(!/http[s]*.*|\/\/.*/.test(src) &amp;&amp; !/^\s*\//.test(src)) &#123; // For "about" page, the first part of "src" can't be removed. // In addition, to support multi-level local directory. var linkArray = link.split('/').filter(function(elem)&#123; return elem != ''; &#125;); var srcArray = src.split('/').filter(function(elem)&#123; return elem != '' &amp;&amp; elem != '.'; &#125;); if(srcArray.length &gt; 1) srcArray.shift(); src = srcArray.join('/'); $(this).attr('src', config.root + link + src); console.info&amp;&amp;console.info("update link as:--&gt;"+config.root + link + src); &#125; &#125;else&#123; console.info&amp;&amp;console.info("no src attr, skipped..."); console.info&amp;&amp;console.info($(this)); &#125; &#125;); data[key] = $.html(); &#125; &#125;&#125;); 3、打开_config.yml文件，修改下述内容 1post_asset_folder: true 4、要显式的图片需要放在和md同名的文件夹下面。例如，有一篇机器学习算法推导（一）逻辑回归.md，图片就要放在 1![2](机器学习算法推导（一）逻辑回归/SouthEast-20190616095710926.png) 这里可以通过Typora的设置来方便实现。 打开Typora-&gt;偏好设置-&gt;编辑器，配置为如下的格式 再重新发布hexo就可以了。 11、sitemap 插件Hexo Seo优化让你的博客在google搜索排名第一 12&lt;meta name=&quot;google-site-verification&quot; content=&quot;Mx7Ikp0IpBtTbSpHDTBV0_CMJA-E8CLn8NRIrwyq5m4&quot; /&gt;&lt;meta name=&quot;baidu-site-verification&quot; content=&quot;ZBTsWx4NdC&quot; /&gt; 12、首页显示文章摘要 进入hexo博客项目的themes/next目录 用文本编辑器打开_config.yml文件 搜索”auto_excerpt”,找到如下部分： 12345# Automatically Excerpt. Not recommand.# Please use &lt;!-- more --&gt; in the post to control excerpt accurately.auto_excerpt: enable: false length: 150 把enable改为对应的false改为true，然后hexo d -g，再进主页，问题就解决了！ 13、启用分类和标签1、在博客的开头要加上 123456title: Hexo + Github 搭建博客入门date: 2017-07-12 11:49:53categories: &quot;工具和环境&quot;tags: - hexodescription: 2、修改主题配置文档 123456menu: home: / categories: /categories #about: /about archives: /archives tags: /tags 3、hexo加上page 如分类 1hexo new page categories 然后打开source/categories/index.md，增加一行 1type: &quot;categories&quot; 增加标签也是一样 1hexo new page tags 然后打开source/tags/index.md，增加一行 1type: &quot;tags&quot; 谷歌与百度的站点地图，前者适用于其他搜索引擎，用来手动提交以增加收录 安装： 12npm install hexo-generator-sitemap@1 --savenpm install hexo-generator-baidu-sitemap@0.1.1 --save _config.yml添加代码： 12baidusitemap: path: baidusitemap.xml 谷歌的sitemap.xml不需要写到配置文件中，自动生效。 在主页后面加/baidusitemap.xml可以看到baidusitemap（谷歌同理），将该网址它提交给百度搜索：百度站长平台，贴吧账号无法在这里使用。 不过由于Github禁止了百度爬虫，百度无法抓取其中的URL： 添加搜索Local search no need any external 3rd-party services and can be extra indexed by search engines. That search method recommended for most users. 安装Install hexo-generator-searchdb by run following command in site root dir: 1$ npm install hexo-generator-searchdb --save hexo 配置Edit site config file and add following content: 1234567hexo/_config.ymlsearch: path: search.xml field: post format: html limit: 10000 themes 配置Edit theme config file to enable Local Search: 12345678910111213next/_config.yml# Local search# Dependencies: https://github.com/theme-next/hexo-generator-searchdblocal_search: enable: true # if auto, trigger search by changing input # if manual, trigger search by pressing enter key or search button trigger: auto # show top n results per article, show all results by setting to -1 top_n_per_article: 1 # unescape html strings to the readable one unescape: false 添加评论DisqusDisqus is a global comment system that improves discussion on websites and connects conversations across the web. Create an account and log into Disqus. Once logged in, click the GET STARTED button on the homepage, then select I want to install Disqus on my site option and you will see the Create a new site interface. Enter your Website Name, which will serve as your Disqus shortname, and select a Category from the drop-down menu. Then click Create Site button. Choose I don&#39;t see my platform listed, install manually with Universal Code, configure Disqus for your site, and click Complete Setup button. Set the valueenable to true, add the obtained Disqus shortname (shortname), and edit other configurations in disqus section in the theme config file as following: 12345next/_config.ymldisqus: enable: false shortname: your-short-disqus-name count: true 不蒜子统计Edit busuanzi_count option in theme config file.When enable: true, global setting is enabled. If site_uv, site_pv, page_pv are all false, Busuanzi only counts but never shows. 绑定代码到Coding创建coding仓库 上传公钥 https://coding.net/user/account/setting/keys 测试SSH Key 是否配置成功 1ssh -T git@git.coding.net 用来部署Hexo博客的Coding项目地址为：git@git.coding.net:ddxy1986/DavidXu-Blog deploy的配置改为 123456deploy: type: git repo: github: git@github.com:Schwimmer/Schwimmer.github.io.git coding: git@git.coding.net:ddxy1986/DavidXu-Blog branch: master 配置Coding项目的Pages服务开启Coding项目的Pages服务 踩过的坑启动时报错1234 Error: Warning: Permanently added &apos;github.com,192.30.253.112&apos; (RSA) to the list of known hosts.sign_and_send_pubkey: signing failed: agent refused operationPermission denied (publickey).fatal: Could not read from remote repository. 处理是 12$ eval &quot;$(ssh-agent -s)&quot;$ ssh-add 生成html时报错1end of the stream or a document separator is expected 更新next主题后，菜单不是中文也不是英文next主题的所有语言配置文件都在\themes\next\languages文件夹下，原来中文对应的是zh-Hans.yml，更新之后变成了zh-CN.yml。 而语言的配置信息再主目录的_config.yml文件，于是找到这里 将其改为zh-CN，解决问题。 安装npm报错1Error: EACCES: permission denied, access &apos;/Users/david/david/myblog/node_modules/babel-polyfill/node_modules/core-js&apos; 用了sudu命令也依旧报错。 解决方案是 you can fix that error by allowing unsafe perms 1sudo npm config set unsafe-perm=true 参考https://github.com/Microsoft/WSL/issues/14 next安装搜索后一直转圈本来以为是npm插件的问题，反复卸载安装几次后还是不行，后面看到这篇文章的做法解决了问题，摘录如下： 因为搜索插件的原理是生成search.xml文件，先找到/public/search.xml，将其拖到浏览器中打开，如果有问题就会提示错误和错误的行号。 一般的问题都是出现了非法字符，定位到md文件，删去非法字符后再打包就OK啦。 主页文章添加阴影效果实现方式：打开\themes\next\source\css\_custom\custom.styl向里面加入： 12345678// 主页文章添加阴影效果 .post &#123; margin-top: 60px; margin-bottom: 60px; padding: 25px; -webkit-box-shadow: 0 0 5px rgba(202, 203, 203, .5); -moz-box-shadow: 0 0 5px rgba(202, 203, 204, .5); &#125; 实现统计功能实现方式：在根目录下安装 hexo-wordcount 运行： 1$ npm install hexo-wordcount --save 然后在主题的配置文件中，配置如下： 123456# Post wordcount display settings# Dependencies: https://github.com/willin/hexo-wordcountpost_wordcount: item_text: true wordcount: true min2read: true 参考：ubuntu下使用hexo搭建博客 对 Hexo + Next + github 搭建的个人博客进行深度美化]]></content>
      <categories>
        <category>工具和环境</category>
      </categories>
      <tags>
        <tag>hexo</tag>
      </tags>
  </entry>
</search>
