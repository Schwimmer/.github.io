<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[topic常用配置项]]></title>
    <url>%2F2019%2F11%2F15%2Fkafka%2F%E7%99%BE%E9%97%AEkafka%2Ftopic%E5%B8%B8%E7%94%A8%E9%85%8D%E7%BD%AE%E9%A1%B9%2F</url>
    <content type="text"><![CDATA[num.partitions topic包含多少个分区，一旦设定后，只能增加不能减少；若需要减少，得新增一个topic。 kafka通过partitions对topic进行横向扩展，当有新broker加入时，通过分区个数实现集群的负载均衡。一般的，topic的partitions的个数大于broker个数。 log.retention.hours 过期时间。默认值是168小时，也就是一周。还有两个其他参数log.retention.minutes和log.retention.ms。如果指定多个，kafka优先使用最小值。 log.retention.bytes 通过保留的字节数判断过期。作用在每个分区。即假设有8个partitions，且设为1G，那该topic最多保留8GB的数据。所以，当topic的分区个数增加时，整个topic可保留的数据也随之增加。如果也设置了hours，只要任意一个条件满足，消息就会被删除。 log.segment.bytes 上面设置在日志片段上，而不是在单个消息上。当消息到达broker时，它们被追加到分区的当前日志片段上。当日志片段大小超过该参数上限（默认是1GB），当前日志片段会被关闭，产生一个新的日志片段。 如果一个日志片段被关闭，就开始等待过期。该参数值越小，就会频繁关闭和分配新文件，从而降低磁盘写入的整体效率。 如果topic消息量不大，那么如何调整该参数大小就很重要。比如，一个topic每天100MB，而该参数是默认值，那么10天才能填满一个日志片段。由于日志片段在被关闭之前是不会过期的，所以如果log.retention,ms=1周，则segment最多需要17天才会过期。 segment大小也会影响通过timestamp获取offset。在获取offset时，kafka会检查分区最后修改时间大于指定timestamp的segment，让该segment的前一个的最后修改时间小于指定timestamp。然后，kafka返回该segment文件开头的offset。 message.max.bytes broker设置这个来限制单个消息的大小，默认是1MB。若生产者发生的消息超过这个大小，不仅不会被接收，还会收到broker返回的错误信息。跟其他与字节相关配置参数一样，该参数指的是压缩后的消息大小，实际大小可以大于这个值。 该值对性能有很大影响。值越大，负责网络连接和请求的线程就要花更多时间处理这些请求。还会增加磁盘写入块的大小，从而影响IO吞吐量。 在服务端和客户端之间协调消息大小 客户端的fetch.message.max.bytes必须与服务端的参数进行协调。若该值更小，则消费者无法获取大的消息，导致消费者被阻塞。 在集群里的broker配置replica.fetch.max.bytes时，遵循同样原则。]]></content>
      <categories>
        <category>百问kafka</category>
      </categories>
  </entry>
</search>
